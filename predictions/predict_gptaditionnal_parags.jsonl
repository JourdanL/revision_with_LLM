{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "instruction": "Rearrange the structure to make the structure clearer.", "revised_paragraph": "Revised paragraph: \"We implement the fusion module as a multi-modal transfer module (MMTM) (Joze et al., 2020). The process begins with the first step, where feature maps from each uni-modal branch are squeezed into vector representations using global average pooling across spatial dimensions. These representations are then concatenated, followed by a linear transformation to derive the cross-modal context representation. Based on this context representation, we predict channel-wise weights for each modality through two independent fully-connected layers. Finally, these weights are utilized to re-calibrate the channel-wise features for each modality.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "instruction": "Rewrite this paragraph completely to make it clearer.", "revised_paragraph": "Revised paragraph: \"We developed the fusion module as a multi-modal transfer module (MMTM) based on the framework proposed by Joze et al. (2020). The initial phase of the MMTM involves compressing the feature maps from each uni-modal branch into vector representations through global average pooling, which is performed across the spatial dimensions. Following this, we concatenate these vector representations and apply a linear transformation to generate a cross-modal context representation. From this context representation, we derive channel-wise weights for each modality using two separate fully connected layers. Finally, these weights are employed to re-calibrate the channel-wise features for each modality.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "instruction": "Remove a redundant sentence. Use clearer expression.", "revised_paragraph": "Revised paragraph: Generalization of meta-learning has been a topic of recent analysis, focusing on the excess risk as a metric of generalization ability in gradient-based meta-learning [3,4,9,14,18,42]. In this context, [27] examines the conditions under which an abundance of tasks with small data can compensate for a paucity of tasks with larger datasets, specifically within mixed linear regression. Additionally, generalization performance has been explored in representation-based meta-learning, albeit in a somewhat different framework [13,16]. Information-theoretical bounds proposed in [10,26] quantify the generalization error based on the mutual information between the input training data and the output of the meta-learning algorithms. Furthermore, the PAC-Bayes framework has been adapted for meta-learning, resulting in a PAC-Bayes meta-population risk bound [1,15,19,34]. Most of these studies concentrate on underparameterized meta-learning scenarios, where the total amount of meta-training data from all tasks surpasses the model parameter's dimensionality. Recently, the area of overparameterized meta-learning has garnered attention; for instance, Bernacchia [6] suggests that in overparameterized MAML, employing a negative learning rate in the inner loop proves optimal during meta-training for linear models with Gaussian data. Meanwhile, Sun et al. [39] demonstrate that the optimal representation in representation-based meta-learning is overparameterized and identify sample complexity for the method of moments estimator.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "instruction": "Improve the English and remove the second sentence.\t", "revised_paragraph": "Revised paragraph: Generalization of meta learning has recently been analyzed using excess risk as a metric of generalization ability in gradient-based meta learning [3,4,9,14,18,42]. The generalization of meta learning has been studied in [27] in the context of mixed linear regression, where the focus lies on investigating when abundant tasks with small data can compensate for a lack of tasks with large datasets. Generalization performance has also been examined in a relevant but distinct setting: representation-based meta learning [13,16]. Information theoretical bounds have been proposed in [10,26], which establish limits on the generalization error based on the mutual information between the input training data and the output of the meta-learning algorithms. Additionally, the PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,15,19,34]. Most of these studies concentrate on scenarios where the meta learning model is underparameterized; specifically, the total number of meta training samples across all tasks exceeds the model parameter dimension. Recently, overparameterized meta learning has garnered significant attention. Bernacchia [6] suggests that in the overparameterized MAML context, a negative learning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [39] demonstrate that the optimal representation in representation-based meta learning is overparameterized and provides sample complexity for the method of moments estimator.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "instruction": "Make expression concise, add conjuction, include all citations.", "revised_paragraph": "Revised paragraph: \"This definition of \u00b5(\u03b8; \u00b7) is inspired by discussions on effective parameter updates in the literature (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021), and previous studies have found that normalization techniques\u2014such as batch normalization (Ioffe & Szegedy, 2015)\u2014ensure that the update direction of \u03b8, specifically \u03b8 / ||\u03b8||\u00b2, accurately reflects how much the update on \u03b8 alters the model f to fit the sample batch.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "instruction": "Rewrite this paragraph to make it clearer.", "revised_paragraph": "Revised paragraph: \"The definition of \u00b5(\u03b8; \u00b7) draws inspiration from discussions in the literature concerning the effective updating of parameters (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Prior research has shown that when normalization techniques are utilized, such as batch normalization (Ioffe & Szegedy, 2015), the direction of the parameter update for \u03b8, represented as \u03b8 / ||\u03b8||\u00b2\u2082, indicates the extent to which changes in \u03b8 alter the model f to better align with the batch of samples.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "instruction": "Make expression concrete, correct typos.", "revised_paragraph": "Revised paragraph: \"The experimental results are summarized in Table 5, where we use CIFAR-10 as in-distribution (ID) data and CIFAR-100 as out-of-distribution (OOD) data. In this setup, the common watermark learning configuration (denoted as 'common') already demonstrates improved performance in near-OOD detection compared to scenarios without watermarking (denoted as 'w/o watermark'). Furthermore, incorporating watermarking with shifting augmentations (specifically permutation and rotation) can further enhance the detection capabilities of the models, resulting in improvements of up to 8.60 and 4.70 in false positive rate at 95% (FPR95) for the softmax and free energy scoring methods, respectively.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "Revised paragraph: \"The experimental results are summarized in Table 5, which utilizes CIFAR-10 as the ID data and CIFAR-100 as the OOD data. In this setup, the common watermark learning method (common) demonstrates improved performance in near-OOD detection compared to scenarios without watermarking (w/o watermark). Furthermore, applying watermarking with shifting augmentations (perm and rotate) enhances the models' detection capabilities, resulting in improvements of up to 8.60 and 4.70 in FPR95 for the softmax and free energy scoring methods, respectively.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "instruction": "Improved the writing and reformulate the third sentence", "revised_paragraph": "Revised paragraph: \"Training Settings. In accordance with the methodology outlined by Zhang et al. (2018b), we apply data augmentation to the training images, involving random rotations of 90\u00b0, 180\u00b0, and 270\u00b0, as well as horizontal flipping. Each training batch comprises 16 low-resolution (LR) color patches, each sized at 48 \u00d7 48 pixels. Our super-resolution prior (SRP) model is optimized using the ADAM optimizer (Kingma & Ba, 2014) with parameters set at \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10^\u22128. The initial learning rate is established at 10^\u22124, subsequently halved every 2 \u00d7 10^5 iterations of back-propagation. We utilize PyTorch (Paszke et al., 2017) to implement our models, leveraging a Tesla V100 GPU.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "instruction": "Improved the writing and reformulate the third sentence", "revised_paragraph": "Revised paragraph: \"Training Settings. Following the methodology outlined by Zhang et al. (2018b), we apply data augmentation to the training images, which are randomly rotated at angles of 90\u00b0, 180\u00b0, and 270\u00b0, as well as flipped horizontally. Each training batch comprises 16 low-resolution (LR) color patches, each measuring 48 \u00d7 48 pixels. Our Super-Resolution Prediction (SRP) model is optimized using the ADAM optimizer (Kingma & Ba, 2014), with parameters \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10^\u22128. The initial learning rate is set at 10^\u22124 and is subsequently halved every 2 \u00d7 10^5 iterations during back-propagation. We utilize PyTorch (Paszke et al., 2017) for model implementation, leveraging a Tesla V100 GPU.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "instruction": "Rewrite this paragraph in a more formal style and remove any unnecessary details.", "revised_paragraph": "Revised paragraph: The visualization of the pruning process is illustrated in Figure 3, which displays the mean L1-norm of filters in two layers of the EDSR baseline during SRP training. The filters are categorized into two groups: pruned and retained. The mean L1-norm of the pruned filters exhibits a gradual decline, attributed to the strengthening penalty that drives the values towards zero. Notably, the L1-norms of the retained filters increase independently, despite the absence of a regularization term promoting their growth. This phenomenon suggests that the network is capable of self-recovery, reminiscent of the compensation effect observed in the human brain (Duffau et al., 2003). Additional visualization results are provided in the appendix.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "instruction": "Rewrite this paragraph in a more formal style and remove the last sentence", "revised_paragraph": "Revised paragraph: \"Visualization of the Pruning Process. To elucidate the operation of the Structured Reparameterization (SRP), Figure 3 presents the mean L1-norm of filters across two layers of the EDSR baseline during the SRP training process. The filters are categorized into two groups: pruned and retained. As illustrated, the mean L1-norm of the pruned filters progressively decreases, attributable to the increasing strength of the penalty, which drives these values towards zero. Notably, the L1-norms of the retained filters exhibit an increasing trend, despite the absence of any regularization term intended to promote their growth.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "instruction": "Make first sentence more concise. Rewrite phrases, prefer short formulations and avoid we.", "revised_paragraph": "Revised paragraph: \"Listwise RL (CDQN) addresses the combinatorial action space issue of listwise actions by adopting the Cascaded DQN (CDQN) framework proposed by Chen et al. (2019a). The primary challenge lies in the impracticality of constructing the entire list simultaneously due to the vast number of potential combinations. Hence, the solution involves incrementally building the list, one action at a time. Each list index is treated as an individual non-combinatorial action suitable for reinforcement learning (RL) training. The Q-network of CDQN is replaced with AGILE to accommodate the variable action space, and the weights of the cascaded Q-networks are shared. Complete details on listwise AGILE can be found in Algorithm 1.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "instruction": "Make first sentence more concise. Rewrite phrases, prefer short formulations and avoid we.", "revised_paragraph": "Revised paragraph: \"Listwise RL (CDQN) addresses the combinatorial action space problem of listwise actions by employing the Cascaded DQN (CDQN) framework of Chen et al. (2019a). The primary challenge arises from the infeasibility of constructing the list all at once due to the vast number of possible lists. Consequently, the focus shifts to incrementally building the list, one action at a time. Each list index functions as an individual, non-combinatorial action suitable for reinforcement learning (RL) training. The Q-network of CDQN is replaced with AGILE to accommodate a varying action space, and weights are shared among the cascaded Q-networks. Complete details of the listwise AGILE are provided in Algorithm 1.\"", "type_approach": "instruction-annot_2"}
