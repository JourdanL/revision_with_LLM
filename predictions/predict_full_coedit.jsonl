{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "instruction": "Prefer extended forms over abbreviations of words.", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "instruction": "Write the abbreviation in their full form.", "revised_paragraph": "\"Generally, those statistical notions can be expressed in terms of different (conditional) independence statements between the involved random variables (Barocas et al., 2019):  y  s (eq. 5),  y  s | y (eq. 6\u20137), and  y  s |  y (eq. 8\u20139).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "instruction": "Be clear about references.", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "instruction": "Lightly clarify the text. Add a reference to appendix at the end.", "revised_paragraph": "\"In this section, we evaluate three different aspects of our contributions: the usefulness of exclusive multiset-equivariance (Subsection 4.1), the differences between our implicit and automatic differentiation (Subsection 4.2), and the applicability of iDSPN to a larger-scale dataset (Subsection 4.3). We provide detailed descriptions of the experimental procedure in Appendix D, show example inputs and outputs in Appendix E, and open-source the code to reproduce all experiments at https://github.com/redacted>/redacted>.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"VZ249HR; 23.8\u201d diagonal, 1920 1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an optical mouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "instruction": "Improve the English of this paragraph", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "instruction": "Slightly revise the liking between phrases.", "revised_paragraph": "\"VZ249HR; 23.8\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flamary et al., 2021).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flamary et al., 2021).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flamary et al., 2021).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flamary et al., 2021).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flamary et al., 2021).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flamary et al., 2021).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flamary et al., 2021).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flamary et al., 2021).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "instruction": "Brush up the sentence for readability", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flamary et al., 2021).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "instruction": "Reorganize the paragraph to make it more logical. Improve the language.", "revised_paragraph": "\"P T =  ( r ) are the representation distributions under treated and untreated groups, respectively, induced by the map r =  ( x ). The discrepancycould be minimized by updating the representation map  with gradient-based optimizers, as it is differentiable with respect to  (Flammary et al., 2021).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Rotamers with d torsional angles can be viewed as points on the d -dimensional torus. The D -dimensional torus is the product of D circles S 1, i.e. T D = S 1    S 1. Therefore, we can model the distribution onT D by modeling the joint distribution of D variables on S 1. In specific, we adopt the coupling layer technique to model the joint distribution (Dinh et al., 2016). On each coupling layer, we update one dimension using the bijective for S 1, keeping the other D  1 dimensions fixed and using them along with the hidden representation of the amino acid as the condition to parameterize the bijective (Figure 2B):\""}, {"intention": "Concision", "revised_paragraph": "\"Rotamers with d torsional angles can be viewed as points on the d -dimensional torus. The D -dimensional torus is the product of D circles S 1. Therefore, we can model the distribution onT D by modeling the joint distribution of D variables on S 1. In specific, we adopt the coupling layer technique to model the joint distribution onT D by updating one dimension using the bijective for S 1, keeping the other D  1 dimensions fixed and using them along with the hidden representation of the amino acid as the condition to parameterize the bijective (Figure 2B):\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Rotamers with d torsional angles can be viewed as points on the d -dimensional torus. The D -dimensional torus is the product of D circles S 1, i.e. T D = S 1    S 1. Therefore, we can model the distribution onT D by modeling the joint distribution of D variables on S 1. In specific, we adopt the coupling layer technique to model the joint distribution (Dinh et al., 2016). On each coupling layer, we update one dimension using the bijective for S 1, keeping the other D  1 dimensions fixed and using them along with the hidden representation of the amino acid as the condition to parameterize the bijective (Figure 2B):\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Rotamers with d torsional angles can be viewed as points on the d -dimensional torus. The D -dimensional torus is the product of D circles S 1. Therefore, we can model the distribution onT D by modeling the joint distribution of D variables on S 1. In specific, we adopt the coupling layer technique to model the joint distribution onT D by updating one dimension using the bijective for S 1, keeping the other D  1 dimensions fixed and using them along with the hidden representation of the amino acid as the condition to parameterize the bijective (Figure 2B):\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Rotamers with d torsional angles can be viewed as points on the d -dimensional torus. The D -dimensional torus is the product of D circles S 1, i.e. T D = S 1    S 1. Therefore, we can model the distribution onT D by modeling the joint distribution of D variables on S 1. In specific, we adopt the coupling layer technique to model the joint distribution (Dinh et al., 2016). On each coupling layer, we update one dimension using the bijective for S 1, keeping the other D  1 dimensions fixed and using them along with the hidden representation of the amino acid as the condition to parameterize the bijective (Figure 2B):\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"We start with the assumption that all rotamers are points on the d -dimensional torus. Then, we take the product of D circles S 1, that is, T D = S 1 * S 1. We then use the coupling layer technique to model the joint distribution of D variables on S 1:\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Rotamers with d torsional angles can be viewed as points on the d -dimensional torus. The D -dimensional torus is the product of D circles S 1, i.e. T D = S 1    S 1. Therefore, we can model the distribution onT D by modeling the joint distribution of D variables on S 1. In specific, we adopt the coupling layer technique to model the joint distribution (Dinh et al., 2016). On each coupling layer, we update one dimension using the bijective for S 1, keeping the other D  1 dimensions fixed and using them along with the hidden representation of the amino acid as the condition to parameterize the bijective (Figure 2B):\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Rotamers with d torsional angles can be viewed as points on the d -dimensional torus. The D -dimensional torus is the product of D circles S 1. Therefore, we can model the distribution onT D by modeling the joint distribution of D variables on S 1. In specific, we adopt the coupling layer technique to model the joint distribution onT D by updating one dimension using the bijective for S 1, keeping the other D  1 dimensions fixed and using them along with the hidden representation of the amino acid as the condition to parameterize the bijective (Figure 2B):\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "instruction": "Please, remove unnecessary details of this paragraph", "revised_paragraph": "\"Rotamers with d torsional angles can be viewed as points on the d -dimensional torus. The D -dimensional torus is the product of D circles S 1, i.e. T D = S 1    S 1. Therefore, we can model the distribution onT D by modeling the joint distribution of D variables on S 1. In specific, we adopt the coupling layer technique to model the joint distribution (Dinh et al., 2016). On each coupling layer, we update one dimension using the bijective for S 1, keeping the other D  1 dimensions fixed and using them along with the hidden representation of the amino acid as the condition to parameterize the bijective (Figure 2B):\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "instruction": "Make this paragraph shorter.", "revised_paragraph": "\"Rotamers with d torsional angles can be viewed as points on the d -dimensional torus. The D -dimensional torus is the product of D circles S 1, i.e. T D = S 1    S 1. Therefore, we can model the distribution onT D by modeling the joint distribution of D variables on S 1. In specific, we adopt the coupling layer technique to model the joint distribution (Dinh et al., 2016). On each coupling layer, we update one dimension using the bijective for S 1, keeping the other D  1 dimensions fixed and using them along with the hidden representation of the amino acid as the condition to parameterize the bijective (Figure 2B):\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We would like to highlight that, sequence-based methodsfor single proteins are not suitable for protein-protein interactions due to the lack of evolutionary information in most cases \u2014 protein-protein interactions involve two or more chains. The chains might belong to different species (e.g. host and virus). Sometimes, inter-chain co-evolution simply does not happen. These make it infeasible to predict mutational effects via mining sequence databases with existing powerful tools such as multiple sequence alignments, protein language models, etc.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We would like to highlight that, sequence-based methodsfor single proteins are not suitable for protein-protein interactions due to the lack of evolutionary information in most cases \u2014 protein-protein interactions involve two or more chains. The chains might belong to different species (e.g. host and virus). Sometimes, inter-chain co-evolution simply does not happen. These make it infeasible to predict mutational effects via mining sequence databases with existing powerful tools such as multiple sequence alignments, protein language models, etc.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We would like to highlight that, sequence-based methodsfor single proteins are not suitable for protein-protein interactions due to the lack of evolutionary information in most cases \u2014 protein-protein interactions involve two or more chains. The chains might belong to different species (e.g. host and virus). Sometimes, inter-chain co-evolution simply does not happen. These make it infeasible to predict mutational effects via mining sequence databases with existing powerful tools such as multiple sequence alignments, protein language models, etc.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We would like to highlight that, sequence-based methodsfor single proteins are not suitable for protein-protein interactions due to the lack of evolutionary information in most cases \u2014 protein-protein interactions involve two or more chains. The chains might belong to different species (e.g. host and virus). Sometimes, inter-chain co-evolution simply does not happen. These make it infeasible to predict mutational effects via mining sequence databases with existing powerful tools such as multiple sequence alignments, protein language models, etc.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We would like to highlight that, sequence-based methodsfor single proteins are not suitable for protein-protein interactions due to the lack of evolutionary information in most cases \u2014 protein-protein interactions involve two or more chains. The chains might belong to different species (e.g. host and virus). Sometimes, inter-chain co-evolution simply does not happen. These make it infeasible to predict mutational effects via mining sequence databases with existing powerful tools such as multiple sequence alignments, protein language models, etc.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We would like to highlight that, sequence-based methodsfor single proteins are not suitable for protein-protein interactions due to the lack of evolutionary information in most cases \u2014 protein-protein interactions involve two or more chains. The chains might belong to different species (e.g. host and virus). Sometimes, inter-chain co-evolution simply does not happen. These make it infeasible to predict mutational effects via mining sequence databases with existing powerful tools such as multiple sequence alignments, protein language models, etc.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We would like to highlight that, sequence-based methodsfor single proteins are not suitable for protein-protein interactions due to the lack of evolutionary information in most cases \u2014 protein-protein interactions involve two or more chains. The chains might belong to different species (e.g. host and virus). Sometimes, inter-chain co-evolution simply does not happen. These make it infeasible to predict mutational effects via mining sequence databases with existing powerful tools such as multiple sequence alignments, protein language models, etc.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We would like to highlight that, sequence-based methodsfor single proteins are not suitable for protein-protein interactions due to the lack of evolutionary information in most cases \u2014 protein-protein interactions involve two or more chains. The chains might belong to different species (e.g. host and virus). Sometimes, inter-chain co-evolution simply does not happen. These make it infeasible to predict mutational effects via mining sequence databases with existing powerful tools such as multiple sequence alignments, protein language models, etc.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "instruction": "Remove unnnecesary examples.", "revised_paragraph": "\"We would like to highlight that, sequence-based(evolution-based) methodsfor single proteins are not suitable for protein-protein interactions due to the lacking of evolutionary information in most cases \u2014 protein-protein interactions involve two or more chains. The chains might belong to different species (e.g. host and virus). Sometimes inter-chain co-evolution simply does not happen (e.g. immune response where effective antibodies are produced to induce rapid clearance of pathogens, leaving no time for the pathogen to evolve). These make it infeasible to predict mutational effects via mining sequence databases with existing powerful tools such as multiple sequence alignments, protein language models, etc.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "instruction": "Rewrite this paragraph to make it shorter while keeping all the informations.", "revised_paragraph": "\"We would like to highlight that, sequence-based(evolution-based) methodsfor single proteins are not suitable for protein-protein interactions due to the lack of evolutionary information in most cases.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Overview Our method consists of three parts. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Next, we show how to use the entropy of the distribution parameterized by the normalizing flow to predict the change in binding free energy (  G ) upon mutation, and how to use neural networks to predict  G more accurately using the unsupervised representations from the RDE.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Overview Our method consists of three parts. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Next, we show how to use the entropy of the distribution parameterized by the normalizing flow to predict the change in binding free energy (  G ) upon mutation, and how to use neural networks to predict  G more accurately using the unsupervised representations from the RDE.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Overview Our method consists of three parts. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Next, we show how to use the entropy of the distribution parameterized by the normalizing flow to predict the change in binding free energy (  G ) upon mutation, and how to use neural networks to predict  G more accurately using the unsupervised representations from the RDE.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Overview Our method consists of three parts. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Next, we show how to use the entropy of the distribution parameterized by the normalizing flow to predict the change in binding free energy (  G ) upon mutation, and how to use neural networks to predict  G more accurately using the unsupervised representations from the RDE.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Overview Our method consists of three parts. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Next, we show how to use the entropy of the distribution parameterized by the normalizing flow to predict the change in binding free energy (  G ) upon mutation, and how to use neural networks to predict  G more accurately using the unsupervised representations from the RDE.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Overview Our method consists of three parts. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Next, we show how to use the entropy of the distribution parameterized by the normalizing flow to predict the change in binding free energy (  G ) upon mutation, and how to use neural networks to predict  G more accurately using the unsupervised representations from the RDE.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Overview Our method consists of three parts. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Next, we show how to use the entropy of the distribution parameterized by the normalizing flow to predict the change in binding free energy (  G ) upon mutation, and how to use neural networks to predict  G more accurately using the unsupervised representations from the RDE.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Overview Our method consists of three parts. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Next, we show how to use the entropy of the distribution parameterized by the normalizing flow to predict the change in binding free energy (  G ) upon mutation, and how to use neural networks to predict  G more accurately using the unsupervised representations from the RDE.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "instruction": "Generate a more formal version of this paragraph", "revised_paragraph": "The rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Then, the entropy of the distribution parameterized by the RDE is used to predict the change in binding free energy ( G ) upon mutation, and the neural network is used to predict the change more accurately using the unsupervised representations from the RDE.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "instruction": "Replace all mentions of amino acid by 'residue'. Revise this paragraph for clarity.", "revised_paragraph": "\"Overview Our method consists of three parts. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environments. Then, we use the entropy of the distribution parameterized by the normalizing flow to predict the change in binding free energy (  G ) upon mutation, and how to use neural networks to predict  G more accurately using the unsupervised representations from the RDE (Section 3.4).", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "instruction": "Check the citation mark format and rewrite", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "instruction": "Make the paragraph slightly more precise.", "revised_paragraph": "\"NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), consists of 1,532 video clips (1,050 training and 482 test ones) of hand gestures in 25 classes. We sample 20% training samples as the validation set and use depth and RGB as two modalities. We adopt the configuration by Joze et al. (2020) for data preparation and use I3D Carreira & Zisserman (2017) as uni-modal branches and MMTMs as fusion modules in the six final inception modules.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel\u2019s occupancy value by its height coordinate in the grid, and then taking a max along the grid\u2019s height axis. The visualizations show that the occupancy module learns to fill the \u201choles\u201d of the partial view, effectively imagining the complete 3D scene.\""}, {"intention": "Concision", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel\u2019s occupancy value by its height coordinate in the grid, and then taking a max along the grid\u2019s height axis. The visualizations show that the occupancy module learns to fill the \u201choles\u201d of the partial view, effectively imagining the complete 3D scene.\""}, {"intention": "Concision", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel\u2019s occupancy value by its height coordinate in the grid, and then taking a max along the grid\u2019s height axis. The visualizations show that the occupancy module learns to fill the \u201choles\u201d of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel\u2019s occupancy value by its height coordinate in the grid, and then taking a max along the grid\u2019s height axis. The visualizations show that the occupancy module learns to fill the \u201choles\u201d of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel\u2019s occupancy value by its height coordinate in the grid, and then taking a max along the grid\u2019s height axis. The visualizations show that the occupancy module learns to fill the \u201choles\u201d of the partial view, effectively imagining the complete 3D scene.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel\u2019s occupancy value by its height coordinate in the grid, and then taking a max along the grid\u2019s height axis. The visualizations show that the occupancy module learns to fill the \u201choles\u201d of the partial view, effectively imagining the complete 3D scene.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "instruction": "Remove second part of last sentence and Replace \"grids\" by \"volumes\" ", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9 (right). We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel\u2019s occupancy value by its height coordinate in the grid, and then taking a max along the grid\u2019s height axis. The visualizations show that the occupancy module learns to fill the \u201choles\u201d of the partial view, effectively imagining the complete 3D scene.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "instruction": "Delete unnecessary details. Make the text more formal.", "revised_paragraph": "\"We show a visualization of the occupancy grids in Figure 9. We visualize the occupancy grids by converting them to heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate in the grid, and then taking a max along the grid's height axis. The visualizations show that the occupancy module learns to fill the \"holes\" of the partial view, effectively imagining the complete 3D scene.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We introduce the first dynamic sparse reparameterization method for training convolutional networks. We showed that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}, {"intention": "Concision", "revised_paragraph": "\"We show that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We show that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We show that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We introduce the first dynamic sparse reparameterization method for training convolutional networks. We showed that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}, {"intention": "Concision", "revised_paragraph": "\"We show that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We introduce the first dynamic sparse reparameterization method for training convolutional networks. We showed that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We introduce the first dynamic sparse reparameterization method for training convolutional networks. We showed that our dynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We show that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We show that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We introduce the first dynamic sparse reparameterization method for training convolutional networks. We showed that ourdynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We introduce the first dynamic sparse reparameterization method for training convolutional networks. We showed that our dynamic sparse reparameterization significantly outperformed static ones. Our method not only outperformed existing dynamic sparse reparameterization techniques, but also incurred much lower computational costs.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "instruction": "Rewrite this paragraph, removing any redundant information for a more concise version.", "revised_paragraph": "\"We introduce the first dynamic sparse reparameterization method for training convolutional networks. We showed that ourdynamic sparse reparameterization significantly outperformed static ones.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "instruction": "Fully rewritte this paragraph in a more concise and direct way fitting the academic style.", "revised_paragraph": "\"We introduce the first dynamic sparse reparameterization method for training convolutional networks. We showed that ourdynamic sparse reparameterization significantly outperformed static ones.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "instruction": "Make the sentence correct, put conjuctions in front of sentences.", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "instruction": "Improve the English and the flow of this paragraph.", "revised_paragraph": "\"Hyperparameter tuning: For our PHN method we select hyperparameters based on the HV computed on a validation set. However, selecting hyperparameters for the baselines is non-trivial as there is no clear criteria that is reasonable in terms of runtime; In order to select hyperparameters based on HV, each approach needs to be trained multiple times on all rays. We therefore select hyperparameters based on a single ray, and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, and filter out the dominated solutions. Finally, we select the combination of hyperparametrs with the highest uniformity.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "instruction": "Make this paragraph shorter", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "instruction": "Make this paragraph shorter.", "revised_paragraph": "\" Figure 2 shows the results. We can observe that in both experiments N. + emp + opt outperforms other methods. Also,even without using the knowledge of any expectations, N. + emp (and Thinning ) show a decentconvergence rate comparable to Herding or iid Bayes, which actually use the additional information.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model interpretability is linked to the domain knowledges. For example, by distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for the networkcongestion practitioners to locatethe bug and modify/improve manually.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model interpretability is linked to the domain knowledges. For example, by distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for the networkcongestion practitioners to locatethe bug and modify/improve manually.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model interpretability is linked to the domain knowledges. For example, by distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for the networkcongestion practitioners to locatethe bug and modify/improve manually.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model interpretability is linked to the domain knowledges. For example, by distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for the networkcongestion practitioners to locatethe bug and modify/improve manually.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model interpretability is linked to the domain knowledges. For example, by distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for the networkcongestion practitioners to locatethe bug and modify/improve manually.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model interpretability is linked to the domain knowledges. For example, by distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for the networkcongestion practitioners to locatethe bug and modify/improve manually.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model interpretability is linked to the domain knowledges. For example, by distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for the networkcongestion practitioners to locatethe bug and modify/improve manually.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model interpretability is linked to the domain knowledges. For example, by distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for the networkcongestion practitioners to locatethe bug and modify/improve manually.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "instruction": "Rewrite the last sentence and make it easier to understand.", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, interpretability is linked to the amount of domain knowledge that is available. By distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for the networkcongestion practitioners to locate the bug and modify/improve manually.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "instruction": "Rephrase the second part of the last sentence.", "revised_paragraph": "\"Interpretability \u2013 a universal boon for ML? In the PCC domain, interpretability is linked to the wealth of domain knowledges. By distilling a blackbox neural network into a white boxsymbolic rule, the congestion rule is made easier for networkcongestion practitioners to locatethe bug and modify/improve manually.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block (He et al., 2016) and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), where the attention mechanism was firstly introduced in image SR. Liu et al. proposed FRANet (Liu et al., 2020) to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved"}, {"intention": "Concision", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), which is a new deep network architecture for image restoration. Liu et al. (Liu et al., 2019) proposed FRANet to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved state-of-the-art results with deeper and"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), which is a new deep network architecture for image restoration. Liu et al. (Liu et al., 2019) proposed FRANet to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved state-of-the-art results with deeper and"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), which is a new deep network architecture for image restoration. Liu et al. (Liu et al., 2019) proposed FRANet to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved state-of-the-art results with deeper and"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block (He et al., 2016) and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), where the attention mechanism was firstly introduced in image SR. Liu et al. proposed FRANet (Liu et al., 2020) to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved"}, {"intention": "Concision", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), which is a new deep network architecture for image restoration. Liu et al. (Liu et al., 2019) proposed FRANet to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved state-of-the-art results with deeper and"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block (He et al., 2016) and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), where the attention mechanism was firstly introduced in image SR. Liu et al. proposed FRANet (Liu et al., 2020) to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN). Liu et al. proposed FRANet (Liu et al., 2020) to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), which is a new deep network architecture for image restoration. Liu et al. (Liu et al., 2019) proposed FRANet to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved state-of-the-art results with deeper and"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), which is a new deep network architecture for image restoration. Liu et al. (Liu et al., 2019) proposed FRANet to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved state-of-the-art results with deeper and"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block (He et al., 2016) and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), where the attention mechanism was firstly introduced in image SR. Liu et al. proposed FRANet (Liu et al., 2020) to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN). Liu et al. proposed FRANet (Liu et al., 2020) to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "instruction": "Be more concise.", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b) for deeper network structure. Lim et al. (Lim et al., 2017) simplified the residual block and constructed deeper and wider networks with a large number of parameters. Zhang et al. (Zhang et al., 2018b) proposed an even deeper network, residual channel attention network (RCAN), where the attention mechanism was firstly introduced in image SR. Liu et al. proposed FRANet (Liu et al., 2019) to make the residual features more focused on critical spatial contents. Later, Zhang et al. (Zhang et al., 2019) proposed residual non-local attention for image restoration, including image SR. Mei et al. proposed CSNLN (Mei et al., 2020) by combining local, in-scale/cross-scale non-local feature correlations, and external statistics. Most of them have achieved state-of-the-art results with deeper", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "instruction": "Use shorter formulations to make some sentences more concise.", "revised_paragraph": "\"SRCNN. Tai et al. later introduced memory block in MemNet (Tai et al., 2017b).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameter number. We also provide operations number with Mult-Adds by setting the output size as 3  1280  720. Our SRPN-L operates less Mult-Adds than most compared methods. Those comparisons indicate that SRP reduces parameters and operations efficiently.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameter number and operations number with Mult-Adds. Those comparisons indicate that SRP reduces parameters and operations efficiently.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameter number. We also provide operations number with Mult-Adds by setting the output size as 3  1280  720. Our SRPN-L operates less Mult-Adds than most compared methods. Those comparisons indicate that SRP reduces parameters and operations efficiently.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameter number and operations number with Mult-Adds. Those comparisons indicate that SRP reduces parameters and operations efficiently.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameter number. We also provide operations number with Mult-Adds by setting the output size as 3  1280  720. Our SRPN-L operates less Mult-Adds than most compared methods. Those comparisons indicate that SRP reduces parameters and operations efficiently.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameter number. We also provide operations number with Mult-Adds by setting the output size as 3 1280 720. Our SRPN-L operates less Mult-Adds than most compared methods. Those comparisons indicate that SRP reduces parameters and operations efficiently.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameter number. We also provide operations number with Mult-Adds by setting the output size as 3  1280  720. Our SRPN-L operates less Mult-Adds than most compared methods. Those comparisons indicate that SRP reduces parameters and operations efficiently.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameter number and operations number with Mult-Adds. Those comparisons indicate that SRP reduces parameters and operations efficiently.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "instruction": "Give me a more formal version of ths paragraph", "revised_paragraph": "Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameters and operations. Those comparisons indicate that SRP reduces parameters and operations efficiently.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "instruction": "Rephrase the text and change SRPN-L to SRPN-Lite", "revised_paragraph": "\"Model Size and Mult-Adds. Compared with recent works (e.g., MemNet, CARN, and IMDN), our SRPN-L has the least parameter number. We also provide operations number with Mult-Adds by setting the output size as 3  1280  720. Our SRPN-L uses fewer Mult-Adds than most compared methods. Those comparisons indicate that SRP reduces parameters and operations efficiently.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "instruction": "Use \"supplemental materials\" instead of \"Appendix\"", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "instruction": "Lightly revise for readability.", "revised_paragraph": "\"ADO iterations in the Bayesian framework are shown in Sec. 3.3 and Appendix A.3. Finally, with theestimated posterior, the predictive uncertainty can be quantified by evaluating the identified systemwith an ensemble of parameters. To further improve the prediction capability, especially for chaoticsystems, we propose to leverage data assimilation techniques, which is shown in the green box anddiscussed in Sec.3.4 and Appendix A.5.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "instruction": "I want to remove the last sentence.", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "instruction": "Delete the last sentence.", "revised_paragraph": "\"Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10  3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 and the Truncated Q-functions with a learning rate of 10  3. Please note, however, that the Shifted Q-function bootstraps from the full Q-estimate.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations whereas AGILE outperformed the ablations in CREATE and Grid World by correctly utilizing the action relation in decision-making.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations whereas AGILE outperformed the ablations in CREATE and Grid World by correctly utilizing the action relation in decision-making.\""}, {"intention": "Concision", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations. In Fig. 6, AGILE outperformed AGILEGCN shows that a GAT is capable of modeling the action relations correctly and AGILE converging faster than AGILE Only Action shows that the intermediate list information is crucial to efficiently learn to attend the other half in the pairing of items.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations whereas AGILE outperformed the ablations in CREATE and Grid World by correctly utilizing the action relation in decision-making.\""}, {"intention": "Content_deletion", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations whereas AGILE outperformed the ablations in CREATE and Grid World by correctly utilizing the action relation in decision-making.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations. In Fig. 6, AGILE outperformed AGILEGCN shows that a GAT is capable of modeling the action relations correctly and AGILE converging faster than AGILE Only Action shows that the intermediate list information is crucial to efficiently learn to attend the other half in the pairing of items.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations whereas AGILE outperformed the ablations in CREATE and Grid World by correctly utilizing the action relation in decision-making.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations whereas AGILE outperformed the ablations in CREATE and Grid World by correctly utilizing the action relation in decision-making.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model, and AGILE could not outperform the ablations. On the other hand, AGILE outperformed the ablations in CREATE and Grid World by correctly utilizing the action relation in decision-making.\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations whereas AGILE outperformed the ablations in CREATE and Grid World by correctly utilizing the action relation in decision-making.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations whereas AGILE outperformed the ablations in CREATE and Grid World by correctly utilizing the action relation in decision-making.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model such that AGILE could not outperform the ablations. In Fig. 6, AGILE outperformed AGILEGCN shows that a GAT is capable of modeling the action relations correctly and AGILE converging faster than AGILE Only Action shows that the intermediate list information is crucial to efficiently learn to attend the other half in the pairing of items.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "instruction": "Make this paragraph shorter and easier to understand", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model, but in CREATE and Grid World it outperformed the ablations.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "instruction": "Simplify the less essential ideas of the paragraph to make it more concise.", "revised_paragraph": "\"In the experiment of Fig. 5, we found that in RecSim the relation of items is easy to model but in CREATE and Grid World it outperformed the ablations.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018) and health care (Schwab et al., 2020). For example,application managers would impose a marketing strategy on the randomly sampled users to see its potential benefit on the click-through rate; drug developers would conduct clinical A/B tests to evaluate the drug effects. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials."}, {"intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018) and health care (Schwab et al., 2020). For example,application managers would impose a marketing strategy on the randomly sampled users to see its potential benefit on the click-through rate; drug developers would conduct clinical A/B tests to evaluate the drug effects. However, RCT is the golden standard for causal inference (Judea & Dana, 2018), hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials. With the growing access to observational data, estimating ITE from observational data has attracted intense research interest.\""}, {"intention": "Concision", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce, education, and health care. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018) and health care (Schwab et al., 2020). For example,application managers would impose a marketing strategy on the randomly sampled users to see its potential benefit on the click-through rate; drug developers would conduct clinical A/B tests to evaluate the drug effects. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials."}, {"intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018) and health care (Schwab et al., 2020). For example,application managers would impose a marketing strategy on the randomly sampled users to see its potential benefit on the click-through rate; drug developers would conduct clinical A/B tests to evaluate the drug effects. However, RCT is the golden standard for causal inference (Judea & Dana, 2018), hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials. With the growing access to observational data, estimating ITE from observational data has attracted intense research interest.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce, education, and health care. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018) and health care (Schwab et al., 2020). For example,application managers would impose a marketing strategy on the randomly sampled users to see its potential benefit on the click-through rate; drug developers would conduct clinical A/B tests to evaluate the drug effects. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018) and health care (Schwab et al., 2020). For example,application managers would impose a marketing strategy on the randomly sampled users to see its potential benefit on the click-through rate; drug developers would conduct clinical A/B tests to evaluate the drug effects. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials.\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce, education, and health care. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018) and health care (Schwab et al., 2020). For example,application managers would impose a marketing strategy on the randomly sampled users to see its potential benefit on the click-through rate; drug developers would conduct clinical A/B tests to evaluate the drug effects. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018) and health care (Schwab et al., 2020). For example,application managers would impose a marketing strategy on the randomly sampled users to see its potential benefit on the click-through rate; drug developers would conduct clinical A/B tests to evaluate the drug effects. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce, education, and health care. However, it is always too expensive to conduct randomized experiments. Hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "instruction": "Remove the part of the sentence that talks about application managers. Improve the english of this paragraph.", "revised_paragraph": "\"Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018) and health care (Schwab et al., 2020). For example,application managers would impose a marketing strategy on the randomly sampled users to see its potential benefit on the click-through rate; drug developers would conduct clinical A/B tests to evaluate the drug effects. However, RCT is the golden standard for causal inference (Judea & Dana, 2018), hence, observational data that can be acquired without intervention has been a tempting shortcut. For example, drug developers tend to assess drug effects with post-marketing monitoring reports instead of the clinical A/B trials. With the growing access to observational data, estimating ITE from observational data has attracted intense research interest.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "instruction": "Make the sentence 2 more concise. Make the sentence 3 more formal.", "revised_paragraph": "\"Estimating individual treatment effects (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, which has been widely used in e-commerce, education, and health care.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k + 1, y k,k + 1,  k,k + 1 ) = y in [ x k, x k + 1 ], whose solution is closed-form.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k + 1, y k,k + 1,  k,k + 1 ) = y in [ x k, x k + 1 ], whose solution is closed-form.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k + 1, y k,k + 1,  k,k + 1 ) = y in [ x k, x k + 1 ], whose solution is closed-form.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k + 1, y k,k + 1,  k,k + 1 ) = y in [ x k, x k + 1 ], whose solution is closed-form.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k + 1, y k,k + 1,  k,k + 1 ) = y in [ x k, x k + 1 ], whose solution is closed-form.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k + 1, y k,k + 1,  k,k + 1 ) = y in [ x k, x k + 1 ], whose solution is closed-form.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k + 1, y k,k + 1,  k,k + 1 ) = y in [ x k, x k + 1 ], whose solution is closed-form.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k + 1, y k,k + 1,  k,k + 1 ) = y in [ x k, x k + 1 ], whose solution is closed-form.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "instruction": "Please, review this paragraph, modify only if necessary", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k +1, y k,k +1,  k,k +1 ) = y in [ x k, x k +1 ], whose solution is closed-form.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "\"In practice, we stack multiple bijectives to enable more complex transforms. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f  1 (y ) can be computed efficiently (Rezende et al., 2020). To find the solution of f  1 (y ), the first step is to locate the unique bin that contains y. Assuming y belongs to the k -th bin, finding its corresponding x amounts to finding the root of the quadratic equation f k (x | x k,k +1, y k,k +1,  k,k +1 ) = y in [ x k, x k +1 ], whose solution is closed-form.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list. An optimal agent should identify the most common category in the available action set and try to recommend most items in its list from category. This requires understanding the relation with the other candidate items from the same category. We train CDQN-based models to maximize the number of clicks in a user session.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list. An optimal agent should identify the most common category in the available action set and try to recommend most items in its list from category. This requires understanding the relation with the other candidate items from the same category. We train CDQN-based models to maximize the number of clicks in a user session.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list. An optimal agent should identify the most common category in the available action set and try to recommend most items in its list from category. This requires understanding the relation with the other candidate items from the same category. We train CDQN-based models to maximize the number of clicks in a user session.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list. An optimal agent should identify the most common category in the available action set and try to recommend most items in its list from category. This requires understanding the relation with the other candidate items from the same category. We train CDQN-based models to maximize the number of clicks in a user session.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list. An optimal agent should identify the most common category in the available action set and try to recommend most items in its list from category. This requires understanding the relation with the other candidate items from the same category. We train CDQN-based models to maximize the number of clicks in a user session.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list. An optimal agent should identify the most common category in the available action set and try to recommend most items in its list from category. This requires understanding the relation with the other candidate items from the same category. We train CDQN-based models to maximize the number of clicks in a user session.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list. An optimal agent should identify the most common category in the available action set and try to recommend most items in its list from category. This requires understanding the relation with the other candidate items from the same category. We train CDQN-based models to maximize the number of clicks in a user session.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list. An optimal agent should identify the most common category in the available action set and try to recommend most items in its list from category. This requires understanding the relation with the other candidate items from the same category. We train CDQN-based models to maximize the number of clicks in a user session.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "instruction": "Rewrite the sentences, making them shorter and more connected.", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "instruction": "Rewrite the sentences of this paragraph for better readability and fitting to the academic style.", "revised_paragraph": "\"We develop on the open-sourced simulator RecSim simulator ((Ie et al., 2019a)) which allows an agent to interact with simulated users by recommending a list of items. We have a base action set of 250 train items and 250 test items, and in each episode 20 items are given to the agent. It must recommend a list of size 6. We take user preference vectoras the state (MDP) and ground truth action representations from the environment. We incorporate CPR by boosting up the probability of user clicking any item proportional to the CPR. This simulates one of the scenarios whereuser preference model is influenced by the entire list. An optimal agent should identify the most common category in the available action set and try to recommend most items in its list from category. This requires understanding the relation with the other candidate items from the same category. We train CDQN-based models to maximize the number of clicks in a user session.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}, {"intention": "Concision", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding. Please refer to Section B of the appendix for more results and discussion.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}, {"intention": "Concision", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding. Please refer to Section B of the appendix for more results and discussion.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Sequence-based models do not predict G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Sequence-based models do not predict G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "instruction": "Simplify the English of this paragraph.", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding as discussed in Section 2.2. Please refer to Section B of the appendix for more results and discussion.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "instruction": "Improve the English in this paragraph.", "revised_paragraph": "\"Sequence-based models do not predict  G accurately for protein-protein binding, as discussed in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight Image SR Models. Recent years have been rising interest in investigating lightweight image SR models. These approaches try to design lightweight architectures, which mainly take advantage of recursive learning and channel splitting. Kim et al. firstly introduced recursive learning in DRCN to decrease model size (Kim et al., 2016b). Ahn et al. designed a cascading mechanism upon a residual network in CARN (Ahn et al., 2018). Hui et al. proposed a lightweight information multi-distillation network (IMDN) (Hui et al., 2019). Recently, neural architecture search was introduced for image SR in FALSR (Chu et al., 2019a). Besides, model compression techniques, like knowledge distillation, have been investigated for image SR."}, {"intention": "Concision", "revised_paragraph": "\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Among them, there are several approaches to decrease model size such as recursive learning and channel splitting."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Among them, there are several approaches to decrease model size such as recursive learning and channel splitting."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight Image SR Models. Recent years have been rising interest in investigating lightweight image SR models. These approaches try to design lightweight architectures, which mainly take advantage of recursive learning and channel splitting. Kim et al. firstly introduced recursive learning in DRCN to decrease model size (Kim et al., 2016b). Ahn et al. designed a cascading mechanism upon a residual network in CARN (Ahn et al., 2018). Hui et al. proposed a lightweight information multi-distillation network (IMDN) (Hui et al., 2019). Recently, neural architecture search was introduced for image SR in FALSR (Chu et al., 2019a). Besides, model compression techniques, like knowledge distillation, have been investigated for image SR."}, {"intention": "Concision", "revised_paragraph": "\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Among them, there are several approaches to decrease model size such as recursive learning and channel splitting."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Among them, there are several approaches to decrease model size such as recursive learning and channel splitting."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight Image SR Models. Recent years have been rising interest in investigating lightweight image SR models. These approaches try to design lightweight architectures, which mainly take advantage of recursive learning and channel splitting. Kim et al. firstly introduced recursive learning in DRCN to decrease model size (Kim et al., 2016b). Ahn et al. designed a cascading mechanism upon a residual network in CARN (Ahn et al., 2018). Hui et al. proposed a lightweight information multi-distillation network (IMDN) (Hui et al., 2019). Recently, neural architecture search was introduced for image SR in FALSR (Chu et al., 2019a). Besides, model compression techniques, like knowledge distillation, have been investigated for image SR."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Some approaches to reduce model size are recursive learning, channel splitting, and neural architecture search."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Among them, there are several approaches to decrease model size such as recursive learning and channel splitting."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight Image SR Models. Recent years have been rising interest in investigating lightweight image SR models. These approaches try to design lightweight architectures, which mainly take advantage of recursive learning and channel splitting. Kim et al. firstly introduced recursive learning in DRCN to decrease model size (Kim et al., 2016b). Ahn et al. designed a cascading mechanism upon a residual network in CARN (Ahn et al., 2018). Hui et al. proposed a lightweight information multi-distillation network (IMDN) (Hui et al., 2019). Recently, neural architecture search was introduced for image SR in FALSR (Chu et al., 2019a). Besides, model compression techniques, like knowledge distillation, have been investigated for image SR."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Some approaches to reduce model size are recursive learning, channel splitting, and neural architecture search."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Among them, there are several approaches to decrease model size such as recursive learning and channel splitting."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "instruction": "Can you make my paragraph more concise?", "revised_paragraph": "\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Among them, there are several approaches to decrease model size such as recursive learning and channel splitting.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "instruction": "Use shorter formulations and more direct language to make the paragraph more concise.", "revised_paragraph": "\"Lightweight Image SR Models. Recently, there has been a growing interest in investigating lightweight image SR models. Among them, there are several approaches to reduce the size of the models by recursive learning and channel splitting.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "instruction": "Rephrase the paragraph", "revised_paragraph": "\"Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "instruction": "Make the paragraph more formal.", "revised_paragraph": "Similar to standard rSLDS, the dynamics are conditionally linear given a leaf node z t. It is intuitive to expect that nearby regions in latent space have similar dynamics. In the context of the tree-structured stick breaking partitions that share a common parent should have similar dynamics. We explicitly model this by enforcing a hierarchical tree-structured prior on the dynamics.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "instruction": "Please, remove the clarifications that do are not necessary for the development of the idea:", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "instruction": "Remove Hui et al. citation and improve writing of the paragraph", "revised_paragraph": "\"Lightweight Network. First, we revise EDSR baseline (i.e.16 residual blocks) (Lim et al., 2017) by removing the final Conv layer to save parameters. Same as IMDN (Hui et al., 2019), the reconstruction was done within the pixel-shuffle layer (Shi et al., 2016). We set the channel number in revised EDSR baseline as 256 and then prune it to 45. For  2, we reduce the number of parameters from 19.5M to 609K and name the compressed model as SRPN-L.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods. TARNet obtains better overall performance than other statistical estimators by absorbing the advantages (R et al., 2019) ofboth T-learner and S-learner. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods. TARNet obtains better overall performance than other statistical estimators by absorbing the advantages (R et al., 2019) ofboth T-learner and S-learner. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods. TARNet obtains better overall performance than other statistical estimators by absorbing the advantages (R et al., 2019) ofboth T-learner and S-learner. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods. TARNet obtains better overall performance than other statistical estimators by absorbing the advantages (R et al., 2019) ofboth T-learner and S-learner. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods. TARNet obtains better overall performance than other statistical estimators by absorbing the advantages (R et al., 2019) ofboth T-learner and S-learner. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods. TARNet obtains better overall performance than other statistical estimators by absorbing the advantages (R et al., 2019) ofboth T-learner and S-learner. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods. TARNet obtains better overall performance than other statistical estimators by absorbing the advantages (R et al., 2019) ofboth T-learner and S-learner. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods. TARNet obtains better overall performance than other statistical estimators by absorbing the advantages (R et al., 2019) ofboth T-learner and S-learner. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "instruction": "The second sentence is too complicated. Make it more understandable. Also brush up the rest.", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods. TARNet obtains better overall performance than other statistical estimators. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "instruction": "Reorganize the ideas in the sentences to improve the logical flow of the text.", "revised_paragraph": "\"Statistical estimators exhibit competitive performance on the PEHE metric. In particular, neuralnetwork estimators outperformthe linear and random forest methods because they can depict the nonlinearity in data. TARNet obtains better overall performance than other statistical estimators by absorbing the advantages (R et al., 2019) ofboth T-learner and S-learner. However, the treatment selection bias makes these estimators biased, leading to sub-optimal performance.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate. As related work, Mhaskar & Micchelli (1992); Mhaskar (1993); Chui et al. (1994); Mhaskar (1996); Pinkus (1999) also developed an approximation error analysis which essentially leads to analyses for Besov spaces. However, the ReLU activation is basically excluded and comprehensive analyses for the Besov space have not been given. Consequently, it has not been clear whether ReLU neural networks can outperform another representative methods such"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate. As related work, Mhaskar & Micchelli (1992); Mhaskar (1993); Chui et al. (1994); Mhaskar (1996); Pinkus (1999) also developed an approximation error analysis which essentially leads to analyses for Besov spaces. However, the ReLU activation is basically excluded and comprehensive analyses for the Besov space have not been given. Consequently, it has not been clear whether ReLU neural networks can outperform another representative methods such"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate. As related work, Mhaskar & Micchelli (1992); Mhaskar (1993); Chui et al. (1994); Mhaskar (1996); Pinkus (1999) also developed an approximation error analysis which essentially leads to analyses for Besov spaces. However, the ReLU activation is basically excluded and comprehensive analyses for the Besov space have not been given. Consequently, it has not been clear whether ReLU neural networks can outperform another representative methods such"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate. As related work, Mhaskar & Micchelli (1992); Mhaskar (1993); Chui et al. (1994); Mhaskar (1996); Pinkus (1999) also developed an approximation error analysis which essentially leads to analyses for Besov spaces. However, the ReLU activation is basically excluded and comprehensive analyses for the Besov space have not been given. Consequently, it has not been clear whether ReLU neural networks can outperform another representative methods such"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate. As related work, Mhaskar & Micchelli (1992); Mhaskar (1993); Chui et al. (1994); Mhaskar (1996); Pinkus (1999) also developed an approximation error analysis which essentially leads to analyses for Besov spaces. However, the ReLU activation is basically excluded and comprehensive analyses for the Besov space have not been given. Consequently, it has not been clear whether ReLU neural networks can outperform another representative methods such"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate. As related work, Mhaskar & Micchelli (1992); Mhaskar (1993); Chui et al. (1994); Mhaskar (1996); Pinkus (1999) also developed an approximation error analysis which essentially leads to analyses for Besov spaces. However, the ReLU activation is basically excluded and comprehensive analyses for the Besov space have not been given. Consequently, it has not been clear whether ReLU neural networks can outperform another representative methods such"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate. As related work, Mhaskar & Micchelli (1992); Mhaskar (1993); Chui et al. (1994); Mhaskar (1996); Pinkus (1999) also developed an approximation error analysis which essentially leads to analyses for Besov spaces. However, the ReLU activation is basically excluded and comprehensive analyses for the Besov space have not been given. Consequently, it has not been clear whether ReLU neural networks can outperform another representative methods such"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate. As related work, Mhaskar & Micchelli (1992); Mhaskar (1993); Chui et al. (1994); Mhaskar (1996); Pinkus (1999) also developed an approximation error analysis which essentially leads to analyses for Besov spaces. However, the ReLU activation is basically excluded and comprehensive analyses for the Besov space have not been given. Consequently, it has not been clear whether ReLU neural networks can outperform another representative methods such"}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "instruction": "Remove unnecessary details.", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "instruction": "The end of the paragraph is too long, remove the part that fit the less in it.", "revised_paragraph": "\"In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H  older space, the Sobolev space, and the function class with total variation as special cases 1. By doing so, (i) we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression, and (ii) we show that deep learning can avoid the curse of dimensionality on the mixed smooth Besov space and achieves the minimax optimal rate. As related work, Mhaskar & Micchelli (1992); Mhaskar (1993); Chui et al. (1994); Mhaskar (1996); Pinkus (1999) also developed an approximation error analysis which essentially leads to analyses for Besov spaces. However, the ReLU activation is basically excluded and comprehensive analyses for the Besov space have not been given. Consequently, it has not been clear whether ReLU neural networks can outperform another representative methods such", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "instruction": "Rewrite so that it looks more organized", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "instruction": "Rewrite this paragraph to make it more easily readable.", "revised_paragraph": "\"This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN, we can also use a learned initial set Y 0 to start closer to a solution. Unlike DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN, we can also use a learned initial set Y 0 to start closer to a solution. Unlike DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN, we can also use a learned initial set Y 0 to start closer to a solution. Unlike DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"By default, we sample a random initial set Y 0 N ( 0, I / 10) to start the optimization with. Similar to DSPN, we can also use a learned initial set Y 0 to start closer to a solution. Unlike DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019): || Y Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"By default, we sample a random initial set Y 0 N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019): || Y Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "instruction": "Clarify your last sentence.", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "instruction": "Make the last sentence more precise.", "revised_paragraph": "\"By default, we sample a random initial set Y 0  N ( 0, I / 10) to start the optimization with. Similar to DSPN however, implicit differentiation treats the optimizer of Equation 7 as a black box, so there is no gradient signal for Y 0. We therefore need to include a regularizer in Equation 6 to give us a gradient for Y 0, for example by adding the regularizer from Rajeswaran et al. (2019):  || Y  Y || 2. Wewill use this when comparing iDSPN to DSPN performance in Subsection 4.2.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95. GD+M) performed for various  with a fixed step-size h  0. 1 and the best test-accuracy is noted (in Figure 3) to be 96. Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all  \u2019s). (Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h, called \u201cthe edge of stability\u201d."}, {"intention": "Concision", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. SEP> For (GD+M), the sharpness can reach up to 2(1+  ) h, hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+M) than that of (GD) may suggest a higher test accuracy for (GD), this is not what we observe from the above experiment. We think the implicit regularization for (GD+M) plays a part in it. We believe IGR for momentum outweighs the sharpness effect in achieving better test accuracy.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. SEP> For (GD+M), the sharpness can reach up to 2(1+  ) h, hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+M) than that of (GD) may suggest a higher test accuracy for (GD), this is not what we observe from the above experiment. We think the implicit regularization for (GD+M) plays a part in it. We believe IGR for momentum outweighs the sharpness effect in achieving better test accuracy.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95. GD+M) performed for various  with a fixed step-size h  0. 1 and the best test-accuracy is noted (in Figure 3) to be 96. Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all  \u2019s). (Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h, called \u201cthe edge of stability\u201d."}, {"intention": "Concision", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. SEP> For (GD+M), the sharpness can reach up to 2(1+  ) h, hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+M) than that of (GD) may suggest a higher test accuracy for (GD), this is not what we observe from the above experiment. We think the implicit regularization for (GD+M) plays a part in it. We believe IGR for momentum outweighs the sharpness effect in achieving better test accuracy.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. SEP> For (GD+M), the sharpness can reach up to 2(1+  ) h, hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+M) than that of (GD) may suggest a higher test accuracy for (GD), this is not what we observe from the above experiment. We think the implicit regularization for (GD+M) plays a part in it. We believe IGR for momentum outweighs the sharpness effect in achieving better test accuracy.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95. GD+M) performed for various  with a fixed step-size h  0. 1 and the best test-accuracy is noted (in Figure 3) to be 96. Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all  \u2019s). (Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h, called \u201cthe edge of stability\u201d."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. GD+M) performed for various with a fixed step-size h = 0. 1 and the best test-accuracy is noted (in Figure 3) to be 96. Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all h). (Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h, called \u201cthe edge of stability\u201d.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. SEP> For (GD+M), the sharpness can reach up to 2(1+  ) h, hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+M) than that of (GD) may suggest a higher test accuracy for (GD), this is not what we observe from the above experiment. We think the implicit regularization for (GD+M) plays a part in it. We believe IGR for momentum outweighs the sharpness effect in achieving better test accuracy.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95. GD+M) performed for various  with a fixed step-size h  0. 1 and the best test-accuracy is noted (in Figure 3) to be 96. Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all  \u2019s). (Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h, called \u201cthe edge of stability\u201d."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. GD+M) performed for various with a fixed step-size h = 0. 1 and the best test-accuracy is noted (in Figure 3) to be 96. Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all h). (Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h, called \u201cthe edge of stability\u201d.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. SEP> For (GD+M), the sharpness can reach up to 2(1+  ) h, hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+M) than that of (GD) may suggest a higher test accuracy for (GD), this is not what we observe from the above experiment. We think the implicit regularization for (GD+M) plays a part in it. We believe IGR for momentum outweighs the sharpness effect in achieving better test accuracy.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "instruction": "Summarize heavily the results and explanations obtained. Fix any typos.", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. GD+M performed for various  with a fixed step-size h  0. 1 and the best test accuracy is noted (in Figure 3) to be 96. Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all  \u2019s). Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h, called \u201cthe edge of stability\u201d. And for (GD+M), the sharpness can reach up to 2(1+  ) h, hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "instruction": "Summarize the second half of the paragraph to make the paragraph shorter.", "revised_paragraph": "\"MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rates and the best test accuracy is noted to be 95. For (GD+M) performed for various  with a fixed step-size h  0. 1 and the best test-accuracy is noted to be 96. Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) across all  \u2019s).", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges and nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges and nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges and nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges and nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges and nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges and nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges and nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges and nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "instruction": "Remove the last sentence of this paragraph.", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges or nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "instruction": "Delete the last sentence of this paragraph.", "revised_paragraph": "\"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by the removal of edges or nodes from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance. Finally, we demonstrated that our influence function could be applied to graph rectification and model attacks. A P ROOFS Lemma 3.1.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"There was a main effect in Position, and Position = Inside had a longer movement time than Position = Outside. We observed a significant interaction of I  Position. At I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"There was a main effect in Position, and Position = Inside had a longer movement time than Position = Outside. We observed a significant interaction of I  Position. At I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"There was a main effect in Position, and Position = Inside had a longer movement time than Position = Outside. We observed a significant interaction of I  Position. At I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"There was a main effect in Position, and Position = Inside had a longer movement time than Position = Outside. We observed a significant interaction of I  Position. At I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"There was a main effect in Position, and Position = Inside had a longer movement time than Position = Outside. We observed a significant interaction of I  Position. At I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"There was a main effect in Position, and Position = Inside had a longer movement time than Position = Outside. Additionally, we observed a significant interaction of I with Position. At I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"There was a main effect in Position, and Position = Inside had a longer movement time than Position = Outside. We observed a significant interaction of I  Position. At I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"There was a main effect in Position, and Position = Inside had a longer movement time than Position = Outside. We observed a significant interaction of I  Position. At I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "instruction": "Modify the first sentence", "revised_paragraph": "\"There was a main effect in Position, and Position = Inside has a longer movement time than Position = Outside. We observed a significant interaction of I  Position. For example, at I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "instruction": "Revise this text to make it more readable and direct.", "revised_paragraph": "\"There was a main effect in Position, and Position = Inside has a longer movement time than Position = Outside. We observed a significant interaction of I  Position. At I = 0, the movement time increased compared to the condition no notch by approxi- mately 11.8% in Position = Inside, and approximately 4.93% in Position = Outside.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size by being exclusively multiset-equivariant like DSPN. As expected, the set-equivariant models are unable to solve this task because they cannot map the equal elements in the input to different elements in the output. This applies even to transformers with random position embeddings, which similarly to TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020) use noise to make elements not exactly equal. Meanwhile, transformers with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size by being exclusively multiset-equivariant like DSPN. As expected, the set-equivariant models are unable to solve this task because they cannot map the equal elements in the input to different elements in the output. This applies even to transformers with random position embeddings, which similarly to TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020) use noise to make elements not exactly equal. Meanwhile, transformers with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size by being exclusively multiset-equivariant like DSPN. As expected, the set-equivariant models are unable to solve this task because they cannot map the equal elements in the input to different elements in the output. This applies even to transformers with random position embeddings, which similarly to TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020) use noise to make elements not exactly equal. Meanwhile, transformers with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size by being exclusively multiset-equivariant like DSPN. As expected, the set-equivariant models are unable to solve this task because they cannot map the equal elements in the input to different elements in the output. This applies even to transformers with random position embeddings, which similarly to TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020) use noise to make elements not exactly equal. Meanwhile, transformers with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size by being exclusively multiset-equivariant like DSPN. As expected, the set-equivariant models are unable to solve this task because they cannot map the equal elements in the input to different elements in the output. This applies even to transformers with random position embeddings, which similarly to TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020) use noise to make elements not exactly equal. Meanwhile, transformers with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size by being exclusively multiset-equivariant like DSPN. As expected, the set-equivariant models are unable to solve this task because they cannot map the equal elements in the input to different elements in the output. This applies even to transformers with random position embeddings, which similarly to TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020) use noise to make elements not exactly equal. Meanwhile, transformers with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size by being exclusively multiset-equivariant like DSPN. As expected, the set-equivariant models are unable to solve this task because they cannot map the equal elements in the input to different elements in the output. This applies even to transformers with random position embeddings, which similarly to TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020) use noise to make elements not exactly equal. Meanwhile, transformers with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size by being exclusively multiset-equivariant like DSPN. As expected, the set-equivariant models are unable to solve this task because they cannot map the equal elements in the input to different elements in the output. This applies even to transformers with random position embeddings, which similarly to TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020) use noise to make elements not exactly equal. Meanwhile, transformers with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "instruction": "Simplify the second sentence.", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size. This is because it does not rely on the order of the elements, which makes it more sample-efficient. However, models with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient. Note that the non-equivariant models are unlikely to benefit significantly from even more training data because they overfit on 1  and 10 , but not anymore on 100.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "instruction": "Rewrite the 2nd sentence to make it easier to read and less confusing.", "revised_paragraph": "\"Results Table 2 shows our results. iDSPN is close to solving the problem at any training set size by being exclusively multiset-equivariant like DSPN. As expected, the set-equivariant models are unable to solve this task because they cannot map the equal elements in the input to different elements in the output. This applies even to transformers with random position embeddings, which similarly to TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020) use noise to make elements not exactly equal. Meanwhile, transformers with position encoding and BiLSTM require at least 100  more training samples to come close to the performance of iDSPN. This is because they lack the correct structural bias of not relying on the order of the elements, which makes them less sample-efficient. Note that the non-equivariant models are unlikely to benefit significantly from even more training data because they overfit on 1  and 10 , but no longer on 100.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q \" g t p x q \" are known at round t and can be used to decide on the next round. This is similar to the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q \", where the constraint function g t p x q is unknown when making decision at round t and can be arbitrarily chosen, as in [24, 20, 30].\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q \" g t p x q \" are known at round t and can be used to decide on the next round. This is similar to the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q \", where the constraint function g t p x q is unknown when making decision at round t and can be arbitrarily chosen, as in [24, 20, 30].\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q \" g t p x q \" are known at round t and can be used to decide on the next round. This is similar to the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q \", where the constraint function g t p x q is unknown when making decision at round t and can be arbitrarily chosen, as in [24, 20, 30].\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q \" g t p x q \" are known at round t and can be used to decide on the next round. This is similar to the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q \", where the constraint function g t p x q is unknown when making decision at round t and can be arbitrarily chosen, as in [24, 20, 30].\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q \" g t p x q \" are known at round t and can be used to decide on the next round. This is similar to the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q \", where the constraint function g t p x q is unknown when making decision at round t and can be arbitrarily chosen, as in [24, 20, 30].\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q \" g t p x q \" are known at round t and can be used to decide on the next round. This is similar to the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q \", where the constraint function g t p x q is unknown when making decision at round t and can be arbitrarily chosen, as in [24, 20, 30].\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q \" g t p x q \" are known at round t and can be used to decide on the next round. This is similar to the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q \", where the constraint function g t p x q is unknown when making decision at round t and can be arbitrarily chosen, as in [24, 20, 30].\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q \" g t p x q \" are known at round t and can be used to decide on the next round. This is similar to the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q \", where the constraint function g t p x q is unknown when making decision at round t and can be arbitrarily chosen, as in [24, 20, 30].\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "instruction": "Make paragraph more concise", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q, where the constraint functions are the same across the time but they are not necessary to be known when making decision at round t. Note the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q, where the constraint function g t p x q is unknown when making decision at round t and can be arbitrarily chosen, as in [24, 20, 30].\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "instruction": "Make this paragraph shorter.", "revised_paragraph": "\"\u2022 Fixed constraints g t p x q \" g t p x q, @ t, where the constraint functions are the same across the time but they are not necessary to be known when making decision at round t. Note the setting ofknown and fixed constraints in [14, 17, 29, 33] is a special case of ours.\u2022 Adversarial constraints g t p x q, where the constraint function g t p x q is unknown when making decision at round t and can be chosen by the adversary, as in [24, 20, 30].\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O ( Tr ( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the  O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O ( Tr ( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the  O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\""}, {"intention": "Concision", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O ( Tr ( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the  O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\""}, {"intention": "Concision", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O ( Tr ( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the  O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O ( Tr ( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the  O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O (Tr (d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a better regret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we propose a new regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O (Tr (d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the O (d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O ( Tr ( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the  O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we propose a new regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O (( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O ( Tr ( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the  O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "instruction": "Improve the English of this paragraph", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O ( Tr ( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the  O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "instruction": "Rewrite the first part of the paragraph to make it more convincing.", "revised_paragraph": "\"Compared with ESTR in [17], (cid:15) -FALB in [15] and LowESTR in [26], our algorithms achieve a betterregret bound, can work with varying action sets and are computationally feasible. For G-ESTT,we extend the GLM-UCB algorithms via a regularization technique along with some noveltechniques. For G-ESTS,we propose a simple and could be easily implemented based on anystate-of-the-art generalized linear bandit algorithms. In particular, when we combine G-ESTS withsome efficient algorithms (e.g. SGD-TS [9]), the total time complexity after a warm-up stage scalesas O ( Tr ( d 1 + d 2 )). We verify that G-ESTT and G-ESTS are the first two algorithms to attain the  O (( d 1 + d 2 ) optimal regret bound of low-rank matrix bandit problems up to logarithmic terms.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "instruction": "Add a citation in the last sentence and modify the rest so that the total length of the paragraph remains the same. ", "revised_paragraph": ": \"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "instruction": "Improve the language in this text.", "revised_paragraph": "\"Datasets. Missing counterfactual makes it infeasible to evaluate the ground-truth PEHE over observational benchmarks. Following Liuyi et al. ; Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant\u2019s future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n =1, whose instances we assume to be sampled i.i.d. from p w. The common approach to address this shortcoming is (when possible) to derive a statistical estimator (cid:98)  that uses this corpus to approximate . There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}, {"intention": "Concision", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n =1, whose instances we assume to be sampled i.i.d. from p w. The common approach to address this shortcoming is (when possible) to derive a statistical estimator (cid:98)  that uses this corpus to approximate . There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n =1, whose instances we assume to be sampled i.i.d. from p w. The common approach to address this shortcoming is (when possible) to derive a statistical estimator (cid:98)  that uses this corpus to approximate . There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus w p w n N n =1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus w p w n N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both and exp :\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "instruction": "Fix formatting issues and simplify the wording of the paragraph.", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "instruction": "Fix the caplocks problem. Slightly shorten the paragraph.", "revised_paragraph": "\"In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n =1, whose instances we assume to be sampled i.i.d. from p w. The common approach to address this shortcoming is (when possible) to derive a statistical estimator (cid:98)  that uses this corpus to approximate . There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence\u2014present in both   and  exp :\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines. For fair comparison, all neural models are trained for 400 epochs with Adam Kingma & Ba (2015) optimizer, where both learning rate and weight decay are set to 1  e  3. Other settings of optimizers follow Kingma & Ba (2015). We search hyperparameters within the range in Figure 5, checkpoint the validation performance every 2 epochs, and export the best model to evaluate its performance on the test dataset.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines. For fair comparison, all neural models are trained for 400 epochs with Adam Kingma & Ba (2015) optimizer, where both learning rate and weight decay are set to 1  e  3. Other settings of optimizers follow Kingma & Ba (2015). We search hyperparameters within the range in Figure 5, checkpoint the validation performance every 2 epochs, and export the best model to evaluate its performance on the test dataset.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines. For fair comparison, all neural models are trained for 400 epochs with Adam Kingma & Ba (2015) optimizer, where both learning rate and weight decay are set to 1  e  3. Other settings of optimizers follow Kingma & Ba (2015). We search hyperparameters within the range in Figure 5, checkpoint the validation performance every 2 epochs, and export the best model to evaluate its performance on the test dataset.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines. For fair comparison, all neural models are trained for 400 epochs with Adam Kingma & Ba (2015) optimizer, where both learning rate and weight decay are set to 1  e  3. Other settings of optimizers follow Kingma & Ba (2015). We search hyperparameters within the range in Figure 5, checkpoint the validation performance every 2 epochs, and export the best model to evaluate its performance on the test dataset.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines. For fair comparison, all neural models are trained for 400 epochs with Adam Kingma & Ba (2015) optimizer, where both learning rate and weight decay are set to 1  e  3. Other settings of optimizers follow Kingma & Ba (2015). We search hyperparameters within the range in Figure 5, checkpoint the validation performance every 2 epochs, and export the best model to evaluate its performance on the test dataset.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines. For fair comparison, all neural models are trained for 400 epochs with Adam Kingma & Ba (2015) optimizer, where both learning rate and weight decay are set to 1  e  3. Other settings of optimizers follow Kingma & Ba (2015). We search hyperparameters within the range in Figure 5, checkpoint the validation performance every 2 epochs, and export the best model to evaluate its performance on the test dataset.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines. For fair comparison, all neural models are trained for 400 epochs with Adam Kingma & Ba (2015) optimizer, where both learning rate and weight decay are set to 1  e  3. Other settings of optimizers follow Kingma & Ba (2015). We search hyperparameters within the range in Figure 5, checkpoint the validation performance every 2 epochs, and export the best model to evaluate its performance on the test dataset.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines. For fair comparison, all neural models are trained for 400 epochs with Adam Kingma & Ba (2015) optimizer, where both learning rate and weight decay are set to 1  e  3. Other settings of optimizers follow Kingma & Ba (2015). We search hyperparameters within the range in Figure 5, checkpoint the validation performance every 2 epochs, and export the best model to evaluate its performance on the test dataset.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "instruction": "Rewrite for fluency (while keeping the original structure of the sentences)", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines. For fair comparison, all neural models are trained for 400 epochs with Adam Kingma & Ba (2015) optimizer, where both learning rate and weight decay are set to 1  e  3. Other settings of optimizers follow Kingma & Ba (2015). We search hyperparameters within the range in Figure 5, checkpoint the validation performance every 2 epochs, and export the best model to evaluate its performance on the test dataset.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "instruction": "Improve the language in this text and make it slightly more formal.", "revised_paragraph": "\"Training protocol. A fully connected neural network with two hidden layers as 60-60 has been selected to realize the representation map  and the factual outcome map  for ESCFR and other neural network based baselines.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "instruction": "Remove any information that is not essential to the main points of the paragraph.", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "instruction": "I do not want to mention a limitation.", "revised_paragraph": "\"ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OTdistance only obtains 58. 78 % accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}, {"intention": "Concision", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O +."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "instruction": "Rewrite this paragraph to be more concise.", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "instruction": "Make it more concise.", "revised_paragraph": "\"We denote O + as the set of segments among images with overlapping object categories. For example, if pixel i is labeled as sofa and another image also contains sofa, all the segments from that image are included in O + ; otherwise they are considered negative segments O.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork, we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork, we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork, we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork, we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork, we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork, we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork, we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork, we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "instruction": "Use correct citation format.", "revised_paragraph": "\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork, we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "instruction": "Reorder the last sentence.", "revised_paragraph": "\"In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020). Furthermore,using the results on the upper bound for the complexity of hypernetwork Galanti & Wolf (2020), we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"This simple sampler tends to produce diverse batches similar to a k -DPP. As shown in Figure 1, switching between the two samplers does not affect the active learner\u2019s statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}, {"intention": "Concision", "revised_paragraph": "\"We show that switching between the two samplers does not affect the active learner's statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"This simple sampler tends to produce diverse batches similar to a k -DPP. As shown in Figure 1, switching between the two samplers does not affect the active learner\u2019s statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"This simple sampler tends to produce diverse batches similar to a k -DPP. As shown in Figure 1, switching between the two samplers does not affect the active learner\u2019s statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We show that switching between the two samplers does not affect the active learner's statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"This simple sampler tends to produce diverse batches similar to a k -DPP. As shown in Figure 1, switching between the two samplers does not affect the active learner\u2019s statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"This simple sampler tends to produce diverse batches similar to a k -DPP. As shown in Figure 1, switching between the two samplers does not affect the active learner\u2019s statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"We show that switching between the two samplers does not affect the active learner's statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"This simple sampler tends to produce diverse batches similar to a k -DPP. As shown in Figure 1, switching between the two samplers does not affect the active learner\u2019s statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"This simple sampler tends to produce diverse batches similar to a k -DPP. As shown in Figure 1, switching between the two samplers does not affect the active learner\u2019s statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We show that switching between the two samplers does not affect the active learner's statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"We show that switching between the two samplers does not affect the active learner's statistical performance while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "instruction": "Simplify the wording of this paragraph.", "revised_paragraph": "\"We show that switching between the two samplers does not affect the active learner's statistical performance much while greatly improving the computational performance. A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "instruction": "Make the last sentence more concise.", "revised_paragraph": "\"A thorough comparison on the running times and test accuracies of k - MEANS ++ and k -DPP basedgradient embedding samplingcan be found in Appendix G.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDENetwork improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDENetwork improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDENetwork improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDENetwork improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDENetwork improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDENetwork improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDENetwork improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDENetwork improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "instruction": "Paraphrase this paragraph using formal language", "revised_paragraph": "Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDE-Network improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "instruction": "Revise this paragraph in a more academic style.", "revised_paragraph": "\"Results According to Table 1, our RDE-Network outperforms all the baselines. Notably,RDE-Network improves per-structure correlations by a large margin, which implies that it is significantly more reliable for practical applications. The advantage of RDE-Network over MIF-Network shows that representations obtained by fitting rotamer densities are more effective than those from masked inverse folding because protein binding is driven by atomic interactions which RDE captures well by modeling the conformation of sidechain atoms.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "instruction": "Revise this paragraph for better readability.", "revised_paragraph": "\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "instruction": "Improve the flow of ideas for better readability.", "revised_paragraph": "\"To leverage the natural sparsity of point clouds andfurther improve efficiency, we sparsely implementall our window center searching, window gathering, and balanced window sampling into CUDAoperations. These operations are mainly based on a hash map that establishes the mapping fromcoordinate space to voxel index [23]. For instance, taking the window gathering operation as an example, wequery each possible position w.r.t. the given center within the window, and retrieve the correspondingfeatures if the position is a valid key in the pre-built hash map. More details are available in the supplementary materials.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance. Kim et al. increased the network depth in VDSR (Kim et al., 2016a) with residual learning and obtained notable improvements over SRCNN. Lim et al. (Lim et al., 2017) and RCAN (Zhang et al., 2018b), have achieved remarkable SR performance. However, they also suffer from heavy model parameters, number of operations, and inference time. Therefore, it is infeasible to directly deploy them on resource-limited platformswithout neural processing units or off-chip memory (Lee et al., 2020).\""}, {"intention": "Concision", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance. Kim et al. increased the network depth in VDSR (Kim et al., 2016a) with residual learning and obtained notable improvements over SRCNN. Lim et al. (Lim et al., 2017) and RCAN (Zhang et al., 2018b), have achieved remarkable SR performance. However, they also suffer from heavy model parameters, number of operations, and inference time. Therefore, it is infeasible to directly deploy them on resource-limited platformswithout neural processing units or off-chip memory (Lee et al., 2020).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance. Kim et al. increased the network depth in VDSR (Kim et al., 2016a) with residual learning and obtained notable improvements over SRCNN. Lim et al. (Lim et al., 2017) and RCAN (Zhang et al., 2018b), have achieved remarkable SR performance. However, they also suffer from heavy model parameters, number of operations, and inference time. Therefore, it is infeasible to directly deploy them on resource-limited platformswithout neural processing units or off-chip memory (Lee et al., 2020).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance."}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance. Kim et al. increased the network depth in VDSR (Kim et al., 2016a) with residual learning and obtained notable improvements over SRCNN. Lim et al. (Lim et al., 2017) and RCAN (Zhang et al., 2018b), have achieved remarkable SR performance. However, they also suffer from heavy model parameters, number of operations, and inference time. Therefore, it is infeasible to directly deploy them on resource-limited platformswithout neural processing units or off-chip memory (Lee et al., 2020).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance. Kim et al. increased the network depth in VDSR (Kim et al., 2016a) with residual learning and obtained notable improvements over SRCNN. Lim et al. (Lim et al., 2017) and RCAN (Zhang et al., 2018b), have achieved remarkable SR performance. However, they also suffer from heavy model parameters, number of operations, and inference time. Therefore, it is infeasible to directly deploy them on resource-limited platformswithout neural processing units or off-chip memory (Lee et al., 2020).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance. Kim et al. increased the network depth in VDSR and obtained notable improvements over SRCNN. Lim et al. (Lim et al., 2017) and RCAN (Zhang et al., 2018b), have achieved remarkable SR performance. However, they also suffer from heavy model parameters, number of operations, and inference time. Therefore, it is infeasible to directly deploy them on resource-limited platformswithout neural processing units or off-chip memory."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance. Kim et al. increased the network depth in VDSR (Kim et al., 2016a) with residual learning and obtained notable improvements over SRCNN. Lim et al. (Lim et al., 2017) and RCAN (Zhang et al., 2018b), have achieved remarkable SR performance. However, they also suffer from heavy model parameters, number of operations, and inference time. Therefore, it is infeasible to directly deploy them on resource-limited platformswithout neural processing units or off-chip memory (Lee et al., 2020).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance. Kim et al. increased the network depth in VDSR (Kim et al., 2016a) with residual learning and obtained notable improvements over SRCNN. Lim et al. (Lim et al., 2017) and RCAN (Zhang et al., 2018b), have achieved remarkable SR performance. However, they also suffer from heavy model parameters, number of operations, and inference time. Therefore, it is infeasible to directly deploy them on resource-limited platformswithout neural processing units or off-chip memory (Lee et al., 2020).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "instruction": "Can you make the last sentence simple?", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014). However, there are only three convolutional (Conv) layers in SRCNN, which is not good enough for SR. Therefore, Kim et al. increased the network depth in VDSR and got better SR performance than SRCNN. However, it is difficult to train deep networks with large number of hidden parameters, number of operations, and inference time. Therefore, it is not feasible to directly deploy deep networks on resource-limited platformswithout neural processing units or off-chip memory.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "instruction": "Use shorter, more direct formulations to make this paragraph more concise. Rewrite the last two sentences to make them more understandable.", "revised_paragraph": "\"Deep CNN is firstly utilized for image SR in SRCNN (Dong et al., 2014) and continuously shows promising SR performance. However, there are only three convolutional (Conv) layers in SRCNN, hindering its performance.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}, {"intention": "Rewritting_light", "revised_paragraph": "MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}, {"intention": "Concision", "revised_paragraph": "MS COCO 2014 dataset: Table 2 shows the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1] and outperforms all the other recentcompetitive methods by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}, {"intention": "Rewritting_light", "revised_paragraph": "MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"intention": "Concision", "revised_paragraph": "MS COCO 2014 dataset: Table 2 shows the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1] and outperforms all the other recentcompetitive methods by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1] and outperforms all the other recentcompetitive methods by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "MS COCO 2014 dataset: Table 2 shows the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1] and outperforms all the other recentcompetitive methods by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "instruction": "Remove unnecessary details and make my numbers clear.", "revised_paragraph": "\"MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "instruction": "Remove the sentence about reproduction", "revised_paragraph": "\"MS COCO 2014 dataset: Table 2 illustrates the segmentation performance on MS COCO 2014 compared with other methods. Our method achieves 42.6% in terms of the mIoU values on validation set, surpassing 1.2% over the IRN [1], regarded as our baseline and outperforming the other recentcompetitive methods [8, 56, 49, 1] by a large margin. In particular, we reproduce different resultsof IRN [1] with CONTA [56], in which we achieve 41.4% mIoU values. Hence, we compare the relative improvements for comparison: CONTA reaches a 0.8% mIoU improvement compared with IRN (32.6 to 33.4), while our method achieves 1.2% mIoU improvement (41.4 to 42.6).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated amino acids are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation.\""}, {"intention": "Concision", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated ones are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation. The probability density is defined over the d -dimensional torus T D = (S 1 ) D, and we show below our proposed flow-based architecture to model the density.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated amino acids are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated amino acids are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated ones are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation. The probability density is defined over the d -dimensional torus T D = (S 1 ) D, and we show below our proposed flow-based architecture to model the density.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated amino acids are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated amino acids are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"The prior rotamers j are inaccurate or unknown in many cases. For example, if we change some amino acids in the protein, the rotamers of the changed amino acids are unknown, and the rotamers of amino acids nearby the changed ones are inaccurate because they are affected by the change.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated amino acids are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated amino acids are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated ones are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation. The probability density is defined over the d -dimensional torus T D = (S 1 ) D, and we show below our proposed flow-based architecture to model the density.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"The prior rotamers j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated ones are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation. The probability density is defined over the d -dimensional torus T D = (S 1 ) D, and we show below our proposed flow-based architecture to model the density.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "instruction": "Replace every apparition of \"\"amino acids\" or \"amino acids in the protein complex\" by \"residues\"", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated amino acids are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation. The probability density is defined over the d -dimensional torus T D = (S 1 ) D, and we show below our proposed flow-based architecture to model the density.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "instruction": "Replace occurrences of amino acids by residues. Make this paragraph a lit bit more concise.", "revised_paragraph": "\"The prior rotamers   j are inaccurate or unknown in many cases. For example, if we mutate some amino acids in the protein complex, the rotamers of the mutated amino acids are unknown, and the rotamers of amino acids nearby the mutated ones are inaccurate because they are affected by the mutation.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For instance, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}, {"intention": "Concision", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). To recap, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For instance, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}, {"intention": "Concision", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). To recap, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). To recap, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For instance, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). To recap, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For instance, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For instance, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For instance, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For instance, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For instance, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\"\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). To recap, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). To recap, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). To recap, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). To recap, the input of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "instruction": "Make the text more concise by describing concepts more high-level.", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For example, to recap theinput of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "instruction": "Make the text more direct and concise.", "revised_paragraph": "\"Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For instance, recap theinput of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity. To address the first challenge, we argue the utmost importance of the model\u2019s capability to anticipate human motions and future states of the environment. To model these properties into the state representations, we incorporate World Dynamics Learning into the training of our model, i.e., learning with five auxiliary tasks to predict target\u2019s position, pedestrians\u2019 positions, self state, teammates\u2019 states and team reward.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity. To address the first challenge, we argue the utmost importance of the model\u2019s capability to anticipate human motions and future states of the environment. To model these properties into the state representations, we incorporate World Dynamics Learning into the training of our model, i.e., learning with five auxiliary tasks to predict target\u2019s position, pedestrians\u2019 positions, self state, teammates\u2019 states and team reward.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity. To address the first challenge, we argue the utmost importance of the model\u2019s capability to anticipate human motions and future states of the environment. To model these properties into the state representations, we incorporate World Dynamics Learning into the training of our model, i.e., learning with five auxiliary tasks to predict target\u2019s position, pedestrians\u2019 positions, self state, teammates\u2019 states and team reward.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity. To address the first challenge, we argue the utmost importance of the model\u2019s capability to anticipate human motions and future states of the environment. To model these properties into the state representations, we incorporate World Dynamics Learning into the training of our model, i.e., learning with five auxiliary tasks to predict target\u2019s position, pedestrians\u2019 positions, self state, teammates\u2019 states and team reward.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity. To address the first challenge, we argue the utmost importance of the model\u2019s capability to anticipate human motions and future states of the environment. To model these properties into the state representations, we incorporate World Dynamics Learning into the training of our model, i.e., learning with five auxiliary tasks to predict target\u2019s position, pedestrians\u2019 positions, self state, teammates\u2019 states and team reward.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity. To address the first challenge, we argue the utmost importance of the model\u2019s capability to anticipate human motions and future states of the environment. To model these properties into the state representations, we incorporate World Dynamics Learning into the training of our model, i.e., learning with five auxiliary tasks to predict target\u2019s position, pedestrians\u2019 positions, self state, teammates\u2019 states and team reward.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity. To address the first challenge, we argue the utmost importance of the model\u2019s capability to anticipate human motions and future states of the environment. To model these properties into the state representations, we incorporate World Dynamics Learning into the training of our model, i.e., learning with five auxiliary tasks to predict target\u2019s position, pedestrians\u2019 positions, self state, teammates\u2019 states and team reward.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity. To address the first challenge, we argue the utmost importance of the model\u2019s capability to anticipate human motions and future states of the environment. To model these properties into the state representations, we incorporate World Dynamics Learning into the training of our model, i.e., learning with five auxiliary tasks to predict target\u2019s position, pedestrians\u2019 positions, self state, teammates\u2019 states and team reward.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "instruction": "Rephrase the text", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "instruction": "Remove redundant words.", "revised_paragraph": "\"We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. In our approach, multiple camera agents perform seamless collaboration for successful reconstructions of 3D human poses. Additionally, it is a decentralized framework which offers flexibility over the size of formation and eliminates dependency to a control hierarchy or a centralized entity.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\" Shan et al. (2022) identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict  G s for all the mutations and rank them in ascending order (lowest  G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking  10%), and RDE-Network ranks them higher.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\" Shan et al. (2022) identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict  G s for all the mutations and rank them in ascending order (lowest  G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking  10%), and RDE-Network ranks them higher.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\" Shan et al. (2022) identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict  G s for all the mutations and rank them in ascending order (lowest  G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking  10%), and RDE-Network ranks them higher.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\" Shan et al. (2022) identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict  G s for all the mutations and rank them in ascending order (lowest  G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking  10%), and RDE-Network ranks them higher.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\" Shan et al. (2022) identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict  G s for all the mutations and rank them in ascending order (lowest  G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking  10%), and RDE-Network ranks them higher.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\" Shan et al. (2022) identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict G s for all the mutations and rank them in ascending order (lowest G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking 10%), and RDE-Network ranks them higher.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\" Shan et al. (2022) identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict  G s for all the mutations and rank them in ascending order (lowest  G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking  10%), and RDE-Network ranks them higher.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\" Shan et al. (2022) identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict  G s for all the mutations and rank them in ascending order (lowest  G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking  10%), and RDE-Network ranks them higher.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "instruction": "Fluidify this paragraph.", "revised_paragraph": "\" Shan et al. identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict  G s for all the mutations and rank them in ascending order (lowest  G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking  10%), and RDE-Network ranks them higher.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "instruction": "Improve the English in this paragraph in an academic style.", "revised_paragraph": "\" Shan et al. identifies 5 single-point mutations on a human antibody against SARS-CoV-2 that enhance neutralization (effectiveness). There are 494 possible single-point mutations on the heavy chain CDR region of the antibody in total. We use the most competitive methods benchmarked in Section 4.1 to predict  G s for all the mutations and rank them in ascending order (lowest  G in the top). A predictor is considered more effective if it ranks more favorable mutations in the top place. Table 2 shows that RDE-Network and DDGPred successfully identify three mutations (Ranking  10%), and RDE-Network ranks them higher.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "instruction": "Rewrite the middle part of the paragraph to make it more better. Replace some words in the paragraph.", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "instruction": "Slightly revise for readability, you can reorganise ideas in sentences if necessary.", "revised_paragraph": "\"The task was created with reference to the previous study [25]. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. First, participants clicked on the start area, and the cursor was fixed at the center of the start area. Assuming the initial position of the cursor may affect the cursor path andthe performance of pointing, we strictly fixed a starting position of the trial. Participants clicked again at the starting position, and the trial began. The start area disappeared as a feedback for the beginning of the trial. They aimed at the target and ended the trial with the next click. If they clicked correctly on the target, we marked the trial as a success; else, the trial was marked as a failure (error). We presented a sound feedback in response to the success or failure of the trial.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}, {"intention": "Concision", "revised_paragraph": "\"Results As shown in Figure 3, | d util (f ) | increases along , especially when log(  )   5 and | d util (f ) | is positively correlated with R (f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util | and it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Results As shown in Figure 3, | d util (f ) | increases along , especially when log(  )   5 and | d util (f ) | is positively correlated with R (f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util | and it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Results As shown in Figure 3, | d util ( f ) | increases along with the log( ) 5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\"\""}, {"depth": 3, "intention": "Rewritting_medium", "revised_paragraph": "\"\"\"Results As shown in Figure 3, | d util ( f ) | increases along with the log( ) 5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\"\"\""}, {"depth": 4, "intention": "Concision", "revised_paragraph": "\"\"\"\"Results As shown in Figure 3, | d util (f ) | increases along with the log( ) 5 and is positively correlated with R (f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It supports the second conjecture in 3.2, which states that the stronger regularization we apply, the larger the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util | and it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\"\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Results As shown in Figure 3, | d util ( f ) | increases along, especially when log( ) 5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Results As shown in Figure 3, | d util (f ) | increases along , especially when log(  )   5 and | d util (f ) | is positively correlated with R (f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util | and it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Results As shown in Figure 3, | d util (f ) | increases along with the log( ) 5 and | d util (f ) | is positively correlated with R (f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util | and it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "instruction": "Split first sentence in two and delete the third sentence", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "instruction": "Exclude redundant expression.", "revised_paragraph": "\"Results As shown in Figure 3, | d util ( f ) | increases along , especially when log(  )   5 and | d util ( f ) | is positively correlated with R ( f ). In other words, the stronger the regularization, the larger the imbalance in utilization between modalities we obverse. It confirms the second conjecture in 3.2, which states that the stronger regularization we apply, the greedier the multi-modal learning process becomes. We see | d speed | follows the same trend as | d util |. Again, it supports our choice of using the conditional learning speed to predict the conditional utilization rate.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Study design For each task, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Study design For each task, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Study design For each task, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Study design For each task, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Study design For each task, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Study design For each task, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Study design For each task, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Study design For each task, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "instruction": "Improve the understandability of the entire paragraph", "revised_paragraph": "\"Study design For each task introduced in 5.1, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "instruction": "The wording in this paragraph is confusing, please improve the readability.", "revised_paragraph": "\"Study design For each task introduced in 5.1, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system is  P 2 -hard, there are practical methods that can compositionally compute upper bounds on the diameter."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system is  P 2 -hard, there are practical methods that can compositionally compute upper bounds on the diameter."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system is  P 2 -hard, there are practical methods that can compositionally compute upper bounds on the diameter."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system is  P 2 -hard, there are practical methods that can compositionally compute upper bounds on the diameter."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system is  P 2 -hard, there are practical methods that can compositionally compute upper bounds on the diameter."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system is  P 2 -hard, there are practical methods that can compositionally compute upper bounds on the diameter."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system is  P 2 -hard, there are practical methods that can compositionally compute upper bounds on the diameter."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system is  P 2 -hard, there are practical methods that can compositionally compute upper bounds on the diameter."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "instruction": "Remove unnecessary details.", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system, and succinct digraphs more generally, is  P 2 -hard (Hemaspaandra et al. 2010), there are practical methods that can compositionally compute upper bounds on the diameter (Baumgartner, Kuehlmann, and Abraham 2002; Rintanen and Gretton 2013; Abdulaziz, Gretton, and\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "instruction": "Concise by removing unnecessary details.", "revised_paragraph": "\"First, it is the tightest topological property of state spaces that has been studied in the literature of model checking and planning, as far as we know. Secondly, although the worst-case complexity of computing the diameter for a factored transition system, and succinct digraphs more generally, is  P 2 -hard, there are practical methods that can compositionally compute upper bounds on the diameter (Baumgartner, Kuehlmann, and Abraham 2002; Rintanen and Gretton 2013; Abdulaziz, Gretton, and\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "instruction": "Rephrase the paragraph", "revised_paragraph": "\"MCMC uses a random forest as a transition kernel that preserves the target distribution and constructs a Markov chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Besides that it is general, if enough computation is performed, the Markov chain generates correct samples from any target distribution, no matter how complex the distribution is.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "instruction": "Balance sentences length.", "revised_paragraph": "\"In MCMC, one chooses a transition kernel that leaves the target distribution invariant and constructs a Markov Chain by applying the kernel repeatedly. The MCMC method relies only on the ergodicity assumption. Other than that it is general, if enough computation is performed, the Markov Chain generates correct samples from any target distribution, no matter how complex the distribution is.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly relies on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}, {"intention": "Content_deletion", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly relies on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}, {"intention": "Concision", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}, {"intention": "Rewritting_heavy", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly relies on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}, {"intention": "Content_deletion", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly relies on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly relies on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"\"In this paper, we find that model-based offline RL's performance significantly relies on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"In this paper, we find that model-based offline RL's performance depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "\"\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "instruction": "Make this paragraph more concise by rewriting the second half.", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly relies on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "instruction": "Make this paragraph shorter.", "revised_paragraph": "\"In this paper, we find that model-based offline RL's performance significantly depends on the trade-off between model return and its uncertainty, while determining the optimal trade-off is usually challenging or intractable without access to the environment that the learned policy will be deployed to. We develop a simple and principal method, Pareto policy pool (P3), that produces a pool of diverse policies on the Pareto front performing different levels of trade-offs, providing the flexibility to select the best policy for each realistic environment from the pool. On the D4RL benchmark, P3 substantially outperforms several recent baseline methods over multiple tasks and shows the potentiality of learning a generalizable policy when the quality of pre-collected experiences is low.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. In general, image SR is ill-posed as a many-to-one mapping problem. To alleviate this problem, plenty of deep convolutional neural networks (CNNs) (Dong et al., 2014; 2016; Kim et al., 2016b; Tai et al., 2017b) have been investigated to achieve accurate mapping from LR image to its HR target.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. In general, image SR is ill-posed as a many-to-one mapping problem. To alleviate this problem, plenty of deep convolutional neural networks (CNNs) (Dong et al., 2014; 2016; Kim et al., 2016b; Tai et al., 2017b) have been investigated to achieve accurate mapping from LR image to its HR target.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. In general, image SR is ill-posed as a many-to-one mapping problem. To alleviate this problem, plenty of deep convolutional neural networks (CNNs) (Dong et al., 2014; 2016; Kim et al., 2016b; Tai et al., 2017b) have been investigated to achieve accurate mapping from LR image to its HR target.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. In general, image SR is ill-posed as a many-to-one mapping problem. To alleviate this problem, plenty of deep convolutional neural networks (CNNs) (Dong et al., 2014; 2016; Kim et al., 2016b; Tai et al., 2017b) have been investigated to achieve accurate mapping from LR image to its HR target.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. In general, image SR is ill-posed as a many-to-one mapping problem. To alleviate this problem, plenty of deep convolutional neural networks (CNNs) (Dong et al., 2014; 2016; Kim et al., 2016b; Tai et al., 2017b) have been investigated to achieve accurate mapping from LR image to its HR target.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. In general, image SR is ill-posed as a many-to-one mapping problem. To alleviate this problem, plenty of deep convolutional neural networks (CNNs) (Dong et al., 2014; 2016; Kim et al., 2016b; Tai et al., 2017b) have been investigated to achieve accurate mapping from LR image to its HR target.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. In general, image SR is ill-posed as a many-to-one mapping problem. To alleviate this problem, plenty of deep convolutional neural networks (CNNs) (Dong et al., 2014; 2016; Kim et al., 2016b; Tai et al., 2017b) have been investigated to achieve accurate mapping from LR image to its HR target.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. In general, image SR is ill-posed as a many-to-one mapping problem. To alleviate this problem, plenty of deep convolutional neural networks (CNNs) (Dong et al., 2014; 2016; Kim et al., 2016b; Tai et al., 2017b) have been investigated to achieve accurate mapping from LR image to its HR target.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "instruction": "Replace the citation to (Tai et al., 2017b) with a citation to (Zhang et al., 2018c; 2020; 2021). Improve the english of this paragraph.", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. In general, image SR is ill-posed as a many-to-one mapping problem. To alleviate this problem, plenty of deep convolutional neural networks (CNNs) (Dong et al., 2014; 2016; Kim et al., 2016b; Tai et al., 2017b) have been investigated to achieve accurate mapping from LR image to its HR target.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "instruction": "Make the langage of this paragraph a bit more simple.", "revised_paragraph": "\"Image super-resolution (SR) is a fundamental computer vision task, which aims to recover a high-resolution image from its low-resolution counterpart. To address this problem, many deep convolutional neural networks (CNNs) have been investigated to achieve accurate mapping from LR image to its HR target.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}, {"intention": "Concision", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "instruction": "Rewrite the second sentence of the paragraph and improve the English in the remainder", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "instruction": "Make this paragraph more concise, keeping the main points of each sentence.", "revised_paragraph": "\"We compare the version of AGILE where the GAT only receives action features as input and no state. Thus, the decision-choice is still aware of other actions, but the learned relations are fixed, not dependent on the state. Figure 7 shows a drop in performance for Grid World and CREATE, where the relevant action relations change based on the state. However, there is no drop in RecSim because CPR task only requires knowing the most common category, which is independent of user state.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Recently, deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever (Rives et al., 2019; Jumper et al., 2021). However, the lack of structural information on mutated protein-protein complexes hinders supervised learning as the insufficiency of training data tends to cause over-fitting.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Recently, deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever (Rives et al., 2019; Jumper et al., 2021). However, the lack of structural information on mutated protein-protein complexes hinders supervised learning as the insufficiency of training data tends to cause over-fitting.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Recently, deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever (Rives et al., 2019; Jumper et al., 2021). However, the lack of structural information on mutated protein-protein complexes hinders supervised learning as the insufficiency of training data tends to cause over-fitting.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Recently, deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever (Rives et al., 2019; Jumper et al., 2021). However, the lack of structural information on mutated protein-protein complexes hinders supervised learning as the insufficiency of training data tends to cause over-fitting.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Recently, deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever (Rives et al., 2019; Jumper et al., 2021). However, the lack of structural information on mutated protein-protein complexes hinders supervised learning as the insufficiency of training data tends to cause over-fitting.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Recently, deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever (Rives et al., 2019; Jumper et al., 2021). However, the lack of structural information on mutated protein-protein complexes hinders supervised learning as the insufficiency of training data tends to cause over-fitting.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Recently, deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever (Rives et al., 2019; Jumper et al., 2021). However, the lack of structural information on mutated protein-protein complexes hinders supervised learning as the insufficiency of training data tends to cause over-fitting.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Recently, deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever (Rives et al., 2019; Jumper et al., 2021). However, the lack of structural information on mutated protein-protein complexes hinders supervised learning as the insufficiency of training data tends to cause over-fitting.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "instruction": "Rewrite the following paragraph using a more formal language.", "revised_paragraph": "Deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever. However, there are several challenges in developing deep learning-based models to predict mutational effects on protein-protein binding.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "instruction": "Rewrite this paragraph for better readability.", "revised_paragraph": "\"Recently, deep learning has gained tremendous success in modeling proteins, making data-driven methods more appealing than ever (Rives et al., 2019; Jumper et al., 2021). However, the lack of structural information on mutated protein-protein complexes hinders supervised learning as the insufficiency of training data tends to cause over-fitting.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "instruction": "Remove unnecessary words and fix the words if they are not in the correct form", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "instruction": "Remove terms that might be considered biased. Make the writing more clear.", "revised_paragraph": "\"AGILE clearly outperforms all the baselines demonstrating that relational knowledge of other available actions is crucial for an optimal policy. RecSim and Real RecSys : result trends are consistent with CREATE, but less pronounced for Real RecSys. Additionally, DQN is worse than CDQNbased architectures because the top-K greedy list action building ignores list interdependence.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Our contribution is twofold. First, we propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"We propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Our contribution is twofold. First, we propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Our contribution is twofold. First, we propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"We propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Our contribution is twofold. First, we propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "instruction": "Rewrite this paragraph for improved readability.", "revised_paragraph": "\"Our contribution is twofold. First, we propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "instruction": "Rewrite this paragraph to make it more readable and fitting to the academic style.", "revised_paragraph": "\"We propose the design of calen- dars that support medication prescriptions. The calendars allow for the scheduling of medication alongside other everyday activities and provide a way for rendering and resolving scheduling conflicts when they are raised by unsafe drug interactions due to violation of administration constraints specified in the prescription. Second, we present the results of a qualitative study with twelve participants interact- ing with the calendar designs. Results indicate that calendars can be designed to support the integration of medication prescriptions and that people would generally be favorable to using a calendar to manage their medications, if the design does not deviate from familiar calendars. These results inform five additional design goals that an integrated calendar should address: the use of familiar design (DG2), avoiding clutter (DG3), allowing for personalization (DG3), supporting personal reflection (DG5), and highlighting for user attention (DG6).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Under the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown.\""}, {"intention": "Concision", "revised_paragraph": "\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Under the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown.\""}, {"intention": "Concision", "revised_paragraph": "\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Under the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C. However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Under the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C. However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "instruction": "Make this paragraph heavily more concise, keeping the main ideas.", "revised_paragraph": "\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown. Particularly for weakly-supervised segmentation, we only have sparsely labeled pixels in the image, resulting in much smaller sets of C + and C  and degraded learning efficiency.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "instruction": "Concise and improve this explanation to make it more easy to understand.", "revised_paragraph": "\"In the supervised setting, we can define the positive and negative sets as the same- and differentcategory pixels with respect to pixel i, which are denoted as C + and C . However, this idea is not applicable to weakly- or un-supervised setting, when the label at x i is unknown.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system which has many modes in section 5, then present our GFlowNet-based solution in section 4.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system which has many modes, then present our GFlowNet-based solution in section 4.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system which has many modes, then present our GFlowNet-based solution in section 4.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system which has many modes in section 5, then present our GFlowNet-based solution in section 4.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system which has many modes in section 5, then present our GFlowNet-based solution in section 4.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system which has many modes in section 5, then present our GFlowNet-based solution in section 4.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system which has many modes, then present our GFlowNet-based solution in section 4.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system which has many modes in section 5, then present our GFlowNet-based solution in section 4.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "instruction": "Make the citation in correct order.", "revised_paragraph": "\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system in which has many modes in section 5, then present our GFlowNet-based solution in section 4.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "instruction": "Revise this paragraph to present the sections in a coherent order.", "revised_paragraph": "\"Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system in which has many modes in section 5, then present our GFlowNet-based solution in section 4.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We simulate a representative RL environment by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We simulate a representative RL environment by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We simulate a representative RL environment by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We simulate a representative RL environment by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We simulate a representative RL environment by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We simulate a representative RL environment by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We simulate a representative RL environment by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We simulate a representative RL environment by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "instruction": "Rewrite the majority of the paragraph, avoiding we and writing in a more neutral tone.", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We train a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "instruction": "Rewrite and reorganize the paragraph to convey the ideas more clearly.", "revised_paragraph": "\"We collect interaction data for one month for a listwise online campaign recommender system. Users are represented by attributes such as age, occupation, and localities. Items attributes are also given such as text features, image features, and reward points of campaigns. We simulate a representative RL environment by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of the users. We train a VAE to learn action representations, which are given to the RL agent as input. The test data consists of 82,445 users and 58 items, about 30 of which are shared with the training items. We report the test reward for models trained with CDQN algorithm.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}, {"intention": "Concision", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The reminder should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The reminder should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}, {"intention": "Concision", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The reminder should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The reminder should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"Medication entries should have a marker that says the time that their reminder will be triggered. The reminder should not be for a whole day, but for a specific minute or time when the reminder is triggered.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The reminder should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Medication entries should have a marker that says the time that their reminder will be triggered. The reminder should not be for a whole day, but for a specific minute or time when the reminder is triggered.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The reminder should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The reminder should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "instruction": "Heavily remove details from this paragraph to make it more concise.", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The reminder should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "instruction": "Please condense my paragraph related to medication conflicts.", "revised_paragraph": "\"Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "instruction": "Use clearer expression, use concise words.", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "instruction": "Revise this paragraph to use clearer and more precise words.", "revised_paragraph": "\"Delayed augmentation. We experiment on the generalization when we start to use augmentationlately as 10M, 20M. As shown in Figure 2(d) and Figure 2(e), the generalization rapidly increases after using augmentation at 10M and 20M. Although we use augmentation later, the augmentation helps the generalization regardless of the usage timing. Golatkar et al. [9] shows that delayed augmentation cannot achieve as much as using augmentation during whole training in supervised-learning. However, (10, 25) improves the generalization comparable with (0, 25), which use augmentation throughouttraining, unlike supervised learning. However, when augmentation noticeably helps the training, suchas Figure 2(e), delayed augmentation struggles to follow earlier one in Figure 2(f), because the RLgradually improves the policy and trajectory by Markov property. Furthermore, RL has a limitednumber of samples unlike supervised learning, so using augmentation from the initial time is morecritical than supervised learning if augmentation helps the training.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\""}, {"intention": "Concision", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) has the same gradients for equal elements, which would make DSPN set-equivariant."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\""}, {"intention": "Concision", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) has the same gradients for equal elements, which would make DSPN set-equivariant."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "instruction": "Change the subject in the first sentence.", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "instruction": "Lightly revise this paragraph for better readability while trying to make it a little shorter without loosing informations.", "revised_paragraph": "\"Note that exclusive multiset-equivariance is not always obtained in DSPN, but depends on the choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which is based on sum pooling \u2013 has the same gradients for equal elements, which would make DSPN set-equivariant. It is specifically the use of the exclusively multiset-equivariant gradient of sorting that makes DSPN exclusively multiset-equivariant.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "instruction": "Make expression concise.", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "\"In this section, we introduce the greedy learner hypothesis to explain challenges observed in training multi-modal DNNs. Before describing our hypothesis, we start by discussing some assumptions on the multi-modal data and preliminary observations made in the literature on multi-modal learning.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "instruction": "Add a sentence to explain the last sentence.", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "instruction": "Improve the logical flow of the last half of the paragraph.", "revised_paragraph": "\"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. Hence, in the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. Then, in the backward pass,Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters  of the encoder. \"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1  1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1  1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1  1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1  1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1  1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1 1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1  1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1  1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "instruction": "Rephrase the paragraph", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1  1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "instruction": "Rephrase the first sentence.", "revised_paragraph": "\"As all figures in the FAUST data set are similarly meshed and oriented, breaking the gauge equivariance in higher layers can actually be beneficial. As shown in Weiler & Cesa (2019), symmetry can be broken by treating non-invariant features as invariant features as input to the final 1  1 convolution. Such architectures are equivariant on lower levels, while allowing orientation sensitivity at higher layers.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays [5]. The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays.\" The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays [5]. The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays.\" The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays [5]. The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays. The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays [5]. The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays.\" The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "instruction": "Improve the writing of this paragraph", "revised_paragraph": "\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays. The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "instruction": "Modify the logical flow of ideas improve the readability of the paragraph.", "revised_paragraph": "\"Patrick et al. proposed the Mouse Ether technique on finding out that when using multiple displays with different resolutions, a user loses the cursor because of unnatural cursor movement between displays [5]. The results showed that the technique improved performance by up to 28% by preventing unnatural warping when the cursor was moved between displays.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i (i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij (i, j = 1... n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i (i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij (i, j = 1... n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i (i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij (i, j = 1... n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i (i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij (i, j = 1... n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i (i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij (i, j = 1... n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i (i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij (i, j = 1... n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i (i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij (i, j = 1... n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i (i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij (i, j = 1... n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j"}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "instruction": "Replace every apparition of \"\"amino acids\" or \"amino acids in the protein complex\" by \"residues\"", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i (i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij (i, j = 1.. n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j,", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "instruction": "Replace all mentions of amino acid by 'residue'. Reorder sentences in a more logical order when needed.", "revised_paragraph": "\"Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i ( i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij ( i, j = 1.. n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Further improvement is expected if  is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\" which, however, is based on heuristics and, as shown in this paper, does not generalize well.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Further improvement is expected if  is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Further improvement is expected if  is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Further improvement is expected if  is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\" which, however, is based on heuristics and, as shown in this paper, does not generalize well.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Further improvement is expected if  is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\" which, however, is based on heuristics and, as shown in this paper, does not generalize well.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Further improvement is expected if is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\" which, however, is based on heuristics and, as shown in this paper, does not generalize well.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Further improvement is expected if  is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Further improvement is expected if  is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\" which, however, is based on heuristics and, as shown in this paper, does not generalize well.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "instruction": "Make the ideas in these paragraph more modular and easier to understand.", "revised_paragraph": "\"Further improvement is expected if  is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "instruction": "Concise this academic paragraph a bit and smooth out the writing.", "revised_paragraph": "\"Further improvement is expected if  is selected independently for each training sample as shown through the Sample-Dependent Focal Loss (FLSD-53) proposed in [19],\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "instruction": "Use \"half\" instead of \"semi.\"", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "instruction": "Replace all semi-circle by half-circle.", "revised_paragraph": "\"To visualize the advantage of our approach, considerthe semi-circle domain in Figure 1, adapted from [3]:a 2-dimensional agent must navigate to a goal, located somewhere on the semi-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional semi-circle.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Different line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}, {"intention": "Concision", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}, {"intention": "Concision", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Different line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Different line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Different line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Different line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "instruction": "Rewrite this paragraph to be considerably more concise.", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "instruction": "I want to trim my paragraph so that the readers can read more easily.", "revised_paragraph": "\"Conflict overlays were easily identifiable on all the designs. The user-preferred way to represent such conflicts is to use indicators for the position of medication entries that are involved in the conflict. The connectors for conflicting pairs should avoid thick solid lines, that create clutter. Instead, thin or dotted lines should be employed. While lines are effective in connecting conflicting entries, employing line style to indicate the nature of the conflict is contrariwise. Dif- ferent line styles may appear similar at a distance and hence fail in communicating the intended message. Line style should be carefully employed to imply an action.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE"}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "instruction": "Improve the english", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "instruction": "Use accurate words and expression.", "revised_paragraph": "\"Proactive Motion Capture Few previous works studied proactive motion capture with a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In comparison, more works studied the control of a multi-camera team. Among them, many are based on optimization with various system designs, including marker-based (N\u00e4geli et al., 2018; Tallamraju et al., 2019), two-stage system (Saini et al., 2019; Tallamraju et al., 2019), hierarchical system (Ho et al., 2021), etc. It is important to note that all the above methods deal with static occlusion sources or clean landscapes. Also, the common similarity shared by these works is the use of hand-crafted optimization objectives and some fixed-form camera formations. These factors resulted in poor adaptability to dynamic scenes saturated with uncertainties. Recently, RL-based methods received more attention due to their potential for dynamic formation adjustments. These works focused on active 3D HPE", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learm critical information under the disturbance of composed non-semantic representations.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learm critical information under the disturbance of composed non-semantic representations.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learm critical information under the disturbance of composed non-semantic representations.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learm critical information under the disturbance of composed non-semantic representations.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learm critical information under the disturbance of composed non-semantic representations.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learm critical information under the disturbance of composed non-semantic representations.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learm critical information under the disturbance of composed non-semantic representations.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learm critical information under the disturbance of composed non-semantic representations.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "instruction": "Change the idea of \"composition\" to \"ensemble\" if this paragraph. Fix any spelling mistake.", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modifies a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learn critical information under the disturbance of composed non-semantic representations.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "instruction": "Rewrite the first sentence. Improve English in this paragraph.", "revised_paragraph": "\"In addition, we combine EM and our proposed OPS together to craft a kind of composed unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this composing method under different training strategies and find that it can always keep effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the abilities to learn critical information under the disturbance of composed non-semantic representations.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"During training, the uni-modal branch largely focuses on the associated modality. The fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Both  y 0 and  y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"During training, the uni-modal branch largely focuses on the associated modality. The fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Both  y 0 and  y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"During training, the uni-modal branch largely focuses on the associated modality. The fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Both  y 0 and  y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"During training, the uni-modal branch largely focuses on the associated modality. The fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Both  y 0 and  y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"During training, the uni-modal branch largely focuses on the associated modality. The fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Both  y 0 and  y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"During training, the uni-modal branch largely focuses on the associated modality, but the fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Thus, both y 0 and y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"During training, the uni-modal branch largely focuses on the associated modality. The fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Both  y 0 and  y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"During training, the uni-modal branch largely focuses on the associated modality. The fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Both  y 0 and  y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "instruction": "Make the sentence understandable.", "revised_paragraph": "\"During training, the uni-modal branch largely focuses on the associated modality. The fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Both  y 0 and  y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "instruction": "Improve the wording of this paragraph.", "revised_paragraph": "\"During training, the uni-modal branch largely focuses on the associated modality. The fusion modules generate cross-modal context information from the uni-modal branches and pass it back to them. Both  y 0 and  y 1 depend on information from both modalities. We end up with two functions, f 0 and f 1, corresponding to the two uni-modal branches:\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution. More illustrations of trigger featuresare provided in App. A3.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution. More illustrations of trigger featuresare provided in App. A3.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution. More illustrations of trigger featuresare provided in App. A3.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution. More illustrations of trigger featuresare provided in App. A3.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution. More illustrations of trigger featuresare provided in App. A3.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution. More illustrations of trigger featuresare provided in App. A3.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution. More illustrations of trigger featuresare provided in App. A3.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution. More illustrations of trigger featuresare provided in App. A3.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "instruction": "Make this paragraph more concise.", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "instruction": "Make this paragraph a bit shorter.", "revised_paragraph": "\"Trigger Feature Hypothesis We hypothesize that the trigger features are sparsely encoded in only a few channels, while clean image features need to be encoded across many channels for the effective classification. This is a key difference from normal data features that are presumably distributed moreevenly across channels, which indicates that these two types of features might behave differently incertain situations, leading to our main technical contribution.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "instruction": "Rephrase this paragraph to make its goal and explanations much more clear.", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "instruction": "Rewrite this paragraph to bring the argument through the idea that the goal is to learn a pixel-wise feature for semantic segmentation.", "revised_paragraph": "\"Feature affinity. We consider propagating the labels from an annotated set to an unlabeled set by nearest neighbor search in the featurespace. We assume that semantic clusters emerge during training with sparse supervision, reinforced by aforementioned pixel-to-segment relationships. By propagating labels in the featurespace, we reinforce the learning of semantic clusters.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "instruction": "Update the last sentence and split it into two sentences to make it easier to understand", "revised_paragraph": "\"Bi-LSTM : The action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a bidirectional LSTM followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "instruction": "Split this paragraph into smaller and more focused points.", "revised_paragraph": "\"Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate can only be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate can only be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate can only be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate can only be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate can only be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate can only be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate can only be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate can only be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "instruction": "Make expression concrete, add conjunction.", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate can only be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "instruction": "Revise the wording of the middle sentence in this paragraph.", "revised_paragraph": "\"As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate was however can be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, the large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, the large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, the large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, the large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, the large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, the large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, the large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, the large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "instruction": "Improve the readablity of the text. Use more concise and straight-forward ideas.", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, a large amount of the information in such sentence embeddings is irrelevant to the target task, and it can be difficult to distinguish relevant from irrelevant information when fine-tuning the languagemodels with a large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "instruction": "Rewrite this paragraph to better fit the academic writing style.", "revised_paragraph": "\"NLP (Cherry et al., 2019). However, much of the information in such sentence embeddings is irrelevant to the target task, and it can be difficult to distinguish relevant from irrelevant information when fine-tuning the languagemodels with a large number of parameters on a small amount of target task data, resulting in over-fitting. For many real-world applications, it can be difficult and expensive tosolve this problem by collecting sufficient annotated data for these large neural models to excel.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"What makes OOD detection particularly challenging? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns"}, {"intention": "Concision", "revised_paragraph": "\"Why does OOD detection require a different approach? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"What makes OOD detection particularly challenging? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"What makes OOD detection particularly challenging? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"What makes OOD detection particularly challenging? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns"}, {"intention": "Concision", "revised_paragraph": "\"Why does OOD detection require a different approach? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"What makes OOD detection particularly challenging? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Why does it take so long to detect OODs? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"What makes OOD detection particularly challenging? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"What makes OOD detection particularly challenging? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"What makes OOD detection particularly challenging? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Why does it take so long to detect OODs? To explain this, modern neural networks are commonly optimized on thein-distribution (ID) data only, and lack explicit knowledge of unknowns during training time. The resulting decision boundary, despite being useful on ID tasks such as classification, can undesirably cover OOD data. We illustrate this in Figure 1. The ID data (gray) consists of three class-conditional Gaussians, on which a three-way softmax classifier is trained. The resulting classifier is overconfident for regions far away from the ID data (see the red shade in Figure 1(b)). When such models are directly employed, the decision boundary can be ill-fated for OOD detection. Ideally, a model should learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal of unknowns. This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge"}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "instruction": "Rewrite this paragraph to make it more concise and convincing.", "revised_paragraph": "\"Why does the lack of supervision signal of unknowns make it hard to comprehensively anticipate unknown data in advance?\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "instruction": "Rewrite this paragraph to make it more precise, clear and concise while fitting the academic style.", "revised_paragraph": "\"Why does the lack of explicit knowledge of unknowns during training time make it difficult to learn a more compact decision boundary that produces low uncertainty for the ID data, with high OOD uncertainty elsewhere ( e.g., Figure 1(c)). This prompts thefollowing question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "instruction": "Improve the English of the first sentence of this paragraph.", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "instruction": "Rephrase the two first sentences for better readability.", "revised_paragraph": "\"Prescriptions come with constraints associated with drug dosage units, frequency and indications. Constraints can occur within the same medication and between different medications. An example of within-medication constraints is found in the the prescription Take 600 mg of Ibuprofen three times a day as needed with food, that has three constraints: 1) that 600mg should be taken at a given time; 2) that the maximum number of intakes per day is three; and 3) that the drug must be taken with food. But medications are often more complex. Consider for example the following prescription:\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and a consequent over-segmentation. It assumes that each segment has an independent normal distribution on a hypersphere. Spherical K-Means clustering (Banerjee et al., 2005) is used for segmenting an image and learning the discriminative feature clustering jointly. It is worth noting that, such an assumption indicates homogeneous representations within each segment. To learn the embedding, SegSort formulates a maximum likelihood loss thatmaximizes the discrimination between segments. In addition, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}, {"intention": "Concision", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that learns a pixel-wise embedding of each image pixel, which can be used to predict the labels of the segments. Moreover, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"intention": "Concision", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that learns a pixel-wise embedding of each image pixel, which can be used to predict the labels of the segments. Moreover, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and a consequent over-segmentation. It assumes that each segment has an independent normal distribution on a hypersphere. Spherical K-Means clustering (Banerjee et al., 2005) is used for segmenting an image and learning the discriminative feature clustering jointly. It is worth noting that, such an assumption indicates homogeneous representations within each segment. To learn the embedding, SegSort formulates a maximum likelihood loss thatmaximizes the discrimination between segments. In addition, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}, {"intention": "Concision", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that learns a pixel-wise embedding of each image pixel, which can be used to predict the labels of the segments. Moreover, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"intention": "Concision", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that learns a pixel-wise embedding of each image pixel, which can be used to predict the labels of the segments. Moreover, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and a consequent over-segmentation. It assumes that each segment has an independent normal distribution on a hypersphere. Spherical K-Means clustering (Banerjee et al., 2005) is used for segmenting an image and learning the discriminative feature clustering jointly. It is worth noting that, such an assumption indicates homogeneous representations within each segment. To learn the embedding, SegSort formulates a maximum likelihood loss thatmaximizes the discrimination between segments. In addition, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that learns a pixel-wise embedding and a consequent over-segmentation. It assumes that each segment has an independent normal distribution on a hypersphere. Spherical K-Means clustering (Banerjee et al., 2005) is used for segmenting an image and learning the discriminative feature clustering jointly. It is worth noting that, such an assumption indicates homogeneous representations within each segment. To learn the embedding, SegSort formulates a maximum likelihood loss thatmaximizes the discrimination between segments. In addition, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that learns a pixel-wise embedding of each image pixel, which can be used to predict the labels of the segments. Moreover, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and a consequent over-segmentation. It assumes that each segment has an independent normal distribution on a hypersphere. Spherical K-Means clustering (Banerjee et al., 2005) is used for segmenting an image and learning the discriminative feature clustering jointly. It is worth noting that, such an assumption indicates homogeneous representations within each segment. To learn the embedding, SegSort formulates a maximum likelihood loss thatmaximizes the discrimination between segments. In addition, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that learns a pixel-wise embedding and a consequent over-segmentation. It assumes that each segment has an independent normal distribution on a hypersphere. Spherical K-Means clustering (Banerjee et al., 2005) is used for segmenting an image and learning the discriminative feature clustering jointly. It is worth noting that, such an assumption indicates homogeneous representations within each segment. To learn the embedding, SegSort formulates a maximum likelihood loss thatmaximizes the discrimination between segments. In addition, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that learns a pixel-wise embedding of each image pixel, which can be used to predict the labels of the segments. Moreover, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "instruction": "Reduce the explanations in this paragraph and just give a high level explanation, to keep it concise.", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that uses a pixel-wise embedding to learn the discriminative feature clustering jointly. Moreover, soft neighborhood assignment (Goldberger et al., 2005) is incorporated to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "instruction": "Make the explanation of SegSort shorter.", "revised_paragraph": "\"SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that uses a pixel-wise embedding to learn the discriminative feature clustering jointly. Moreover, soft neighborhood assignment (Goldberger et al., 2005) is used to enforce grouping of semantically similar segments. During inference, the segment labels are predicted by K-Nearest Neighbor retrievals.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To study its performance impact in a more constrained setting, SDN was paired with a VAE architecture much simpler than IAF-VAE. Apart from the implementation simplicity and shorter training time, a non-hierarchical VAE is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"To study its performance impact in a more constrained setting, SDN was paired with a VAE architecturely much simpler than IAF-VAE. Apart from the implementation simplicity and shorter training time, a non-hierarchical VAE is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"To study its performance impact in a more constrained setting, SDN was paired with a VAE architecturely much simpler than IAF-VAE. Apart from the implementation simplicity and shorter training time, a non-hierarchical VAE is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To study its performance impact in a more constrained setting, SDN was paired with a VAE architecture much simpler than IAF-VAE. Apart from the implementation simplicity and shorter training time, a non-hierarchical VAE is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To study its performance impact in a more constrained setting, SDN was paired with a VAE architecture much simpler than IAF-VAE. Apart from the implementation simplicity and shorter training time, a non-hierarchical VAE is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"To study its performance impact in a more constrained setting, SDN was paired with a VAE architecture much simpler than IAF-VAE. Apart from the implementation simplicity and shorter training time, a non-hierarchical VAE is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"To study its performance impact in a more constrained setting, SDN was paired with a VAE architecturely much simpler than IAF-VAE. Apart from the implementation simplicity and shorter training time, a non-hierarchical VAE is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To study its performance impact in a more constrained setting, SDN was paired with a VAE architecture much simpler than IAF-VAE. Apart from the implementation simplicity and shorter training time, a non-hierarchical VAE is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "instruction": "Make sentence precise.", "revised_paragraph": "\"To study its performance impact in a more constrained setting, SDN was paired with a VAE architecturely much simpler than IAF-VAE. Apart from the implementation simplicity and shorter training time, a non-hierarchical VAE is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "instruction": "Rephrase the second sentence, mostly focusing on the second half.", "revised_paragraph": "\"We experimented on a non-hierarchical VAE, which is more suitable for representation learning \u2013 there is a single stochastic vector and not a hierarchy of feature maps, which enables better control of the latent space. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder to the quality of learned latent representations.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"When the pruning process is finished, we remove the unimportant filters (not zeroing out them only, but literally removing them from the model), which results in a small model. Then we finetune the small model to regain performance following the common practice in pruning (Reed, 1993).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"When the pruning process is finished, we remove the unimportant filters (not zeroing out them only, but literally removing them from the model), which results in a small model. Then we finetune the small model to regain performance following the common practice in pruning (Reed, 1993).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"When the pruning process is finished, we remove the unimportant filters (not zeroing out them only, but literally removing them from the model), which results in a small model. Then we finetune the small model to regain performance following the common practice in pruning (Reed, 1993).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"When the pruning process is finished, we remove the unimportant filters (not zeroing out them only, but literally removing them from the model), which results in a small model. Then we finetune the small model to regain performance following the common practice in pruning (Reed, 1993).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"When the pruning process is finished, we remove the unimportant filters (not zeroing out them only, but literally removing them from the model), which results in a small model. Then we finetune the small model to regain performance following the common practice in pruning (Reed, 1993).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"When the pruning process is finished, we remove the unimportant filters (not zeroing out them only, but literally removing them from the model), which results in a small model. Then we finetune the small model to regain performance following the common practice in pruning (Reed, 1993).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"When the pruning process is finished, we remove the unimportant filters (not zeroing out them only, but literally removing them from the model), which results in a small model. Then we finetune the small model to regain performance following the common practice in pruning (Reed, 1993).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"When the pruning process is finished, we remove the unimportant filters (not zeroing out them only, but literally removing them from the model), which results in a small model. Then we finetune the small model to regain performance following the common practice in pruning (Reed, 1993).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "instruction": "Please rephrase my paragraph.", "revised_paragraph": "\"We remove the unimportant filters (not just zeroing them, but literally removing them from the model), which gives us a small model, and then we finetune it to get back its performance, as is common practice in pruning (Reed, 1993).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "instruction": "Revise this academic paragraph for readability.", "revised_paragraph": "\"When the pruning process is finished, we remove the unimportant filters (not zeroing out them only, but literally removing them from the model), which results in a small model. Then we finetune the small model to regain performance following the common practice in pruning (Reed, 1993).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \u2022 If a data point is instead rejected by the biased classifier we use our de-biased classifier to decide whether to add it to the Pseudo-label dataset from PLOT. \u2022 We then apply the Pseudo-label mechanism from PLOT, i.e. retraining on optimistic lables, on these candidates to decide final acceptance.\""}, {"intention": "Concision", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \u2022 If a data point is instead rejected by the biased classifier we use our de-biased classifier to decide whether to add it to the Pseudo-label dataset from PLOT. \u2022 We then apply the Pseudo-label mechanism from PLOT, i.e. retraining on optimistic lables, on these candidates to decide final acceptance.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \u2022 If a data point is instead rejected by the biased classifier we use our de-biased classifier to decide whether to add it to the Pseudo-label dataset from PLOT. \u2022 We then apply the Pseudo-label mechanism from PLOT, i.e. retraining on optimistic lables, on these candidates to decide final acceptance.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \""}, {"intention": "Rewritting_light", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \u2022 If a data point is instead rejected by the biased classifier we use our de-biased classifier to decide whether to add it to the Pseudo-label dataset from PLOT. \u2022 We then apply the Pseudo-label mechanism from PLOT, i.e. retraining on optimistic lables, on these candidates to decide final acceptance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \u2022 If a data point is instead rejected by the biased classifier we use our de-biased classifier to decide whether to add it to the Pseudo-label dataset from PLOT. \u2022 We then apply the Pseudo-label mechanism from PLOT, i.e. retraining on optimistic lables, on these candidates to decide final acceptance.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \u2022 If a data point is instead rejected by the biased classifier we use our de-biased classifier to decide whether to add it to the Pseudo-label dataset from PLOT. \u2022 We then apply the Pseudo-label mechanism from PLOT, i.e. retraining on optimistic lables, on these candidates to decide final acceptance.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \u2022 If a data point is instead rejected by the biased classifier we use our de-biased classifier to decide whether to add it to the Pseudo-label dataset from PLOT. \u2022 We then apply the Pseudo-label mechanism from PLOT, i.e. retraining on optimistic lables, on these candidates to decide final acceptance.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "instruction": "Rewrite the bullet points, making them more independent and preferring active over passive formulations", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \u2022 If a data point is instead rejected by the biased classifier we use our de-biased classifier to decide whether to add it to the Pseudo-label dataset from PLOT. \u2022 We then apply the Pseudo-label mechanism from PLOT, i.e. retraining on optimistic lables, on these candidates to decide final acceptance.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "instruction": "Shorten the last sentence. Make this paragraph more direct.", "revised_paragraph": "\"\u2022 If a data point is accepted by the biased classifier, it is accepted and added to the dataset with the true label. \u2022 If a data point is instead rejected by the biased classifier we use our de-biased classifier to decide whether to add it to the Pseudo-label dataset from PLOT.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Importantly, it is equipped with a simple normalization of the layer's activations, and an optional temperature-scaling mechanism (Hinton et al., 2015), producing a soft WTA instead of selecting a single \"hard\" winner neuron. This allows us to prove formally that a SoftHebb layer is a generative mixture model that objectively minimizes its Kullback-Leibler (KL) divergence from the input distribution through Bayesian inference, thus providing a new theoretical perspective of these networks.\""}, {"intention": "Concision", "revised_paragraph": "\"We demonstrate that our model can learn faster and more accurately than a supervised two-layer perceptron, and it is robust to both generative and adversarial attacks, including projected gradient descent (PGD) (Madry et al., 2017), and without any explicit defence.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We demonstrate that our model can learn faster and more accurately than a supervised two-layer perceptron, and it is robust to both generative and adversarial attacks, including projected gradient descent (PGD) (Madry et al., 2017), and without any explicit defence.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We demonstrate that our model can learn faster and more accurately than a supervised two-layer perceptron, and it is robust to both generative and adversarial attacks, including projected gradient descent (PGD) (Madry et al., 2017), and without any explicit defence.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Importantly, it is equipped with a simple normalization of the layer's activations, and an optional temperature-scaling mechanism (Hinton et al., 2015), producing a soft WTA instead of selecting a single \"hard\" winner neuron. This allows us to prove formally that a SoftHebb layer is a generative mixture model that objectively minimizes its Kullback-Leibler (KL) divergence from the input distribution through Bayesian inference, thus providing a new theoretical perspective of these networks.\""}, {"intention": "Concision", "revised_paragraph": "\"We demonstrate that our model can learn faster and more accurately than a supervised two-layer perceptron, and it is robust to both generative and adversarial attacks, including projected gradient descent (PGD) (Madry et al., 2017), and without any explicit defence.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Importantly, it is equipped with a simple normalization of the layer's activations, and an optional temperature-scaling mechanism (Hinton et al., 2015), producing a soft WTA instead of selecting a single \"hard\" winner neuron. This allows us to prove formally that a SoftHebb layer is a generative mixture model that objectively minimizes its Kullback-Leibler (KL) divergence from the input distribution through Bayesian inference, thus providing a new theoretical perspective of these networks.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Importantly, it is equipped with a simple normalization of the layer's activations, and an optional temperature-scaling mechanism (Hinton et al., 2015), which allows us to prove formally that a SoftHebb layer is a generative mixture model that objectively minimizes its Kullback-Leibler (KL) divergence from the input distribution through Bayesian inference, thus providing a new theoretical perspective of these networks.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We demonstrate that our model can learn faster and more accurately than a supervised two-layer perceptron, and it is robust to both generative and adversarial attacks, including projected gradient descent (PGD) (Madry et al., 2017), and without any explicit defence.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We demonstrate that our model can learn faster and more accurately than a supervised two-layer perceptron, and it is robust to both generative and adversarial attacks, including projected gradient descent (PGD) (Madry et al., 2017), and without any explicit defence.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Importantly, it is equipped with a simple normalization of the layer's activations, and an optional temperature-scaling mechanism (Hinton et al., 2015), producing a soft WTA instead of selecting a single \"hard\" winner neuron. This allows us to prove formally that a SoftHebb layer is a generative mixture model that objectively minimizes its Kullback-Leibler (KL) divergence from the input distribution through Bayesian inference, thus providing a new theoretical perspective of these networks.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Importantly, it is equipped with a simple normalization of the layer's activations, and an optional temperature-scaling mechanism (Hinton et al., 2015), which allows us to prove formally that a SoftHebb layer is a generative mixture model that objectively minimizes its Kullback-Leibler (KL) divergence from the input distribution through Bayesian inference, thus providing a new theoretical perspective of these networks.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "instruction": "Make this paragraph shorter by removing details.", "revised_paragraph": "\"We demonstrate that our model can learn faster and more accurately than a supervised two-layer perceptron, and it is robust to both generative and adversarial attacks. Our model also exhibits inherent properties of deflection (Qin et al., 2020) of the adversarial attacks, and generates object interpolations.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "instruction": "Summarize the middle of the paragraph to make it shorter and more concise. Remove unnecessary details.", "revised_paragraph": "\"We demonstrate that our model can learn faster and more accurately than a supervised two-layer perceptron, and it is robust to one of the strongest white-box adversarial attacks, i.e. projected gradient descent (PGD) (Madry et al., 2017), and without any explicit defence.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach. Zhao et al. ; Grcic et al. (2021) trained a generative model and synthesize outliers in the pixel space, which cannot be applied to object detection where a scene consists of both known and unknown objects. Their regularization terms are based on entropy maximization, which is different from VOS.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach. Zhao et al. ; Grcic et al. (2021) trained a generative model and synthesize outliers in the pixel space, which cannot be applied to object detection where a scene consists of both known and unknown objects. Their regularization terms are based on entropy maximization, which is different from VOS.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach. Zhao et al. ; Grcic et al. (2021) trained a generative model and synthesize outliers in the pixel space, which cannot be applied to object detection where a scene consists of both known and unknown objects. Their regularization terms are based on entropy maximization, which is different from VOS.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach. Zhao et al. ; Grcic et al. (2021) trained a generative model and synthesize outliers in the pixel space, which cannot be applied to object detection where a scene consists of both known and unknown objects. Their regularization terms are based on entropy maximization, which is different from VOS.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach. Zhao et al. ; Grcic et al. (2021) trained a generative model and synthesize outliers in the pixel space, which cannot be applied to object detection where a scene consists of both known and unknown objects. Their regularization terms are based on entropy maximization, which is different from VOS.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach. Zhao et al. ; Grcic et al. (2021) trained a generative model and synthesize outliers in the pixel space, which cannot be applied to object detection where a scene consists of both known and unknown objects. Their regularization terms are based on entropy maximization, which is different from VOS.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach. Zhao et al. ; Grcic et al. (2021) trained a generative model and synthesize outliers in the pixel space, which cannot be applied to object detection where a scene consists of both known and unknown objects. Their regularization terms are based on entropy maximization, which is different from VOS.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach. Zhao et al. ; Grcic et al. (2021) trained a generative model and synthesize outliers in the pixel space, which cannot be applied to object detection where a scene consists of both known and unknown objects. Their regularization terms are based on entropy maximization, which is different from VOS.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "instruction": "Shorten this paragraph.", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "instruction": "Make the first sentence a lot shorter.", "revised_paragraph": "\"Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, which is a post-hoc approach.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "instruction": "Change some words in this paragraph for the better ", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "instruction": "Improve the linking between ideas to make the paragraph more precise and readable.", "revised_paragraph": "\"Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize self-attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize self-attentions heads separately from one point.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize self-attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize self-attentions heads separately from one point.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize self-attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize self-attentions heads separately from one point.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize self-attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize self-attentions heads separately from one point.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize self-attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize self-attentions heads separately from one point.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize self-attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize self-attentions heads separately from one point.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize self-attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize self-attentions heads separately from one point.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize self-attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize self-attentions heads separately from one point.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "instruction": "Revise this paragraph to be more concise.", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize self-attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize self-attentions heads separately from one point.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "instruction": "This paragraph need to be shorter, do it by removing details but don\u2019t touch the first sentence.", "revised_paragraph": "\"Attention mechanism in transformer is the key component which models relations between feature representations. In this section, we visualize the attention mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. In Figure 8, we visualize attention heads from different points. These attention heads exhibit different behaviours that seem related to structure, semantic and color respectively. These visualizations show how the Entroformer finds related context to support its distribution prediction for the current latent. This allows the Entroformer to capture richer dependencies of the latents and achieve better compression performance. In Figure 9, we visualize attention heads separately from one point.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "instruction": "Improve the paragraph.", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). Marrying filter pruning with image SR seems a plausible solution to strike a better performance-complexity trade-off. However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "instruction": "Rewrite the third sentence using more appropriate language.", "revised_paragraph": "\"On the other hand, neural network pruning is well-known as an effective technique to reduce model complexity (Reed, 1993; Sze et al., 2017). For acceleration, researchers mainly focus on filter pruning (a.k.a. structured pruning) (Li et al., 2017) rather than weight-element pruning (a.k.a. unstructured pruning) (Han et al., 2015; 2016b). However, filter pruning methods in classification can hardly translate to SR networks directly. The main reason is that, residual connections are well-known hard to prune in structured pruning (Li et al., 2017) while they are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) has 32 residual blocks; RCAN (Zhang et al., 2018b) even has nested residual blocks).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We start from defining two disjoint sets \u2013 positive and negative segments (exemplars) with respect to pixel i. Our goal is to group i with positive segments while separating it from negative ones. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is to decrease (increase) the distance between  (i ) and its positive (negative) segments.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We start from defining two disjoint sets \u2013 positive and negative segments (exemplars) with respect to pixel i. Our goal is to group i with positive segments while separating it from negative ones. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is to decrease (increase) the distance between  (i ) and its positive (negative) segments.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We start from defining two disjoint sets \u2013 positive and negative segments (exemplars) with respect to pixel i. Our goal is to group i with positive segments while separating it from negative ones. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is to decrease (increase) the distance between  (i ) and its positive (negative) segments.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We start from defining two disjoint sets \u2013 positive and negative segments (exemplars) with respect to pixel i. Our goal is to group i with positive segments while separating it from negative ones. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is to decrease (increase) the distance between  (i ) and its positive (negative) segments.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We start from defining two disjoint sets \u2013 positive and negative segments (exemplars) with respect to pixel i. Our goal is to group i with positive segments while separating it from negative ones. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is to decrease (increase) the distance between  (i ) and its positive (negative) segments.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We start from defining two disjoint sets \u2013 positive and negative segments (exemplars) with respect to pixel i. Our goal is to group i with positive segments while separating it from negative ones. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is to decrease (increase) the distance between  (i ) and its positive (negative) segments.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We start from defining two disjoint sets \u2013 positive and negative segments (exemplars) with respect to pixel i. Our goal is to group i with positive segments while separating it from negative ones. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is to decrease (increase) the distance between  (i ) and its positive (negative) segments.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We start from defining two disjoint sets \u2013 positive and negative segments (exemplars) with respect to pixel i. Our goal is to group i with positive segments while separating it from negative ones. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is to decrease (increase) the distance between  (i ) and its positive (negative) segments.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "instruction": "Make this paragraph heavily more concise in the explanations made.", "revised_paragraph": "\"Metric learning develops a feature representation based on data grouping and separation cues. Our method (Fig. 3) segments an image by learning a pixel-wise embedding with a contrastive loss between pixels and segments. We start from defining two disjoint sets \u2013 positive and negative segments with respect to pixel i. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is to decrease (increase) the distance between  (i ) and its positive (negative) segments.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "instruction": "Don't give to much details about the method of learning, just keep the main idea.", "revised_paragraph": "\"Metric learning develops a feature representation based on data grouping and separation cues. Our method (Fig. 3) segments an image by learning a pixel-wise embedding with a contrastive loss between pixels and segments. We start from defining two disjoint sets \u2013 positive and negative segments (exemplars) with respect to pixel i. Given latent feature  (i ) at pixel iand a specific distance metric, the objective is todecrease (increase) the distance between  (i ) and its positive (negative) segments.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also verifies that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}, {"intention": "Concision", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also shows that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also verifies that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also shows that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also verifies that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also verifies that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also verifies that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also shows that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also verifies that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also shows that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also shows that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also verifies that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "instruction": "Remove redundant details. Use more precise words.", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also verifies that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "instruction": "Make it more precise when necessary.", "revised_paragraph": "\"We now introduce the theorem, which offers a guideline on the neural network architecture for operator learning. It suggests that if the entire architecture can be replaced with a fully connected neural network, large complexity should be required for training. It also verifies that the lower bound for a universal activation function is a sharp bound on the number of parameters. We note here an assumption, which is a sufficient condition for proving the theorem.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights in a setting of regular probability measures. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010) demonstrates the method's efficiency and necessity to have a method that is applicable for general probability measures. The approach still works without restricting optimal weights to be in the unit simplex, which would allow for extrapolation beyond the convex hull of the control units, providing a notion of tangential regression. It can also be extended to a continuum of measures, using established consistency results of barycenters ("}, {"intention": "Concision", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights in a setting of regular probability measures. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010) demonstrates the method's efficiency and necessity to have a method that is applicable for general probability measures. The approach still works without restricting optimal weights to be in the unit simplex, which would allow for extrapolation beyond the convex hull of the control units, providing a notion of tangential regression. It can also be extended to a continuum of measures, using established consistency results of barycenters ("}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights in a setting of regular probability measures. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010) demonstrates the method's efficiency and necessity to have a method that is applicable for general probability measures. The approach still works without restricting optimal weights to be in the unit simplex, which would allow for extrapolation beyond the convex hull of the control units, providing a notion of tangential regression. It can also be extended to a continuum of measures, using established consistency results of barycenters ("}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. We construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "instruction": "Please, make this paragraph mor concise, delete unnecessary details", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "instruction": "Combine sentences 3 and 4 into a really short one keeping only the main idea. Improve the choice of wording.", "revised_paragraph": "\"We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights. For general probability measures, we construct our projection by first creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account H. Zhang et al. [28] proposed to balance the effects of W and H (Eq. 2).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account both W and H (Eq. 2).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account H. Zhang et al. [28] proposed to balance the effects of W and H (Eq. 2).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account both W and H (Eq. 2).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account H. Zhang et al. [28] proposed to balance the effects of W and H (Eq. 2).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account H. Zhang et al. [28] proposed to balance the effects of W and H (Eq. 2).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account H. Zhang et al. [28] proposed to balance the effects of W and H (Eq. 2).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account both W and H (Eq. 2).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "instruction": "Rewrite this paragraph and focus more on the first sentence", "revised_paragraph": "\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account both W and H (Eq. 2).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "instruction": "Improve this paragraph for clarity, mainly the first sentence.", "revised_paragraph": "\"Because typical targets on GUIs are rectangular, target height ( H ) also affects the movement time [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for a bivariate (2D) pointing task that takes into account H. Zhang et al. [28] proposed to balance the effects of W and H (Eq. 2).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"In summary, our contributions include: 1) proposing a novel (, )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "instruction": "Make the sentence precise.", "revised_paragraph": "\"In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "instruction": "Improve english in this text.", "revised_paragraph": "\"In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support. To achieve this, we work in the 2Wasserstein space, that is, the set of all probability measures with finite second moments equipped with the 2 -Wasserstein distance.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support. To achieve this, we work in the 2Wasserstein space, that is, the set of all probability measures with finite second moments equipped with the 2 -Wasserstein distance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support. To achieve this, we work in the 2Wasserstein space, that is, the set of all probability measures with finite second moments equipped with the 2 -Wasserstein distance.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support. To achieve this, we work in the 2Wasserstein space, that is, the set of all probability measures with finite second moments equipped with the 2 -Wasserstein distance.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support. To achieve this, we work in the 2Wasserstein space, that is, the set of all probability measures with finite second moments equipped with the 2 -Wasserstein distance.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "instruction": "Please, make this paragraph easier to read.", "revised_paragraph": "\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "instruction": "Rewrite and reorganise this paragraph to improve the english and be more convincing, let the last sentence as it is.", "revised_paragraph": "\"We introduce a notion of projection between sets of probability measures supported on Euclidean spaces. The proposed definition is applicable between sets of general probability measures with different supports and possesses good computational and statistical properties. Italso provides a unique solution to the projection problem under mild conditions and can replicate the geometric properties of the target measure, such as its shape and support. To achieve this, we work in the 2Wasserstein space, that is, the set of all probability measures with finite second moments equipped with the 2 -Wasserstein distance.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"intention": "Concision", "revised_paragraph": "MLP-based Architectures. Res-MLP (Touvron et al., 2021a) is proposed, which also obtains impressive performance with residual MLP only trained on ImageNet1K. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and external attention to improve the performance of the pure MLP-based architecture, respectively."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"intention": "Concision", "revised_paragraph": "MLP-based Architectures. Res-MLP (Touvron et al., 2021a) is proposed, which also obtains impressive performance with residual MLP only trained on ImageNet1K. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and external attention to improve the performance of the pure MLP-based architecture, respectively."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"intention": "Concision", "revised_paragraph": "MLP-based Architectures. Res-MLP (Touvron et al., 2021a) is proposed, which also obtains impressive performance with residual MLP only trained on ImageNet1K. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and external attention to improve the performance of the pure MLP-based architecture, respectively."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"intention": "Concision", "revised_paragraph": "MLP-based Architectures. Res-MLP (Touvron et al., 2021a) is proposed, which also obtains impressive performance with residual MLP only trained on ImageNet1K. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and external attention to improve the performance of the pure MLP-based architecture, respectively."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "MLP-based Architectures. Res-MLP (Touvron et al., 2021a) is proposed, which also obtains impressive performance with residual MLP only trained on ImageNet1K. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and external attention to improve the performance of the pure MLP-based architecture, respectively."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "MLP-based Architectures. Res-MLP (Touvron et al., 2021a) is proposed, which also obtains impressive performance with residual MLP only trained on ImageNet1K. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and external attention to improve the performance of the pure MLP-based architecture, respectively."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "MLP-based Architectures. Res-MLP (Touvron et al., 2021a) is proposed, which also obtains impressive performance with residual MLP only trained on ImageNet1K. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and external attention to improve the performance of the pure MLP-based architecture, respectively."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "MLP-based Architectures. Res-MLP (Touvron et al., 2021a) is proposed, which also obtains impressive performance with residual MLP only trained on ImageNet1K. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and external attention to improve the performance of the pure MLP-based architecture, respectively."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "instruction": "Revise this paragraph to be more concise.", "revised_paragraph": "MLP-based Architectures. Res-MLP (Touvron et al., 2021a) is proposed, which also obtains impressive performance with residual MLP only trained on ImageNet1K. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and external attention to improve the performance of the pure MLP-based architecture, respectively.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "instruction": "Make this paragraph shorter by deleting details.", "revised_paragraph": "\"MLP-based Architectures. MLP-Mixer (Tolstikhin et al., 2021) has designed a very concise framework that utilizes matrix transposition and MLP to transmit information between spatial features. Resort to MLP, skip connection between layers and normalization layer, MLP-Mixer obtains promising experimental results. The concurrent work FF (Melas-Kyriazi, 2021) also applies a similar network architecture and reaches similar conclusions. Such experimental results are surprising, which shows that the MLP-based architecture also achieves comparable performance with CNN-based architectures and transformer-based architectures. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) introduce Spatial Gating Unit (SGU) and External Attention to improve the performance of the pure MLP-based architecture, respectively.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The surprising result of our experimental evaluation is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \u201cEx-def\u201d baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}, {"intention": "Concision", "revised_paragraph": "\"The surprising result of our experiments is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The surprising result of our experiments is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The surprising result of our experiments is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"The surprising result of our experimental evaluation is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \u201cEx-def\u201d baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The surprising result of our experiments is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The surprising result of our experimental evaluation is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \u201cEx-def\u201d baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"The surprising result of our experiments is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The surprising result of our experiments is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The surprising result of our experiments is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"The surprising result of our experiments is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The surprising result of our experiments is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "instruction": "Rewrite the last sentence, making it more concise.", "revised_paragraph": "\"The surprising result of our experimental evaluation is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "instruction": "Make the last sentence more concise.", "revised_paragraph": "\"The surprising result of our experimental evaluation is that, for runtimes of 1h, the black box optimizers are hardly ever able to improve upon Naive AutoML. In fact, the experiments even show that the \"Ex-def\" baseline itself is already quite strong in this time frame. This is not a contradiction to the results in Thornton et al. (2013), where a timeout of 30 hours was used. While this observations calls for more exhaustive experiments (with longer runtimes), it is already evident that simple baselines are much stronger than they were supposed to be until now.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they spread out in the graph in a similar way, and therefore when they influence the other nodes in a similar way (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they spread out in the graph in a similar way, and therefore when they influence the other nodes in a similar way (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they spread out in the graph in a similar way, and therefore when they influence the other nodes in a similar way (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they spread out in the graph in a similar way, and therefore when they influence the other nodes in a similar way (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they spread out in the graph in a similar way, and therefore when they influence the other nodes in a similar way (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they spread out in the graph in a similar way, and therefore when they influence the other nodes in a similar way (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they spread out in the graph in a similar way, and therefore when they influence the other nodes in a similar way (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they spread out in the graph in a similar way, and therefore when they influence the other nodes in a similar way (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "instruction": "Remove the ideas which are not particularly essential for the overall paragraph.", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they diffuse in a similar way through the graph, and therefore when they influence the other nodes in a similar manner (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "instruction": "Delete the first part of the first sentence and adapt it in consequence.", "revised_paragraph": "\"Before we define the diffusion distance, we briefly introduce the intuition behind it: two nodes are considered similar when they diffuse in a similar way through the graph, and therefore when they influence the other nodes in a similar manner (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. More precisely, the diffusion distance at time K between nodes i and j is defined as follows:\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"One way to check for any correspondences is to simply group the validation samples into M equalmass bins (henceforth called validation-bins) and compare the confidence with the training samples that fall into the same validation-bins. But first we clarify a few notations that are of interest.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"One way to check for any correspondences is to simply group the validation samples into M equalmass bins (henceforth called validation-bins) and compare the confidence with the training samples that fall into the same validation-bins. But first we clarify a few notations that are of interest.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"One way to check for any correspondences is to simply group the validation samples into M equalmass bins (henceforth called validation-bins) and compare the confidence with the training samples that fall into the same validation-bins. But first we clarify a few notations that are of interest.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"One way to check for any correspondences is to simply group the validation samples into M equalmass bins (henceforth called validation-bins) and compare the confidence with the training samples that fall into the same validation-bins. But first we clarify a few notations that are of interest.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"One way to check for any correspondences is to simply group the validation samples into M equalmass bins (henceforth called validation-bins) and compare the confidence with the training samples that fall into the same validation-bins. But first we clarify a few notations that are of interest.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"One way to check for any correspondences is to simply group the validation samples into M equalmass bins (henceforth called validation-bins) and compare the confidence with the training samples that fall into the same validation-bins. But first we clarify a few notations that are of interest.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"One way to check for any correspondences is to simply group the validation samples into M equalmass bins (henceforth called validation-bins) and compare the confidence with the training samples that fall into the same validation-bins. But first we clarify a few notations that are of interest.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"One way to check for any correspondences is to simply group the validation samples into M equalmass bins (henceforth called validation-bins) and compare the confidence with the training samples that fall into the same validation-bins. But first we clarify a few notations that are of interest.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "instruction": "Make the language of this paragraph more formal.", "revised_paragraph": "One way to check for correspondences is to simply group the validation samples into M equalmass bins and compare the confidence with the training samples that fall into the same bins. However, first we clarify a few notations that are of interest.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "instruction": "Improve the writinng in the linking of the two last sentences to make it more formal.", "revised_paragraph": "\"One way to check for any correspondences is to simply group the validation samples into M equalmass bins (henceforth called validation-bins) and compare the confidence with the training samples that fall into the same bins. However, first we clarify a few notations that are of interest.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "instruction": "Please exclude the content that seems unnecessary.", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "instruction": "Remove the second item of the list.", "revised_paragraph": "\"\u2022 The NTK is defined using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper) is defined using the gradient of the DNN output with respect to input parameter space. In other words, the variables to be differentiated are different. \u2022 The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H  older, it is difficult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We proposed a new inference lgorithm for distributions parametrized by normalizing flow models. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. Overall, we believe that the idea of a pre-generator creating structured noise is a useful and general method for leveraging pre-trained generators to solve new generative problems.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We proposed a new inference lgorithm for distributions parametrized by normalizing flow models. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. Overall, we believe that the idea of a pre-generator creating structured noise is a useful and general method for leveraging pre-trained generators to solve new generative problems.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We proposed a new inference lgorithm for distributions parametrized by normalizing flow models. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. Overall, we believe that the idea of a pre-generator creating structured noise is a useful and general method for leveraging pre-trained generators to solve new generative problems.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We proposed a new inference lgorithm for distributions parametrized by normalizing flow models. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. Overall, we believe that the idea of a pre-generator creating structured noise is a useful and general method for leveraging pre-trained generators to solve new generative problems.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We proposed a new inference lgorithm for distributions parametrized by normalizing flow models. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. Overall, we believe that the idea of a pre-generator creating structured noise is a useful and general method for leveraging pre-trained generators to solve new generative problems.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We proposed a new inference lgorithm for distributions parametrized by normalizing flow models. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. Overall, we believe that the idea of a pre-generator creating structured noise is a useful and general method for leveraging pre-trained generators to solve new generative problems.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We proposed a new inference lgorithm for distributions parametrized by normalizing flow models. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. Overall, we believe that the idea of a pre-generator creating structured noise is a useful and general method for leveraging pre-trained generators to solve new generative problems.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We proposed a new inference lgorithm for distributions parametrized by normalizing flow models. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. Overall, we believe that the idea of a pre-generator creating structured noise is a useful and general method for leveraging pre-trained generators to solve new generative problems.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "instruction": "Remove details which are unnecessary for the overall paragraph. Fix any spelling mistakes.", "revised_paragraph": "\"We proposed a new inference algorithm for distributions parametrized by normalizing flow models. The need for approximate inference is motivated by our theoretical hardness result for exact inference, which is surprising given that it applies to invertible models. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. Overall, we believe that the idea of a pre-generator creating structured noise is a useful and general method for leveraging pre-trained generators to solve new generative problems.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "instruction": "Correct and concise the two first sentences.", "revised_paragraph": "\"We proposed a new inference lgorithm for distributions parametrized by normalizing flow models. The need for approximate inference is motivated by our theoretical hardness result for exact inference,which is surprising given that it applies to invertible models.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (\"Ex-def\") baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.\""}, {"intention": "Concision", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools. For example, a very simple baseline would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare to each other.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (\"Ex-def\") baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (\"Ex-def\") baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools. For example, a very simple baseline would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare to each other.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (\"Ex-def\") baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (\"Ex-def\") baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (\"Ex-def\") baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (\"Ex-def\") baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (\"Ex-def\") baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools. For example, a very simple baseline would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare to each other.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools. For example, a very simple baseline would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare to each other.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "instruction": "Edit some formulations to sound more neutral.", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "instruction": "Make the beginning of the paragraph shorter.", "revised_paragraph": "\"Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "instruction": "Rewrite the middle sentence of this paragraph to make it clearer.", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "instruction": "Rewrite the long sentence in the middle sentence to improve clarity.", "revised_paragraph": "\"In this section we discuss how SafeNet can be instantiated in practice. There are two aspects the data owners need to agree upon before instantiating SafeNet: i) The MPC framework used for secure training and prediction phase and ii) the parameters in Theorem 6 to achieve poisoning robustness. The MPC framework is agreed upon by choosing the total number of outsourced servers N participating in the MPC, the number of corrupted servers T and the nature of the adversary (semihonest or malicious in the SOC paradigm). The owners then agree upon a filtering threshold  and the number of poisoned owners t that can be tolerated. Once these parameters are chosen the maximum allowed error probability of the local models trained by the honest owners based on Lemma 5 and\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "instruction": "Make this paragraph considerably more concise. Remove any information that is not essential to this paragraph itself.", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "instruction": "Delete the third sentence. Concise the first and last one.", "revised_paragraph": "\"We consider propagating semantic labels from labeled data C to unlabeled data U by exploiting the aforementioned relationships. We denote C and U as the sets of segment indices. Our label propagation is driven by grouping and separating data in a learned feature space. We now describe each pixel-to-segment semantic relationship for augmenting the setsof positive/negative segments using both labeled and unlabeled pixels.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features. Furthermore, ResNet (He et al., 2016) is proposed, which utilizes the residual connection to transfer features in different layers, thereby alleviating the problem of gradient vanishing and obtaining superior performance. After that, the residual module becomes an important component of the network design and is also employed in subsequent transformer-based architectures and MLP-based architectures. Some papers have made further improvements to the convolution operation in CNN-based architectures, such as dilated convolution (Yu & Koltun, 2016) and deformable convolution (Dai et al., 2017). EfficientNet (Tan & Le, 2019; 2021) introduces neural architecture search into CNN to search for a suitable structure.\""}, {"intention": "Concision", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features. Furthermore, ResNet (He et al., 2016) is proposed, which utilizes the residual connection to transfer features in different layers, thereby alleviating the problem of gradient vanishing and obtaining superior performance. After that, the residual module becomes an important component of the network design and is also employed in subsequent transformer-based architectures and MLP-based architectures. Some papers have made further improvements to the convolution operation in CNN-based architectures, such as dilated convolution (Yu & Koltun, 2016) and deformable convolution (Dai et al., 2017). EfficientNet (Tan & Le, 2019; 2021) introduces neural architecture search into CNN to search for a suitable structure.\""}, {"intention": "Concision", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features. Furthermore, ResNet (He et al., 2016) is proposed, which utilizes the residual connection to transfer features in different layers, thereby alleviating the problem of gradient vanishing and obtaining superior performance. After that, the residual module becomes an important component of the network design and is also employed in subsequent transformer-based architectures and MLP-based architectures. Some papers have made further improvements to the convolution operation in CNN-based architectures, such as dilated convolution (Yu & Koltun, 2016) and deformable convolution (Dai et al., 2017). EfficientNet (Tan & Le, 2019; 2021) introduces neural architecture search into CNN to search for a suitable structure.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features. Furthermore, ResNet (He et al., 2016) is proposed, which utilizes the residual connection to transfer features in different layers, thereby alleviating the problem of gradient vanishing and obtaining superior performance. After that, the residual module becomes an important component of the network design and is also employed in subsequent transformer-based architectures and MLP-based architectures. Some papers have made further improvements to the convolution operation in CNN-based architectures, such as dilated convolution (Yu & Koltun, 2016) and deformable convolution (Dai et al., 2017). EfficientNet (Tan & Le, 2019; 2021) introduces neural architecture search into CNN to search for a suitable structure.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "instruction": "Make this paragraph more concise.", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "instruction": "Remove the sentence about the residual module. Make the paragraph more concise.", "revised_paragraph": "\"CNN-based Architectures. Since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition in 2012, the CNN-based architectures have gradually been utilized to automatically extract image features instead of hand-crafted features. Furthermore, ResNet (He et al., 2016) is proposed, which utilizes the residual connection to transfer features in different layers, thereby alleviating the problem of gradient vanishing and obtaining superior performance. After that, the residual module becomes an important component of the network design and is also employed in subsequent transformer-based architectures and MLP-based architectures. Some papers have made further improvements to the convolution operation in CNN-based architectures, such as dilated convolution (Yu & Koltun, 2016) and deformable convolution (Dai et al., 2017). EfficientNet (Tan & Le, 2019; 2021) introduces neural architecture search into CNN to search for a suitable structure.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "instruction": "Rewrite this paragraph to improve readability and make contributions more evident.", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "instruction": "Improve the logical flow of ideas in this text.", "revised_paragraph": "\"S UMMARY We propose a novel universal weakly-supervised semantic segmentation method via Semisupervised Pixel-wise Metric Learning. Four common types of pixel-to-segment attraction and repulsion relationships can be derived, whether the partial annotation is coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our results on PASCAL VOC and DensePose show consistent and substantial gains over SOTA, especially for the sparsest keypoint supervision. \"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold for cost optimal planning problems that have actions with 0-cost. This is one hurdle to the application of SAT-based planning to such problems since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}, {"intention": "Concision", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold that can be used to prove that the planning problem is solvable. This is important since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold for cost optimal planning problems that have actions with 0-cost. This is one hurdle to the application of SAT-based planning to such problems since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold for cost optimal planning problems that have actions with 0-cost. This is one hurdle to the application of SAT-based planning to such problems since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold that can be used to prove that the planning problem is solvable. This is important since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold for cost optimal planning problems that have actions with 0-cost. This is one hurdle to the application of SAT-based planning to such problems since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold for cost optimal planning problems that have actions with 0-cost. This is one hurdle to the application of SAT-based planning to such problems since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold that can be used to prove that the planning problem is solvable. This is important since, without a reasonable completeness threshold, the planning problem can be very hard to solve and the planning problem can be very large. Some approaches try to solve the planning problem by using an over-approximation of the transition relation underlying the planning problem to the encoding. However, this can lead to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold for cost optimal planning problems that have actions with 0-cost. This is one hurdle to the application of SAT-based planning to such problems since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold for cost optimal planning problems that have actions with 0-cost. This is one hurdle to the application of SAT-based planning to such problems since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold that can be used to prove that the planning problem is solvable. This is important since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold that can be used to prove that the planning problem is solvable. This is important since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold for cost optimal planning problems that have actions with 0-cost. This is one hurdle to the application of SAT-based planning to such problems since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "instruction": "Concise the last sentence of this text.", "revised_paragraph": "\"A gap in the literature seems to be a practical completeness threshold for cost optimal planning problems that have actions with 0-cost. This is one hurdle to the application of SAT-based planning to such problems since, without a reasonable completeness threshold, optimality can only be proved after solving the compilation for a horizon that is the number of states in the state space. This is impractical for most problems since it can be exponentially bigger than the size of the given problem. It should be noted that some approaches try to circumvent the need for a tight completeness threshold, such as the ones by Robinson et al. and Leofante et al., which add an over-approximation of the transition relation underlying the planning problem to the encoding. Nonetheless, these approaches still need to compute compilations for multiple horizons and they are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the given problem, i.e. it could be solvable even if the concrete problem is not solvable.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with an optimal discriminator such that r ( s, a ) = log E ( s,a ) D ( s,a ). As a result, objective (9) becomes:\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with an optimal discriminator such that r ( s, a ) = log E ( s,a ) D ( s,a ). As a result, objective (9) becomes:\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with an optimal discriminator such that r ( s, a ) = log E ( s,a ) D ( s,a ). As a result, objective (9) becomes:\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with an optimal discriminator such that r ( s, a ) = log E ( s,a ) D ( s,a ). As a result, objective (9) becomes:\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with an optimal discriminator such that r ( s, a ) = log E ( s,a ) D ( s,a ). As a result, objective (9) becomes:\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with an optimal discriminator such that r ( s, a ) = log E ( s,a ) D ( s,a ). As a result, objective (9) becomes:\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with an optimal discriminator such that r ( s, a ) = log E ( s,a ) D ( s,a ). As a result, objective (9) becomes:\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with an optimal discriminator such that r ( s, a ) = log E ( s,a ) D ( s,a ). As a result, objective (9) becomes:\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "instruction": "Be more specific when talking about the result.", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with a optimal discriminator such that r (s, a ) = log E ( s,a ) D ( s,a ). As a result, objective (9) becomes:\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "instruction": "Improve this text to fit a more academic style.", "revised_paragraph": "\"To observe the consequence of having a discriminator trained on empirical distributions, we assume that the reward is represented with a optimal discriminator such that r (s, a ) = log E (s,a ) D (s,a ). As a result, objective (9) becomes:\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}, {"intention": "Concision", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods."}, {"intention": "Rewritting_light", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "instruction": "Remove unnecessary content in the last sentence.", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "instruction": "Make the last sentence shorter, only keep the main idea. Slightly concise this paragraph and improve the english.", "revised_paragraph": "\"Our work is also related to other work on the importance of noise in SGDs, which have been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) observe empirically that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of the gradient noise in the SGD stationary distribution. Additionally, our work also provides intuition toward explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). CLR schedules have demonstrated good optimization and generalization performances, but are grounded on empirical observation rather than on a theoretical understanding. We show that one can replace learning rate annealing with an equivalent batch size schedule. It suggests that the benefit of CLR relates to the noise that it induces and can be thought of as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing (Graham & Storkey, 2017).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions. However, they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Furthermore, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions. However, they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Furthermore, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions. However, they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Furthermore, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions. However, they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Furthermore, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions. However, they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Furthermore, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions. However, they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Furthermore, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions. However, they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Furthermore, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions. However, they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Furthermore, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "instruction": "Restructure the last two sentences in this paragraph", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions, but they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Additionally, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "instruction": "Revise this paragraph to make it more clear and concise.", "revised_paragraph": "\"Four participants answered that they intentionally used edges (Figure 5 (iv)) in all conditions. However, they were affected by the cursor hidden by the notch, causing them to lose sight of the cursor. Furthermore, all participants answered that when the cursor was hidden by the notch, they tried to find the cursor by moving the mouse vigorously.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "instruction": "Rewrite the opening sentences of the paragraph to make them more explicit and clear.", "revised_paragraph": "\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "instruction": "Replace the listing by normal text to better incorporate de six building blocks into the paragraph.", "revised_paragraph": "\"According to Ethier et al. [58], a prescription is made of the following six building blocks which define the modalities of administration for a given drug: 1) drug prescription item (specifying actions re- lated to one or several drugs), 2) drug administration specification (specifying the drug), 3) drug course specification (specifying duration, initiation, and termination), 4) drug dosage specification (specifying the dosage of a drug),5) drug dose administration specification (administration instructions), and6) drug dispensing specification (specifying the dispensing of a drug product). Kumar et al. [59] summarizes these building blocks as superscription (directive to take), inscription (name and dose), subscription (directions to the pharmacists), and signature (Instructions for Patient), and Fox [60] as drug name, drug dose, drug dose units, drug dose frequency, du- ration (comprising start and end date), and indication. Like others (e.g. [14,31]), we adopt the latter classification by Fox [60] because of the simplicity and directness of the naming convention.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by additively introducing different relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}, {"intention": "Concision", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by adding more relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by adding more relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by adding more relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by additively introducing different relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}, {"intention": "Concision", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by adding more relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by additively introducing different relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by adding more relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by adding more relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by adding more relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by additively introducing different relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by adding more relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "instruction": "Edit this paragraph to be more concise.", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by additively introducing different relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "instruction": "Improve the english of this paragraph and make it slightly shorter.", "revised_paragraph": "\"Visual quality comparison and Ablation study. Fig. shows that our results are well aligned with image boundary and visually close to fully-supervised counterpart. Fig. 7 shows significant improvement of our results by additively introducing different relationships for more regularization. Please refer to the Appendix for more details and ablation studies.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Twelve local university students from a different participant group from experiment 1 participated in this experiment. The average age was 22.3 years ( SD = 1. 67). All participants were skilled at mouse operation and used their dominant right hand.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Twelve local university students from a different participant group from experiment 1 participated in this experiment. The average age was 22.3 years ( SD = 1. 67). All participants were skilled at mouse operation and used their dominant right hand.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Twelve local university students from a different participant group from experiment 1 participated in this experiment. The average age was 22.3 years ( SD = 1. 67). All participants were skilled at mouse operation and used their dominant right hand.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Twelve local university students from a different participant group from experiment 1 participated in this experiment. The average age was 22.3 years ( SD = 1. 67). All participants were skilled at mouse operation and used their dominant right hand.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Twelve local university students from a different participant group from experiment 1 participated in this experiment. The average age was 22.3 years ( SD = 1. 67). All participants were skilled at mouse operation and used their dominant right hand.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Twelve local university students from a different participant group from experiment 1 participated in this experiment. The average age was 22.3 years ( SD = 1. 67). All participants were skilled at mouse operation and used their dominant right hand.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Twelve local university students from a different participant group from experiment 1 participated in this experiment. The average age was 22.3 years ( SD = 1. 67). All participants were skilled at mouse operation and used their dominant right hand.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Twelve local university students from a different participant group from experiment 1 participated in this experiment. The average age was 22.3 years ( SD = 1. 67). All participants were skilled at mouse operation and used their dominant right hand.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "instruction": "Rephrase the paragraph", "revised_paragraph": "\"This experiment was carried out by 12 local university students who were aged on average 22.3 years (SD = 1.67) and all of them were experienced with mouse manipulation using their dominant right arm.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "instruction": "Revise this text to make it more clear.", "revised_paragraph": "\"Twelve local university students from a different participants group from experiment 1 participated in this experiment. The average age was 22.3 years ( SD = 1. 67). All participants were skillful in mouse operation and used their dominant right hand.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"However, as neural network estimators mainly update parameters with stochastic gradient methods, only a subset of the representation\u2019s distribution is accessible within each iteration. As such, a shortcut (Liuyi et al., 2018) is to calculate the group discrepancy at a stochastic mini-batch level:\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"However, as neural network estimators mainly update parameters with stochastic gradient methods, only a subset of the representation\u2019s distribution is accessible within each iteration. As such, a shortcut (Liuyi et al., 2018) is to calculate the group discrepancy at a stochastic mini-batch level:\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"However, as neural network estimators mainly update parameters with stochastic gradient methods, only a subset of the representation\u2019s distribution is accessible within each iteration. As such, a shortcut (Liuyi et al., 2018) is to calculate the group discrepancy at a stochastic mini-batch level:\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"However, as neural network estimators mainly update parameters with stochastic gradient methods, only a subset of the representation\u2019s distribution is accessible within each iteration. As such, a shortcut (Liuyi et al., 2018) is to calculate the group discrepancy at a stochastic mini-batch level:\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"However, as neural network estimators mainly update parameters with stochastic gradient methods, only a subset of the representation\u2019s distribution is accessible within each iteration. As such, a shortcut (Liuyi et al., 2018) is to calculate the group discrepancy at a stochastic mini-batch level:\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"However, as neural network estimators mainly update parameters with stochastic gradient methods, only a subset of the representation\u2019s distribution is accessible within each iteration. As such, a shortcut (Liuyi et al., 2018) is to calculate the group discrepancy at a stochastic mini-batch level:\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"However, as neural network estimators mainly update parameters with stochastic gradient methods, only a subset of the representation\u2019s distribution is accessible within each iteration. As such, a shortcut (Liuyi et al., 2018) is to calculate the group discrepancy at a stochastic mini-batch level:\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"However, as neural network estimators mainly update parameters with stochastic gradient methods, only a subset of the representation\u2019s distribution is accessible within each iteration. As such, a shortcut (Liuyi et al., 2018) is to calculate the group discrepancy at a stochastic mini-batch level:\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "instruction": "check the wordings but keep the original content as much as possible", "revised_paragraph": "\"However, as neural network estimators mainly update parameters with stochastic gradient methods, only a subset of the representation\u2019s distribution is accessible within each iteration. As such, a shortcut (Liuyi et al., 2018) is to calculate the group discrepancy at a stochastic mini-batch level:\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "instruction": "Improve the language to make it more formal.", "revised_paragraph": "\"However, as neural network estimators mainly update parameters using stochastic gradient methods, only a subset of the representation's distribution is accessible within each iteration. As such, a shortcut can be calculated using the following method:\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}, {"intention": "Concision", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] uses three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] uses three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] uses three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "instruction": "Remove unnecessary details.", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "instruction": "Delete unnecessary details, mostly in the two first sentences.", "revised_paragraph": "\"Besides AT and RND, diverse defenses have also been proposed, and it would be interesting to see their results. DENT [19] optimizes the model in test-time, trying to learn the AE distribution. PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. They are originally developed for gradient-based attacks, but also provide some protection against SQAs. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Due to its utilization of large-scale testing samples, QueryNet greatly hurts DNNs, but AAA is still the defense that protects the model best.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "instruction": "Rephrase the last sentence.", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements of this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "instruction": "Rewrite the last sentence to better convey the idea.", "revised_paragraph": "\"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL combines elements this framework to allow iterative communication between downstream classifiers and rule selectors to allow each to mutually enhance the other. This allows ReGAL to uniquely offer the ease of model-generated LFs while still gaining the nuanced insight ofhuman annotator input.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"intention": "Concision", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"intention": "Concision", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"intention": "Concision", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"intention": "Concision", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "instruction": "Remove the second part of the first sentence", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "instruction": "Exclude unnecessary details.", "revised_paragraph": "\"First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis. We make this observation across all tasks, confirming that the conventional multi-modal learning process is greedy regardless of network architectures and tasks.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "instruction": "Exclude unnecessary ideas.", "revised_paragraph": "\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "instruction": "Rewrite the first half of this paragraph to make it clearer and easier to read.", "revised_paragraph": "\"Mahapatra & Rajan (2020) presented Exact Pareto Optimal (EPO), an MOO optimization method that can converge to a desired ray in loss space. Given a preference ray r, EPO search for an exact Pareto optimal solution, i.e. a solution that is (i) Pareto optimal, and; (ii) Lies on the intersect of the Pareto front and the preference vector r. The EPO method balances two goals: Finding a descent direction and getting to the desired ray. EPO searches for a point in the convex hull of the gradients, known by D\u00e9sid\u00e9ri (2012) to include descent directions, that has maximal angle with a vector d bal which pulls the point to the desired ray. EPO combines gradient descent and controlled ascent enabling it to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy. To achieve a trade-off between imitation learning and optimal value learning, we propose Expectile V -learning (EVL), which is based on a new expectile operator that smoothly interpolates between the Bellman expectation operator and optimality operator.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy. To achieve a trade-off between imitation learning and optimal value learning, we propose Expectile V -learning (EVL), which is based on a new expectile operator that smoothly interpolates between the Bellman expectation operator and optimality operator.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). By doing so, they keep the whole learning procedure within the dataset's support. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "instruction": "Remove a redundant sentence. Correct citation format.", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Moreover, learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy. To achieve a trade-off between imitation learning and optimal value learning, we propose Expectile V -learning (EVL), which is based on a new expectile operator that smoothly interpolates between the Bellman expectation operator and optimality operator.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "instruction": "Make it shorter by removing what is not essential.", "revised_paragraph": "\"Another line of methods, on the contrary, uses the returns of the behavior policy as the signal for policy learning. However, the behavior policy of the dataset can be imperfect and insufficient to guide policy learning. Learning optimal values within the dataset, on the other extreme, can lead to erroneously optimistic value estimates since data is limited and off-policy. To achieve a trade-off between imitation learning and optimal value learning, we propose Expectile V -learning (EVL), which is based on a new expectile operator that smoothly interpolates between the Bellman expectation operator and optimality operator.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "instruction": "Revise the opening of this paragraph to make it more compelling.", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot\u2019s behavior would make sense in the updated model, which captures the user\u2019s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "instruction": "Rewrite the first sentence to make it more convincing.", "revised_paragraph": "\"In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For both KGs, we sample 30 questions from the CSQA and OBQA test sets which were correctly answered by MHGRN. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability (Read) and usability (Use), with ratings aggregated via majority voting. We obtain a Fleiss\u2019  of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability and usability, with ratings aggregated via majority voting. Readability (Read) is whether the path makes sense, usability (Use) is whether the path is relevant to the given question-answer pair, and both are measured on a [0, 1] scale. We obtain a Fleiss\u2019  of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For both KGs, we sample 30 questions from the CSQA and OBQA test sets which were correctly answered by MHGRN. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability (Read) and usability (Use), with ratings aggregated via majority voting. We obtain a Fleiss\u2019  of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability and usability, with ratings aggregated via majority voting. Readability (Read) is whether the path makes sense, usability (Use) is whether the path is relevant to the given question-answer pair, and both are measured on a [0, 1] scale. We obtain a Fleiss\u2019  of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For both KGs, we sample 30 questions from the CSQA and OBQA test sets which were correctly answered by MHGRN. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability (Read) and usability (Use), with ratings aggregated via majority voting. We obtain a Fleiss\u2019  of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability (Read) and usability (Use), with ratings aggregated via majority voting. We obtain a Fleiss\u2019 of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For both KGs, we sample 30 questions from the CSQA and OBQA test sets which were correctly answered by MHGRN. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability (Read) and usability (Use), with ratings aggregated via majority voting. We obtain a Fleiss\u2019  of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability and usability, with ratings aggregated via majority voting. Readability (Read) is whether the path makes sense, usability (Use) is whether the path is relevant to the given question-answer pair, and both are measured on a [0, 1] scale. We obtain a Fleiss\u2019  of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "instruction": "Review the following paragraph, only when necesarry make modificatons to make it easier to read", "revised_paragraph": "\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability and usability, with ratings aggregated via majority voting. Readability (Read) is whether the path makes sense, usability (Use) is whether the path is relevant to the given question-answer pair, and both are measured on a [0, 1] scale. We obtain a Fleiss\u2019  of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "instruction": "Better balance the length of the first and second sentences.", "revised_paragraph": "\"Human Evaluation of KG Explanations We conduct a user study to measure KG-augmented models\u2019 ability to give plausible explanations, using the original KG or RLRR perturbed KG. For each question, we retrieve the top-scoring path for each answer choice via MHGRN\u2019s path decoder attention. We then ask three human subjects to rate each path for readability (Read) and usability (Use), with ratings aggregated via majority voting. We obtain a Fleiss\u2019  of 0. 1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", meaning they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", meaning they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", meaning they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", meaning they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", meaning they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", meaning they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", meaning they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", meaning they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "instruction": "Make the ideas more concise.", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", in the sense that they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "instruction": "Remove unnecessary details.", "revised_paragraph": "\"In this paper, we prove new generalization bounds for convolutional networks that take account of this effect. As in earlier analyses for the fully connected case, our bounds are in terms of the distance from the initial weights, and the number of parameters. Additionally, our bounds are \"size-free\", in the sense that they are independent of the number of pixels in the input, or the height and width of the hidden feature maps.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In this work, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, achieving superior performance gains over recent methods quantitatively and visually.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In this work, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, achieving superior performance gains over recent methods quantitatively and visually.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In this work, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, achieving superior performance gains over recent methods quantitatively and visually.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In this work, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, achieving superior performance gains over recent methods quantitatively and visually.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In this work, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, achieving superior performance gains over recent methods quantitatively and visually.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In this work, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, achieving superior performance gains over recent methods quantitatively and visually.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In this work, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, achieving superior performance gains over recent methods quantitatively and visually.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In this work, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, achieving superior performance gains over recent methods quantitatively and visually.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "instruction": "Replace all occurrences of SRPN-L with SRPN-Lite. Improve the english of this paragraph.", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In particular, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network SRPN-L and a very deep one SRPN. We conduct extensive comparisons with both lightweight and larger image SR networks. SRPN-L and SRPN achieve superior performance gains over recent methods quantitatively and visually.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "instruction": "Replace SRPN-L by SPRN-Lite. Make the first and last sentence more fitting to the academic style.", "revised_paragraph": "\"Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. However, they are impractical or neglected to be extended to larger networks. In particular, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ L 2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network SRPN-L and a very deep one SRPN. We conduct extensive comparisons with both lightweight and larger image SR networks. SRPN-L and SRPN achieve superior performance gains over recent methods quantitatively and visually.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some use game theoretic notions such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.\""}, {"intention": "Concision", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is that there are many different ways to motivate and evaluate post hoc explanations. This causes problems such as not knowing which method to use when.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is that there are many different ways to motivate and evaluate post hoc explanations. This causes problems such as not knowing which method to use when.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is that there are many different ways to motivate and evaluate post hoc explanations. This causes problems such as not knowing which method to use when.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is that there are many different ways to motivate and evaluate post hoc explanations. This causes problems such as not knowing which method to use when.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some use game theoretic notions such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some use game theoretic notions such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is that there are many different ways to motivate and evaluate different methods. For example, some methods are motivated by function approximation, some use game theory such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is that there are many different ways to motivate and evaluate post hoc explanations. This causes problems such as not knowing which method to use when.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is that there are many different ways to motivate and evaluate post hoc explanations. This causes problems such as not knowing which method to use when.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is that there are many different ways to motivate and evaluate post hoc explanations. This causes problems such as not knowing which method to use when.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is that there are many different ways to motivate and evaluate post hoc explanations. This causes problems such as not knowing which method to use when.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "instruction": "Make as concise as possible the paragraph, removing any ideas that are not essential. Use a clearer word choice.", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some use game theoretic notions such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "instruction": "Concise this paragraph while improving the academic english.", "revised_paragraph": "\"A critical problem in the literature on post hoc explanations is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some use game theoretic notions such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be taken apart and vice-versa.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be taken apart and vice-versa.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be taken apart and vice-versa.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. For example, end-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be taken apart and vice-versa.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communicating the suggested conflict resolution action.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "instruction": "Clarify the wording in this paragraph.", "revised_paragraph": "\"When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be taken apart and vice-versa.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "instruction": "Reword my sentence about entries.", "revised_paragraph": "\"Arrows are effective in communicating the suggested conflict resolution action. End-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be separated, and vice versa.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an illustrative example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\""}, {"intention": "Concision", "revised_paragraph": "\"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an illustrative example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an illustrative example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an illustrative example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "instruction": "Make this paragraph shorter by eliminating details about further work.", "revised_paragraph": "\"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "instruction": "Delete the sentence about further study and the reference to section 2.", "revised_paragraph": "\"Another future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an illustrative example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, the assumption may not hold since the backdoor may be changed during the stealing process. In this section, we verify this limitation.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, the assumption may not hold since the backdoor may be changed during the stealing process. In this section, we verify this limitation.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, the assumption may not hold since the backdoor may be changed during the stealing process. In this section, we verify this limitation.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, the assumption may not hold since the backdoor may be changed during the stealing process. In this section, we verify this limitation.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, the assumption may not hold since the backdoor may be changed during the stealing process. In this section, we verify this limitation.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, the assumption may not hold since the backdoor may be changed during the stealing process. In this section, we verify this limitation.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, the assumption may not hold since the backdoor may be changed during the stealing process. In this section, we verify this limitation.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, the assumption may not hold since the backdoor may be changed during the stealing process. In this section, we verify this limitation.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "instruction": "Remove information on why the assumption might not hold.", "revised_paragraph": "\"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, the assumption may not hold since the backdoor may be changed during the stealing process. In this section, we verify this limitation.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "instruction": "Make the second sentence much shorter, only keep the main idea.", "revised_paragraph": "\"We verify this limitation and show how it can be used to improve the detection rate of backdoor-based model watermarking.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"This paper studies the generalization performance of the gradient-based meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high. One limitation of this work is that the analysis focuses on themeta linearregression case. While thisanalysis can capture practical cases where we reuse the feature extractor from pre-trained models andonly meta-train the parameters in the last linear layer, it is also promising to extend our analysis tononlinear cases via means of random features and neural tangent kernels in the future work.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"This paper studies the generalization performance of the gradient-based meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high.\""}, {"intention": "Concision", "revised_paragraph": "\"We study the generalization performance of the gradient-based meta learning with an overparameterized model. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We study the generalization performance of the gradient-based meta learning with an overparameterized model. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"This paper studies the generalization performance of the gradient-based meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high. One limitation of this work is that the analysis focuses on themeta linearregression case. While thisanalysis can capture practical cases where we reuse the feature extractor from pre-trained models andonly meta-train the parameters in the last linear layer, it is also promising to extend our analysis tononlinear cases via means of random features and neural tangent kernels in the future work.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"This paper studies the generalization performance of the gradient-based meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"This paper studies the generalization performance of the gradient-based meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high. One limitation of this work is that the analysis focuses on themeta linearregression case. While thisanalysis can capture practical cases where we reuse the feature extractor from pre-trained models andonly meta-train the parameters in the last linear layer, it is also promising to extend our analysis tononlinear cases via means of random features and neural tangent kernels in the future work.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"We study the generalization performance of the gradient-based meta learning with an overparameterized model. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high. One limitation of this work is that the analysis focuses on themeta linearregression case. While thisanalysis can capture practical cases where we reuse the feature extractor from pre-trained models andonly meta-train the parameters in the last linear layer, it is also promising to extend our analysis tononlinear cases via means of random features and neural tangent kernels in the future work.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"We study the generalization performance of the gradient-based meta learning with an overparameterized model. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high. While thisanalysis can capture practical cases where we reuse the feature extractor from pre-trained models and only meta-train the parameters in the last linear layer, it is also promising to extend our analysis tononlinear cases via means of random features and neural tangent kernels in the future work.\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We study the generalization performance of the gradient-based meta learning with an overparameterized model. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"We study the generalization performance of the gradient-based meta learning with an overparameterized model. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"This paper studies the generalization performance of the gradient-based meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "instruction": "Exclude unnecessary reasoning, correct the typos.", "revised_paragraph": "\"This paper studies the generalization performance of the gradient-based meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high. One limitation of this work is that the analysis focuses on themeta linearregression case. While thisanalysis can capture practical cases where we reuse the feature extractor from pre-trained models andonly meta-train the parameters in the last linear layer, it is also promising to extend our analysis tononlinear cases via means of random features and neural tangent kernels in the future work.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "instruction": "Improve the english of this paragraph, particularly the last part. Replace all mentions of \"gradient-based meta learning\" with \"nested meta learning\".", "revised_paragraph": "\"This paper studies the generalization performance of the gradient-based meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We show that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-normsolution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to happen in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high. One limitation of this work is that the analysis focuses on themeta linearregression case. While thisanalysis can capture practical cases where we reuse the feature extractor from pre-trained models andonly meta-train the parameters in the last linear layer, it is also promising to extend our analysis tononlinear cases via means of random features and neural tangent kernels in the future work.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the cost model are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}, {"intention": "Concision", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture the driving style of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the costmodel are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the cost model are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the cost model are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the cost model are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}, {"intention": "Concision", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture the driving style of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the costmodel are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the cost model are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) and IOC [11] formulations. We design a set of features f as well as a risk feature f that capture the driving style of the demonstrator. From the demonstration data we then learn the risk metric parameters and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P is assumed to be the exponential distribution. As such, the generated trajectories from the costmodel are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the cost model are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the cost model are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the cost model are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) and IOC [11] formulations. We design a set of features f as well as a risk feature f that capture the driving style of the demonstrator. From the demonstration data we then learn the risk metric parameters and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, where the probability P is assumed to be the exponential distribution. As such, the generated trajectories from the costmodel are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "instruction": "Please, paraphrase this paragraph.", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, wherethe probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the costmodel are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "instruction": "This paragraph is confusing, rewrite the second and the two last sentence for clarity. Smooth out the liking between sentences.", "revised_paragraph": "\"Problem 1 defines a feature matching problem similar to many inverse reinforcement learning (IRL) [10] and IOC [11] formulations. We design a set of features f as well as a risk feature f  that capture thedriving and risk management preferences of the demonstrator. From the demonstration data we then learn the risk metric parameters  and the weights that combine the feature values. This combination gives us a costmodel. Solving for a trajectory that optimizes this costmodel results in driving behaviors similar to the demonstrator. Existing IOC approaches are able to imitate standard driving behaviors, wherethe probability P  is assumed to be the exponential distribution. As such, the generated trajectories from the cost model are exponentially more preferred by the agent. In our case, the additionof the risk measure allows us to match drivers better under risky situations. While none of theseapproaches exactly mimic the demonstrator, they capture the driving style of the demonstrator andallow generalization to new risky scenarios.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an average over three runs. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an average over three runs. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an average over three runs. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an average over three runs. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an average over three runs. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an average over three runs. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an average over three runs. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an average over three runs. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "instruction": "Shorten this paragraph by removing details about the figure.", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an averageover three runs,injecting in each run 10% random data points from \u2013 respectively \u2013 one of the three other datasets. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "instruction": "Remove unnecessary details to make this paragraph shorter.", "revised_paragraph": "\"Fig 2 plots this proportion for different datasets and models. Each bar is an average over three runs,injecting in each run 10% random data points from \u2013 respectively \u2013 one of the three other datasets. The biggest influence on how much uncertainty sampling selects outliers is the dataset, with the biggest proportion for newsgroup, where 80% of the selected data points are outliers on average (for\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "instruction": "Improve the English of this paragraph", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "instruction": "Rewrite  ", "revised_paragraph": "\"We refer to the training steps at which we perform forward and backward passes normally as regular steps. We introduce re-balancing steps at which we force the model to update only one of the unimodal branches in order to accelerate learning from the associated input modality. See Appendix A. for the full explanation of the re-balancing step.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "instruction": "Fuse the last two sentences for conciseness.", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN significantly outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "instruction": "Merge the two last sentences to make it shorter.", "revised_paragraph": "\"MVC problem respectively. In both problems and across the five datasets, Meta-EGN significantly outperforms EGN and RUN-CSP, both before and after the fine-tuning step. On RB graphs, Meta-EGN outperforms Gurobi9.5 for the MC problem. For the MVC problem, Meta-EGN outperforms Gurobi9.5 on RB500.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probabilisticdistribution of n! discrete feasible solutions. The compact, continuous and differentiable spaceof  allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probabilisticdistribution of n! discrete feasible solutions. The compact, continuous and differentiable spaceof  allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far. In other words, we also no longer need costly MCMC-based sampling for optimizing our model dueto the chain-rule decomposition. Instead, we use autoregressive factorization for sampling from theauxiliary distribution, which is faster than sampling with MCMC from the distribution defined by theenergy function.\""}, {"intention": "Concision", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probability distribution of n! discrete feasible solutions. This allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far. In other words, we also no longer need costly MCMC-based sampling for optimizing our model dueto the chain-rule decomposition. Instead, we use autoregressive factorization for sampling from theauxiliary distribution, which is faster than sampling with MCMC from the distribution defined by theenergy function.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probability distribution of n! discrete feasible solutions. This allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far. In other words, we also no longer need costly MCMC-based sampling for optimizing our model dueto the chain-rule decomposition. Instead, we use autoregressive factorization for sampling from theauxiliary distribution, which is faster than sampling with MCMC from the distribution defined by theenergy function.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probabilisticdistribution of n! discrete feasible solutions. The compact, continuous and differentiable spaceof  allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probabilisticdistribution of n! discrete feasible solutions. The compact, continuous and differentiable spaceof  allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far. In other words, we also no longer need costly MCMC-based sampling for optimizing our model dueto the chain-rule decomposition. Instead, we use autoregressive factorization for sampling from theauxiliary distribution, which is faster than sampling with MCMC from the distribution defined by theenergy function.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probabilisticdistribution of n! discrete feasible solutions. The compact, continuous and differentiable spaceof  allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Here the higher valued i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix R n n to parameterize the probabilisticdistribution of n! discrete feasible solutions. The compact, continuous and differentiable spaceof allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"Here the higher valued i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix R n n to parameterize the probabilisticdistribution of n! discrete feasible solutions. This allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far.\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probability distribution of n! discrete feasible solutions. This allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far. In other words, we also no longer need costly MCMC-based sampling for optimizing our model dueto the chain-rule decomposition. Instead, we use autoregressive factorization for sampling from theauxiliary distribution, which is faster than sampling with MCMC from the distribution defined by theenergy function.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probabilisticdistribution of n! discrete feasible solutions. The compact, continuous and differentiable spaceof  allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Here the higher valued i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix R n n to parameterize the probabilisticdistribution of n! discrete feasible solutions. The compact, continuous and differentiable spaceof allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "instruction": "Make this paragraph more concise.", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probability distribution of n! discrete feasible solutions. This allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far. In other words, we also no longer need costly MCMC-based sampling for optimizing our model dueto the chain-rule decomposition. Instead, we use autoregressive factorization for sampling from theauxiliary distribution, which is faster than sampling with MCMC from the distribution defined by theenergy function.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "instruction": "Delete the second sentence. Improve the english in the first sentence.", "revised_paragraph": "\"Here the higher valued  i,j means the higher probability for the edge from node i to node j to be sampled. More importantly, notice that we use matrix   R n  n to parameterize the probabilisticdistribution of n! discrete feasible solutions. The compact, continuous and differentiable spaceof  allows us to leverage gradient-based optimization without costly MDP-based construction of feasible solutions, which has been a bottleneck for scaling up in representative DRL solvers so far. In other words, we also no longer need costly MCMC-based sampling for optimizing our model dueto the chain-rule decomposition. Instead, we use autoregressive factorization for sampling from theauxiliary distribution, which is faster than sampling with MCMC from the distribution defined by theenergy function.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"A prescription is a common and important form of medical intervention that is used in modern clinical settings. It comes as a recommendation from an healthcare provider to a patient [1]. It indicates actions such as taking medications, following a diet, or executing physical exercises [2]. When agreed upon between the patient and the healthcare provider, the patient is expected to follow a prescription. Non-adherence to prescriptions is a significant problem in healthcare [2,4]. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}, {"intention": "Concision", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about how to do something, such as taking medication, following a diet, or exercising. When agreed upon between the patient and the healthcare provider, the patient is expected to do this. Non-adherence to prescriptions is a big problem in healthcare. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about how to do something, such as taking medication, following a diet, or exercising. When agreed upon between the patient and the healthcare provider, the patient is expected to do this. Non-adherence to prescriptions is a big problem in healthcare. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about how to do something, such as taking medication, following a diet, or exercising. When agreed upon between the patient and the healthcare provider, the patient is expected to do this. Non-adherence to prescriptions is a big problem in healthcare. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about how to do something, such as taking medication, following a diet, or exercising. When agreed upon between the patient and the healthcare provider, the patient is expected to do this. Non-adherence to prescriptions is a big problem in healthcare. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"A prescription is a common and important form of medical intervention that is used in modern clinical settings. It comes as a recommendation from an healthcare provider to a patient [1]. It indicates actions such as taking medications, following a diet, or executing physical exercises [2]. When agreed upon between the patient and the healthcare provider, the patient is expected to follow a prescription. Non-adherence to prescriptions is a significant problem in healthcare [2,4]. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"A prescription is a common and important form of medical intervention that is used in modern clinical settings. It comes as a recommendation from an healthcare provider to a patient [1]. It indicates actions such as taking medications, following a diet, or executing physical exercises [2]. When agreed upon between the patient and the healthcare provider, the patient is expected to follow a prescription. Non-adherence to prescriptions is a significant problem in healthcare [2,4]. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about what actions to take, eat, or do something to help with an illness. When agreed upon between the patient and the healthcare provider, the patient is expected to follow the prescription. Non-adherence to prescriptions is a significant problem in healthcare.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about how to do something, such as taking medication, following a diet, or exercising. When agreed upon between the patient and the healthcare provider, the patient is expected to do this. Non-adherence to prescriptions is a big problem in healthcare. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about how to do something, such as taking medication, following a diet, or exercising. When agreed upon between the patient and the healthcare provider, the patient is expected to do this. Non-adherence to prescriptions is a big problem in healthcare. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about how to do something, such as taking medication, following a diet, or exercising. When agreed upon between the patient and the healthcare provider, the patient is expected to do this. Non-adherence to prescriptions is a big problem in healthcare. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about how to do something, such as taking medication, following a diet, or exercising. When agreed upon between the patient and the healthcare provider, the patient is expected to do this. Non-adherence to prescriptions is a big problem in healthcare. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "instruction": "Revise this paragraph to be more concise.", "revised_paragraph": "\"A prescription is a recommendation from a healthcare provider to a patient about how to take care of oneself. SEP> When agreed upon between the patient and the healthcare provider, the patient is expected to follow the prescription. Non-adherence to prescriptions is a significant problem in healthcare. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "instruction": "Merge the two first sentences in one shorter one. Improve the sentence defining adherence to make it clearer.", "revised_paragraph": "\"A prescription is a common and important form of medical intervention that is used in modern clinical settings. It comes as a recommendation from an healthcare provider to a patient [1]. It indicates actions such as taking medications, following a diet, or executing physical exercises [2]. When agreed upon between the patient and the healthcare provider, the patient is expected to follow a prescription. The extent to which this implementation corresponds to the agreed upon recommendation is known as adherence. Non-adherence to prescriptions is a significant problem in healthcare [2,4]. Adherence rates average 50% and account for 33-69% of hospital re-admissions, resulting into billions of dollars per year [5,6].\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy buthave been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints,the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3  4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3  4 q violation. With Slater's condition, [20] presents an online gradient descent algorithmbased on the drift-plus-penalty method [19], which achieves O p? T q regret and O p? T q violation. Itremains open that whether O p? T 3  4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition.\""}, {"intention": "Concision", "revised_paragraph": "\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy buthave been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints, the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3  4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3  4 q violation. With Slater's condition, [20] presents an online gradient descent algorithmbased on the drift-plus-penalty method [19] that achieves O p? T q regret and O p? T q violation. Itremains open that whether O p? T 3  4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy buthave been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints, the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3  4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3  4 q violation. With Slater's condition, [20] presents an online gradient descent algorithmbased on the drift-plus-penalty method [19] that achieves O p? T q regret and O p? T q violation. Itremains open that whether O p? T 3  4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy buthave been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints,the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3  4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3  4 q violation. With Slater's condition, [20] presents an online gradient descent algorithmbased on the drift-plus-penalty method [19], which achieves O p? T q regret and O p? T q violation. Itremains open that whether O p? T 3  4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy buthave been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints,the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3  4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3  4 q violation. With Slater's condition, [20] presents an online gradient descent algorithmbased on the drift-plus-penalty method [19], which achieves O p? T q regret and O p? T q violation. Itremains open that whether O p? T 3  4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy but have been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints, the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p? T 3 4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p? T 3 4 q violation. Itremains open that whether O p? T 3 4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy buthave been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints, the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3  4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3  4 q violation. With Slater's condition, [20] presents an online gradient descent algorithmbased on the drift-plus-penalty method [19] that achieves O p? T q regret and O p? T q violation. Itremains open that whether O p? T 3  4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy buthave been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints,the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3  4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3  4 q violation. With Slater's condition, [20] presents an online gradient descent algorithmbased on the drift-plus-penalty method [19], which achieves O p? T q regret and O p? T q violation. Itremains open that whether O p? T 3  4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "instruction": "Remove the second last sentence", "revised_paragraph": "\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy buthave been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints,the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3  4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3  4 q violation. With Slater\u2019s condition, [20] presents an online gradient descent algorithmbased on the drift-plus-penalty method [19], which achieves O p? T q regret and O p? T q violation. Itremains open that whether O p? T 3  4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "instruction": "Remove unnecessary sentence from this paragraph to make it shorter.", "revised_paragraph": "\"COCO-Soft with adversarial constraints: Adversarial constraints are more difficult to satisfy buthave been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints, the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3  4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3  4 q violation. With Slater\u2019s condition, [20] presents an online gradient descent algorithmbased on the drift-plus-penalty method [19] that achieves O p? T q regret and O p? T q violation. Itremains open that whether O p? T 3  4 q violation can be reduced with adversarial constraints (soft orhard) while keeping O p? T q regret without Slater's condition.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in RecSim, we observe that the agent is able to maximize the CPR score by"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in RecSim, we observe that the agent is able to maximize the CPR score by"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in RecSim, we observe that the agent is able to maximize the CPR score by"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in RecSim, we observe that the agent is able to maximize the CPR score by"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in RecSim, we observe that the agent is able to maximize the CPR score by"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in RecSim, we observe that the agent is able to maximize the CPR score by"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in RecSim, we observe that the agent is able to maximize the CPR score by"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in RecSim, we observe that the agent is able to maximize the CPR score by"}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "instruction": "Make this paragraph better. Rewrite a sentece about the Grid World", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring. This shows that for selecting trampoline, the agent checks for the presence of spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in Rec", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "instruction": "Improve the clarity in this paragraph.", "revised_paragraph": "\"In Figure 6, we analyze the agent performance qualitatively. (a) In CREATE, at t = 0, the selected action spring in AGILE\u2019s GAT attends to various other tools, especially covers all the tools that get activated with spring, such as trampoline. At t = 1, the trampoline tool is selected with a strong attention on spring. This shows that for selecting trampoline, the agent checks for the presence of spring, so it is possible to place it before or after the trampoline. (b) In Grid World, we visualize the Summary-GAT ablation to see how summarizer utilizes attention. We consider the case where both dig  lava skills are available. The agent goes right, digs the orange lava, and is about to enter the pink lava. At this point, the Right action attends with a high weight to Dig  Pink skill, checking for its presence before making an irreversible decision of entering the lava. In contrast, the Utility Policy always follows the safe suboptimal path as it is blind to the knowledge of dig-skills before entering lava. Finally, in Rec", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such,  1 and  0 would overfit the respective group\u2019s properties and thus cannot generalize well to the entire population. Therefore, the resulting   would be biased.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such,  1 and  0 would overfit the respective group\u2019s properties and thus cannot generalize well to the entire population. Therefore, the resulting   would be biased.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such,  1 and  0 would overfit the respective group\u2019s properties and thus cannot generalize well to the entire population. Therefore, the resulting   would be biased.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such,  1 and  0 would overfit the respective group\u2019s properties and thus cannot generalize well to the entire population. Therefore, the resulting   would be biased.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such,  1 and  0 would overfit the respective group\u2019s properties and thus cannot generalize well to the entire population. Therefore, the resulting   would be biased.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such, 1 and 0 would overfit the respective group\u2019s properties and thus cannot generalize well to the entire population. Therefore, the resulting would be biased.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such,  1 and  0 would overfit the respective group\u2019s properties and thus cannot generalize well to the entire population. Therefore, the resulting   would be biased.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such,  1 and  0 would overfit the respective group\u2019s properties and thus cannot generalize well to the entire population. Therefore, the resulting   would be biased.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "instruction": "Improve the english of this paragraph.", "revised_paragraph": "\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such,  1 and  0 would overfit the respective group\u2019s properties and thus cannot generalize well to the entire population. Therefore, the resulting   would be biased.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "instruction": "Edit the paragraph to make it more formal and precise.", "revised_paragraph": "\"However, as shown in Figure 2 (a), the treatment selection bias shifts covariate distributions across groups. As such,  1 and  0 would overfit the respective group's properties and thus cannot generalize well to the entire population. Therefore, the resulting   would be biased.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that this loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\""}, {"intention": "Concision", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, particularly when the target values the agent seeks to predict are zero.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\""}, {"intention": "Content_deletion", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that this loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, particularly when the target values the agent seeks to predict are zero.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that this loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that this loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"In this section we show that neural models lose their ability to quickly fit new targets when trained on sequential prediction tasks, where the target values change over time. This loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, particularly when the target values the agent seeks to predict are zero.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, particularly when the target values the agent seeks to predict are zero.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "instruction": "Rewrite the first sentence. Remove the example to make it shorter.", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, including but not limited to those found in value-based RL. We find that this loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "instruction": "Revise the first sentence in a more academic style. Remove unnecessary details.", "revised_paragraph": "\"In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, including but not limited to those found in value-based RL. We find that this loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors. Different from careful network designs as most compared methods have done, we start with the existing EDSR baseline (Lim et al., 2017) and prune it to a much smaller network, showing the effectiveness of our proposed SRP.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors. Different from careful network designs as most compared methods have done, we start with the existing EDSR baseline (Lim et al., 2017) and prune it to a much smaller network, showing the effectiveness of our proposed SRP.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors. Different from careful network designs as most compared methods have done, we start with the existing EDSR baseline (Lim et al., 2017) and prune it to a much smaller network, showing the effectiveness of our proposed SRP.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors. Different from careful network designs as most compared methods have done, we start with the existing EDSR baseline (Lim et al., 2017) and prune it to a much smaller network, showing the effectiveness of our proposed SRP.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors. Different from careful network designs as most compared methods have done, we start with the existing EDSR baseline (Lim et al., 2017) and prune it to a much smaller network, showing the effectiveness of our proposed SRP.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors. Different from careful network designs as most compared methods have done, we start with the existing EDSR baseline (Lim et al., 2017) and prune it to a much smaller network, showing the effectiveness of our proposed SRP.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors. Different from careful network designs as most compared methods have done, we start with the existing EDSR baseline (Lim et al., 2017) and prune it to a much smaller network, showing the effectiveness of our proposed SRP.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors. Different from careful network designs as most compared methods have done, we start with the existing EDSR baseline (Lim et al., 2017) and prune it to a much smaller network, showing the effectiveness of our proposed SRP.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "instruction": "Rewrite the following paragraph, make it more formal.", "revised_paragraph": "\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "instruction": "Improve the writing and change SRPN-L to SRPN-Lite", "revised_paragraph": "\"When compared with all previous methods, our SRPN-L performs the best on all the datasets with all scaling factors. Different from careful network designs as most compared methods have done, we start with the existing EDSR baseline (Lim et al., 2017) and prune it to a much smaller network, showing the effectiveness of our proposed SRP.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better. We also see that the error consistently decreases as the number of inducing points M is increased, and reaches the minimum at M = 80.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better. We also see that the error consistently decreases as the number of inducing points M is increased, and reaches the minimum at M = 80.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better. We also see that the error consistently decreases as the number of inducing points M is increased, and reaches the minimum at M = 80.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better. We also see that the error consistently decreases as the number of inducing points M is increased, and reaches the minimum at M = 80.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better. We also see that the error consistently decreases as the number of inducing points M is increased, and reaches the minimum at M = 80.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better. We also see that the error consistently decreases as the number of inducing points M is increased, and reaches the minimum at M = 80.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better. We also see that the error consistently decreases as the number of inducing points M is increased, and reaches the minimum at M = 80.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better. We also see that the error consistently decreases as the number of inducing points M is increased, and reaches the minimum at M = 80.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "instruction": "Rephrase the sentence related to Figures 2c-d.", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better. We also see that the error consistently decreases as the number of inducing points M is increased, and reaches the minimum at M = 80.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "instruction": "Rephrase the first long sentence to better fit the academic style.", "revised_paragraph": "\"SDE model. Figures 2c-dclearly illustrate that time-variant drift function leads to reduced prediction error, which hints that the dynamics underlying a golf swing motion are learned better.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentationinterrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain the regularization when augmentation helps the training.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentationinterrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain the regularization when augmentation helps the training.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentationinterrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain the regularization when augmentation helps the training.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentationinterrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain the regularization when augmentation helps the training.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentationinterrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain the regularization when augmentation helps the training.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentationinterrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain the regularization when augmentation helps the training.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentationinterrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain the regularization when augmentation helps the training.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentationinterrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain the regularization when augmentation helps the training.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "instruction": "Add missing spaces.", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentationinterrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain the regularization when augmentation helps the training.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "instruction": "Improve the english in the paragraph, make it slightly more formal.", "revised_paragraph": "\"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentation is interrupted when training with a single background because the learning direction toward generalization about various backgrounds is not helpful to train. On the other hand, the training can have helpwhen the difficulty is solved by augmentation.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}, {"intention": "Concision", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}, {"intention": "Concision", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods and knowledge distillation (KD) based methods. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods and knowledge distillation (KD) based methods. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "instruction": "Please, rewrite this paragraph, make it easier to read", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "instruction": "Write in a more passive style and remove the last sentence", "revised_paragraph": "\"We further compare our network pruning method with representative model compression techniques for image SR. Specifically, we compare with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). We provide quantitative results in Tab. 4. Our SRPN-L obtains the best performance with the least parameter number and Mult-Adds. With our SRP pruning method, we do not have to search lots of architectures or train a teacher network, which consumes extra computation resources. These comparisons show that our SRP method has great potential for efficient image SR.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "instruction": "Make this paragraph more concise by introducing acronyms earlier.", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "instruction": "Introduce the acronym DVAE earlier to avoid repeating it.", "revised_paragraph": "\"Discrete Variational Auto-Encoder. In a discrete variational autoencoder (DVAE) (Rolfe, 2016), the network layers before the sampling solver represent the encoder and the layers after the sampling solver represent the decoder. We consider the task of training a DVAE on the M NIST dataset where the encoder maps the input image to a discrete distribution of k -hot binary vector of length 20 in the latent space and the decoder reconstructs the image.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Discussion. In this paper, we show that ID-calibrated ensembles, a simple method of calibrating a standard and robust model only on ID data and then ensembling them, can eliminate the tradeoff between in-distribution (ID) and out-of-distribution (OOD) accuracy on a wide range of natural shifts. We hope that this leads to more widespread use and deployment of robustness interventions.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Discussion. In this paper, we show that ID-calibrated ensembles, a simple method of calibrating a standard and robust model only on ID data and then ensembling them, can eliminate the tradeoff between in-distribution (ID) and out-of-distribution (OOD) accuracy on a wide range of natural shifts. We hope that this leads to more widespread use and deployment of robustness interventions.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Discussion. In this paper, we show that ID-calibrated ensembles, a simple method of calibrating a standard and robust model only on ID data and then ensembling them, can eliminate the tradeoff between in-distribution (ID) and out-of-distribution (OOD) accuracy on a wide range of natural shifts. We hope that this leads to more widespread use and deployment of robustness interventions.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Discussion. In this paper, we show that ID-calibrated ensembles, a simple method of calibrating a standard and robust model only on ID data and then ensembling them, can eliminate the tradeoff between in-distribution (ID) and out-of-distribution (OOD) accuracy on a wide range of natural shifts. We hope that this leads to more widespread use and deployment of robustness interventions.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Discussion. In this paper, we show that ID-calibrated ensembles, a simple method of calibrating a standard and robust model only on ID data and then ensembling them, can eliminate the tradeoff between in-distribution (ID) and out-of-distribution (OOD) accuracy on a wide range of natural shifts. We hope that this leads to more widespread use and deployment of robustness interventions.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Discussion. In this paper, we show that ID-calibrated ensembles, a simple method of calibrating a standard and robust model only on ID data and then ensembling them, can eliminate the tradeoff between in-distribution (ID) and out-of-distribution (OOD) accuracy on a wide range of natural shifts. We hope that this leads to more widespread use and deployment of robustness interventions.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Discussion. In this paper, we show that ID-calibrated ensembles, a simple method of calibrating a standard and robust model only on ID data and then ensembling them, can eliminate the tradeoff between in-distribution (ID) and out-of-distribution (OOD) accuracy on a wide range of natural shifts. We hope that this leads to more widespread use and deployment of robustness interventions.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Discussion. In this paper, we show that ID-calibrated ensembles, a simple method of calibrating a standard and robust model only on ID data and then ensembling them, can eliminate the tradeoff between in-distribution (ID) and out-of-distribution (OOD) accuracy on a wide range of natural shifts. We hope that this leads to more widespread use and deployment of robustness interventions.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "instruction": "Rename this section to a more approapiate title.", "revised_paragraph": "\"Discussion. In this paper, we show that ID-calibrated ensembles, a simple method of calibrating a standard and robust model only on ID data and then ensembling them, can eliminate the tradeoff between in-distribution (ID) and out-of-distribution (OOD) accuracy on a wide range of natural shifts. We hope that this leads to more widespread use and deployment of robustness interventions.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "instruction": "Rename the section \"Conclusion and Future Work\"", "revised_paragraph": "Conclusion and Future Work", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model are identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model are identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}, {"intention": "Concision", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model is identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model is identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model are identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}, {"intention": "Concision", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model is identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model is identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model are identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model are identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model are identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"Statistics We conduct linear regression analysis to show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental G values. For short, we denote the merged coefficient by w unbnd M R and w unbnd W R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model is identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model are identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model is identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model is identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, (w unbnd M R w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model is identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "instruction": "Simplify the explanation of the merged w unbnd M R and w unbnd W R.", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w unbnd W L, w unbnd W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model is identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "instruction": "Concise the penultimate sentence. Improve the English in this paragraph.", "revised_paragraph": "\"Statistical Significance To show that there is a statistically significant relationship between the entropy estimated by the RDE and the experimental  G values, we conduct linear regression analysis using the RDE-Linear model defined in Eq.9. The linear model contains 7 coefficients and 1 bias: w bound W L, w bound W R, w bound M L, w bound M R, w unbnd M L, ( w unbnd M R  w unbnd W R ), and b. Here, w unbnd M R and w unbnd W R are merged because the receptor is not mutated, so the entropy estimated by the model are identical. For short, we denote the merged coefficient by w unbnd R. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "instruction": "Make this paragraph more clear.", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations (Table 6 in the appendix). The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "instruction": "Improve the English in this paragraph.", "revised_paragraph": "\"RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Reweighting methods weight individuals with balanced score to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Reweighting methods weight individuals with balanced score to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Reweighting methods weight individuals with balanced score to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Reweighting methods weight individuals with balanced score to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Reweighting methods weight individuals with balanced score to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Reweighting methods weight individuals with balanced score to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Reweighting methods weight individuals with balanced score to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Reweighting methods weight individuals with balanced score to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "instruction": "Use formal words in the last sentence.", "revised_paragraph": "Reweighting methods weight individuals with a balanced score to obtain globally balanced distributions. The inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "instruction": "Reorder the last sentence arguments. Make this paragraph a bit more precise.", "revised_paragraph": "\"Reweighting methods weight individuals with balanced score to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. However, these methods suffer from high variance and are vulnerable to non-overlapped units.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of   U (  n ).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of   U (  n ).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of   U (  n ).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of   U (  n ).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of   U (  n ).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h = 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of U ( n ).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of   U (  n ).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of   U (  n ).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "instruction": "Make the last sentence logical.", "revised_paragraph": "\"The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of   U (  n ).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "instruction": "Make the last sentence more formal and academic.", "revised_paragraph": "The easiest way to ensure m n = m n + 1 is to set the time step h = 0 but this makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. However, the acceptance probability remains 0 for any h > 0 and thus it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid for any choice of   U ( n ).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns"}, {"intention": "Rewritting_light", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR [7] and two implementations of CLLR, i.e., the l 2, 1 -normbased regularization and nuclear-norm-based regularization. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  ="}], "type_approach": "separate-labels-union"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns"}, {"intention": "Rewritting_light", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR [7] and two implementations of CLLR, i.e., the l 2, 1 -normbased regularization and nuclear-norm-based regularization. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  ="}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns"}, {"intention": "Rewritting_light", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR [7] and two implementations of CLLR, i.e., the l 2, 1 -normbased regularization and nuclear-norm-based regularization. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  ="}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns"}, {"intention": "Rewritting_light", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR [7] and two implementations of CLLR, i.e., the l 2, 1 -normbased regularization and nuclear-norm-based regularization. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  ="}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns"}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e., = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns"}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e., = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns"}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e., = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns"}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e., = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the regularizer to maintain the corresponding non-zero columns\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "instruction": "Remove details about the baseline results and improve the readability.", "revised_paragraph": "\"In this subsection, we conduct ablation study on the superiority of thelow-dimensional contrastive embedding ( i.e., our method) over the traditional contrastive embedding ( i.e., thebaseline method). We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ) and the simply fixed low-dimensional space (dimension =256 and 512 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ). Our method learns contrastive embeddings in low-dimensional space, where we use the thegularizer to maintain the corresponding non-zer", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "instruction": "Remove sentences that are unnecessary here. Simplify this text a bit.", "revised_paragraph": "\"In this section, we conduct an ablation study on the superiority of our method over the traditional contrastive embedding method. We use the STL-10and CIFAR-10 datasets to train the baseline SimCLR and two implementations of CLLR. We train all models with 100 and 400 epochs with the same batch size and learning rate, respectively, and we record the test accuracy of all methods by finetuning a linear softmax. The baseline method learns contrastive embeddings in the high-dimensionalspace (dimension = 2048, 3072, and 4096 ). We also include the baseline results that do not use the l 2, 1 -norm and nuclear normconstraints ( i.e.,  = 0 ).", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although we do not need thevalue of c, we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although we do not need thevalue of c, we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although we do not need thevalue of c, we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although we do not need thevalue of c, we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although we do not need thevalue of c, we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although we do not need thevalue of c, we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although we do not need thevalue of c, we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although we do not need thevalue of c, we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "instruction": "Rewrite some formulations, giving preference to shorter ones.", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although Lemma 1 does not have an explicit construction of c, thanks to the shift-invariant property of the Softmax normalization, we can leave it as an under-determined constant in our positional embedding design, which is Eq. (1) insection 4. Still, given a set of test points  x i  Ni =1, one can do a geometric sequence search 1 to search for a c such that the N  N matrix c +  k (x i, x j )] Ni,j =1  0. Hence, in this work, we do not need thevalue of c, but we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "instruction": "Shorten this paragraph a bit while keeping all the informations.", "revised_paragraph": "\"Lemma 1 implies the CPD kernels in Corollary 1 can be made PD if they are added with large enoughconstants; for example, c   x  x \u2032  p for large enough c. Although Lemma 1 does not have an explicit construction of c, thanks to the shift-invariant property of the Softmax normalization, we can leave it as an under-determined constant in our positional embedding design, which is Eq. (1) insection 4. Still, given a set of test points  x i  Ni =1, one can do a geometric sequence search 1 to search for a c such that the N  N matrix c +  k (x i, x j )] Ni,j =1  0. Hence, in this work, we do not need thevalue of c, but we can compute it if we do need its value, e.g., deriving the feature map of c +  k.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "instruction": "Improve the writing of this text", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "instruction": "Use accurate and scientific words.", "revised_paragraph": "\"There are a lot of measure benchmarking studies considering node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020), etc.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods.\""}, {"intention": "Concision", "revised_paragraph": "Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"intention": "Concision", "revised_paragraph": "Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"intention": "Concision", "revised_paragraph": "Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods."}, {"intention": "Content_deletion", "revised_paragraph": "\"Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"intention": "Concision", "revised_paragraph": "Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "instruction": "Summarize this:", "revised_paragraph": "Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods. Biophysical methods focus on modeling inter-atomic interactions, e.g. hydrogen bonding, electrostatic forces, etc., with mechanical and statistical energy functions. These methods use their underlying energy function to sample conformations of the mutated protein complex and predict the change in binding free energy upon mutations. Statistical methods are based on feature engineering. Descriptors that summarize the geometric, physical, evolutionary, and motif properties of proteinsare used to fit the statistical model that predicts the effect of mutations on binding free energy. Traditional methodsgenerally face the trade-off between speed and accuracy due to the time-consuming sampling process. Sophisticated energy functions and feature engineering underlying these methods depend heavily on human knowledge, thus limiting their pace to improve with the fast-growing of available protein structures.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "instruction": "Make this paragraph shorter.", "revised_paragraph": "\"Traditional approaches to predicting the effect of mutation on protein binding can be roughly divided into two classes: biophysical methods and statistical methods.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "instruction": "Switch the two parts of the first sentence", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "instruction": "Reorder the first sentence.", "revised_paragraph": "\"Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned, With pre-summrizer, and No twin-GAT showed the similar performance which is better than No target-q-change. The difference between AGILE-Tuned and No target-q-change shows thatsince the cascaded networkconsiders the intermediate list constructed in decision-making, in the computation of the target qvalues the agent also needs to refer to the q-value of the next position in the same list instead of another list from the future time-step.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned, With pre-summrizer, and No twin-GAT showed the similar performance which is better than No target-q-change. The difference between AGILE-Tuned and No target-q-change shows thatsince the cascaded networkconsiders the intermediate list constructed in decision-making, in the computation of the target qvalues the agent also needs to refer to the q-value of the next position in the same list instead of another list from the future time-step.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned, With pre-summrizer, and No twin-GAT showed the similar performance which is better than No target-q-change. The difference between AGILE-Tuned and No target-q-change shows thatsince the cascaded networkconsiders the intermediate list constructed in decision-making, in the computation of the target qvalues the agent also needs to refer to the q-value of the next position in the same list instead of another list from the future time-step.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned, With pre-summrizer, and No twin-GAT showed the similar performance which is better than No target-q-change. The difference between AGILE-Tuned and No target-q-change shows thatsince the cascaded networkconsiders the intermediate list constructed in decision-making, in the computation of the target qvalues the agent also needs to refer to the q-value of the next position in the same list instead of another list from the future time-step.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned, With pre-summrizer, and No twin-GAT showed the similar performance which is better than No target-q-change. The difference between AGILE-Tuned and No target-q-change shows thatsince the cascaded networkconsiders the intermediate list constructed in decision-making, in the computation of the target qvalues the agent also needs to refer to the q-value of the next position in the same list instead of another list from the future time-step.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned, With pre-summrizer, and No twin-GAT showed the similar performance which is better than No target-q-change. The difference between AGILE-Tuned and No target-q-change shows thatsince the cascaded networkconsiders the intermediate list constructed in decision-making, in the computation of the target qvalues the agent also needs to refer to the q-value of the next position in the same list instead of another list from the future time-step.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned, With pre-summrizer, and No twin-GAT showed the similar performance which is better than No target-q-change. The difference between AGILE-Tuned and No target-q-change shows thatsince the cascaded networkconsiders the intermediate list constructed in decision-making, in the computation of the target qvalues the agent also needs to refer to the q-value of the next position in the same list instead of another list from the future time-step.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned, With pre-summrizer, and No twin-GAT showed the similar performance which is better than No target-q-change. The difference between AGILE-Tuned and No target-q-change shows thatsince the cascaded networkconsiders the intermediate list constructed in decision-making, in the computation of the target qvalues the agent also needs to refer to the q-value of the next position in the same list instead of another list from the future time-step.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "instruction": "Rewrite the last sentence, splitting it into two to make it easier to understand", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned and No target-q-change both showed good performance.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "instruction": "Simplify heavily the explanations in this paragraph keeping the main points.", "revised_paragraph": "\"Figure 13(b) shows the result on both train and test actions. AGILE-Tuned and With pre-summrizer, and No twin-GAT showed the similar performance which is better than No target-q-change. This shows that since the cascaded networkconsiders the intermediate list constructed in decision-making, in the computation of the target qvalues the agent also needs to refer to the q-value of the next position in the same list instead of another list from the future time-step.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Figure 6 shows a schematic of the task. In experiment 1, we strictly set the starting position of the trial at a fixed location. In experiment 2, we did not set the starting position of the trial as a condition. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as in experiment 1.\""}, {"intention": "Concision", "revised_paragraph": "\"Except for this change, the task was the same as in experiment 1.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Except for this change, the task was the same as in experiment 1.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Except for this change, the task was the same as in experiment 1.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Figure 6 shows a schematic of the task. In experiment 1, we strictly set the starting position of the trial at a fixed location. In experiment 2, we did not set the starting position of the trial as a condition. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as in experiment 1.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Except for this change, the task was the same as in experiment 1.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Figure 6 shows a schematic of the task. In experiment 1, we strictly set the starting position of the trial at a fixed location. In experiment 2, we did not set the starting position of the trial as a condition. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as in experiment 1.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"The starting position of the trial was set to a fixed location in experiment 1, but in experiment 2, we did not set this as a condition. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as in experiment 1.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Except for this change, the task was the same as in experiment 1.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Except for this change, the task was the same as in experiment 1.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"With the exception of this change, the task was the same as in experiment 1.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Except for this change, the task was the same as in experiment 1.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "instruction": "Make the second sentence more concise", "revised_paragraph": "\"Except for this change, the task was the same as in experiment 1.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "instruction": "Make sentence 2 shorter.", "revised_paragraph": "\"Except for this change, the task was the same as in experiment 1.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.\""}, {"intention": "Concision", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too difficult, here is a more intuitive description of Eq."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.\""}, {"intention": "Concision", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too difficult, here is a more intuitive description of Eq."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too difficult, here is a more intuitive description of Eq."}, {"intention": "Rewritting_light", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too difficult, here is a more intuitive description of Eq."}, {"intention": "Rewritting_light", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. 6: \"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. 6: \"\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too difficult, here is a more intuitive description of Eq."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too difficult, here is a more intuitive description of Eq.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too difficult, here is a more intuitive description of Eq."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too difficult, here is a more intuitive description of Eq.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "instruction": "Remove the second setence and make the paragraph more concise", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "instruction": "Remove unnecessary information, use concicse expression.", "revised_paragraph": "\"Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}, {"intention": "Concision", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}, {"intention": "Concision", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "instruction": "Revise this paragraph for better clarity.", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "instruction": "Make this paragraph more simple to read and concise phrases that are to long when possible.", "revised_paragraph": "\"It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport. Dunipace et al. (2021) use the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment causal inference, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "instruction": "Improve the words using in this paragraph", "revised_paragraph": "\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "instruction": "Modify this paragraph to make it more direct and easy to read.", "revised_paragraph": "\"Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch. Avoiding the notch or moving the cursor carefully around the notch can increase the movement time. In this study, we conducted a series of experiments to evaluate the effect of the notch on the movement of the mouse cursor.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they don\u2019t know (Nguyen et al., 2015). In particular, neural networks have been shown to produce high posterior probability for out-of-distribution (OOD) test inputs, which should not be predicted by the model. Taking self-driving car as an example, an object detection model trained to recognize in-distribution objects ( e.g., cars, stop signs) can produce a high-confidence prediction for an unseen object of a moose (see Figure 1(a)). Such a failure case raises concerns in model reliability, and worse, may lead to a catastrophic effect when deployed in safety-critical applications.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they don\u2019t know (Nguyen et al., 2015). In particular, neural networks have been shown to produce high posterior probability for out-of-distribution (OOD) test inputs, which should not be predicted by the model. Taking self-driving car as an example, an object detection model trained to recognize in-distribution objects ( e.g., cars, stop signs) can produce a high-confidence prediction for an unseen object of a moose (see Figure 1(a)). Such a failure case raises concerns in model reliability, and worse, may lead to a catastrophic effect when deployed in safety-critical applications.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they don\u2019t know (Nguyen et al., 2015). In particular, neural networks have been shown to produce high posterior probability for out-of-distribution (OOD) test inputs, which should not be predicted by the model. Taking self-driving car as an example, an object detection model trained to recognize in-distribution objects ( e.g., cars, stop signs) can produce a high-confidence prediction for an unseen object of a moose (see Figure 1(a)). Such a failure case raises concerns in model reliability, and worse, may lead to a catastrophic effect when deployed in safety-critical applications.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they don\u2019t know (Nguyen et al., 2015). In particular, neural networks have been shown to produce high posterior probability for out-of-distribution (OOD) test inputs, which should not be predicted by the model. Taking self-driving car as an example, an object detection model trained to recognize in-distribution objects ( e.g., cars, stop signs) can produce a high-confidence prediction for an unseen object of a moose (see Figure 1(a)). Such a failure case raises concerns in model reliability, and worse, may lead to a catastrophic effect when deployed in safety-critical applications.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they don\u2019t know (Nguyen et al., 2015). In particular, neural networks have been shown to produce high posterior probability for out-of-distribution (OOD) test inputs, which should not be predicted by the model. Taking self-driving car as an example, an object detection model trained to recognize in-distribution objects ( e.g., cars, stop signs) can produce a high-confidence prediction for an unseen object of a moose (see Figure 1(a)). Such a failure case raises concerns in model reliability, and worse, may lead to a catastrophic effect when deployed in safety-critical applications.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they don\u2019t know (Nguyen et al., 2015). In particular, neural networks have been shown to produce high posterior probability for out-of-distribution (OOD) test inputs, which should not be predicted by the model. Taking self-driving car as an example, an object detection model trained to recognize in-distribution objects ( e.g., cars, stop signs) can produce a high-confidence prediction for an unseen object of a moose (see Figure 1(a)). Such a failure case raises concerns in model reliability, and worse, may lead to a catastrophic effect when deployed in safety-critical applications.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they don\u2019t know (Nguyen et al., 2015). In particular, neural networks have been shown to produce high posterior probability for out-of-distribution (OOD) test inputs, which should not be predicted by the model. Taking self-driving car as an example, an object detection model trained to recognize in-distribution objects ( e.g., cars, stop signs) can produce a high-confidence prediction for an unseen object of a moose (see Figure 1(a)). Such a failure case raises concerns in model reliability, and worse, may lead to a catastrophic effect when deployed in safety-critical applications.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they don\u2019t know (Nguyen et al., 2015). In particular, neural networks have been shown to produce high posterior probability for out-of-distribution (OOD) test inputs, which should not be predicted by the model. Taking self-driving car as an example, an object detection model trained to recognize in-distribution objects ( e.g., cars, stop signs) can produce a high-confidence prediction for an unseen object of a moose (see Figure 1(a)). Such a failure case raises concerns in model reliability, and worse, may lead to a catastrophic effect when deployed in safety-critical applications.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they don\u2019t know (Nguyen et al., 2015). In particular, neural networks have been shown to produce high posterior probability for out-of-distribution (OOD) test inputs, which should not be predicted by the model. Taking self-driving car as an example, an object detection model trained to recognize in-distribution objects ( e.g., cars, stop signs) can produce a high-confidence prediction for an unseen object of a moose (see Figure 1(a)). Such a failure case raises concerns in model reliability, and worse, may lead to a catastrophic effect when deployed in safety-critical applications.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "instruction": "Make this paragraph more formal and fitting to academic style.", "revised_paragraph": "\"Modern deep neural networks have achieved unprecedented success in known contexts for which they are trained, yet they do not necessarily know what they do not know.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that  and S are interchangeable as long as the controllable noise /S remains the same. This is true for both cyclic and constant schedules. In the cyclic case, we experimentally show hints that cyclical learning rates oscillate between sharp/deep and wide/shallow minima as long as the stage of increased noise is long enough to allow for mixing.\""}, {"intention": "Concision", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that  and S are interchangeable as long as the controllable noise /S remains the same. This is true for both cyclic and constant schedules. In the cyclic case, we experimentally show hints that cyclical learning rates oscillate between sharp/deep and wide/shallow minima as long as the stage of increased noise is long enough to allow for mixing.\""}, {"intention": "Concision", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that  and S are interchangeable as long as the controllable noise /S remains the same. This is true for both cyclic and constant schedules. In the cyclic case, we experimentally show hints that cyclical learning rates oscillate between sharp/deep and wide/shallow minima as long as the stage of increased noise is long enough to allow for mixing.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that  and S are interchangeable as long as the controllable noise /S remains the same. This is true for both cyclic and constant schedules. In the cyclic case, we experimentally show hints that cyclical learning rates oscillate between sharp/deep and wide/shallow minima as long as the stage of increased noise is long enough to allow for mixing.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that  and S are interchangeable as long as the controllable noise /S remains the same. This is true for both cyclic and constant schedules. In the cyclic case, we experimentally show hints that cyclical learning rates oscillate between sharp/deep and wide/shallow minima as long as the stage of increased noise is long enough to allow for mixing.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that and S are interchangeable as long as the controllable noise /S remains the same.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that  and S are interchangeable as long as the controllable noise /S remains the same. This is true for both cyclic and constant schedules. In the cyclic case, we experimentally show hints that cyclical learning rates oscillate between sharp/deep and wide/shallow minima as long as the stage of increased noise is long enough to allow for mixing.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that and S are interchangeable as long as the controllable noise /S remains the same.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "instruction": "I want to make my paragraph shorter and clearer.", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that  and S are exchangeable as long as the controllable noise /S remains the same. This is true for both cyclic and constant schedules. In the cyclic case, we experimentally show hints that cyclical learning rates oscillate between sharp/deep and wide/shallow minima as long as the stage of increased noise is long enough to allow for mixing.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "instruction": "Delete the context in the first sentence. Delete the second sentence from the end. Smooth out the writing.", "revised_paragraph": "\"We discuss the limitations of the theory and in what situations it breaks down, exemplified by when the learning rate gets too large. We also experimentally verify that  and S are exchangeable as long as the controllable noise /S remains the same. This is true for both cyclic and constant schedules. In the cyclic case, we experimentally show hints that cyclical learning rates oscillate between sharp/deep and wide/shallow minima as long as the stage of increased noise is long enough to allow for mixing.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our proposed architecture. The main idea is to use symmetrized KL divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix C.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our proposed architecture. The main idea is to use symmetrized KL divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix C.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our proposed architecture. The main idea is to use symmetrized KL divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix C.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our proposed architecture. The main idea is to use symmetrized KL divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix C.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our proposed architecture. The main idea is to use symmetrized KL divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix C.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our proposed architecture. The main idea is to use symmetrized KL divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix C.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our proposed architecture. The main idea is to use symmetrized KL divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix C.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our proposed architecture. The main idea is to use symmetrized KL divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix C.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "instruction": "Review this paragraph, remove unnecessary details", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our proposed architecture. The main issue is that the statistical distance is not differentiable (as classifier   is binary) so wewant to replace it with a differentiable proxy. We show a high-level description of our training procedure in Algorithm 1. In each step, we sample a batch of x 0 and xfrom the respective distributions and encode them to the representations z 0 and z 1. We then estimate a symmetrized KL-divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix C", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "instruction": "Make the second sentence more concise and fitting to the academic style.", "revised_paragraph": "\"Training flow-based encoders The next challenge is to design a training procedure for our newly proposed architecture. The main issue is that the statistical distance is not differentiable (as classifier   is binary) so wewant to replace it with a differentiable proxy. We show a high-level description of our training procedure in Algorithm 1. In each step, we sample a batch of x 0 and xfrom the respective distributions and encode them to the representations z 0 and z 1. We then estimate a symmetrized KL-divergence between distributions Z 0 and Z 1, denoted as L 0 + L 1, and combine it with a classification loss L clf using tradeoff parameter , and run a gradient step to minimize the joint loss. While we use a convex scalarization scheme to obtain the joint loss in Algorithm 1, our approach is independent of the concrete multi-objective optimization objective. We will demonstrate the compatibility with other scalarization schemes in Appendix", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C. To complete this task with Design A, participants had tovertically scroll to the end of the day to see all entries. Three participants (P3, P5, and P7) complained about this., and P8 said \"The time frames are a bit big. So it makes like I said, it really makes it scroll off that you can\u2019t see it all in one consolidated view\". With Design B, participants were expected to use the daily medication summaries provided at the top. Three participants (P1, P6, and P9) found the daily summaries helpful in performing this task. However, three participants (P3, P4, and P5) also complained about the lines demarcating days not being clear. For example, P4 said \"I have a harder time differentiating the calendar component the days, because there\u2019s not a strong border between the days of the week.\".\""}, {"intention": "Concision", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C."}, {"intention": "Content_deletion", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C. To complete this task with Design A, participants had tovertically scroll to the end of the day to see all entries. Three participants (P3, P5, and P7) complained about this., and P8 said \"The time frames are a bit big. So it makes like I said, it really makes it scroll off that you can\u2019t see it all in one consolidated view\". With Design B, participants were expected to use the daily medication summaries provided at the top. Three participants (P1, P6, and P9) found the daily summaries helpful in performing this task. However, three participants (P3, P4, and P5) also complained about the lines demarcating days not being clear. For example, P4 said \"I have a harder time differentiating the calendar component the days, because there\u2019s not a strong border between the days of the week.\".\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C. To complete this task with Design A, participants had tovertically scroll to the end of the day to see all entries. Three participants (P3, P5, and P7) complained about this., and P8 said \"The time frames are a bit big. So it makes like I said, it really makes it scroll off that you can\u2019t see it all in one consolidated view\". With Design B, participants were expected to use the daily medication summaries provided at the top. Three participants (P1, P6, and P9) found the daily summaries helpful in performing this task. However, three participants (P3, P4, and P5) also complained about the lines demarcating days not being clear. For example, P4 said \"I have a harder time differentiating the calendar component the days, because there\u2019s not a strong border between the days of the week.\".\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"A and Design B, and 7.0 seconds with Design C. To complete this task with Design A, participants had to scroll to the end of the day to see all entries. Three participants complained about this., and P8 said \"The time frames are a bit big. So it really makes it scroll off that you can\u2019t see it all in one consolidated view\". With Design B, participants were expected to use the daily medication summaries provided at the top. Three participants (P1, P6, and P9) found the daily summaries helpful in performing this task. However, three participants (P3, P4, and P5) also complained about the lines demarcating days not being clear."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "instruction": "Remove unnecessary details for the paragraph.", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C. To complete this task with Design A, participants had tovertically scroll to the end of the day to see all entries. Three participants (P3, P5, and P7) complained about this. For example, P3 said \"I find it's a lot of scrolling down. It would be helpful if there was a way to condense it or to make it possible to see the entire calendar available in terms of morning, afternoon, and evening.\", and P8 said \"The time frames are a bit big. So it really makes it scroll off that you can't see it all in one consolidated view.\".", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "instruction": "The first sentence is a bit unclear.", "revised_paragraph": "\"A and Design B, and 7.0 seconds with Design C. To complete this task with Design A, participants had tovertically scroll to the end of the day to see all entries. Three participants (P3, P5, and P7) complained about this. For example, P3 said \"I find it\u2019s a lot of scrolling down. It would be helpful if there was a way to condense it or to make it possible to see the entire calendar available in terms of morning, afternoon, and evening.\", and P8 said \"The time frames are a bit big. So it really makes it scroll off that you can\u2019t see it all in one consolidated view.\".", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, parameters during training."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, parameters during training."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, parameters during training."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, parameters during training."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, parameters during training."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, parameters during training."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, parameters during training."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, parameters during training."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "instruction": "Edit the last sentence of this paragraph to make it shorter and remove the reference to Section 5.", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, reparameterization during training.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "instruction": "Rewrite the last sentence to make it more concise.", "revised_paragraph": "\"Most closely related to our work are dynamic sparse reparameterization techniques that emerged only recently. Like ours, these methods adaptively alter, by certain heuristic rules, parameters during training.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "instruction": "Rephrase the paragraph", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "instruction": "Make this paragraph more clear and precise.", "revised_paragraph": "\"These models use an inference network that takes as input the full video frame sequences to predict the locations of 2D object bounding boxes, as well as frame-to-frame displacements, in order to minimize view prediction error in 2D. We were not able to produce meaningful results from their inference networks. The success of Hsieh et al. (2018) may partially depend on carefully selected priors for 2D object bounding box location and object size parameters that match the moving MNIST dataset statistics used in the paper, as suggested by the publicly available code. We do not assume knowledgeor existence ofsuch object location or size priors for our CARLA data.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s. Such a formulation is based on three assumptions: 1) The size of the original labeled set is large enough to cover the feature space, 2) the labeled segments are distributed uniformly in the feature space, and 3) the embedding already encodes certain semantic information. Therefore, we only apply this relationship to propagate the keypoint annotations in the DensePose dataset, where each body part is annotated by a point.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s. Such a formulation is based on three assumptions: 1) The size of the original labeled set is large enough to cover the feature space, 2) the labeled segments are distributed uniformly in the feature space, and 3) the embedding already encodes certain semantic information. Therefore, we only apply this relationship to propagate the keypoint annotations in the DensePose dataset, where each body part is annotated by a point.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s. Such a formulation is based on three assumptions: 1) The size of the original labeled set is large enough to cover the feature space, 2) the labeled segments are distributed uniformly in the feature space, and 3) the embedding already encodes certain semantic information. Therefore, we only apply this relationship to propagate the keypoint annotations in the DensePose dataset, where each body part is annotated by a point.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s. Such a formulation is based on three assumptions: 1) The size of the original labeled set is large enough to cover the feature space, 2) the labeled segments are distributed uniformly in the feature space, and 3) the embedding already encodes certain semantic information. Therefore, we only apply this relationship to propagate the keypoint annotations in the DensePose dataset, where each body part is annotated by a point.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s. Such a formulation is based on three assumptions: 1) The size of the original labeled set is large enough to cover the feature space, 2) the labeled segments are distributed uniformly in the feature space, and 3) the embedding already encodes certain semantic information. Therefore, we only apply this relationship to propagate the keypoint annotations in the DensePose dataset, where each body part is annotated by a point.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s. Such a formulation is based on three assumptions: 1) The size of the original labeled set is large enough to cover the feature space, 2) the labeled segments are distributed uniformly in the feature space, and 3) the embedding already encodes certain semantic information. Therefore, we only apply this relationship to propagate the keypoint annotations in the DensePose dataset, where each body part is annotated by a point.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s. Such a formulation is based on three assumptions: 1) The size of the original labeled set is large enough to cover the feature space, 2) the labeled segments are distributed uniformly in the feature space, and 3) the embedding already encodes certain semantic information. Therefore, we only apply this relationship to propagate the keypoint annotations in the DensePose dataset, where each body part is annotated by a point.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s. Such a formulation is based on three assumptions: 1) The size of the original labeled set is large enough to cover the feature space, 2) the labeled segments are distributed uniformly in the feature space, and 3) the embedding already encodes certain semantic information. Therefore, we only apply this relationship to propagate the keypoint annotations in the DensePose dataset, where each body part is annotated by a point.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "instruction": "Rewrite this paragraph to make it considerably clearer.", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C, where  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s. Such a formulation is based on three assumptions: 1) The size of the original labeled set is large enough to cover the feature space, 2) the labeled segments are distributed uniformly in the feature space, and 3) the embedding already encodes certain semantic information. Therefore, we only apply this relationship to propagate the keypoint annotations in the DensePose dataset, where each body part is annotated by a point.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "instruction": "Revise this paragraph to improve readability and cohesiveness.", "revised_paragraph": "\"To be specific, we assign a semantic label for each unlabeled segment by finding its nearest labeled segment in the feature space. We denote this new labeled set (together with the original labeled set) as  C, where  C + denotes all the same-category segments other than segment s in  C and pixel i belongs to the segment s.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"intention": "Concision", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"intention": "Concision", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "instruction": "I want to use other words in my paragraph.", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "instruction": "Revise this text to make it a little more concise and fitting to the academic style.", "revised_paragraph": "\"Given the issue above, it is necessary to prune all the Conv layers in residual blocks if we seek acceleration of practical use. Thus, we need a method to align the pruned indices in all constrained Conv layers. Regularization then arises as a natural solution given its prevailing use to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), and they are only useful when applied to small abstractions in the context of compositionally computing upper bounds on other topological properties. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions\u2019 recurrence diameters (Abdulaziz 2017)[Chapter 3, Theorem 2]. Accordingly, due to this absence of a practical way to compute it or tightly bound it, the recurrence diameter cannot be practically used as a completeness threshold.\""}, {"intention": "Concision", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time, and they are only useful when applied to small abstractions. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time, and they are only useful when applied to small abstractions. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), and they are only useful when applied to small abstractions in the context of compositionally computing upper bounds on other topological properties. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions\u2019 recurrence diameters (Abdulaziz 2017)[Chapter 3, Theorem 2]. Accordingly, due to this absence of a practical way to compute it or tightly bound it, the recurrence diameter cannot be practically used as a completeness threshold.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), and they are only useful when applied to small abstractions in the context of compositionally computing upper bounds on other topological properties. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions\u2019 recurrence diameters (Abdulaziz 2017)[Chapter 3, Theorem 2]. Accordingly, due to this absence of a practical way to compute it or tightly bound it, the recurrence diameter cannot be practically used as a completeness threshold.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time, and they are only useful when applied to small abstractions. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time, and they are only useful when applied to small abstractions. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), and they are only useful when applied to small abstractions in the context of compositionally computing upper bounds on other topological properties. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions\u2019 recurrence diameters (Abdulaziz 2017)[Chapter 3, Theorem 2]. Accordingly, due to this absence of a practical way to compute it or tightly bound it, the recurrence diameter cannot be practically used as a completeness threshold.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "instruction": "I want to get rid of unnecessary details.", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), and they are only useful when applied to small abstractions in the context of compositionally computing upper bounds on other topological properties. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "instruction": "Remove the references in the second half of the paragraph. Reorder the last sentence to improve readability.", "revised_paragraph": "\"Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), and they are only useful when applied to small abstractions in the context of compositionally computing upper bounds on other topological properties. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions\u2019 recurrence diameters (Abdulaziz 2017)[Chapter 3, Theorem 2]. Accordingly, due to this absence of a practical way to compute it or tightly bound it, the recurrence diameter cannot be practically used as a completeness threshold.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "instruction": "Rewrite the second sentence. Replace some words for the better", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "instruction": "Make this paragraph more logical and precise.", "revised_paragraph": "\"In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). Finally, in experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasis on the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasis on the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasis on the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasis on the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasis on the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasis on the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasis on the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasis on the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "instruction": "Remove unnecessary details on specific numerical performance of the model. Link to https://github.com/hwwang55/MolR instead of supplementary material.", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasis on the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation. The key idea of our approach is to preserve the equivalence of molecules with respect to chemical reactions in the embedding space, i.e., forcing the sum of reactant embeddings and the sum of product embeddings to be equal for each chemical equation. This constraint is proven effective to 1) keep the embedding space well-organized and 2) improve the generalization ability of molecule representation. Moreover, our model can use any GNN as the molecule encoder and is thus agnostic to GNN architectures. Experimental results demonstrate that our method achieves state-of-the-art performance in a variety of downstream tasks, e.g., 17.4% absolute Hit@1 gain in chemical reaction prediction, 2.3% absolute AUC gain in molecule property prediction, and 18.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "instruction": "Make the second last sentence from the end of this paragraph more concise by removing too precise details.  For the last sentence, the code is now provided on github.", "revised_paragraph": "\"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasize the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To this end, we define a kind of (,  )-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To this end, we define a kind of (,  )-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To this end, we define a kind of (,  )-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To this end, we define a kind of (,  )-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To this end, we define a kind of (,  )-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To this end, we define a kind of (,  )-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To this end, we define a kind of (,  )-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To this end, we define a kind of (,  )-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "instruction": "Use accurate words.", "revised_paragraph": "\"To this end, we define a kind of (,  )-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "instruction": "Make the second half of this paragraph more precise and direct.", "revised_paragraph": "\"To this end, we define a kind of (,  ) -measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. With the above theoretical findings, we then study two canonical contrastive losses, InfoNCE and cross-correlation, to see how they satisfy the first two factors. Furthermore, we conduct various experiments to study the third factor, and observe that the downstream performance is highly correlated to the concentration of augmented data.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] are used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB) with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] are used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB) with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] are used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB) with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] are used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB) with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] are used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB) with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] are used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB) with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] are used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB) with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] are used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB) with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "instruction": "Remove some details on model training to make the paragraph more concise.", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] respectively have the channel of 24, 32, 56, and 160, and they are resized and concatenated together to form a 272-channel feature map. The reduced channel dimension is set as 256. AdamWoptimizer [18] with weight decay 1  10  4 is used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "instruction": "Remove unnecessary details to shorten this paragraph.", "revised_paragraph": "\"Setup. Anomaly detection aims to detect whether an image contains anomalous regions. The performance is evaluated on MVTec-AD [3]. The image size is selected as 224  224, and the size forresizing feature maps is set as 14  14. The feature maps from stage-1 to stage-4 of EfficientNet-b4[37] respectively have the channel of 24, 32, 56, and 160, and they are resized and concatenated together to form a 272-channel feature map. The reduced channel dimension is set as 256. AdamWoptimizer [18] with weight decay 1  10  4 is used for training. Our model is trained for 1000 epochs on 8 GPUs (NVIDIA Tesla V100 16GB) with batch size 64. The learning rate is 1  10  4 initially, and dropped by 0.1 after 800 epochs. The neighbor size is set as 7  7. The jittering scale and jitteringprobability are chosen as 20 and 1, respectively. The evaluation is run with 5 random seeds.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Semantic co-occurrence. Semantic context characterizes the co-occurrences of different objects and can be used to group and separate pixels. We define semantic context as the union of object classes in each image. Hence, even without the location of labels, we can leverage semantic context to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}, {"intention": "Concision", "revised_paragraph": "\"Semantic co-occurrence. Semantic context can be used to group and separate pixels. We define semantic context as the union of object classes in each image. With this information, we can use it to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Semantic co-occurrence. Semantic context can be used to group and separate pixels. We define semantic context as the union of object classes in each image. With this information, we can use it to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Semantic co-occurrence. Semantic context can be used to group and separate pixels. We define semantic context as the union of object classes in each image. With this information, we can use it to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Semantic co-occurrence. Semantic context characterizes the co-occurrences of different objects and can be used to group and separate pixels. We define semantic context as the union of object classes in each image. Hence, even without the location of labels, we can leverage semantic context to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}, {"intention": "Concision", "revised_paragraph": "\"Semantic co-occurrence. Semantic context can be used to group and separate pixels. We define semantic context as the union of object classes in each image. With this information, we can use it to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Semantic co-occurrence. Semantic context characterizes the co-occurrences of different objects and can be used to group and separate pixels. We define semantic context as the union of object classes in each image. Hence, even without the location of labels, we can leverage semantic context to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Semantic co-occurrence. Semantic context can be used to group and separate pixels. We define semantic context as the union of object classes in each image. Hence, even without the location of labels, we can leverage semantic context to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Semantic co-occurrence. Semantic context can be used to group and separate pixels. We define semantic context as the union of object classes in each image. With this information, we can use it to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Semantic co-occurrence. Semantic context can be used to group and separate pixels. We define semantic context as the union of object classes in each image. With this information, we can use it to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Semantic co-occurrence. Semantic context characterizes the co-occurrences of different objects and can be used to group and separate pixels. We define semantic context as the union of object classes in each image. Hence, even without the location of labels, we can leverage semantic context to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Semantic co-occurrence. Semantic context can be used to group and separate pixels. We define semantic context as the union of object classes in each image. Hence, even without the location of labels, we can leverage semantic context to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "instruction": "Rewrite this paragraph to be more concise.", "revised_paragraph": "\"Semantic co-occurrence. Semantic context is the co-occurrences of different objects and can be used to group and separate pixels. We define semantic context as the union of object classes in each image.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "instruction": "Split the last sentence and make it slightly shorter. Improve the english.", "revised_paragraph": "\"Semantic co-occurrence. Semantic context characterizes the co-occurrences of different objects and can be used to group and separate pixels. We define semantic context as the union of object classes in each image. Moreover, we can leverage semantic context to impose global regularization in the latent feature space, i.e., the pixel-wise feature embedding should be separated from all the other pixels from images without overlapping object categories.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we respectively experiment with removing the hierarchical encoder, hierarchical decoder,skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}, {"intention": "Concision", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we respectively experiment with removing the hierarchical encoder, hierarchical decoder,skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}, {"intention": "Concision", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we respectively experiment with removing the hierarchical encoder, hierarchical decoder,skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we respectively experiment with removing the hierarchical encoder, hierarchical decoder,skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "instruction": "Rewrite the last sentence to make it more concise.", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "instruction": "Make the paragraph shorter.", "revised_paragraph": "\"Hierarchical Modules. As reported in Table 7, on top of our final solution of Point-M2AE in the first row, we experiment with removing the hierarchical encoder, hierarchical decoder, skip connections, and local spatial self-attention layers from our framework. Specifically, we replace our encoder and decoder with 1-stage plain architectures similar to MAE, which contains 15 and 2blocks of vanilla self-attention layers, respectively. We observe the absence of multi-stage structures either in encoder or decoder would hurt the performance, and the hierarchical encoder plays a better role than the decoder. Also, the skip connectionsand local spatial attention can well benefit thenetwork by providing complementary information and local inductive bias.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "instruction": "Remove the second sentence", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "instruction": "Remove unnecessary details to make this paragraph shorter.", "revised_paragraph": "\"In this section, we investigate the influence of activation functions in PINNs for solving PDE/ODE systems. We evaluate and compare the effectiveness of several common activation functions on some simple problems with analytical solutions. The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "instruction": "Rewrite the first sentence to also explain the structure of the section.", "revised_paragraph": "\"MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "instruction": "Rewrite the first sentence to better introduce the section.", "revised_paragraph": "\"We experimented on three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. Our code will be open-sourced.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. We first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to data stochasticity ( e.g., consistency regularization under different augmentations) or model stochasticity ( e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel  -model by simultaneously encouraging the invariance to data and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model and data stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. We first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to data stochasticity ( e.g., consistency regularization under different augmentations) or model stochasticity ( e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel  -model by simultaneously encouraging the invariance to data and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model and data stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. We first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to data stochasticity ( e.g., consistency regularization under different augmentations) or model stochasticity ( e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel  -model by simultaneously encouraging the invariance to data and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model and data stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. We first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to data stochasticity ( e.g., consistency regularization under different augmentations) or model stochasticity ( e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel  -model by simultaneously encouraging the invariance to data and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model and data stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. We first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to data stochasticity ( e.g., consistency regularization under different augmentations) or model stochasticity ( e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel  -model by simultaneously encouraging the invariance to data and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model and data stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. We first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to data stochasticity ( e.g., consistency regularization under different augmentations) or model stochasticity ( e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel  -model by simultaneously encouraging the invariance to data and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model and data stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. We first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to data stochasticity ( e.g., consistency regularization under different augmentations) or model stochasticity ( e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel  -model by simultaneously encouraging the invariance to data and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model and data stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. We first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to data stochasticity ( e.g., consistency regularization under different augmentations) or model stochasticity ( e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel  -model by simultaneously encouraging the invariance to data and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model and data stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "instruction": "Remove the second-to-last sentence.", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. However, the existing data-efficient methods in deep learning either encourage invariance to data stochasticity ( e.g., consistency regularization under different augmentations) or model stochasticity ( e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel  -model by simultaneously encouraging the invariance to data stochasticity and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "instruction": "Delete the sentence about the minmax game.", "revised_paragraph": "\"To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. Further, we propose a novel  -model by simultaneously encouraging the invariance to data stochasticity and model stochasticity. Further, the  -model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model stochasticity. Extensive experiments verify the superiority of the  -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \u2022 Curricula achieve (almost) no improvement in the standard setting (Section 4). We show curriculum learning, random, and anti-curriculum learning perform almost equally well in the standard setting. Furthermore, we establish that using similar techniques to remove examples from the training set (as opposed to introducing them) also does not help. \u2022 Curriculum learning improves over standard training when training time is limited (Section 5). We mimic the large data regime, where training for multiple epochs is not feasible, we limit the number of iterations in the training algorithm and compare curriculum, random and anti-curriculum ordering against standard training. Our experiments reveal a clear advantage of curriculum learning over other methods."}, {"intention": "Concision", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \u2022 Curricula achieve (almost) no improvement in the standard setting (Section 4). We show curriculum learning, random, and anti-curriculum learning perform almost equally well in the standard setting. Furthermore, we establish that using similar techniques to remove examples from the training set (as opposed to introducing them) also does not help. \u2022 Curriculum learning improves over standard training when training time is limited (Section 5). We mimic the large data regime, where training for multiple epochs is not feasible, we limit the number of iterations in the training algorithm and compare curriculum, random and anti-curriculum ordering against standard training. Our experiments reveal a clear advantage of curriculum learning over other methods."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \""}, {"intention": "Content_deletion", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \u2022 Curricula achieve (almost) no improvement in the standard setting (Section 4). We show curriculum learning, random, and anti-curriculum learning perform almost equally well in the standard setting. Furthermore, we establish that using similar techniques to remove examples from the training set (as opposed to introducing them) also does not help. \u2022 Curriculum learning improves over standard training when training time is limited (Section 5). We mimic the large data regime, where training for multiple epochs is not feasible, we limit the number of iterations in the training algorithm and compare curriculum, random and anti-curriculum ordering against standard training. Our experiments reveal a clear advantage of curriculum learning over other methods."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \u2022 Curricula achieve (almost) no improvement in the standard setting (Section 4). We show curriculum learning, random, and anti-curriculum learning perform almost equally well in the standard setting. Furthermore, we establish that using similar techniques to remove examples from the training set (as opposed to introducing them) also does not help. \u2022 Curriculum learning improves over standard training when training time is limited (Section 5). We mimic the large data regime, where training for multiple epochs is not feasible, we limit the number of iterations in the training algorithm and compare curriculum, random and anti-curriculum ordering against standard training. Our experiments reveal a clear advantage of curriculum learning over other methods."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \u2022 Curricula achieve (almost) no improvement in the standard setting (Section 4). We show curriculum learning, random, and anti-curriculum learning perform almost equally well in the standard setting. Furthermore, we establish that using similar techniques to remove examples from the training set (as opposed to introducing them) also does not help. \u2022 Curriculum learning improves over standard training when training time is limited (Section 5). We mimic the large data regime, where training for multiple epochs is not feasible, we limit the number of iterations in the training algorithm and compare curriculum, random and anti-curriculum ordering against standard training. Our experiments reveal a clear advantage of curriculum learning over other methods."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"\u2022 Implicit Curricula: Examples are learned in a consistent order. We show that this order can be changed by changing the order in which examples are presented during training. Finally, we show that well-known notions of sample difficulty are highly correlated with each other."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \u2022 Curricula achieve (almost) no improvement in the standard setting (Section 4). We show curriculum learning, random, and anti-curriculum learning perform almost equally well in the standard setting. Furthermore, we establish that using similar techniques to remove examples from the training set (as opposed to introducing them) also does not help. \u2022 Curriculum learning improves over standard training when training time is limited (Section 5). We mimic the large data regime, where training for multiple epochs is not feasible, we limit the number of iterations in the training algorithm and compare curriculum, random and anti-curriculum ordering against standard training. Our experiments reveal a clear advantage of curriculum learning over other methods."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \u2022 Curricula achieve (almost) no improvement in the standard setting (Section 4). We show curriculum learning, random, and anti-curriculum learning perform almost equally well in the standard setting. Furthermore, we establish that using similar techniques to remove examples from the training set (as opposed to introducing them) also does not help. \u2022 Curriculum learning improves over standard training when training time is limited (Section 5). We mimic the large data regime, where training for multiple epochs is not feasible, we limit the number of iterations in the training algorithm and compare curriculum, random and anti-curriculum ordering against standard training. Our experiments reveal a clear advantage of curriculum learning over other methods."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "instruction": "Remove the less important details in the results.", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \u2022 Curricula achieve (almost) no improvement in the standard setting (Section 4). We show curriculum learning, random, and anti-curriculum learning perform almost equally well in the standard setting. Furthermore, we establish that using similar techniques to remove examples from the training set (as opposed to introducing them) also does not help. \u2022 Curriculum learning improves over standard training when training time is limited (Section 5). We mimic the large data regime, where training for multiple epochs is not feasible, we limit the number of iterations in the training algorithm and compare curriculum, random and anti-curriculum ordering against standard training. Our experiments reveal a clear advantage of curriculum learning over other methods.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "instruction": "Remove unnecessary details.", "revised_paragraph": "\"\u2022 Implicit Curricula: Examples are learned in a consistent order (Section 2). We show that the order in which examples are learned is consistent across runs, similar training methods, and similar architectures. Furthermore, we show that it is possible to change this order by changing the order in which examples are presented during training. Finally, we establish that well-known notions of sample difficulty are highly correlated with each other. \u2022 Curricula achieve (almost) no improvement in the standard setting (Section 4). We show curriculum learning, random, and anti-curriculum learning perform almost equally well in the standard setting. Furthermore, we establish that using similar techniques to remove examples from the training set (as opposed to introducing them) also does not help. \u2022 Curriculum learning improves over standard training when training time is limited (Section 5). We mimic the large data regime, where training for multiple epochs is not feasible, we limit the number of iterations in the training algorithm and compare curriculum, random and anti-curriculum ordering against standard training. Our experiments reveal a clear advantage of curriculum learning over other methods.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The user model takes as input the user information and a set of item embeddings in the list. The user information is passed on to a single layer gated recurrent network(GRU (Cho et al., 2014)) followed by a 2-layer MLP to extract the compact representation of the state. Also, the set of item embeddings is processed by the same architecture of the GRU network(this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list followed by the sigmoid function to transform to the individual click likelihood.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The user model takes as input the user information and a set of item embeddings in the list. The user information is passed on to a single layer gated recurrent network(GRU (Cho et al., 2014)) followed by a 2-layer MLP to extract the compact representation of the state. Also, the set of item embeddings is processed by the same architecture of the GRU network(this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list followed by the sigmoid function to transform to the individual click likelihood.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The user model takes as input the user information and a set of item embeddings in the list. The user information is passed on to a single layer gated recurrent network(GRU (Cho et al., 2014)) followed by a 2-layer MLP to extract the compact representation of the state. Also, the set of item embeddings is processed by the same architecture of the GRU network(this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list followed by the sigmoid function to transform to the individual click likelihood.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The user model takes as input the user information and a set of item embeddings in the list. The user information is passed on to a single layer gated recurrent network(GRU (Cho et al., 2014)) followed by a 2-layer MLP to extract the compact representation of the state. Also, the set of item embeddings is processed by the same architecture of the GRU network(this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list followed by the sigmoid function to transform to the individual click likelihood.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The user model takes as input the user information and a set of item embeddings in the list. The user information is passed on to a single layer gated recurrent network(GRU (Cho et al., 2014)) followed by a 2-layer MLP to extract the compact representation of the state. Also, the set of item embeddings is processed by the same architecture of the GRU network(this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list followed by the sigmoid function to transform to the individual click likelihood.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The user model takes as input the user information and a set of item embeddings in the list. The user information is passed on to a single layer gated recurrent network(GRU (Cho et al., 2014)) followed by a 2-layer MLP to extract the compact representation of the state. Also, the set of item embeddings is processed by the same architecture of the GRU network(this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list followed by the sigmoid function to transform to the individual click likelihood.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The user model takes as input the user information and a set of item embeddings in the list. The user information is passed on to a single layer gated recurrent network(GRU (Cho et al., 2014)) followed by a 2-layer MLP to extract the compact representation of the state. Also, the set of item embeddings is processed by the same architecture of the GRU network(this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list followed by the sigmoid function to transform to the individual click likelihood.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The user model takes as input the user information and a set of item embeddings in the list. The user information is passed on to a single layer gated recurrent network(GRU (Cho et al., 2014)) followed by a 2-layer MLP to extract the compact representation of the state. Also, the set of item embeddings is processed by the same architecture of the GRU network(this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list followed by the sigmoid function to transform to the individual click likelihood.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "instruction": "Make the third sentence shorter and easier to understand", "revised_paragraph": "\"The user model takes as input the user information and the list of items in the list. The user information is passed on to a single layer gated recurrent network (GRU) followed by a 2-layer MLP to represent the state of the user. Also, the set of item embeddings is processed by the same architecture of the GRU network (this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "instruction": "Simplify the convoluted sentences to make the paragraph more concise.", "revised_paragraph": "\"The user model takes as input the user information and the list of items in the list. Then, the user information is passed on to a single layer gated recurrent network (GRU) followed by a 2-layer MLP to represent the state of the user. Also, the set of item embeddings is processed by the same architecture of the GRU network (this and the one before are not shared and initialized differently) as the list-embedding. Finally, a 2-layer MLP takes as input the concatenation of those two embeddings and provides the scores of items in the list.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}, {"intention": "Concision", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}, {"intention": "Concision", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as, result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l 3 is challenging due to the calculation of F ( p, k, l 1 ) (4).\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as, result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l 3 is challenging due to the calculation of F ( p, k, l 1 ) (4).\"\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as, result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l 3 is challenging due to the calculation of F ( p, k, l 1 ) (4).\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as, result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l 3 is challenging due to the calculation of F ( p, k, l 1 ) (4).\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "instruction": "Remove the second last sentence ", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. However, we remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "instruction": "Remove unnecessary information, use accurate expression and evidence.", "revised_paragraph": "\"The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as  , result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l  3 is challenging due to the calculation of F ( p, k,   l  1 ) (4).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Conventional TCP CC uses a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely on the variation of delay. Recently, different CC techniques specialized for data-center networks are alsoproposed.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Conventional TCP CC uses a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely on the variation of delay. Recently, different CC techniques specialized for data-center networks are alsoproposed.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Conventional TCP CC uses a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely on the variation of delay. Recently, different CC techniques specialized for data-center networks are alsoproposed.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Conventional TCP CC uses a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely on the variation of delay. Recently, different CC techniques specialized for data-center networks are alsoproposed.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Conventional TCP CC uses a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely on the variation of delay. Recently, different CC techniques specialized for data-center networks are alsoproposed.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Conventional TCP CC uses a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely on the variation of delay. Recently, different CC techniques specialized for data-center networks are alsoproposed.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Conventional TCP CC uses a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely on the variation of delay. Recently, different CC techniques specialized for data-center networks are alsoproposed.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Conventional TCP CC uses a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely on the variation of delay. Recently, different CC techniques specialized for data-center networks are alsoproposed.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "instruction": "Make the last sentence slightly shorter.", "revised_paragraph": "\"Conventional TCP CC adopts a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely onthe variation of delay, e.g., Vegas. Other CC designs combine packet lossand delay. Recently, different CC techniques specialized for data-center networks are alsoproposed.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "instruction": "Make the paragraph slightly shorter.", "revised_paragraph": "\"Conventional TCP CC adopts a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, e.g., Cubic, Reno, and NewReno, and others rely onthe variation of delay, e.g., Vegas. Other CC designs combine packet lossand delay. Recently, different CC techniques specialized for data-center networks are alsoproposed [2, 3, 23].\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "instruction": "Make the concepts a bit more specific, such that some vague ideas are more clear.", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "instruction": "Revise the writing for better readability.", "revised_paragraph": "\"Results. Fig. 4 shows that certain alterations\u2014such as completely removing articles from the evaluated text\u2014have almost no impact on the divergence between our reference and test corpora for various . In fact, text without any articles is judged as better than GPT-2 XL \u2019s by most of the cluster-based divergences. Further, while this perturbation undoubtedly affects the text\u2019s fluency, it has less of an effect on this divergence than, e.g., truncating texts. This is arguably undesirable: A metric of text quality should place more emphasis on fluency than surface statistics, such as length.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "instruction": "Please, review the following paragraph, rewrite it in a clearer way", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "instruction": "Rephrase the text and change SRPN-L to SRPN-Lite", "revised_paragraph": "\"Visual Comparisons. We further provide visual comparisons (  4) in Fig.4 for challenging cases. We can observe that most of the compared methods cannot recover structural details with proper directions and suffer from blurring artifacts. In contrast, our SRPN-L can better alleviate the blurring artifacts and recover more structures. These visual comparisons are consistent with the quantitative results, demonstrating the superiority of our SRP method.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920 1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920 1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "instruction": "Improve the English in this paragraph by choosing better words", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "instruction": "Improve the liking between phrases.", "revised_paragraph": "\"We used different apparatus for experiments 1 and 2, which did not have a significant effect on the conclusions of this study. We used a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display was manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920  1080 pixels) and its refresh rate was set at 360 Hz. We used an optical mouse, Logitech Gaming Mouse (G300s; 1600 DPI). The mouse- cursor speed via the OS setting was set to the middle of the slider in the control-display and \u201d Enhance pointer precision \u201d setting was turned on to match the participant\u2019s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and used in full-screen mode.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medica- tion entries was cluttering the designs. The amount of medicationidentification information which is visually present in the calendar entry should also be minimized. Medication labels, including name and dosage, tend to overflow the containing entry. Labels were a source of confusion as to which entry they referred to when multiple entries occupied the same cell. They should be abstracted from the overview and instead be made available as details on demand.\""}, {"intention": "Concision", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medication entries was cluttering the designs.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medication entries was cluttering the designs.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medication entries was cluttering the designs.\""}, {"intention": "Content_deletion", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medica- tion entries was cluttering the designs. The amount of medicationidentification information which is visually present in the calendar entry should also be minimized. Medication labels, including name and dosage, tend to overflow the containing entry. Labels were a source of confusion as to which entry they referred to when multiple entries occupied the same cell. They should be abstracted from the overview and instead be made available as details on demand.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medication entries was cluttering the designs.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medica- tion entries was cluttering the designs. The amount of medicationidentification information which is visually present in the calendar entry should also be minimized. Medication labels, including name and dosage, tend to overflow the containing entry. Labels were a source of confusion as to which entry they referred to when multiple entries occupied the same cell. They should be abstracted from the overview and instead be made available as details on demand.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medication entries was cluttering the designs.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medication entries was cluttering the designs.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medication entries was cluttering the designs.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medication entries was cluttering the designs.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medication entries was cluttering the designs.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "instruction": "Remove unnecessary details and explanations.", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medica- tion entries was cluttering the designs. The amount of medicationidentification information which is visually present in the calendar entry should also be minimized. Medication labels, including name and dosage, tend to overflow the containing entry. Labels were a source of confusion as to which entry they referred to when multiple entries occupied the same cell. They should be abstracted from the overview and instead be made available as details on demand.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "instruction": "I want to restate my third sentence.", "revised_paragraph": "\"Color should be made less dominant and should not be used as the primary identifier for medication entries. While solid dull color was effective in indicating busy slots, using color fill for medica- tion entries was cluttering the designs.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}, {"intention": "Concision", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which shows that the PEHE can be optimized by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which shows that the PEHE can be optimized by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which shows that the PEHE can be optimized by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which shows that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "instruction": "At the last part, state that the proof will be shown in the appendix. Also, make the sentence more sophisticated.", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimal by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "instruction": "Make this sentence more concise. Add a reference to Appendix A.3. where the proof is.", "revised_paragraph": "\"We further derive the upper bound of PEHE in the stochastic batch form as in Theorem 3.1 based on Uri et al. (2017), which demonstrates that the PEHE can be optimized by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at a mini-batch level.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN. DESP (Zhang et al., 2021) is exclusively multiset-equivariant but it is not a standard set predictor, so we do not compare it against it in the experiments.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN. DESP (Zhang et al., 2021) is exclusively multiset-equivariant but it is not a standard set predictor, so we do not compare it against it in the experiments.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN. DESP (Zhang et al., 2021) is exclusively multiset-equivariant but it is not a standard set predictor, so we do not compare it against it in the experiments.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN. DESP (Zhang et al., 2021) is exclusively multiset-equivariant but it is not a standard set predictor, so we do not compare it against it in the experiments.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN. DESP (Zhang et al., 2021) is exclusively multiset-equivariant but it is not a standard set predictor, so we do not compare it against it in the experiments.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN. DESP (Zhang et al., 2021) is exclusively multiset-equivariant but it is not a standard set predictor, so we do not compare it against it in the experiments.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN. DESP (Zhang et al., 2021) is exclusively multiset-equivariant but it is not a standard set predictor, so we do not compare it against it in the experiments.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN. DESP (Zhang et al., 2021) is exclusively multiset-equivariant but it is not a standard set predictor, so we do not compare it against it in the experiments.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "instruction": "Make this paragraph more concise by using more direct formulations", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN. DESP (Zhang et al., 2021) is exclusively multiset-equivariant but it does not use the Jacobian of sorting, but has the slightly different goal of diverse sampling by learning set energies without a traditional set loss, so we do not compare against them in the experiments.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "instruction": "Make the paragraph shorter but don't touch at the first sentence.", "revised_paragraph": "\"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). DESP (Zhang et al., 2021) is exclusively multiset-equivariant but not a standard set predictor, it also uses the Jacobian of sorting, but has the slightly different goal of diverse sampling by learning set energies without a traditional set loss, so we do not compare against them in the experiments.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "instruction": "Explain the concept more clearly.", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "instruction": "Rewrite this paragraph to improve its clarity.", "revised_paragraph": "\"These fusion modules enable information flow from one branch to another. This network architecture employs intermediate fusion, according the categorization of multi-modal fusion strategies in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltruaitis et al., 2018). It has demonstrated competitive performance against multi-modal DNNs with late fusion in many tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Since proteinprotein interactions determine a large number of biological functions, developing methods to modulate protein-protein interactions is critical. A typical way to modulate protein-protein interactions is to mutate amino acids on the interface \u2014 some mutations improve the strength of binding while others weaken and even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists choose either to increase or decrease the binding strength depending on specific goals. For example, if one would like to enhance the effect of a neutralizing antibody against a virus, it is usually necessary to increase the binding strength between the antibody and the viral protein. However, as the combinatorial space of amino acid mutations"}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Since proteinprotein interactions determine a large number of biological functions, developing methods to modulate protein-protein interactions is critical. A typical way to modulate protein-protein interactions is to mutate amino acids on the interface \u2014 some mutations improve the strength of binding while others weaken and even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists choose either to increase or decrease the binding strength depending on specific goals. For example, if one would like to enhance the effect of a neutralizing antibody against a virus, it is usually necessary to increase the binding strength between the antibody and the viral protein. However, as the combinatorial space of amino acid mutations"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Since proteinprotein interactions determine a large number of biological functions, developing methods to modulate protein-protein interactions is critical. A typical way to modulate protein-protein interactions is to mutate amino acids on the interface \u2014 some mutations improve the strength of binding while others weaken and even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists choose either to increase or decrease the binding strength depending on specific goals. For example, if one would like to enhance the effect of a neutralizing antibody against a virus, it is usually necessary to increase the binding strength between the antibody and the viral protein. However, as the combinatorial space of amino acid mutations"}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Since proteinprotein interactions determine a large number of biological functions, developing methods to modulate protein-protein interactions is critical. A typical way to modulate protein-protein interactions is to mutate amino acids on the interface \u2014 some mutations improve the strength of binding while others weaken and even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists choose either to increase or decrease the binding strength depending on specific goals. For example, if one would like to enhance the effect of a neutralizing antibody against a virus, it is usually necessary to increase the binding strength between the antibody and the viral protein. However, as the combinatorial space of amino acid mutation"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Since proteinprotein interactions determine a large number of biological functions, developing methods to modulate protein-protein interactions is critical. A typical way to modulate protein-protein interactions is to mutate amino acids on the interface \u2014 some mutations improve the strength of binding while others weaken and even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists choose either to increase or decrease the binding strength depending on specific goals. For example, if one would like to enhance the effect of a neutralizing antibody against a virus, it is usually necessary to increase the binding strength between the antibody and the viral protein. However, as the combinatorial space of amino acid mutations"}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "instruction": "Improve the English in this paragraph for better readability.", "revised_paragraph": "\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "instruction": "Lightly revise this paragraph to make it more clear and precise while keeping the academic style.", "revised_paragraph": "\"Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We used K = 2000 neurons. First we trained the network for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. In our validation testing we found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. Each training experiment we will describe was repeated five times with varying random initializations and input order. We will report the mean and standard deviation of accuracies. Inference of the input labels by the WTA network of 2000 neurons was performed in two different ways. The first approach is single-layer, where after training the network we assigned a label to each of the 2000 neurons, in a standard approach that is used in unsupervised clustering. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18  0. 06"}, {"intention": "Concision", "revised_paragraph": "\"We used K = 2000 neurons and trained it for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. We found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. We also trained the network with a perceptron classifier on top of the WTA layer. The classifier layer was trained with the Adam optimizer and cross-entropy loss for 60 epochs, while the previously-trained WTA parameters were frozen. We found that the SoftHebb model outperformed the hard WTA (Fig. 1A).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We used K = 2000 neurons. First we trained the network for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. In our validation testing we found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. Each training experiment we will describe was repeated five times with varying random initializations and input order. We will report the mean and standard deviation of accuracies. Inference of the input labels by the WTA network of 2000 neurons was performed in two different ways. The first approach is single-layer, where after training the network we assigned a label to each of the 2000 neurons, in a standard approach that is used in unsupervised clustering. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18  0. 06"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We used K = 2000 neurons. First we trained the network for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. In our validation testing we found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. Each training experiment we will describe was repeated five times with varying random initializations and input order. We will report the mean and standard deviation of accuracies. Inference of the input labels by the WTA network of 2000 neurons was performed in two different ways. The first approach is single-layer, where after training the network we assigned a label to each of the 2000 neurons, in a standard approach that is used in unsupervised clustering. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18  0. 06"}, {"intention": "Concision", "revised_paragraph": "\"We used K = 2000 neurons and trained it for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. We found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. We also trained the network with a perceptron classifier on top of the WTA layer. The classifier layer was trained with the Adam optimizer and cross-entropy loss for 60 epochs, while the previously-trained WTA parameters were frozen. We found that the SoftHebb model outperformed the hard WTA (Fig. 1A).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We used K = 2000 neurons. First we trained the network for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. In our validation testing we found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. Each training experiment we will describe was repeated five times with varying random initializations and input order. We will report the mean and standard deviation of accuracies. Inference of the input labels by the WTA network of 2000 neurons was performed in two different ways. The first approach is single-layer, where after training the network we assigned a label to each of the 2000 neurons, in a standard approach that is used in unsupervised clustering. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18  0. 06"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We used K = 2000 neurons. First we trained the network for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. In our validation testing we found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. Each training experiment we will describe was repeated five times with varying random initializations and input order. We will report the mean and standard deviation of accuracies. Inference of the input labels by the WTA network of 2000 neurons was performed in two different ways. The first approach is single-layer, where after training the network we assigned a label to each of the 2000 neurons, in a standard approach that is used in unsupervised clustering. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18  0. 06"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"We used K = 2000 neurons and trained it for 100 epochs. We found that softmax with a base of 1000 performed best. We will report the mean and standard deviation of accuracies. We used two different ways to infer the input labels by the WTA network of 2000 neurons. First, we used a simple approach where we assigned a label to each of the 2000 neurons after training the network. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18 0. 06\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We used K = 2000 neurons. First we trained the network for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. In our validation testing we found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. Each training experiment we will describe was repeated five times with varying random initializations and input order. We will report the mean and standard deviation of accuracies. Inference of the input labels by the WTA network of 2000 neurons was performed in two different ways. The first approach is single-layer, where after training the network we assigned a label to each of the 2000 neurons, in a standard approach that is used in unsupervised clustering. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18  0. 06"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We used K = 2000 neurons. First we trained the network for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. In our validation testing we found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. Each training experiment we will describe was repeated five times with varying random initializations and input order. We will report the mean and standard deviation of accuracies. Inference of the input labels by the WTA network of 2000 neurons was performed in two different ways. The first approach is single-layer, where after training the network we assigned a label to each of the 2000 neurons, in a standard approach that is used in unsupervised clustering. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18  0. 06"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"We used K = 2000 neurons and trained it for 100 epochs. We found that softmax with a base of 1000 performed best. We will report the mean and standard deviation of accuracies. We used two different ways to infer the input labels by the WTA network of 2000 neurons. First, we used a simple approach where we assigned a label to each of the 2000 neurons after training the network. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18 0. 06\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We used K = 2000 neurons. First we trained the network for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. In our validation testing we found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. Each training experiment we will describe was repeated five times with varying random initializations and input order. We will report the mean and standard deviation of accuracies. Inference of the input labels by the WTA network of 2000 neurons was performed in two different ways. The first approach is single-layer, where after training the network we assigned a label to each of the 2000 neurons, in a standard approach that is used in unsupervised clustering. For each neuron, we found the label of the training set that makes it win the WTA competition most often. The second approach was two-layer and based on supervised training of a perceptron classifier on top of the WTA layer. SoftHebb achieved an accuracy of (96. 18  0. 06"}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "instruction": "Remove training details. Rewrite last paragraph to shorten.", "revised_paragraph": "\"We used K = 2000 neurons and trained it for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. We found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. We also trained the network with a perceptron classifier on top of the WTA layer. The classifier layer was trained with the Adam optimizer and cross-entropy loss for 60 epochs, while the previously-trained WTA parameters were frozen. We found that the SoftHebb model outperformed the hard WTA (Fig. 1A).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "instruction": "Remove unnecessary details to make the paragraph shorter.", "revised_paragraph": "\"We used K = 2000 neurons and trained it for 100 epochs, i.e. randomly ordered presentations of the 60000 training digits. We found that softmax with a base of 1000 (see Section 2.7) performed best. The learning rate  of Eq. 8 decreased linearly from 0.03 to 0 throughout training. We also trained the network with a perceptron classifier on top of the WTA layer. The classifier layer was trained with the Adam optimizer and cross-entropy loss for 60 epochs, while the previously-trained WTA parameters were frozen. SoftHebb achieved an accuracy of (96. 18  0. 06)% and (96. 94  0. 02)%. We also trained the weights of a network with a hard-WTA setup, i.e. where the strongest-activated neuron's output y k is 1, and the other neurons are suppressed to 0, for each input. We found that an initial learning rate of 0.05 was best for the hardWTA network. The SoftHebb", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}, {"intention": "Concision", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "instruction": "Rewrite the middle part of this paragraph and improve the English in the remainder", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difficult in a fully-connected GCN.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "instruction": "Make this paragraph a bit more concise.", "revised_paragraph": "\"We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers. The proposed method can be run on a computer with 12900K CPU, 1080TI and 128GB RAM. Figure 2 shows the framework of TTERGM that has five major components - data collection module, network processing module, feature extraction module, pattern analysis module, and a generative network module. The data collection module is discussed in Section 3.3.\""}, {"intention": "Concision", "revised_paragraph": "\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers. The proposed method can be run on a computer with 12900K CPU, 1080TI and 128GB RAM. Figure 2 shows the framework of TTERGM that has five major components - data collection module, network processing module, feature extraction module, pattern analysis module, and a generative network module. The data collection module is discussed in Section 3.3.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers. The proposed method can be run on a computer with 12900K CPU, 1080TI and 128GB RAM. Figure 2 shows the framework of TTERGM that has five major components - data collection module, network processing module, feature extraction module, pattern analysis module, and a generative network module. The data collection module is discussed in Section 3.3.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers. The proposed method can be run on a computer with 12900K CPU, 1080TI and 128GB RAM. The data collection module is discussed in Section 3.3.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers. The proposed method can be run on a computer with 12900K CPU, 1080TI and 128GB RAM. Figure 2 shows the framework of TTERGM that has five major components - data collection module, network processing module, feature extraction module, pattern analysis module, and a generative network module. The data collection module is discussed in Section 3.3.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "instruction": "Remove the information about the code. And remove the last sentence.", "revised_paragraph": "\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers (Code isavailable at https://github.com/alvin68633466/TTERGM-Social-Theory-Driven-network-simulation). TTERGM was run on a computer with 12900K CPU, 1080TI and 128GB RAM. Figure 2 shows the framework of TTERGM that has five major components - data collection module, network processing module, feature extraction module, pattern analysis module, and a generative network module. The data collection module is discussed in Section 3.3.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "instruction": "Remove the mentions to the code and to other sections.", "revised_paragraph": "\"TERGM models estimated within the markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers (Code isavailable at https://github.com/alvin68633466/TTERGM-Social-Theory-Driven-network-simulation). TTERGM was run on a computer with 12900K CPU, 1080TI and 128GB RAM. Figure 2 shows the framework of TTERGM that has five major components - data collection module, network processing module, feature extraction module, pattern analysis module, and a generative network module. The data collection module is discussed in Section 3.3.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time [3,9,10,24,25]. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving a cursor horizontally relative to the edge at which the target is adjacent. Additionally, the target adjacent to the corner of the screen can be pointed fast simply by hitting the corner with the cursor.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving a cursor horizontally relative to the edge at which the target is adjacent.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time [3,9,10,24,25]. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving a cursor horizontally relative to the edge at which the target is adjacent. Additionally, the target adjacent to the corner of the screen can be pointed fast simply by hitting the corner with the cursor.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving a cursor horizontally relative to the edge at which the target is adjacent.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time [3,9,10,24,25]. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving a cursor horizontally relative to the edge at which the target is adjacent. Additionally, the target adjacent to the corner of the screen can be pointed fast simply by hitting the corner with the cursor.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving a cursor horizontally relative to the edge at which the target is adjacent. Additionally, the target adjacent to the corner of the screen can be pointed fast simply by hitting the corner with the cursor.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time [3,9,10,24,25]. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving a cursor horizontally relative to the edge at which the target is adjacent. Additionally, the target adjacent to the corner of the screen can be pointed fast simply by hitting the corner with the cursor.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving a cursor horizontally relative to the edge at which the target is adjacent.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "instruction": "Rewrite this paragraph and choose better words", "revised_paragraph": "It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving the cursor horizontally relative to the edge at which the target is adjacent. Additionally, the target adjacent to the corner of the screen can be pointed fast simply by hitting the corner with the cursor (24).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "instruction": "Reorganise the flow of ideas when a sentence is confusing. Try to shorten the paragraph a bit.", "revised_paragraph": "\"It is known that the edge target (placing the target adjacent to the edge of the screen) can reduce the movement time [3,9,10,24,25]. Pointing at a target in the center of the screen requires the cursor to stop just inside the target. When pointing an edge target, the cursor stops at the edge. As a result, the pointing can be completed by moving a cursor horizontally relative to the edge at which the target is adjacent. Additionally, the target adjacent to the corner of the screen can be pointed fast simply by hitting the corner with the cursor [24].\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No representations, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii) on other items in the list.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No representations, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii) on other items in the list.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No representations, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii) on other items in the list.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No representations, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii) on other items in the list.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No representations, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii) on other items in the list.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No representations, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii) on other items in the list.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No representations, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii) on other items in the list.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No representations, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii) on other items in the list.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "instruction": "Rewrite the middle sentences, preferring active formulations over passive ones.", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No representations, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii) on other items in the list.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "instruction": "\"No representations\" become \"No action representations\". Rewrite the \"Mask-Input-Output\" and \"Utility-Policy\" points in the list for better readability. Uniformise the language in the paragraph.", "revised_paragraph": "\"\u2022 Mask-Output (No representations, No input action set): Assuming a fixed action space in the output, q-values or policy probabilities are masked out for unavailable actions. It represents prior works on the subject - Boutilier et al. ; Chandak et al. (2020a), Huang & Onta\u00f3n (2020). \u2022 Mask-Input-Output (No representations): Augments the binary availability mask of given actions, 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No input action set): Proposed by Jain et al. (2020), action representations are used independently for computing each action\u2019s utility, ignoring any interdependence. \u2022 Simple DQN (No cascade, No input action set): For listwise RL specifically, we include the DQN baseline that simply selects top-K items, instead of reasoning about the overall list. Thus, it ignores both action interdependences: (i) on other available actions, (ii)", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can"}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "instruction": "Rewrite this paragraph for improved readability.", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "instruction": "Improve the readability of this paragraph.", "revised_paragraph": "\"Let  s k | s k  Z 3  Mk =0 denote a series of window sizes, where s 0 is the size of the query windowand s 1,...,M are the sizes of M successively larger key windows. Let V =  v i | v i = (x i, f i )  |V| i =1 bethe input voxel set, with xyz coordinates x i  Z 3 and feature vector f i  R C for voxel i. We firstpartition the voxel set into non-overlapping 3D windowseach of size s 0, and find the non-emptyones as query windows with their centers denoted by  c i | c i  Z 3  Li =0, where L is the total numberof query windows. To get query voxels V c i, s 0for the query window centered on c i, one can", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn't have.\""}, {"intention": "Concision", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for sharing parameters in heterogeneous ensembles. We find that our automatic sharing improves single member performance by 2% compared to the baselines. We also find that adding parameters improves performance by up to 2% when compared to standard ensembles on ImageNet.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn't have.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn't have.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for sharing parameters in heterogeneous ensembles. We find that our automatic sharing improves single member performance by 2% compared to the baselines. We also find that adding parameters improves performance by up to 2% when compared to standard ensembles on ImageNet.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn't have.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn't have.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"In this work, we introduce SuperWeight Ensembles, a method for sharing parameters in heterogeneous ensembles. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn't have.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn't have.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn't have.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for sharing parameters in heterogeneous ensembles. We find that our automatic sharing improves single member performance by 2% compared to the baselines. We also find that adding parameters improves performance by up to 2% when compared to standard ensembles on ImageNet.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"In this work, we introduce SuperWeight Ensembles, a method for sharing parameters in heterogeneous ensembles. We find that our automatic sharing improves single member performance by 2% compared to the baselines. We also find that adding parameters improves performance by up to 2% when compared to standard ensembles on ImageNet.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn't have.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "instruction": "Make this paragraph a bit more concise.", "revised_paragraph": "\"In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. We find that our automatic sharing improves single member performance by 2% compared to the baselines. We also find that adding parameters improves performance by up to 2% when compared to standard ensembles on ImageNet with just 50% of the parameters.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The target network can be considered a target network in HyperDeepONet. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of basis. Still, there was a trade-off in which the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The neural network with a low complexity could approximate the inner product with better performance since the inner product is an infinitely differentiable function. The DeepONet showed defects as it could be replaced with a neural network with E (u ) and y as input. A large number of basis p in DeepONet increases the number of parameters of the trunk net, which can be considered a target network in HyperDeepONet. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of basis. Still, there was a trade-off in which the first hidden layer of the target network required numerous units. There was no restriction on the dimension of the last hidden layer in the target network for NOMAD, which uses a fully nonlinear reconstruction. However, the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\""}, {"intention": "Concision", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The inner product can be written as (int(i) for u, y) or (int(i) for x, y) and the number of parameters is the same."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The inner product can be written as (int(i) for u, y) or (int(i) for x, y) and the number of parameters is the same."}, {"intention": "Rewritting_light", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The neural network with a low complexity could approximate the inner product with better performance since the inner product is an infinitely differentiable function. The DeepONet showed defects as it could be replaced with a neural network with E (u ) and y as input. A large number of basis p in DeepONet increases the number of parameters of the trunk net, which can be considered a target network in HyperDeepONet. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of basis. Still, there was a trade-off in which the first hidden layer of the target network required numerous units. There was no restriction on the dimension of the last hidden layer in the target network for NOMAD, which uses a fully nonlinear reconstruction. However, the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The target network can be considered a target network in HyperDeepONet. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of basis. Still, there was a trade-off in which the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The target network can be considered a target network in HyperDeepONet. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of basis. Still, there was a trade-off in which the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of basis. However, there was a trade-off in which the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of parameters. However, there was a trade-off in which the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The inner product can be written as (int(i) for u, y) or (int(i) for x, y) and the number of parameters is the same."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The inner product can be written as (int(i) for u, y) or (int(i) for x, y) and the number of parameters is the same.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The target network can be considered a target network in HyperDeepONet. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of basis. Still, there was a trade-off in which the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "instruction": "Remove unnecessary details. Include citation.", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The inner product can be approximated with better performance since the inner product is an infinitely differentiable function. The DeepONet showed defects as it could be replaced with a neural network with E (u ) and y as input. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of basis. Still, there was a trade-off in which the first hidden layer of the target network required numerous units. There was no restriction on the dimension of the last hidden layer in the target network for NOMAD, which uses a fully nonlinear reconstruction. However, the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "instruction": "Rewrite the beginning of the paragraph to improve the argumentation.", "revised_paragraph": "\"The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net. The neural network with a low complexity could approximate the inner product with better performance since the inner product is an infinitely differentiable function. The DeepONet showed defects as it could be replaced with a neural network with E ( u ) and y as input. A large number of basis p in DeepONet increases the number of parameters of the trunk net, which can be considered a target network in HyperDeepONet. Models such as Shift-DeepONet and flexDeepONet could achieve the desired accuracy with a small number of basis. Still, there was a trade-off in which the first hidden layer of the target network required numerous units. There was no restriction on the dimension of the last hidden layer in the target network for NOMAD, which uses a fully nonlinear reconstruction. However, the first hidden layer of the target network had to be wide enough, increasing the number of parameters. Details can be found in Appendix C.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy (Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}, {"intention": "Content_deletion", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as unsupervised predictors of the mutational effects on binding.\""}, {"intention": "Concision", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. Recently, the success of protein language models in has drawn interest in adopting the mask-predict (BERT) paradigm to protein 3D structures. The masked information can be used to predict the change in binding free energy due to mutations. Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy (Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy (Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}, {"intention": "Content_deletion", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as unsupervised predictors of the mutational effects on binding.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. Recently, the success of protein language models in has drawn interest in adopting the mask-predict (BERT) paradigm to protein 3D structures. The masked information can be used to predict the change in binding free energy due to mutations. Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}, {"intention": "Rewritting_heavy", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy (Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy (Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy (Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). Hence, they can serve as unsupervised predictors of the mutational effects on binding.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict (BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy. Hence, they can serve as unsupervised predictors of the mutational effects on binding."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy (Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy (Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can serve as a surrogate to the change in binding free energy (Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). Hence, they can serve as unsupervised predictors of the mutational effects on binding.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. Recently, the success of protein language models in has drawn interest in adopting the mask-predict (BERT) paradigm to protein 3D structures. The masked information can be used to predict the change in binding free energy due to mutations. Hence, they can serve as unsupervised predictors of the mutational effects on binding.\""}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "\"\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. Recently, the success of protein language models in has drawn interest in adopting the mask-predict (BERT) paradigm to protein 3D structures. The masked information can be used to predict the change in binding free energy due to mutations. Hence, they can serve as unsupervised predictors of the mutational effects on binding.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "instruction": "Please, rewrite this paragraph.", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. More recently, the success of protein language models in has drawn interest in adopting the mask-predict(BERT) paradigm to protein 3D structures. The masked information can be used to predict the binding free energy of a given protein backbone. Hence, they can serve as unsupervised predictors of the mutational effects on binding.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "instruction": "Rewrite this paragraph to make it shorter while keeping all the informations.", "revised_paragraph": "\"Nevertheless, these pre-training strategies do not capture well the foundation of protein-protein interactions. Recently, the success of protein language models in has drawn interest in adopting the mask-predict (BERT) paradigm to protein 3D structures. The masked information can be used to predict the change in binding free energy due to mutations. Hence, they can serve as unsupervised predictors of the mutational effects on binding.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "instruction": "Add brackets to the citations", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "instruction": "Put the references between parenthesis.", "revised_paragraph": "\"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph based methods which are often based on variations of graph convolutional networks (GCNs) Kipf & Welling (2017); Defferrard et al. GCNs have been applied on spherical meshes Perraudin et al. and cortical surfaces Cucurull et al. ; Zhao et al. Verma et al. (2018) augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "instruction": "Replace some words in the paragraph", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "instruction": "Slightly revise for readability.", "revised_paragraph": "\"We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "instruction": "Use uppercases properly.", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "instruction": "Use capital letters at the beginning of every words in the names of segmentation methods.", "revised_paragraph": "\"Image semantic segmentation is the task of pixel-level semantic label allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the semantic segmentation task [6, 58, 19] in recent years. However, training sucha fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and propose a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model's ability to handle highly dynamic scenes. \u2022 We contribute high-fidelity environments built for simulating realistic-looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and propose a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model's ability to handle highly dynamic scenes. \u2022 We contribute high-fidelity environments built for simulating realistic-looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and propose a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model's ability to handle highly dynamic scenes. \u2022 We contribute high-fidelity environments built for simulating realistic-looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and propose a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model's ability to handle highly dynamic scenes. \u2022 We contribute high-fidelity environments built for simulating realistic-looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and propose a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model's ability to handle highly dynamic scenes. \u2022 We contribute high-fidelity environments built for simulating realistic-looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and propose a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model's ability to handle highly dynamic scenes. \u2022 We contribute high-fidelity environments built for simulating realistic-looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and propose a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model's ability to handle highly dynamic scenes. \u2022 We contribute high-fidelity environments built for simulating realistic-looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and propose a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model's ability to handle highly dynamic scenes. \u2022 We contribute high-fidelity environments built for simulating realistic-looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "instruction": "Switch the second and the third setence and then rephrase the first three sentences", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and propose a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model's ability to handle highly dynamic scenes. We contribute high-fidelity environments built for simulating realistic- looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "instruction": "Change the position of two points.", "revised_paragraph": "\"\u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and proposed a novel multi-camera (n  3) collaboration framework. We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines.\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model\u2019s ability to handle highly dynamic scenes. \u2022 We contribute high-fidelity environments built for simulating realistic- looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the models. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the models. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the models. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the models. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the models. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the models. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the models. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the models. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "instruction": "Can you paraphrase the last sentence?", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the networks. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "instruction": "Rewrite the last sentence preferring passive voice over active.", "revised_paragraph": "\"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the networks. To pursue more efficient image SR networks, we then propose structure-regularized pruning (SRP) method to compress them.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}, {"intention": "Concision", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}, {"intention": "Concision", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "instruction": "Give me a shorter version of this:", "revised_paragraph": "We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "instruction": "Make this paragraph twice as short by making the content more concise and deleting unnecessary details.", "revised_paragraph": "\"Recently, deep learning-based approaches to predicting mutational effects on protein binding have emerged. We group them into three categories: end-to-end models, pre-training-based models, and unsupervised models.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "instruction": "Remove any unessential information in this paragraph.", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with a two-stage optimization strategy. At the first stage in the inner loop, we fix both visual and textfeatures and optimize the optimal transport problem by a fast Sinkhorn distances algorithm. Then,in the outer loop, we fix all parameters of optimal transport and back-propagate the gradient to learnthe prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "instruction": "Please exclude the content related to optimal transport.", "revised_paragraph": "\"We solve this problem by introducing the optimal transport theory [51] and formulate the feature setsas a discrete probability distribution where each feature has an equal probability value. Furthermore,to reduce the computational cost and avoid the extra model parameters, we learn the prompts with a two-stage optimization strategy. At the first stage in the inner loop, we fix both visual and textfeatures and optimize the optimal transport problem by a fast Sinkhorn distances algorithm Then,in the outer loop, we fix all parameters of optimal transport and back-propagate the gradient to learnthe prompts with different characteristics. Compared with conventional distance (such as Euclideandistance of mean features), optimal transport can align different visual features for each local prompt, which is more robust to the visual misalignment and tolerates well feature shift. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method. These experiments span the visual classification of generic objects,scenes, actions, fine-grained categories, and so on. The significant result improvement demonstratesthat PLOT can effectively learn representative and comprehensive prompts.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "instruction": "Make the use of a citation in the second sentence correct. Update the third sentence.", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "instruction": "Improve the readability of this paragraph.", "revised_paragraph": "\"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics such as centrality indicate how broadly influence extends (e.g. geographic interest) Weber and Luo [2014]. Other features includeproject volume, documentation volume, presence ofsupporting files, codevolume and standardlibrary usage. The popularity velocity can be measured by (Total_Stars / project_life). Few studies have examined influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule [23]. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}, {"intention": "Concision", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule [23]. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule [23]. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Electronic calendars have become instrumental in the management of daily activities. For example, they are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have also been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Electronic calendars have become instrumental in the management of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "instruction": "Rewrite the latter half of this paragraph to make it more concise.", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "instruction": "Merge the two sentences in the middle  about integrating prescription magagement in a new shorter sentence. Improve the english in the last sentence.", "revised_paragraph": "\"Electronic calendars have become instrumental in the manage- ment of daily activities [16\u201318]. They are used to coordinate interactions among individual schedules of family or team members and can convey meaning and values behind the priorities of schedul- ing [19]. Calendars have been used to visualize temporal trends that include everyday activities such as energy use in work places, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging that incorporates a simple day or date feature have been used in efforts to help manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule by prompting them to maintain the prescribed medication containers (23). While such prescription managers come as stand-alone tools, we look at the possibility of integrating prescription management into the main calendar already used by the patient. Such integration comes with challenges. The first challenge is how to render the prescription entries so that the user can differentiate between a normal calendar entry and one that is part of a prescription. The second challenge is how to ensure that the patient rescheduling a prescription entry does so within the safety envelop of the prescription.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"To avoid the significant variance in the IHDP benchmark, we conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, reducing the out-ofsample PEHE to 2.768 and 2.633, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"To avoid the significant variance in the IHDP benchmark, we conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, reducing the out-ofsample PEHE to 2.768 and 2.633, respectively.\""}, {"intention": "Concision", "revised_paragraph": "\"We conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"To avoid the significant variance in the IHDP benchmark, we conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, reducing the out-ofsample PEHE to 2.768 and 2.633, respectively.\""}, {"intention": "Concision", "revised_paragraph": "\"We conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"To avoid the significant variance in the IHDP benchmark, we conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, reducing the out-ofsample PEHE to 2.768 and 2.633, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"To avoid the significant variance in the IHDP benchmark, we conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, reducing the out-ofsample PEHE to 2.768 and 2.633, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"To avoid the significant variance in the IHDP benchmark, we conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, reducing the out-ofsample PEHE to 2.768 and 2.633, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"To avoid the significant variance in the IHDP benchmark, we conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"To avoid the significant variance in the IHDP benchmark, we conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, reducing the out-ofsample PEHE to 2.768 and 2.633, respectively.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"We conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, reducing the out-ofsample PEHE to 2.768 and 2.633, respectively.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"We conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "instruction": "Make the first sentence more concise.", "revised_paragraph": "\"We conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, respectively. Finally, ESCFR combines the RMPR and PFOR in a unified framework in Section 3.4 and further reduces the out-of-sample PEHE to 2.316.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "instruction": "Simplify the first sentence. Improve the connections between sentences.", "revised_paragraph": "\"To avoid the significant variance in the IHDP benchmark, we conduct ablation study on the ACIC benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims in Section 3. In Table 2, ESCFR firstly augments TARNet with stochastic optimal transport in Section 3.1, which effectively reduces the out-of-sample PEHE from 3.254 to 3.207. Afterwards, it mitigates the MSE issue with RMPR in Section 3.2 and the UCE issue with PFOR in Section 3.3, reducing the out-ofsample PEHE to 2.768 and 2.633, respectively.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "instruction": "Make this paragraph a bit more fluid.", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or phys- ical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "instruction": "I want to rewrite the first sentence.", "revised_paragraph": "\"Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "instruction": "Move the less important results to an appendix.", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "instruction": "Replace less important results by a reference to Appendix B. Revise this paragraph.", "revised_paragraph": "\"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines. However, MSE and UCE issues hinder the mitigation of treatment selection bias by these methods. The proposed ESCFR achieves significant improvement over most metrics compared with various state-of-the-art baselines 3. Combined with aforementioned comparisons, we attribute its superiority to our design of the RMPR and PFOR regularizers, making it robust to MSE and UCE.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines. However, MSE and UCE issues hinder the mitigation of treatment selection bias by these methods. The proposed ESCFR achieves significant improvement over most metrics compared with various state-of-the-art baselines 3. Combined with aforementioned comparisons, we attribute its superiority to our design of the RMPR and PFOR regularizers, making it robust to MSE and UCE.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines. However, MSE and UCE issues hinder the mitigation of treatment selection bias by these methods. The proposed ESCFR achieves significant improvement over most metrics compared with various state-of-the-art baselines 3. Combined with aforementioned comparisons, we attribute its superiority to our design of the RMPR and PFOR regularizers, making it robust to MSE and UCE.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines. However, MSE and UCE issues hinder the mitigation of treatment selection bias by these methods. The proposed ESCFR achieves significant improvement over most metrics compared with various state-of-the-art baselines 3. Combined with aforementioned comparisons, we attribute its superiority to our design of the RMPR and PFOR regularizers, making it robust to MSE and UCE.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "instruction": "Remove redundant information and use more scientific words.", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "instruction": "Make this text simpler and more readable. Remove unnecessary details about AUUC.", "revised_paragraph": "\"Representation-based methods mitigate the treatment selection bias and enhance the overall performance. In particular, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, significantly outperforming most statistical methods. It also gets an AUUC of 0.715 on IHDP, exceeding all other baselines.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "instruction": "Correct some issues in the paragraph and replace certain words to improve it", "revised_paragraph": "\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "instruction": "Improve the overall clarity of the paragraph.", "revised_paragraph": "\"Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two"}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "instruction": "Remove details about the theoretical framework and make this paragraph more concise.", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two algorithms,", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "instruction": "Remove unnecessary content to make this paragraph shorter.", "revised_paragraph": "\"We choose for M a small constant number, since L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1, and we set r to a number of particle functions that can represent the posterior SP reasonably well. Thus, we are interested in estimating (cid:101)  F L D, X ( Q [ T ] ) (cid:12)(cid:12) F =0 with mini-batches. In principle, an unbiased estimate of l ( D, f iX D ) is n/s  l ( D s, f i (cid:101) X ), which suggests that  = s/n. However, in practice we found that  to s/n still results in reasonable performance. However, our theoretical framework gives the reassuring guarantee that if we use full-batch training, we would, in fact, maximize a lower bound of log p ( D ). In the following, we present two", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "instruction": "Make the last sentence more concise.", "revised_paragraph": "\"Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "instruction": "Make the last sentence shorter.", "revised_paragraph": "\"Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is conveyed with a label.\""}, {"intention": "Concision", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is shown on a label.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is conveyed with a label.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is conveyed with a label.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is shown on a label.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is conveyed with a label.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is conveyed with a label.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration, their color indicates their type, or category, as set by the user, and their name is shown with a label.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is conveyed with a label.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is conveyed with a label.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is shown on a label.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is shown on a label.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is conveyed with a label. In this design, we also represent medication entries with rectangles (or bars), whose vertical position and height indicates start and end of the allowed administration period for the medication. Medication entries have an embossed horizontal marker placed at some point along the bar to indicate the preferred administration period (at which point the reminder would trigger if programmed). Preferred administration time of a medication entry is shown with higher opacity and allowed administrative time with lower opacity. Color hue encodes the type of medication.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "instruction": "Make the first sentence more concise and direct.", "revised_paragraph": "\"Calendar entries are shown like in standard calendars: the height of rectangular entries indicates their duration,their color hue indicates their type, or category, as set by the user, and their name is conveyed with a label.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures. Thus, itis an unsupervised learner of the effectof mutations on binding and it alleviates the difficulty rising from the scarcity of annotated mutation data. In addition, our method outperforms empirical energy functions and machine learning models for  G prediction. In addition, as a generative model for rotamers, the RDE predicts sidechain conformations accurately.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures. Thus, itis an unsupervised learner of the effectof mutations on binding and it alleviates the difficulty rising from the scarcity of annotated mutation data. In addition, our method outperforms empirical energy functions and machine learning models for  G prediction. In addition, as a generative model for rotamers, the RDE predicts sidechain conformations accurately.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures. Thus, itis an unsupervised learner of the effectof mutations on binding and it alleviates the difficulty rising from the scarcity of annotated mutation data. In addition, our method outperforms empirical energy functions and machine learning models for  G prediction. In addition, as a generative model for rotamers, the RDE predicts sidechain conformations accurately.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures. Thus, itis an unsupervised learner of the effectof mutations on binding and it alleviates the difficulty rising from the scarcity of annotated mutation data. In addition, our method outperforms empirical energy functions and machine learning models for  G prediction. In addition, as a generative model for rotamers, the RDE predicts sidechain conformations accurately.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures. Thus, itis an unsupervised learner of the effectof mutations on binding and it alleviates the difficulty rising from the scarcity of annotated mutation data. In addition, our method outperforms empirical energy functions and machine learning models for  G prediction. In addition, as a generative model for rotamers, the RDE predicts sidechain conformations accurately.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures. Thus, itis an unsupervised learner of the effectof mutations on binding and it alleviates the difficulty rising from the scarcity of annotated mutation data. In addition, our method outperforms empirical energy functions and machine learning models for  G prediction. In addition, as a generative model for rotamers, the RDE predicts sidechain conformations accurately.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures. Thus, itis an unsupervised learner of the effectof mutations on binding and it alleviates the difficulty rising from the scarcity of annotated mutation data. In addition, our method outperforms empirical energy functions and machine learning models for  G prediction. In addition, as a generative model for rotamers, the RDE predicts sidechain conformations accurately.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures. Thus, itis an unsupervised learner of the effectof mutations on binding and it alleviates the difficulty rising from the scarcity of annotated mutation data. In addition, our method outperforms empirical energy functions and machine learning models for  G prediction. In addition, as a generative model for rotamers, the RDE predicts sidechain conformations accurately.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "instruction": "Give me a more formal version of the following paragraph.", "revised_paragraph": "Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures. Thus, it is an unsupervised learner of the effectof mutations on binding. Additionally, our method does not require the structure of the mutated protein as input. Rather, it treats mutated structures as latent variables and the rotamer density estimator is an approximator of the latent distribution. Our method outperforms empirical energy functions and machine learning models for  G prediction. In addition, as a generative model for rotamers, the RDE predicts sidechain conformations accurately.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "instruction": "Rewrite this paragraph in a more formal and academic way.", "revised_paragraph": "Our method provides a solution to the aforementioned challenges. Training the rotamer density estimator requires only protein structures, which can be obtained from the protein sequence. This method can predict the  G of a protein more accurately than other models.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}, {"intention": "Content_deletion", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "instruction": "Please, remove unnecessary details of this paragraph", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the data is cropped into a patch containing 128 amino acids. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "instruction": "Delete unnecessary details. Improve the linking between ideas.", "revised_paragraph": "\"The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database containing refined X-ray structures in PDB. Structures with resolution worse than 3.5 A are removed. All the protein chains are clustered by 50% sequence identity. This process leads to 38,413 chain clusters, and they are randomly divided into the training set, the validation set, and the test set by 95%/0.5%/4.5%. At training time, the data loader randomly selects a cluster and then randomly chooses a chain from the cluster. During training, the structure is cropped into a patch containing 128 amino acids. The patch is constructed by first choosing a seed amino acid, and then finding its 127 nearest neighbors according to C-beta distances. To emulate mutations, the rotamers of 10% of amino acids in the patch are masked. Noise is added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid is less than 8 A.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "instruction": "Split the long sentences into more concise sentences.", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "instruction": "The second sentence is too long, split it and make it more readable.", "revised_paragraph": "\"For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module except for Figure 5, for which we use a learning rate of 1  10  4 as SPAIR to ensure fair comparison.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy) respectively. Distinguished from a conventional modular system, we additionally give a context to NLG to satisfy the option framework. Moreover, since the primitive action space (i.e. a vocabulary) comprises a termination symbol, NLG can take over the responsibility of termination. For this reason, termination policy is absorbed in the intra-option policy. HDNO is formally defined in Definition 1.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy) respectively.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy) respectively. Distinguished from a conventional modular system, we additionally give a context to NLG to satisfy the option framework. Moreover, since the primitive action space (i.e. a vocabulary) comprises a termination symbol, NLG can take over the responsibility of termination. For this reason, termination policy is absorbed in the intra-option policy. HDNO is formally defined in Definition 1.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy) respectively.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy) respectively. Distinguished from a conventional modular system, we additionally give a context to NLG to satisfy the option framework. Moreover, since the primitive action space (i.e. a vocabulary) comprises a termination symbol, NLG can take over the responsibility of termination. For this reason, termination policy is absorbed in the intra-option policy. HDNO is formally defined in Definition 1.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy) respectively. Distinguished from a conventional modular system, we additionally give a context to NLG to satisfy the option framework. Moreover, since the primitive action space (i.e. a vocabulary) comprises a termination symbol, NLG can take over the responsibility of termination. For this reason, termination policy is absorbed in the intra-option policy. HDNO is formally defined in Definition 1.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy) respectively. Distinguished from a conventional modular system, we additionally give a context to NLG to satisfy the option framework. Moreover, since the primitive action space (i.e. a vocabulary) comprises a termination symbol, NLG can take over the responsibility of termination. For this reason, termination policy is absorbed in the intra-option policy. HDNO is formally defined in Definition 1.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy) respectively.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "instruction": "Rewrite some formulations to describe HDNO more as a state than a progress.", "revised_paragraph": "HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy), respectively. Distinguished from a conventional modular system, we additionally give a context to NLG to satisfy the option framework. Moreover, since the primitive action space (i.e. a vocabulary) comprises a termination symbol, NLG can take over the responsibility of termination. For this reason, termination policy is absorbed in the intra-option policy. HDNO is formally defined in Definition 1.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "instruction": "Make the last sentence more direct. Give slightly more context for better readability.", "revised_paragraph": "HDNO. Specifically, a dialogue act in HDNO is seen as an option whereas each generated word from NLG becomes a primitive action. Accordingly, dialogue policy and NLG become the policy over option (i.e. high-level policy) and the intra-option policy (i.e. low-level policy) respectively. Distinguished from a conventional modular system, we additionally give a context to NLG to satisfy the option framework. Moreover, since the primitive action space (i.e. a vocabulary) comprises a termination symbol, NLG can take over the responsibility of termination. For this reason, termination policy is absorbed in the intra-option policy. HDNO is formally defined in Definition 1.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort"}, {"intention": "Concision", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embedding at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort"}, {"intention": "Concision", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embedding at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embedding at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort.\""}, {"intention": "Content_deletion", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort"}, {"intention": "Concision", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embedding at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Low-level image similarity. We propagate the labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V, respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Low-level image similarity. We propagate the labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V, respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embedding at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "\"\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embedding at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V, respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Low-level image similarity. We propagate the labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embeddings at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V, respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "instruction": "Make this paragraph considerably more concise. Remove any unnecessary details that are not essential for the main point of the paragraph.", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embedding at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "instruction": "This paragraph is too long, make it almost 50% shorter but keep the important informations.", "revised_paragraph": "\"Low-level image similarity. We propagatethe labels within visually coherent regions,as visual similarity often goes with semantic similarity. To generate an over-segmentation, we follow Hwang et al. by using the HED contour detector (Xie & Tu, 2015) (pre-trained on BSDS dataset (Arbelaez et al., 2010)) and the procedure in gPb-owt-ucm (Arbelaez et al., 2010). Such bottom-up segmentation techniques consider both local and global appearance affinity without semantic information. Some of the segments could contain pixels from different categories. For learning pixel embedding at pixel i, we define positive and negative segments w.r.t. i as i \u2019s own segment and all the other segments, denoted as V + and V , respectively. We follow SegSort Hwang et al. (2019) to align the contour-based over-segmentations with segmentations generated by K-Means clustering in SegSort.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Hopper-v2 \") from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations. We then run OTR to select the best episodes from the D4RL dataset based on the episodic return."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Hopper-v2 \") from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations. We then run OTR to select the best episodes from the D4RL dataset based on the episodic return."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Hopper-v2 \") from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations. We then run OTR to select the best episodes from the D4RL dataset based on the episodic return."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Hopper-v2 \") from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations. We then run OTR to select the best episodes from the D4RL dataset based on the episodic return."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Hopper-v2 \") from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations. We then run OTR to select the best episodes from the D4RL dataset based on the episodic return."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Hopper-v2 \") from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations. We then run OTR to select the best episodes from the D4RL dataset based on the episodic return."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Hopper-v2 \") from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations. We then run OTR to select the best episodes from the D4RL dataset based on the episodic return."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Hopper-v2 \") from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations. We then run OTR to select the best episodes from the D4RL dataset based on the episodic return."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "instruction": "Remove the fourth sentence", "revised_paragraph": "\"Hopper-v2 ) from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations and the unlabeled dataset. For the expert demonstrations, we choose the best episodes from the D4RL dataset based on the episodic return. In practice, the expert demonstrations can be provided separately and we are only selecting the expert demonstrations in this way for ease of evaluation. To obtain the unlabeled dataset, we discard the original reward information in the dataset. We then run OTR to label the dataset based on the optimal coupling between the unlabeled episodes and the chosen expert demonstrations. Afterward, we proceed with running the offline RL algorithm.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "instruction": "Exclude unnecessary information.", "revised_paragraph": "\"Hopper-v2 ) from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2 and medium-expert-v2 datasets to construct the expert demonstrations and the unlabeled dataset. For the expert demonstrations, we choose the best episodes from the D4RL dataset based on the episodic return. In practice, the expert demonstrations can be provided separately and we are only selecting the expert demonstrations in this way for ease of evaluation. To obtain the unlabeled dataset, we discard the original reward information in the dataset. We then run OTR to label the dataset based on the optimal coupling between the unlabeled episodes and the chosen expert demonstrations. Afterward, we proceed with running the offline RL algorithm.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors the affect the movement time are the target size and the distance from the initial position of the cursor to the target. Furthermore, placing distractions (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors the affect the movement time are the target size and the distance from the initial position of the cursor to the target. Furthermore, placing distractions (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors the affect the movement time are the target size and the distance from the initial position of the cursor to the target. Furthermore, placing distractions (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors the affect the movement time are the target size and the distance from the initial position of the cursor to the target. Furthermore, placing distractions (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors the affect the movement time are the target size and the distance from the initial position of the cursor to the target. Furthermore, placing distractions (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors the affect the movement time are the target size and the distance from the initial position of the cursor to the target. Furthermore, placing distractions (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors the affect the movement time are the target size and the distance from the initial position of the cursor to the target. Furthermore, placing distractions (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors the affect the movement time are the target size and the distance from the initial position of the cursor to the target. Furthermore, placing distractions (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "instruction": "Improve English in this paragraph. Explain more about the experiments", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors that affect the movement time are the target size and the distance from the initial position of the cursor to the target. The movement time increases as the distance increases and the target size decreases. Furthermore, placing distractions (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "instruction": "Add a sentence to introduce the experiment. Improve the paragraph for better readability.", "revised_paragraph": "\"Pointing (point targets such as buttons or icons) should be fast and accurate. The two main factors the affect the movement time are the target size and the distance from the initial position of the cursor to the target [11,19]. The movement time increases as the distance increases and the target size decreases. Furthermore, placing obstacles (which do not hide the cursor) on the path to the target increases the movement time [6,23]. By placing a notch, the user could miss the cursor position inside the notch or lose sight of the cursor, which may increase movement time considering the user avoids the notch or moves the mouse cursor carefully near the notch. In experiment 1, longer movement timeswere recorded because the cursor was hidden by the notch, when pointing a target at the top edge from another target, which was also at the top edge.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to 4 direction movements and a turn-left skill. Additionally, two actions out of 4 special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava, are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward. We use PPO to train all methods.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to 4 direction movements and a turn-left skill. Additionally, two actions out of 4 special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava, are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward. We use PPO to train all methods.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to 4 direction movements and a turn-left skill. Additionally, two actions out of 4 special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava, are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward. We use PPO to train all methods.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to 4 direction movements and a turn-left skill. Additionally, two actions out of 4 special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava, are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward. We use PPO to train all methods.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to 4 direction movements and a turn-left skill. Additionally, two actions out of 4 special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava, are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward. We use PPO to train all methods.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to 4 direction movements and a turn-left skill. Additionally, two actions out of 4 special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava, are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward. We use PPO to train all methods.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to 4 direction movements and a turn-left skill. Additionally, two actions out of 4 special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava, are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward. We use PPO to train all methods.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to 4 direction movements and a turn-left skill. Additionally, two actions out of 4 special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava, are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward. We use PPO to train all methods.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "instruction": "Rewrite some sentences, making them more connected and using more formal language.", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to four direction movements and a turn-left skill. However, two actions out of four special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "instruction": "Use a slightly more academic logical language.", "revised_paragraph": "\"We modify the grid world environment (Chevalier-Boisvert et al., 2018) where an agent navigates a 2D maze with two lava rivers to reach a goal. The agent always has access to 4 direction movements and a turn-left skill. However, two actions out of 4 special skills: turn-right, step-forward, dig-orange-lava and dig-pink-lava, are randomly sampled for the agent in every task instance. The agent can walk over lava for one timestep without dying, but it can remove the lava by using the matching dig-lava skill. Thus, when available, dig-lava skills can be used to build shortcut paths to the goal on the other end, and thus receive a higher reward.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier"}, {"intention": "Concision", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases. Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier et al., 2021).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases. Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier et al., 2021).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based. Structure-based methods aim at predicting thermal stability or fitness of the protein rather than binding free energy between proteins. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases. Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier et al., 2017)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases. Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier et al., 2021).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases. Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier et al., 2021).\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "instruction": "Review the following paragraph", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "instruction": "Make this paragraph shorter and more fitted to academic style.", "revised_paragraph": "\"Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "instruction": "Improve the english of this paragraph.", "revised_paragraph": "\"Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "instruction": "Edit this paragraph by making more formal choices of wording.", "revised_paragraph": "Estimating individual treatment effects from observational data is very challenging due to the existence of treatment selection bias. Most existing representation-based methods mitigate this issue by aligning distributions of different treatment groups in the representation space. However, they still suffer from two critical problems: (1) Mini-batch Sampling Effects (MSE), where the alignment easily fails due to the outcome imbalance or outliers in the batch; and (2) Unobserved Confounder Effects (UCE), where the unobserved confounders damage the correct alignment.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metrics, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metrics, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metrics, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metrics, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metrics, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metrics, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metrics, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metrics, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "instruction": "Make first half concise and second half precise.", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metric, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "instruction": "Improve the writing in this paragraph.", "revised_paragraph": "\"Matching methods, e.g., PSM exhibit promising performance on ranking metric, which explains why they are favored by counterfactual ranking applications (Betlei et al., 2021) in practice. However, their poor performance on PEHE hinders their application in counterfactual estimation applications such as advertising systems where accuracy metrics are more critical.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbours [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbours [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbours [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbours [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbours [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbours [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbours [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbours [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "instruction": "Rewrite some formulations, preferring shorter ones and fix typos.", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbors [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "instruction": "Improve the english of this text.", "revised_paragraph": "\"Branch Decider. Since the network context is not known during deployment, this creates the needfor a branch decider module. The branch decider reuses clusters labels from the training stage for a K Nearest Neighbours [45] classification. The light-weight distance based metric is used to classify the inference-time observation into one of the training groupings, and thereby executing the corresponding branch\u2019s symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features, and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates, and then concatenate together all SuperWeights used by the layer to create its final weights.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features, and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates, and then concatenate together all SuperWeights used by the layer to create its final weights.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features, and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates, and then concatenate together all SuperWeights used by the layer to create its final weights.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features, and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates, and then concatenate together all SuperWeights used by the layer to create its final weights.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features, and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates, and then concatenate together all SuperWeights used by the layer to create its final weights.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features, and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates, and then concatenate together all SuperWeights used by the layer to create its final weights.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features, and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates, and then concatenate together all SuperWeights used by the layer to create its final weights.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features, and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates, and then concatenate together all SuperWeights used by the layer to create its final weights.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "instruction": "Edit the first part of this paragraph for conciseness.", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features (e.g., edge or texture detectors), and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates (discussed in Section 3.1), and then concatenate together all SuperWeights used by the layer to create its final weights (process illustrated in center-right column of Figure 2).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "instruction": "Make the first half of the paragraphe shorter by merging the two sentences and removing the details about how superweights are generated.", "revised_paragraph": "\"SuperWeights, which are linear combination of templates which get reused by multiple layers. These SuperWeights capture a single operation on the input features (e.g., edge or texture detectors), and are themselves generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. Thus, to generate the weights for a single layer, we must first construct SuperWeights from the trainable parameters held by Weight Templates (discussed in Section 3.1), and then concatenate together all SuperWeights used by the layer to create its final weights (process illustrated in center-right column of Figure 2).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. SEP> They could rely on the bars that indicate allowed medication intake times with Design A and Design C."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. SEP> They could rely on the bars that indicate allowed medication intake times with Design A and Design C."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. SEP> They could rely on the bars that indicate allowed medication intake times with Design A and Design C."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"intention": "Concision", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. SEP> They could rely on the bars that indicate allowed medication intake times with Design A and Design C."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. SEP> They could rely on the bars that indicate allowed medication intake times with Design A and Design C."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. SEP> They could rely on the bars that indicate allowed medication intake times with Design A and Design C."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. SEP> They could rely on the bars that indicate allowed medication intake times with Design A and Design C."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. SEP> They could rely on the bars that indicate allowed medication intake times with Design A and Design C."}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "instruction": "Make this paragraph much more concise.", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. SEP> They could rely on the bars that indicate allowed medication intake times with Design A and Design C.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "instruction": "Please write more concisely about design B.", "revised_paragraph": "\"A, three with Design B, and 10 with Design C. To complete this task, participants could rely on the bars that indicate allowed medication intake times with Design A and Design C. With Design B, the marker on the medication entry indicated the allowed time. As most participants were not successful in completing this task with Design B, they provided ample feedback on this design. Five participants said the design does not support the task, for example, P1 \"it doesn\u2019t show any other time of the day that you can take it\". Three participants (P5, P11, and P12) said they can reschedule in any free slot, for example, P9 said \"It seems that 7am is a possibility because there is no other and there is no indication of conflicts.\" P10 and P6 reasoned that a medication that is supposed to be taken at a specific time point should not occupy a full hour on the calendar.", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We adopted the idea proposed in Chen et al. They aim to build a model for supervised SNLI task (Bowman et al., 2015), and the model concatenates the outputs from a global mean-pooling function and a global max-pooling function to serve as a sentence representation, and shows a performance boost on the SNLI dataset.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We adopted the idea proposed in Chen et al. They aim to build a model for supervised SNLI task (Bowman et al., 2015), and the model concatenates the outputs from a global mean-pooling function and a global max-pooling function to serve as a sentence representation, and shows a performance boost on the SNLI dataset.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We adopted the idea proposed in Chen et al. They aim to build a model for supervised SNLI task (Bowman et al., 2015), and the model concatenates the outputs from a global mean-pooling function and a global max-pooling function to serve as a sentence representation, and shows a performance boost on the SNLI dataset.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We adopted the idea proposed in Chen et al. They aim to build a model for supervised SNLI task (Bowman et al., 2015), and the model concatenates the outputs from a global mean-pooling function and a global max-pooling function to serve as a sentence representation, and shows a performance boost on the SNLI dataset.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We adopted the idea proposed in Chen et al. They aim to build a model for supervised SNLI task (Bowman et al., 2015), and the model concatenates the outputs from a global mean-pooling function and a global max-pooling function to serve as a sentence representation, and shows a performance boost on the SNLI dataset.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We adopted the idea proposed in Chen et al. They aim to build a model for supervised SNLI task (Bowman et al., 2015), and the model concatenates the outputs from a global mean-pooling function and a global max-pooling function to serve as a sentence representation, and shows a performance boost on the SNLI dataset.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We adopted the idea proposed in Chen et al. They aim to build a model for supervised SNLI task (Bowman et al., 2015), and the model concatenates the outputs from a global mean-pooling function and a global max-pooling function to serve as a sentence representation, and shows a performance boost on the SNLI dataset.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We adopted the idea proposed in Chen et al. They aim to build a model for supervised SNLI task (Bowman et al., 2015), and the model concatenates the outputs from a global mean-pooling function and a global max-pooling function to serve as a sentence representation, and shows a performance boost on the SNLI dataset.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "instruction": "Rewrite this paragraph using more formal language", "revised_paragraph": "\"We adopted the idea proposed in Chen et al.\" They aim to build a model for supervised SNLI, and the model uses a global mean-pooling function and a global max-pooling function to serve as a sentence representation. This model performs better on the SNLI dataset. Additionally, Conneau et al. (2017) found that the model with global max-pooling function has stronger transferability than the model with a global mean-pooling function after supervised training on SNLI.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "instruction": "Rephrase the text", "revised_paragraph": "\"We adopted the idea proposed by Chen et al. They aim to build a model for supervised SNLI task, and the model uses the outputs of a global mean-pooling function and a global max-pooling function to serve as a sentence representation, and shows better performance on the SNLI dataset.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}, {"intention": "Concision", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}, {"intention": "Concision", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"intention": "Concision", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"intention": "Concision", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to help with the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to help with the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\"\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "instruction": "Improve the English of this paragraph and make it shorter.", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "instruction": "Make the wording of this paragraph much more straight forward, to be more consice.", "revised_paragraph": "\"\u2022 AGILE-Tuned without sync-freq-change: In Mnih et al. (2015), the authors used the periodic syncing between the target and the main networks to alleviate the issue of the frequently moving target in updating the Q-network. In this work, we compared two extreme cases of the frequency period in syncing the networks; 10 ( Sync-freq=10 in Fig. 13 (a)) and 500 ( AGILE-Tuned ). \u2022 AGILE-Tuned without graph-dim-change: In order to understand the difficulty in expressing the action relation through the compact representation, we compared the big and the small representations in the action graph, i e., the node-features are encoded in 32 ( Graph-dim=32 ) or 64 ( AGILE-Tuned ) dimensions.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Recently, Ji et al. (2019) presented Action Genome, a new video dataset annotated by SGs. This dataset includes spatio-temporal SG annotations, where for each video, few individual frames were chosen and spatially annotated by SGs. Here, we use the Something-Something V2 (Goyal et al., 2017) dataset that is larger (200K vs. 10K videos) and more diverse since it includes basic human activities created by a large number of crowd workers. Finally, we propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\""}, {"intention": "Concision", "revised_paragraph": "\"We propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Recently, Ji et al. (2019) presented Action Genome, a new video dataset annotated by SGs. This dataset includes spatio-temporal SG annotations, where for each video, few individual frames were chosen and spatially annotated by SGs. Here, we use the Something-Something V2 (Goyal et al., 2017) dataset that is larger (200K vs. 10K videos) and more diverse since it includes basic human activities created by a large number of crowd workers. Finally, we propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Recently, Ji et al. (2019) presented Action Genome, a new video dataset annotated by SGs. This dataset includes spatio-temporal SG annotations, where for each video, few individual frames were chosen and spatially annotated by SGs. Here, we use the Something-Something V2 (Goyal et al., 2017) dataset that is larger (200K vs. 10K videos) and more diverse since it includes basic human activities created by a large number of crowd workers. Finally, we propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Recently, Ji et al. (2019) presented Action Genome, a new video dataset annotated by SGs. This dataset includes spatio-temporal SG annotations, where for each video, few individual frames were chosen and annotated by SGs. Here, we use the Something-Something V2 (Goyal et al., 2017) dataset that is larger (200K vs. 10K videos) and more diverse since it includes basic human activities created by a large number of crowd workers. Finally, we propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Recently, Ji et al. (2019) presented Action Genome, a new video dataset annotated by SGs. This dataset includes spatio-temporal SG annotations, where for each video, few individual frames were chosen and spatially annotated by SGs. Here, we use the Something-Something V2 (Goyal et al., 2017) dataset that is larger (200K vs. 10K videos) and more diverse since it includes basic human activities created by a large number of crowd workers. Finally, we propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "instruction": "Remove the argument that Action Graph is a more natural representation.", "revised_paragraph": "\"Recently, Ji et al. (2019) presented Action Genome, a new video dataset annotated by SGs. This dataset includes spatio-temporal SG annotations, where for each video, few individual frames were chosen and spatially annotated by SGs. Here, we use the Something-Something V2 (Goyal et al., 2017) dataset that is larger (200K vs. 10K videos) and more diverse since it includes basic human activities created by a large number of crowd workers. Finally, we propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "instruction": "Remove the less important details in the last sentence.", "revised_paragraph": "\"Recently, Ji et al. (2019) presented Action Genome, a new video dataset annotated by SGs. This dataset includes spatio-temporal SG annotations, where for each video, few individual frames were chosen and spatially annotated by SGs. Here, we use the Something-Something V2 (Goyal et al., 2017) dataset that is larger (200K vs. 10K videos) and more diverse since it includes basic human activities created by a large number of crowd workers. Finally, we propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}, {"intention": "Concision", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}, {"intention": "Concision", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set I, C, O and A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set I, C, O and A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\"\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set I, C, O and A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set I, C, O and A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "instruction": "Move the less important details of the training into an appendix. ", "revised_paragraph": ": \"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "instruction": "VOC is now named PASCAL VOC. Replace the last two sentence by a reference to an appendix. Correct the english in this paragraph.", "revised_paragraph": "\"Architecture, training and testing. For all the experiments on VOC, we base our architecture as DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. For training our models, we set  I,  C,  O and  A according to different types of annotations and datasets, which is shown in table 1. For inference, we follow SegSort (Hwang et al., 2019) to perform k-nearest neighbor retrievals. See Appendix for more detail of hyper-parameters and setting for training and testing.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food. Over 80% of the participants preferred Design B because of its prob- able similitude to already existing calendars. This was surprising to us because Design A was the design that was intended to resemble existing calendars. The sidelining of Design A can be attributed mainly to the height of medication entries which spanned the entire allowed administration period. This, according to participants, introduced too much clutter. Results indicate that the preferred layout should be vertically oriented with days of the week at the top and times of the day on the left. The dosage used on the medication entry should be one that users are familiar with. The unit used should also be consistent with the ones used in the prescriptions. It should show the actual quantity (e.g., milligrams) as opposed to relative classifications such as number of pills or tablets. This observation also applies to the icon used to denote medication that should"}, {"intention": "Concision", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food. Over 80% of the participants preferred Design B because of its prob- able similitude to already existing calendars. This was surprising to us because Design A was the design that was intended to resemble existing calendars. The sidelining of Design A can be attributed mainly to the height of medication entries which spanned the entire allowed administration period. This, according to participants, introduced too much clutter. Results indicate that the preferred layout should be vertically oriented with days of the week at the top and times of the day on the left. The dosage used on the medication entry should be one that users are familiar with. The unit used should also be consistent with the ones used in the prescriptions. It should show the actual quantity (e.g., milligrams) as opposed to relative classifications such as number of pills or tablets. This observation also applies to the icon used to denote medication that should"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food. Over 80% of the participants preferred Design B because of its prob- able similitude to already existing calendars. This was surprising to us because Design A was the design that was intended to resemble existing calendars. The sidelining of Design A can be attributed mainly to the height of medication entries which spanned the entire allowed administration period. This, according to participants, introduced too much clutter. Results indicate that the preferred layout should be vertically oriented with days of the week at the top and times of the day on the left. The dosage used on the medication entry should be one that users are familiar with. The unit used should also be consistent with the ones used in the prescriptions. It should show the actual quantity (e.g., milligrams) as opposed to relative classifications such as number of pills or tablets. This observation also applies to the icon used to denote medication that should"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"The design of a calendar should not deviate from calendar interfaces that users are familiar with. This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food. Over 80% of the participants preferred Design B because of its prob- able similitude to already existing calendars. This was surprising to us because Design A was the design that was intended to resemble existing calendars. The sidelining of Design A can be attributed mainly to the height of medication entries which spanned the entire allowed administration period. This, according to participants, introduced too much clutter. Results indicate that the preferred layout should be vertically oriented with days of the week at the top and times of the day on the left. The dosage used on the medication entry should be one that users are familiar with. The unit used should also be consistent with the ones used in the prescriptions. It should show the actual quantity (e.g., milligrams) as opposed to relative classifications such as number of pills or tablets. This observation also applies to the icon used to denote medication that should"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "instruction": "Make this paragraph more concise.", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "instruction": "Shorten my sentence related to realistic food-related icons.", "revised_paragraph": "\"The design of a calendar should not deviate from calendar interfaces that users are familiar with ( DG2 ). This was observed in various aspects of the design such as layout, medication entries, and icons used to annotate entries such as those which should be taken with food. Over 80% of the participants preferred Design B because of its prob- able similitude to already existing calendars. This was surprising to us because Design A was the design that was intended to resemble existing calendars.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "instruction": "Make this paragraph more concise.", "revised_paragraph": "\"The central novelty of our work is in realizing that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "instruction": "Make this paragraph shorter.", "revised_paragraph": "\"The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "instruction": "Rewrite this paragraph to improve its clarity.", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "instruction": "This paragraph is confusing, rewrite to make it clearer and more readable.", "revised_paragraph": "\"As a quick example of selection collider bias, if we were to ask you the gender of some random person born in 1801,and one in 1999, you may toss a coin to determine your answer, asbirth date and gender are unconditionally independent in the real world. However, if instead we where to ask about the gender of a person born in 1801, and one in 1999, that we saw on two random Wikipedia articles today, then you may condition your guess on some combination of birth date, gender, and importantly, what gets recorded in Wikipedia.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. We use the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\""}, {"intention": "Concision", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods. Our results are comparable to those of the two baselines. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. We use the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\""}, {"intention": "Concision", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods. Our results are comparable to those of the two baselines. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. We use the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. We use the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\"\""}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"We use the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods. Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. We use the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. We use the RDE to predict sidechain torsional angles for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) and SCWRL4 and show that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\"\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "instruction": "Make this paragraph more fluid.", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. We use the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "instruction": "Make the beginning of the paragraph more concise. Make the end of the paragraph more fitting to the academic style.", "revised_paragraph": "\"The rotamer density estimator (RDE) is a generative model for sidechain structures. It can be used to predict sidechain conformations by sampling from the estimated distribution. We use the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, 10 rotamers are sampled independently, and the one with the highest probability is selected as the final prediction. We compare RDE with two baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). Table 4 shows that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Detailed per-amino-acid accuracy is presented in Table 11 in the appendix.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"intention": "Concision", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "instruction": "Make this paragraph more concise.", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "instruction": "Make the last sentence more concise.", "revised_paragraph": "\"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (2.2), and a pretraining objective (2.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. Finally, we describe how we finetune the pretrained model for downstream tasks (2.4).\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has higher time complexity and quadratic space complexity with respect to input length, leading to higher run time than other stack RNNs but often better task performance.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has higher time complexity and quadratic space complexity with respect to input length, leading to higher run time than other stack RNNs but often better task performance.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has higher time complexity and quadratic space complexity with respect to input length, leading to higher run time than other stack RNNs but often better task performance.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has higher time complexity and quadratic space complexity with respect to input length, leading to higher run time than other stack RNNs but often better task performance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has higher time complexity and quadratic space complexity with respect to input length, leading to higher run time than other stack RNNs but often better task performance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has higher time complexity and quadratic space complexity with respect to input length, leading to higher run time than other stack RNNs but often better task performance.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has higher time complexity and quadratic space complexity with respect to input length, leading to higher run time than other stack RNNs but often better task performance.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has higher time complexity and quadratic space complexity with respect to input length, leading to higher run time than other stack RNNs but often better task performance.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "instruction": "Make this paragraph shorter", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has higher time complexity and quadratic space complexity with respect to input length, leading to higher run time than other stack RNNs but often better task performance.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "instruction": "Remove the unnessential details from the paragraph.", "revised_paragraph": "\"Whereas the superposition stack can be viewed as calculating expectations over individual stack elements, the Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has cubic time complexity and quadratic space complexity with respect to input length, leading to higher wall-clock run time than other stack RNNs but often better task performance.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model. A model with higher R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values for each model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values for each model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values for each model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values for each model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model. A model with higher R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model. A model with higher R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values. A model with higher R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values for each model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values for each model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values for each model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values for each model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "instruction": "Restructured some sentences in this paragraph and merge the last two sentences ", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model. A model with higher R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "instruction": "Improve the liking between phrases.", "revised_paragraph": "\"Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model. A model with higher R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was considered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "instruction": "Simplify the first sentence.", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "instruction": "Improve the readability of those sentences.", "revised_paragraph": "\"By applying the implicit function theorem on Equation 8, we obtain the Jacobians  Y  ( z,  ) / z and  Y  ( z,  ) / , which is all we need in order for iDSPN to fit into an autodiff framework. Appendix B contains the full details of how this works.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "instruction": "Make the beginning of this paragraph shorter.", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "instruction": "Make the beginning of this paragraph shorter.", "revised_paragraph": "\"In this work we try to address that gap, and study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions with 0-cost.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance. Thus, the semantic distance can be partially characterized by the proposed augmented distance. Based on the augmented distance, we now introduce the (,  ) -augmentation to measure the concentration of augmented data.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance. Thus, the semantic distance can be partially characterized by the proposed augmented distance. Moreover, based on the augmented distance, we now introduce the (,  ) -augmentation to measure the concentration of augmented data.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance. Thus, the semantic distance can be partially characterized by the proposed augmented distance. Moreover, based on the augmented distance, we now introduce the (,  ) -augmentation to measure the concentration of augmented data.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance. Thus, the semantic distance can be partially characterized by the proposed augmented distance. Based on the augmented distance, we now introduce the (,  ) -augmentation to measure the concentration of augmented data.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance. Thus, the semantic distance can be partially characterized by the proposed augmented distance. Based on the augmented distance, we now introduce the (,  ) -augmentation to measure the concentration of augmented data.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance. Thus, the semantic distance can be partially characterized by the proposed augmented distance. Based on the augmented distance, we now introduce the (, ) -augmentation to measure the concentration of augmented data.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance. Thus, the semantic distance can be partially characterized by the proposed augmented distance. Moreover, based on the augmented distance, we now introduce the (,  ) -augmentation to measure the concentration of augmented data.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance. Thus, the semantic distance can be partially characterized by the proposed augmented distance. Based on the augmented distance, we now introduce the (,  ) -augmentation to measure the concentration of augmented data.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "instruction": "Use formal words.", "revised_paragraph": "\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "instruction": "Improve this paragraph (mostly the first sentence) to make it less confusing.", "revised_paragraph": "\"For the dog images in Figure 2, although they are quite different at the pixel level, they contain similar semantic meanings. Meanwhile, they have a small augmented distance. Thus, the semantic distance can be partially characterized by the proposed augmented distance. Moreover, based on the augmented distance, we now introduce the (,  ) -augmentation to measure the concentration of augmented data.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we take inspiration from. In this area, TL is often used to specify the ego agent\u2019s desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL. The authors of [20, 21] learns finite state automata from demonstration and use them to guide planning with the value iteration network which avoids exploration. It can sometimes be tedious to manually design a TL formula that yields satisfying behaviors. Work has been done to make components of the formula learnable from data. In [22]learns linear temporal logic (LTL) formulas from demonstrations. Given the close relationship between TL and automaton[23], the authors of [24] proposes a method that learns reward machines (an automata-like reward presentation) from demonstrations. A commonality that these methods that they operate on propositions (binary variables with values true or false). This also limits these methods to operate on discreteand finite state and actionspaces. Our method works with STL which operates"}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we take inspiration from. In this area, TL is often used to specify the ego agent\u2019s desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL. The authors of [20, 21] learns finite state automata from demonstration and use them to guide planning with the value iteration network which avoids exploration. It can sometimes be tedious to manually design a TL formula that yields satisfying behaviors. Work has been done to make components of the formula learnable from data. In [22]learns linear temporal logic (LTL) formulas from demonstrations. Given the close relationship between TL and automaton[23], the authors of [24] proposes a method that learns reward machines (an automata-like reward presentation) from demonstrations. This also limits these methods to operate on discreteand finite state and actionspaces. Our method works with STL which operates on continuous signals, therefore, we are able tolearn from continuous demonstration trajectories"}, {"intention": "Concision", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we have taken inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we have taken inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we have taken inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL."}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we take inspiration from. In this area, TL is often used to specify the ego agent\u2019s desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL. The authors of [20, 21] learns finite state automata from demonstration and use them to guide planning with the value iteration network which avoids exploration. It can sometimes be tedious to manually design a TL formula that yields satisfying behaviors. Work has been done to make components of the formula learnable from data. In [22]learns linear temporal logic (LTL) formulas from demonstrations. Given the close relationship between TL and automaton[23], the authors of [24] proposes a method that learns reward machines (an automata-like reward presentation) from demonstrations. This also limits these methods to operate on discreteand finite state and actionspaces. Our method works with STL which operates on continuous signals, therefore, we are able tolearn from continuous demonstration trajectories"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"intention": "Concision", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we have taken inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL."}, {"intention": "Rewritting_light", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we take inspiration from. In this area, TL is often used to specify the ego agent\u2019s desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL. The authors of [20, 21] learns finite state automata from demonstration and use them to guide planning with the value iteration network which avoids exploration. It can sometimes be tedious to manually design a TL formula that yields satisfying behaviors. Work has been done to make components of the formula learnable from data. In [22]learns linear temporal logic (LTL) formulas from demonstrations. Given the close relationship between TL and automaton[23], the authors of [24] proposes a method that learns reward machines (an automata-like reward presentation) from demonstrations. A commonality that these methods that they operate on propositions (binary variables with values true or false). This also limits these methods to operate on discreteand finite state and actionspaces. Our method works with STL which operates"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we take inspiration from. In this area, TL is often used to specify the ego agent\u2019s desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL. The authors of [20, 21] learns finite state automata from demonstration and use them to guide planning with the value iteration network which avoids exploration. It can sometimes be tedious to manually design a TL formula that yields satisfying behaviors. Work has been done to make components of the formula learnable from data. In [22]learns linear temporal logic (LTL) formulas from demonstrations. Given the close relationship between TL and automaton[23], the authors of [24] proposes a method that learns reward machines (an automata-like reward presentation) from demonstrations. A commonality that these methods that they operate on propositions (binary variables with values true or false). This also limits these methods to operate on discreteand finite state and actionspaces. Our method works with STL which operates"}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Temporal logic (TL)-guided policy learning is an area that we take inspiration from. In this area, TL is often used to specify the ego agent\u2019s desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL. The authors of [20, 21] learns finite state automata from demonstration and use them to guide planning with the value iteration network which avoids exploration. It can sometimes be tedious to manually design a TL formula that yields satisfying behaviors. Work has been done to make components of the formula learnable from data. In [22]learns linear temporal logic (LTL) formulas from demonstrations. Given the close relationship between TL and automaton[23], the authors of [24] proposes a method that learns reward machines (an automata-like reward presentation) from demonstrations. A commonality that these methods that they operate on propositions (binary variables with values true or false). This also limits these methods to operate on discreteand finite state and actionspaces. Our method works with STL which"}, {"depth": 3, "intention": "Concision", "revised_paragraph": "\"\"\"Temporal logic (TL)-guided policy learning is an area that we take inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we have taken inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we have taken inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Temporal logic (TL)-guided policy learning is an area that we have taken inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we have taken inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"Temporal logic (TL)-guided policy learning is an area that we have taken inspiration from. In this area, TL is often used to specify the ego agent's desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "instruction": "Make this paragraph easier to read, remove unnecessary details if needed", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we take inspiration from. In this area, TL is often used to specify the ego agent\u2019s desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL. The authors of [20, 21] learns finite state automata from demonstration and use them to guide planning with the value iteration network which avoids exploration. It can sometimes be tedious to manually design a TL formula that yields satisfying behaviors. Work has been done to make components of the formula learnable from data. In [22]learns linear temporal logic (LTL) formulas from demonstrations. Given the close relationship between TL and automaton[23], the authors of [24] proposes a method that learns reward machines (an automata-like reward presentation) from demonstrations. This also limits these methods to operate on discreteand finite state and actionspaces. Our method works with STL which operates on continuous signals, therefore, we are able tolearn from continuous demonstration trajectories", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "instruction": "Summarize the last third of this paragraph in one sentence. Smooth out the writing.", "revised_paragraph": "\"Temporal logic (TL)-guided policy learning is an area that we take inspiration from. In this area, TL is often used to specify the ego agent\u2019s desired high-level behavior and used to generate rewards. The authors of [17, 18, 19] provide surveys of recent work on the use of TL in RL. The authors of [20, 21] learns finite state automata from demonstration and use them to guide planning with the value iteration network which avoids exploration. It can sometimes be tedious to manually design a TL formula that yields satisfying behaviors. Work has been done to make components of the formula learnable from data. In [22]learns linear temporal logic (LTL) formulas from demonstrations. Given the close relationship between TL and automaton[23], the authors of [24] proposes a method that learns reward machines (an automata-like reward presentation) from demonstrations. This also limits these methods to operate on discreteand finite state and actionspaces. Our method works with STL which operates on continuous signals, therefore, we are able tolearn from continuous demonstration trajectories", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions of representations in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions of representations in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions of representations in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions of representations in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions of representations in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "\"\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions of representations in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions of representations in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions of representations in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "instruction": "Make the benefit clearer.", "revised_paragraph": "\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions of representations in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "instruction": "Reorder the elements in sentences to improve the readability.", "revised_paragraph": "\"Representation-based methods, e.g., BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), balance the distributions in the latent space. Liuyi et al. and Hassanpour & Greiner (2020) further augment CFR with local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) propose to balance the distributions of representations with adversarial training. Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and the suitability for large-scale scenarios.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, by design, this token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, by design, this token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, by design, this token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, by design, this token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, by design, this token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, by design, this token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, by design, this token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, by design, this token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "instruction": "Simplify the conclusions of this paragraph wo make it clearer and more concise.", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, this token is not translation-invariant by design. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant.", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "instruction": "Simplify the last sentence  by removing the notion of translation-equivariant  and just calling it conditional positional encodings.", "revised_paragraph": "\"In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, this token is not translation-invariant by design. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.\"", "type_approach": "instruction-annot_2"}]
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features; this is a natural and practical assumption [27, 30] that encompasses numerical representations of the instance itself\u2014 e.g. bits representing a query or a graph\u2014or other information such as weather or day of the week. These are passed to functions\u2014e.g. linear predictors, neural nets, or trees\u2014whose parameters can be learned from data. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}, {"intention": "Concision", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features that can be used to train a model that captures the underlying dynamics of the system. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we solve the problem by restricting to matrices with columns in the simplex, i.e. rectangular stochastic matrices. Both sets of results are shown in Appendix C. Notably, for page migration our guarantees cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features that can be used to train a model that captures the underlying dynamics of the system. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we solve the problem by restricting to matrices with columns in the simplex, i.e. rectangular stochastic matrices. Both sets of results are shown in Appendix C. Notably, for page migration our guarantees cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features that can be used to train a model that captures the underlying dynamics of the system. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we solve the problem by restricting to matrices with columns in the simplex, i.e. rectangular stochastic matrices. Both sets of results are shown in Appendix C. Notably, for page migration our guarantees cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}, {"intention": "Rewritting_light", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features; this is a natural and practical assumption [27, 30] that encompasses numerical representations of the instance itself\u2014 e.g. bits representing a query or a graph\u2014or other information such as weather or day of the week. These are passed to functions\u2014e.g. linear predictors, neural nets, or trees\u2014whose parameters can be learned from data. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"intention": "Concision", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features that can be used to train a model that captures the underlying dynamics of the system. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we solve the problem by restricting to matrices with columns in the simplex, i.e. rectangular stochastic matrices. Both sets of results are shown in Appendix C. Notably, for page migration our guarantees cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features; this is a natural and practical assumption [27, 30] that encompasses numerical representations of the instance itself\u2014 e.g. bits representing a query or a graph\u2014or other information such as weather or day of the week. These are passed to functions\u2014e.g. linear predictors, neural nets, or trees\u2014whose parameters can be learned from data. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "\"\"We instead study the setting where all instances come with instance-specific features that can be used to train models that capture the dynamics of the system. Such models can be trained on data from real world applications, such as search and routing on web pages. \"\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features that can be used to train a model that captures the underlying dynamics of the system. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we solve the problem by restricting to matrices with columns in the simplex, i.e. rectangular stochastic matrices. Both sets of results are shown in Appendix C. Notably, for page migration our guarantees cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features that can be used to train a model that captures the underlying dynamics of the system. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we solve the problem by restricting to matrices with columns in the simplex, i.e. rectangular stochastic matrices. Both sets of results are shown in Appendix C. Notably, for page migration our guarantees cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "\"\"We instead study the setting where all instances come with instance-specific features that can be used to train a model that captures the underlying dynamics of the system. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we solve the problem by restricting to matrices with columns in the simplex, i.e. rectangular stochastic matrices. Both sets of results are shown in Appendix C. Notably, for page migration our guarantees cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\"\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features that can be used to train a model that captures the underlying dynamics of the system. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we solve the problem by restricting to matrices with columns in the simplex, i.e. rectangular stochastic matrices. Both sets of results are shown in Appendix C. Notably, for page migration our guarantees cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\""}], "type_approach": "iterative-labels-annot_2"}
[{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "instruction": "Remove unecessary details, use abbrieviation. ", "revised_paragraph": ": \"We instead study the setting where all instances come with instance-specific features; this is a natural and practical assumption [27, 30] that encompasses numerical representations of the instance itself\u2014 e.g. bits representing a query or a graph\u2014or other information such as weather or day of the week. These are passed to functions\u2014e.g. linear predictors, neural nets, or trees\u2014whose parameters can be learned from data. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\"", "type_approach": "instruction-annot_1"}]
[{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "instruction": "Make this paragraph a bit more concise.", "revised_paragraph": "\"We instead study the setting where all instances come with instance-specific features that can be used to train a model that captures the underlying dynamics of the system. We study linear predictors, which are often amenable to similar analyses as above since the composition of a convex and affine function is convex. For example, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, our guarantees cover the auto-regressive setting where the server probabilities are determined by a fixed linear transform of past states.\"", "type_approach": "instruction-annot_2"}]
