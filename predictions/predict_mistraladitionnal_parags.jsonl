{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": " Revised paragraph:\n\nThe multi-modal transfer module (MMTM), which we implement as our fusion module (Joze et al., 2020), operates by first transforming the feature maps of each uni-modal branch into vector representations through global average pooling along spatial dimensions. Subsequently, we concatenate these representations and subject them to a linear transformation to generate cross-modal context representations. We employ two independent fully-connected layers to estimate channel-wise weights based on the cross-modal context representations. Lastly, these weights are employed to re-calibrate the channel-wise features for each modality."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": " Revised paragraph:\n\nThe multi-modal transfer module (MMTM), which we implement as our fusion module (Joze et al., 2020), operates by first transforming the feature maps of each uni-modal branch into vector representations through global average pooling along spatial dimensions. Subsequently, we concatenate these representations and subject them to a linear transformation to generate cross-modal context representations. We employ two independent fully-connected layers to estimate channel-wise weights based on the cross-modal context representations. Lastly, these weights are employed to re-calibrate the channel-wise features for each modality."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": " Revised paragraph:\n\nThe multi-modal transfer module (MMTM), which we implement as our fusion module (Joze et al., 2020), operates by first transforming the feature maps of each uni-modal branch into vector representations through global average pooling along spatial dimensions. Subsequently, we concatenate these representations and subject them to a linear transformation to generate cross-modal context representations. We employ two independent fully-connected layers to estimate channel-wise weights based on the cross-modal context representations. Lastly, these weights are employed to re-calibrate the channel-wise features for each modality."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": " Revised paragraph:\n\nThe multi-modal transfer module (MMTM), which we implement as our fusion module (Joze et al., 2020), operates by first transforming the feature maps of each uni-modal branch into vector representations through global average pooling along spatial dimensions. Subsequently, we concatenate these representations and subject them to a linear transformation to generate cross-modal context representations. We employ two independent fully-connected layers to estimate channel-wise weights based on the cross-modal context representations. Lastly, these weights are employed to re-calibrate the channel-wise features for each modality."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": " Revised paragraph:\n\nThe multi-modal transfer module (MMTM), which we implement as our fusion module (Joze et al., 2020), operates by first transforming the feature maps of each uni-modal branch into vector representations through global average pooling along spatial dimensions. Subsequently, we concatenate these representations and subject them to a linear transformation to generate cross-modal context representations. We employ two independent fully-connected layers to estimate channel-wise weights based on the cross-modal context representations. Lastly, these weights are employed to re-calibrate the channel-wise features for each modality."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": " Revised paragraph:\n\nThe multi-modal transfer module (MMTM), which we implement as our fusion module (Joze et al., 2020), operates by first transforming the feature maps of each uni-modal branch into vector representations through global average pooling along spatial dimensions. Subsequently, we concatenate these representations and subject them to a linear transformation to generate cross-modal context representations. We employ two independent fully-connected layers to estimate channel-wise weights based on the cross-modal context representations. Lastly, these weights are employed to re-calibrate the channel-wise features for each modality."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": " Revised paragraph:\n\nThe multi-modal transfer module (MMTM), which we implement as our fusion module (Joze et al., 2020), operates by first transforming the feature maps of each uni-modal branch into vector representations through global average pooling along spatial dimensions. Subsequently, we concatenate these representations and subject them to a linear transformation to generate cross-modal context representations. We employ two independent fully-connected layers to estimate channel-wise weights based on the cross-modal context representations. Lastly, these weights are employed to re-calibrate the channel-wise features for each modality."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": " Revised paragraph:\n\nThe multi-modal transfer module (MMTM), which we implement as our fusion module (Joze et al., 2020), operates by first transforming the feature maps of each uni-modal branch into vector representations through global average pooling along spatial dimensions. Subsequently, we concatenate these representations and subject them to a linear transformation to generate cross-modal context representations. We employ two independent fully-connected layers to estimate channel-wise weights based on the cross-modal context representations. Lastly, these weights are employed to re-calibrate the channel-wise features for each modality."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "instruction": "Rearrange the structure to make the structure clearer.", "revised_paragraph": " Revised paragraph: \"First, we apply global average pooling over spatial dimensions in each uni-modal branch to obtain vector representations of feature maps (Joze et al., 2020). Next, we concatenate these representations and perform a linear transformation to generate a cross-modal context representation. Subsequently, we predict channel-wise weights for each modality based on this context representation using two independent fully-connected layers. Lastly, these weights are employed to re-calibrate the channel-wise features per modality.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.03", "instruction": "Rewrite this paragraph completely to make it clearer.", "revised_paragraph": " Revised paragraph:\n\nThe fusion module is implemented as a multi-modal transfer module (MMTM) based on Joze et al.'s work in 2020. MMTM operates by transforming the feature maps from each uni-modal branch into vector representations via global average pooling along spatial dimensions. The resulting vectors are then concatenated, followed by a linear transformation to generate the cross-modal context representation. Using this context representation, we compute independent channel-wise weights for each modality through two fully-connected layers. These weights are subsequently employed to recalibrate the channel-wise features corresponding to each modality.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": " Revised paragraph:\n\nMeta learning's generalization ability has been examined through the examination of excess risk in gradient-based methods [3, 4, 9, 14, 18, 42]. Generalization studies in meta learning have been done in various contexts. For instance, in [27], the focus was on mixed linear regression for small and large data tasks. Mutual information-bounded generalization errors have been proposed in [10, 26]. The PAC-Bayes framework has been applied to meta learning as suggested in [1, 15, 19, 34]. Most of these studies concentrate on underparameterized meta learning models. Bernacchia [6] showed the effectiveness of negative learning rates during meta-training for linear models and overparameterized MAML. Sun et al. [39] demonstrated the need for overparameterized representations in representation-based meta learning."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": " Revised paragraph:\n\nMeta learning's generalization ability has been examined through the examination of excess risk in gradient-based methods [3, 4, 9, 14, 18, 42]. Generalization studies in meta learning have been done in various contexts. For instance, in [27], the focus was on mixed linear regression for small and large data tasks. Mutual information-bounded generalization errors have been proposed in [10, 26]. The PAC-Bayes framework has been applied to meta learning as suggested in [1, 15, 19, 34]. Most of these studies concentrate on underparameterized meta learning models. Bernacchia [6] showed the effectiveness of negative learning rates during meta-training for linear models and overparameterized MAML. Sun et al. [39] demonstrated the need for overparameterized representations in representation-based meta learning."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": " Revised paragraph:\n\nMeta learning's generalization ability has been examined through the examination of excess risk in gradient-based methods [3, 4, 9, 14, 18, 42]. Generalization studies in meta learning have been done in various contexts. For instance, in [27], the focus was on mixed linear regression for small and large data tasks. Mutual information-bounded generalization errors have been proposed in [10, 26]. The PAC-Bayes framework has been applied to meta learning as suggested in [1, 15, 19, 34]. Most of these studies concentrate on underparameterized meta learning models. Bernacchia [6] showed the effectiveness of negative learning rates during meta-training for linear models and overparameterized MAML. Sun et al. [39] demonstrated the need for overparameterized representations in representation-based meta learning."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": " Revised paragraph:\n\nMeta learning's generalization ability has been examined through the examination of excess risk in gradient-based methods [3, 4, 9, 14, 18, 42]. Generalization studies in meta learning have been done in various contexts. For instance, in [27], the focus was on mixed linear regression for small and large data tasks. Mutual information-bounded generalization errors have been proposed in [10, 26]. The PAC-Bayes framework has been applied to meta learning as suggested in [1, 15, 19, 34]. Most of these studies concentrate on underparameterized meta learning models. Bernacchia [6] showed the effectiveness of negative learning rates during meta-training for linear models and overparameterized MAML. Sun et al. [39] demonstrated the need for overparameterized representations in representation-based meta learning."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": " Revised paragraph:\n\nMeta learning's generalization ability has been examined through the examination of excess risk in gradient-based methods [3, 4, 9, 14, 18, 42]. Generalization studies in meta learning have been done in various contexts. For instance, in [27], the focus was on mixed linear regression for small and large data tasks. Mutual information-bounded generalization errors have been proposed in [10, 26]. The PAC-Bayes framework has been applied to meta learning as suggested in [1, 15, 19, 34]. Most of these studies concentrate on underparameterized meta learning models. Bernacchia [6] showed the effectiveness of negative learning rates during meta-training for linear models and overparameterized MAML. Sun et al. [39] demonstrated the need for overparameterized representations in representation-based meta learning."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": " Revised paragraph:\n\nMeta learning's generalization ability has been examined through the examination of excess risk in gradient-based methods [3, 4, 9, 14, 18, 42]. Generalization studies in meta learning have been done in various contexts. For instance, in [27], the focus was on mixed linear regression for small and large data tasks. Mutual information-bounded generalization errors have been proposed in [10, 26]. The PAC-Bayes framework has been applied to meta learning as suggested in [1, 15, 19, 34]. Most of these studies concentrate on underparameterized meta learning models. Bernacchia [6] showed the effectiveness of negative learning rates during meta-training for linear models and overparameterized MAML. Sun et al. [39] demonstrated the need for overparameterized representations in representation-based meta learning."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": " Revised paragraph:\n\nMeta learning's generalization ability has been examined through the examination of excess risk in gradient-based methods [3, 4, 9, 14, 18, 42]. Generalization studies in meta learning have been done in various contexts. For instance, in [27], the focus was on mixed linear regression for small and large data tasks. Mutual information-bounded generalization errors have been proposed in [10, 26]. The PAC-Bayes framework has been applied to meta learning as suggested in [1, 15, 19, 34]. Most of these studies concentrate on underparameterized meta learning models. Bernacchia [6] showed the effectiveness of negative learning rates during meta-training for linear models and overparameterized MAML. Sun et al. [39] demonstrated the need for overparameterized representations in representation-based meta learning."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": " Revised paragraph:\n\nMeta learning's generalization ability has been examined through the examination of excess risk in gradient-based methods [3, 4, 9, 14, 18, 42]. Generalization studies in meta learning have been done in various contexts. For instance, in [27], the focus was on mixed linear regression for small and large data tasks. Mutual information-bounded generalization errors have been proposed in [10, 26]. The PAC-Bayes framework has been applied to meta learning as suggested in [1, 15, 19, 34]. Most of these studies concentrate on underparameterized meta learning models. Bernacchia [6] showed the effectiveness of negative learning rates during meta-training for linear models and overparameterized MAML. Sun et al. [39] demonstrated the need for overparameterized representations in representation-based meta learning."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "instruction": "Remove a redundant sentence. Use clearer expression.", "revised_paragraph": " Revised paragraph: Recent studies have analyzed the excess risk as a metric of generalization ability in gradient-based meta learning [3, 4, 9, 14, 18, 42]. Research in meta learning has focused on the context of mixed linear regression [27], investigating when abundant tasks with small data can compensate for the lack of tasks with big data. In a different setting, representation-based meta learning [13, 16] has been studied for its generalization performance. Information theoretical bounds have proposed limitations on the generalization error based on mutual information between input training data and the output of meta-learning algorithms [10, 26]. The PAC-Bayes framework has been extended to meta learning to establish a PAC-Bayes meta-population risk bound [1, 15, 19, 34]. Most research has considered the underparameterized case, where the total number of meta training data from all tasks is larger than the dimension of the model parameter. However, overparameterized meta learning has gained increasing attention. Bernacchia [6] proposed that in overparameterized MAML, an optimal negative learning rate exists in the inner loop during meta-training for linear models with Gaussian data. Sun et al. [39] demonstrated that the optimal representation in representation-based meta learning is overparameterized and provides sample complexity for the method of moment estimator.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "instruction": "Improve the English and remove the second sentence.\t", "revised_paragraph": " Revised paragraph: \"The excess risk as a metric of generalization ability in gradient-based meta learning has been analyzed recently in works including [3, 4, 9, 14, 18, 42]. These studies have focused on investigating the generalization performance of meta learning in various contexts. In [27], the authors examined meta learning in mixed linear regression and explored the potential for compensating for limited tasks with large data. Representation-based meta learning was studied in [13, 16]. Both works proposed information theoretical bounds that quantify the generalization error in terms of mutual information between the input training data and the output of the meta-learning algorithms [10, 26]. The PAC-Bayes framework was extended to meta learning for providing a PAC-Bayes meta-population risk bound, as shown in [1, 15, 19, 34]. Most of these studies emphasized underparameterized meta learning models, in which the total number of meta training data from all tasks exceeded the dimension of the model parameter. However, recent research has shown that overparameterized meta learning deserves attention. Bernacchia [6] suggested that an optimal negative learning rate in the inner loop exists during meta training for linear models with Gaussian data in overparameterized meta learning. Sun et al. [39] discovered that the optimal representation in representation-based meta learning is overparameterized and offers sample complexity for the method of moment estimator.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nThe definition of \u00b5 (\u03b8 ; \u00b7) in this study is influenced by discussions in the literature regarding effective parameter updates (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Previously, studies have shown that normalization techniques, such as batch normalization (Ioffe & Szegedy, 2015), modify the direction of \u03b8, or \u03b8 / ||\u03b8||, to indicate the extent to which the update on \u03b8 adjusts the model f to fit a given batch of samples."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nThe definition of \u00b5 (\u03b8 ; \u00b7) in this study is influenced by discussions in the literature regarding effective parameter updates (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Previously, studies have shown that normalization techniques, such as batch normalization (Ioffe & Szegedy, 2015), modify the direction of \u03b8, or \u03b8 / ||\u03b8||, to indicate the extent to which the update on \u03b8 adjusts the model f to fit a given batch of samples."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nThe definition of \u00b5 (\u03b8 ; \u00b7) in this study is influenced by discussions in the literature regarding effective parameter updates (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Previously, studies have shown that normalization techniques, such as batch normalization (Ioffe & Szegedy, 2015), modify the direction of \u03b8, or \u03b8 / ||\u03b8||, to indicate the extent to which the update on \u03b8 adjusts the model f to fit a given batch of samples."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nThe definition of \u00b5 (\u03b8 ; \u00b7) in this study is influenced by discussions in the literature regarding effective parameter updates (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Previously, studies have shown that normalization techniques, such as batch normalization (Ioffe & Szegedy, 2015), modify the direction of \u03b8, or \u03b8 / ||\u03b8||, to indicate the extent to which the update on \u03b8 adjusts the model f to fit a given batch of samples."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nThe definition of \u00b5 (\u03b8 ; \u00b7) in this study is influenced by discussions in the literature regarding effective parameter updates (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Previously, studies have shown that normalization techniques, such as batch normalization (Ioffe & Szegedy, 2015), modify the direction of \u03b8, or \u03b8 / ||\u03b8||, to indicate the extent to which the update on \u03b8 adjusts the model f to fit a given batch of samples."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nThe definition of \u00b5 (\u03b8 ; \u00b7) in this study is influenced by discussions in the literature regarding effective parameter updates (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Previously, studies have shown that normalization techniques, such as batch normalization (Ioffe & Szegedy, 2015), modify the direction of \u03b8, or \u03b8 / ||\u03b8||, to indicate the extent to which the update on \u03b8 adjusts the model f to fit a given batch of samples."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nThe definition of \u00b5 (\u03b8 ; \u00b7) in this study is influenced by discussions in the literature regarding effective parameter updates (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Previously, studies have shown that normalization techniques, such as batch normalization (Ioffe & Szegedy, 2015), modify the direction of \u03b8, or \u03b8 / ||\u03b8||, to indicate the extent to which the update on \u03b8 adjusts the model f to fit a given batch of samples."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nThe definition of \u00b5 (\u03b8 ; \u00b7) in this study is influenced by discussions in the literature regarding effective parameter updates (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Previously, studies have shown that normalization techniques, such as batch normalization (Ioffe & Szegedy, 2015), modify the direction of \u03b8, or \u03b8 / ||\u03b8||, to indicate the extent to which the update on \u03b8 adjusts the model f to fit a given batch of samples."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "instruction": "Make expression concise, add conjuction, include all citations.", "revised_paragraph": " Revised paragraph: This definition of \u00b5 (\u03b8 ; \u00b7) is inspired by the literature on effective parameter updates (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). Previous studies, such as Ioffe and Szegedy (2015) on batch normalization, have shown that the update direction of \u03b8, specifically \u03b8 / || \u03b8 ||, reflects the magnitude of the change in the model f brought about by the update on \u03b8 when normalization techniques are applied.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.09", "instruction": "Rewrite this paragraph to make it clearer.", "revised_paragraph": " Revised paragraph:\n\nThe definition of \u00b5 (\u03b8 ; \u00b7) in this study is influenced by the discourse surrounding parameter update effectiveness in the literature (Van Laarhoven, 2017; Zhang et al., 2019; Brock et al., 2021). According to previous research, application of normalization techniques like batch normalization (Ioffe & Szegedy, 2015) results in the direction of \u03b8 (i.e., \u03b8 / || \u03b8 ||) reflecting the magnitude of the update on \u03b8, indicating the degree to which the model f is influenced and adjusted to fit the given batch of samples.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"The summarized results of the experiment are presented in Table 5. In this study, we employed CIFAR-10 as in-domain (ID) data and CIFAR-100 as out-of-domain (OOD) data. The routine watermarking setup (common) significantly enhances near-OOD detection performance compared to models without watermarking (w/o watermark). Furthermore, the application of shifting augmentations (permute and rotate) in watermarking amplifies the detection abilities of models, achieving up to 8.60 and 4.70 reductions in False Positive Rate at 95% (FPR95) for softmax and free energy scoring, respectively.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"The summarized results of the experiment are presented in Table 5. In this study, we employed CIFAR-10 as in-domain (ID) data and CIFAR-100 as out-of-domain (OOD) data. The routine watermarking setup (common) significantly enhances near-OOD detection performance compared to models without watermarking (w/o watermark). Furthermore, the application of shifting augmentations (permute and rotate) in watermarking amplifies the detection abilities of models, achieving up to 8.60 and 4.70 reductions in False Positive Rate at 95% (FPR95) for softmax and free energy scoring, respectively.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"The summarized results of the experiment are presented in Table 5. In this study, we employed CIFAR-10 as in-domain (ID) data and CIFAR-100 as out-of-domain (OOD) data. The routine watermarking setup (common) significantly enhances near-OOD detection performance compared to models without watermarking (w/o watermark). Furthermore, the application of shifting augmentations (permute and rotate) in watermarking amplifies the detection abilities of models, achieving up to 8.60 and 4.70 reductions in False Positive Rate at 95% (FPR95) for softmax and free energy scoring, respectively.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"The summarized results of the experiment are presented in Table 5. In this study, we employed CIFAR-10 as in-domain (ID) data and CIFAR-100 as out-of-domain (OOD) data. The routine watermarking setup (common) significantly enhances near-OOD detection performance compared to models without watermarking (w/o watermark). Furthermore, the application of shifting augmentations (permute and rotate) in watermarking amplifies the detection abilities of models, achieving up to 8.60 and 4.70 reductions in False Positive Rate at 95% (FPR95) for softmax and free energy scoring, respectively.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"The summarized results of the experiment are presented in Table 5. In this study, we employed CIFAR-10 as in-domain (ID) data and CIFAR-100 as out-of-domain (OOD) data. The routine watermarking setup (common) significantly enhances near-OOD detection performance compared to models without watermarking (w/o watermark). Furthermore, the application of shifting augmentations (permute and rotate) in watermarking amplifies the detection abilities of models, achieving up to 8.60 and 4.70 reductions in False Positive Rate at 95% (FPR95) for softmax and free energy scoring, respectively.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"The summarized results of the experiment are presented in Table 5. In this study, we employed CIFAR-10 as in-domain (ID) data and CIFAR-100 as out-of-domain (OOD) data. The routine watermarking setup (common) significantly enhances near-OOD detection performance compared to models without watermarking (w/o watermark). Furthermore, the application of shifting augmentations (permute and rotate) in watermarking amplifies the detection abilities of models, achieving up to 8.60 and 4.70 reductions in False Positive Rate at 95% (FPR95) for softmax and free energy scoring, respectively.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"The summarized results of the experiment are presented in Table 5. In this study, we employed CIFAR-10 as in-domain (ID) data and CIFAR-100 as out-of-domain (OOD) data. The routine watermarking setup (common) significantly enhances near-OOD detection performance compared to models without watermarking (w/o watermark). Furthermore, the application of shifting augmentations (permute and rotate) in watermarking amplifies the detection abilities of models, achieving up to 8.60 and 4.70 reductions in False Positive Rate at 95% (FPR95) for softmax and free energy scoring, respectively.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"The summarized results of the experiment are presented in Table 5. In this study, we employed CIFAR-10 as in-domain (ID) data and CIFAR-100 as out-of-domain (OOD) data. The routine watermarking setup (common) significantly enhances near-OOD detection performance compared to models without watermarking (w/o watermark). Furthermore, the application of shifting augmentations (permute and rotate) in watermarking amplifies the detection abilities of models, achieving up to 8.60 and 4.70 reductions in False Positive Rate at 95% (FPR95) for softmax and free energy scoring, respectively.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "instruction": "Make expression concrete, correct typos.", "revised_paragraph": " Revised paragraph:\n\nThe experimental outcomes are encapsulated in Table 5, with CIFAR-10 serving as in-domain data and CIFAR-100 as out-of-domain data. In this experimentation, the typical watermark learning setup (common) significantly enhances the performance of near-OOD detection over situations devoid of watermarking (w/o watermark). Furthermore, watermarking infused with shifting augmentations, such as permute and rotation, augment the detection capabilities of the models, culminating in maximum improvements of 8.60% and 4.70% in FPR95 for the softmax and free energy scoring, respectively.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "sK_VkqBv2X.rJUJNwFOc.03", "instruction": "Improve the English of this paragraph.", "revised_paragraph": " Revised paragraph: \"The experimental outcomes are presented in Table 5. For ID data, we employ CIFAR-10, while OOD data is represented by CIFAR-100. In the standard watermarking learning configuration (common), we observe enhanced near-OOD detection performance as compared to instances devoid of watermarking (w/o watermark). Furthermore, implementing shifting augmentations (permute and rotate) in watermarking techniques significantly strengthens the models' detection abilities, resulting in approximately 8.60 and 4.70 reductions in FPR95 for softmax and free energy scoring, respectively.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nTraining Procedures: Adhering to Zhang et al. (2018b), we apply data augmentation to our training data. Specifically, images are rotated randomly by 90\u00b0, 180\u00b0, 270\u00b0, and horizontally flipped. Each training batch comprises sixteen LR color patches, with a size of 48 \u00d7 48 pixels. Our SRP model is optimized using the Adam algorithm (Kingma & Ba, 2014), with learning rate decay set to \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u207b\u2078. The initial learning rate is defined as 10\u207b\u2074. After every 2 \u00d7 10\u2075 iterations, the learning rate is reduced by half during backpropagation. We utilize PyTorch (Paszke et al., 2017) to develop our models, and a Tesla V100 GPU is employed for their implementation."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nTraining Procedures: Adhering to Zhang et al. (2018b), we apply data augmentation to our training data. Specifically, images are rotated randomly by 90\u00b0, 180\u00b0, 270\u00b0, and horizontally flipped. Each training batch comprises sixteen LR color patches, with a size of 48 \u00d7 48 pixels. Our SRP model is optimized using the Adam algorithm (Kingma & Ba, 2014), with learning rate decay set to \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u207b\u2078. The initial learning rate is defined as 10\u207b\u2074. After every 2 \u00d7 10\u2075 iterations, the learning rate is reduced by half during backpropagation. We utilize PyTorch (Paszke et al., 2017) to develop our models, and a Tesla V100 GPU is employed for their implementation."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nTraining Procedures: Adhering to Zhang et al. (2018b), we apply data augmentation to our training data. Specifically, images are rotated randomly by 90\u00b0, 180\u00b0, 270\u00b0, and horizontally flipped. Each training batch comprises sixteen LR color patches, with a size of 48 \u00d7 48 pixels. Our SRP model is optimized using the Adam algorithm (Kingma & Ba, 2014), with learning rate decay set to \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u207b\u2078. The initial learning rate is defined as 10\u207b\u2074. After every 2 \u00d7 10\u2075 iterations, the learning rate is reduced by half during backpropagation. We utilize PyTorch (Paszke et al., 2017) to develop our models, and a Tesla V100 GPU is employed for their implementation."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nTraining Procedures: Adhering to Zhang et al. (2018b), we apply data augmentation to our training data. Specifically, images are rotated randomly by 90\u00b0, 180\u00b0, 270\u00b0, and horizontally flipped. Each training batch comprises sixteen LR color patches, with a size of 48 \u00d7 48 pixels. Our SRP model is optimized using the Adam algorithm (Kingma & Ba, 2014), with learning rate decay set to \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u207b\u2078. The initial learning rate is defined as 10\u207b\u2074. After every 2 \u00d7 10\u2075 iterations, the learning rate is reduced by half during backpropagation. We utilize PyTorch (Paszke et al., 2017) to develop our models, and a Tesla V100 GPU is employed for their implementation."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nTraining Procedures: Adhering to Zhang et al. (2018b), we apply data augmentation to our training data. Specifically, images are rotated randomly by 90\u00b0, 180\u00b0, 270\u00b0, and horizontally flipped. Each training batch comprises sixteen LR color patches, with a size of 48 \u00d7 48 pixels. Our SRP model is optimized using the Adam algorithm (Kingma & Ba, 2014), with learning rate decay set to \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u207b\u2078. The initial learning rate is defined as 10\u207b\u2074. After every 2 \u00d7 10\u2075 iterations, the learning rate is reduced by half during backpropagation. We utilize PyTorch (Paszke et al., 2017) to develop our models, and a Tesla V100 GPU is employed for their implementation."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nTraining Procedures: Adhering to Zhang et al. (2018b), we apply data augmentation to our training data. Specifically, images are rotated randomly by 90\u00b0, 180\u00b0, 270\u00b0, and horizontally flipped. Each training batch comprises sixteen LR color patches, with a size of 48 \u00d7 48 pixels. Our SRP model is optimized using the Adam algorithm (Kingma & Ba, 2014), with learning rate decay set to \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u207b\u2078. The initial learning rate is defined as 10\u207b\u2074. After every 2 \u00d7 10\u2075 iterations, the learning rate is reduced by half during backpropagation. We utilize PyTorch (Paszke et al., 2017) to develop our models, and a Tesla V100 GPU is employed for their implementation."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nTraining Procedures: Adhering to Zhang et al. (2018b), we apply data augmentation to our training data. Specifically, images are rotated randomly by 90\u00b0, 180\u00b0, 270\u00b0, and horizontally flipped. Each training batch comprises sixteen LR color patches, with a size of 48 \u00d7 48 pixels. Our SRP model is optimized using the Adam algorithm (Kingma & Ba, 2014), with learning rate decay set to \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u207b\u2078. The initial learning rate is defined as 10\u207b\u2074. After every 2 \u00d7 10\u2075 iterations, the learning rate is reduced by half during backpropagation. We utilize PyTorch (Paszke et al., 2017) to develop our models, and a Tesla V100 GPU is employed for their implementation."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": " Revised paragraph:\n\nTraining Procedures: Adhering to Zhang et al. (2018b), we apply data augmentation to our training data. Specifically, images are rotated randomly by 90\u00b0, 180\u00b0, 270\u00b0, and horizontally flipped. Each training batch comprises sixteen LR color patches, with a size of 48 \u00d7 48 pixels. Our SRP model is optimized using the Adam algorithm (Kingma & Ba, 2014), with learning rate decay set to \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u207b\u2078. The initial learning rate is defined as 10\u207b\u2074. After every 2 \u00d7 10\u2075 iterations, the learning rate is reduced by half during backpropagation. We utilize PyTorch (Paszke et al., 2017) to develop our models, and a Tesla V100 GPU is employed for their implementation."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "instruction": "Improved the writing and reformulate the third sentence", "revised_paragraph": " Revised paragraph:\n\nTraining Procedures: In accordance with Zhang et al. (2018b), we apply data augmentation to our training dataset by rotating the images randomly at 90\u00b0, 180\u00b0, 270\u00b0, and horizontal flips. Each training batch accommodates sixteen LR color patches, sized 48 \u00d7 48 pixels. Our Super-Resolution Pre-training (SRP) model is optimized employing the ADAM algorithm (Kingma & Ba, 2014), with \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u1d49\u207b\u2078. The initial learning rate is set at 10\u1d49\u207b\u2074, which is subsequently lowered by half following every 2 \u00d7 10\u1d47\u2075 iterations of back-propagation. The PyTorch platform (Paszke et al., 2017) is utilized to create our models, integrating a Tesla V100 GPU.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.16", "instruction": "Improved the writing and reformulate the third sentence", "revised_paragraph": " Revised paragraph:\n\nTraining Parameters: Adhering to Zhang et al. (2018b), we apply data augmentation to our training dataset. This involves randomly rotating images by 90\u00b0, 180\u00b0, 270\u00b0, and horizontally flipping them. Each training batch consists of 16 LR color patches, each of size 48 \u00d7 48. We employ the ADAM optimizer (Kingma & Ba, 2014) with hyperparameters \u03b21 = 0.9, \u03b22 = 0.999, and \u03b5 = 10\u22128 to train our SRP model. The initial learning rate is set at 10\u22124, which is subsequentlyhalved every 2 \u00d7 105 iterations during back-propagation. We utilize PyTorch (Paszke et al., 2017) for model implementation, accompanied by a Tesla V100 GPU.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To gain a figurative understanding of how SRP (Sparse Residual Pruning) functions, Figure 3 displays the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are categorized into two groups: pruned and kept. The mean L1-norm of pruned filters decreases progressively due to the growing strength of the penalty, pushing them towards zero. Notably, the L1-norms of the kept filters surge (absence of a regularization term encouraging their expansion). This observation implies the network self-learns to adapt, akin to the compensation effect in the human brain (Duffau et al., 2003). For further visualization results, refer to the appendix.\""}, {"intention": "Content_deletion", "revised_paragraph": " Revised paragraph: During SRP training, the mean L 1-norms of filters in two layers of EDSR baseline decrease. Pruned filters have progressively smaller norms due to the increasing penalty, while kept filters exhibit unexpected growth (Fig. 3). This behavior indicates the network's ability to self-heal or compensate, similar to the compensation effect in the human brain. (Duffau et al., 2003). Additional visualization results are included in the appendix."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To gain a figurative understanding of how SRP (Sparse Residual Pruning) functions, Figure 3 displays the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are categorized into two groups: pruned and kept. The mean L1-norm of pruned filters decreases progressively due to the growing strength of the penalty, pushing them towards zero. Notably, the L1-norms of the kept filters surge (absence of a regularization term encouraging their expansion). This observation implies the network self-learns to adapt, akin to the compensation effect in the human brain (Duffau et al., 2003). For further visualization results, refer to the appendix.\""}, {"intention": "Content_deletion", "revised_paragraph": " Revised paragraph: During SRP training, the mean L 1-norms of filters in two layers of EDSR baseline decrease. Pruned filters have progressively smaller norms due to the increasing penalty, while kept filters exhibit unexpected growth (Fig. 3). This behavior indicates the network's ability to self-heal or compensate, similar to the compensation effect in the human brain. (Duffau et al., 2003). Additional visualization results are included in the appendix."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To gain a figurative understanding of how SRP (Sparse Residual Pruning) functions, Figure 3 displays the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are categorized into two groups: pruned and kept. The mean L1-norm of pruned filters decreases progressively due to the growing strength of the penalty, pushing them towards zero. Notably, the L1-norms of the kept filters surge (absence of a regularization term encouraging their expansion). This observation implies the network self-learns to adapt, akin to the compensation effect in the human brain (Duffau et al., 2003). For further visualization results, refer to the appendix.\""}, {"intention": "Content_deletion", "revised_paragraph": " Revised paragraph: During SRP training, the mean L 1-norms of filters in two layers of EDSR baseline decrease. Pruned filters have progressively smaller norms due to the increasing penalty, while kept filters exhibit unexpected growth (Fig. 3). This behavior indicates the network's ability to self-heal or compensate, similar to the compensation effect in the human brain. (Duffau et al., 2003). Additional visualization results are included in the appendix."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To gain a figurative understanding of how SRP (Sparse Residual Pruning) functions, Figure 3 displays the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are categorized into two groups: pruned and kept. The mean L1-norm of pruned filters decreases progressively due to the growing strength of the penalty, pushing them towards zero. Notably, the L1-norms of the kept filters surge (absence of a regularization term encouraging their expansion). This observation implies the network self-learns to adapt, akin to the compensation effect in the human brain (Duffau et al., 2003). For further visualization results, refer to the appendix.\""}, {"intention": "Content_deletion", "revised_paragraph": " Revised paragraph: During SRP training, the mean L 1-norms of filters in two layers of EDSR baseline decrease. Pruned filters have progressively smaller norms due to the increasing penalty, while kept filters exhibit unexpected growth (Fig. 3). This behavior indicates the network's ability to self-heal or compensate, similar to the compensation effect in the human brain. (Duffau et al., 2003). Additional visualization results are included in the appendix."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To gain a figurative understanding of how SRP (Sparse Residual Pruning) functions, Figure 3 displays the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are categorized into two groups: pruned and kept. The mean L1-norm of pruned filters decreases progressively due to the growing strength of the penalty, pushing them towards zero. Notably, the L1-norms of the kept filters surge (absence of a regularization term encouraging their expansion). This observation implies the network self-learns to adapt, akin to the compensation effect in the human brain (Duffau et al., 2003). For further visualization results, refer to the appendix.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": " Revised paragraph: \"Figure 3 demonstrates the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are labeled as pruned or kept. The mean L1-norm of pruned filters decreases, while that of kept filters increases. This indicates the network adapts during training.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To gain a figurative understanding of how SRP (Sparse Residual Pruning) functions, Figure 3 displays the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are categorized into two groups: pruned and kept. The mean L1-norm of pruned filters decreases progressively due to the growing strength of the penalty, pushing them towards zero. Notably, the L1-norms of the kept filters surge (absence of a regularization term encouraging their expansion). This observation implies the network self-learns to adapt, akin to the compensation effect in the human brain (Duffau et al., 2003). For further visualization results, refer to the appendix.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": " Revised paragraph: \"Figure 3 demonstrates the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are labeled as pruned or kept. The mean L1-norm of pruned filters decreases, while that of kept filters increases. This indicates the network adapts during training.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To gain a figurative understanding of how SRP (Sparse Residual Pruning) functions, Figure 3 displays the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are categorized into two groups: pruned and kept. The mean L1-norm of pruned filters decreases progressively due to the growing strength of the penalty, pushing them towards zero. Notably, the L1-norms of the kept filters surge (absence of a regularization term encouraging their expansion). This observation implies the network self-learns to adapt, akin to the compensation effect in the human brain (Duffau et al., 2003). For further visualization results, refer to the appendix.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": " Revised paragraph: \"Figure 3 demonstrates the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are labeled as pruned or kept. The mean L1-norm of pruned filters decreases, while that of kept filters increases. This indicates the network adapts during training.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To gain a figurative understanding of how SRP (Sparse Residual Pruning) functions, Figure 3 displays the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are categorized into two groups: pruned and kept. The mean L1-norm of pruned filters decreases progressively due to the growing strength of the penalty, pushing them towards zero. Notably, the L1-norms of the kept filters surge (absence of a regularization term encouraging their expansion). This observation implies the network self-learns to adapt, akin to the compensation effect in the human brain (Duffau et al., 2003). For further visualization results, refer to the appendix.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": " Revised paragraph: \"Figure 3 demonstrates the mean L1-norms of filters in the two layers of the EDSR baseline during SRP training. Filters are labeled as pruned or kept. The mean L1-norm of pruned filters decreases, while that of kept filters increases. This indicates the network adapts during training.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "instruction": "Rewrite this paragraph in a more formal style and remove any unnecessary details.", "revised_paragraph": " Revised paragraph:\n\nThe pruning process in SRP is illustrated in Figure 3 through the mean L1-norms of filters from two layers of the EDSR baseline during training. Filters are categorized into pruned and kept groups. Notably, the mean L1-norms of pruned filters progressively decrease as the penalty intensifies, guiding them towards zero. Intriguingly, the mean L1-norms of kept filters unexpectedly increase without any regularization term to augment their sizes. This finding indicates the network's self-healing ability, akin to the compensation effect in the human brain (Duffau et al., 2003). additional visualization results are presented in the appendix.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.18", "instruction": "Rewrite this paragraph in a more formal style and remove the last sentence", "revised_paragraph": " Revised paragraph: In Figure 3, the evolution of the mean L\u2081-norms of filters in the two layers of the EDSR baseline during SRP training is depicted. These filters are categorized into two groups: pruned and kept. The gradual decrease in the mean L\u2081-norms of pruned filters signifies the growing strength of the penalty, leading them towards zero. Notably, the mean L\u2081-norms of the kept filters exhibit an increase, indicating the network's innate capability to adapt and recover, resembling the compensation effect in the human brain (Duffau et al., 2003). Further visualization results have been included in the appendix.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the Cascaded DQN (CDQN) framework proposed by Chen et al. (2019a). The primary hurdle is the infeasibility of generating the complete list at once due to the enormous number of potential list combinations. Therefore, we construct the list progressively, action by action. Consequently, each list index is redefined as an independent, non-combinatorial action that can be managed via RL. In lieu of the CDQN Q-network, we integrate AGILE to facilitate a dynamic action space. We additionally synchronize the weights of the cascaded Q-networks. A detailed account of listwise AGILE can be found in Algorithm 1.\""}, {"intention": "Concision", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the incremental approach of Cascaded DQN (Chen et al., 2019a). Each list index is treated as an individual action, enabling RL training. We replace CDQN's Q-network with AGILE for adaptive action space. Q-network weights are shared. Details are in Algorithm 1.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the Cascaded DQN (CDQN) framework proposed by Chen et al. (2019a). The primary hurdle is the infeasibility of generating the complete list at once due to the enormous number of potential list combinations. Therefore, we construct the list progressively, action by action. Consequently, each list index is redefined as an independent, non-combinatorial action that can be managed via RL. In lieu of the CDQN Q-network, we integrate AGILE to facilitate a dynamic action space. We additionally synchronize the weights of the cascaded Q-networks. A detailed account of listwise AGILE can be found in Algorithm 1.\""}, {"intention": "Concision", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the incremental approach of Cascaded DQN (Chen et al., 2019a). Each list index is treated as an individual action, enabling RL training. We replace CDQN's Q-network with AGILE for adaptive action space. Q-network weights are shared. Details are in Algorithm 1.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "revisions": [{"intention": "Concision", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the incremental approach of Cascaded DQN (Chen et al., 2019a). Each list index is treated as an individual action, enabling RL training. We replace CDQN's Q-network with AGILE for adaptive action space. Q-network weights are shared. Details are in Algorithm 1.\""}, {"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the Cascaded DQN (CDQN) framework proposed by Chen et al. (2019a). The primary hurdle is the infeasibility of generating the complete list at once due to the enormous number of potential list combinations. Therefore, we construct the list progressively, action by action. Consequently, each list index is redefined as an independent, non-combinatorial action that can be managed via RL. In lieu of the CDQN Q-network, we integrate AGILE to facilitate a dynamic action space. We additionally synchronize the weights of the cascaded Q-networks. A detailed account of listwise AGILE can be found in Algorithm 1.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "revisions": [{"intention": "Concision", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the incremental approach of Cascaded DQN (Chen et al., 2019a). Each list index is treated as an individual action, enabling RL training. We replace CDQN's Q-network with AGILE for adaptive action space. Q-network weights are shared. Details are in Algorithm 1.\""}, {"intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the Cascaded DQN (CDQN) framework proposed by Chen et al. (2019a). The primary hurdle is the infeasibility of generating the complete list at once due to the enormous number of potential list combinations. Therefore, we construct the list progressively, action by action. Consequently, each list index is redefined as an independent, non-combinatorial action that can be managed via RL. In lieu of the CDQN Q-network, we integrate AGILE to facilitate a dynamic action space. We additionally synchronize the weights of the cascaded Q-networks. A detailed account of listwise AGILE can be found in Algorithm 1.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the Cascaded DQN (CDQN) framework proposed by Chen et al. (2019a). The primary hurdle is the infeasibility of generating the complete list at once due to the enormous number of potential list combinations. Therefore, we construct the list progressively, action by action. Consequently, each list index is redefined as an independent, non-combinatorial action that can be managed via RL. In lieu of the CDQN Q-network, we integrate AGILE to facilitate a dynamic action space. We additionally synchronize the weights of the cascaded Q-networks. A detailed account of listwise AGILE can be found in Algorithm 1.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": " Revised paragraph: \"We address the combinatorial action space problem in CDQN (Listwise RL) by adopting the Cascaded DQN (CDQN) framework (Chen et al., 2019a). To overcome the impracticality of generating the entire list at once, we construct it progressively, action by action. Each list index is then transformed into an independent, non-combinatorial action, enabling RL management. Instead of the CDQN Q-network, we introduce AGILE for a flexible action space. Synchronized weights for the cascaded Q-networks are also incorporated. For a comprehensive understanding of listwise AGILE, refer to Algorithm 1.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the Cascaded DQN (CDQN) framework proposed by Chen et al. (2019a). The primary hurdle is the infeasibility of generating the complete list at once due to the enormous number of potential list combinations. Therefore, we construct the list progressively, action by action. Consequently, each list index is redefined as an independent, non-combinatorial action that can be managed via RL. In lieu of the CDQN Q-network, we integrate AGILE to facilitate a dynamic action space. We additionally synchronize the weights of the cascaded Q-networks. A detailed account of listwise AGILE can be found in Algorithm 1.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": " Revised paragraph: \"We address the combinatorial action space problem in CDQN (Listwise RL) by adopting the Cascaded DQN (CDQN) framework (Chen et al., 2019a). To overcome the impracticality of generating the entire list at once, we construct it progressively, action by action. Each list index is then transformed into an independent, non-combinatorial action, enabling RL management. Instead of the CDQN Q-network, we introduce AGILE for a flexible action space. Synchronized weights for the cascaded Q-networks are also incorporated. For a comprehensive understanding of listwise AGILE, refer to Algorithm 1.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the incremental approach of Cascaded DQN (Chen et al., 2019a). Each list index is treated as an individual action, enabling RL training. We replace CDQN's Q-network with AGILE for adaptive action space. Q-network weights are shared. Details are in Algorithm 1.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To tackle the issue of large combinatorial action spaces in Listwise RL (CDQN), we adopt an incremental approach as used in Cascaded DQN (Chen et al., 2019a). In this method, each list index is regarded as an independent action, permitting RL training to proceed. We substitute CDQN's Q-network with AGILE for adaptive action space. The weights of the Q-network are shared between all instances.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": " Revised paragraph: \"To address the combinatorial action space issue in Listwise RL (CDQN), we adopt the incremental approach of Cascaded DQN (Chen et al., 2019a). Each list index is treated as an individual action, enabling RL training. We replace CDQN's Q-network with AGILE for adaptive action space. Q-network weights are shared. Details are in Algorithm 1.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": " Revised paragraph: \"To tackle the issue of large combinatorial action spaces in Listwise RL (CDQN), we adopt an incremental approach as used in Cascaded DQN (Chen et al., 2019a). In this method, each list index is regarded as an independent action, permitting RL training to proceed. We substitute CDQN's Q-network with AGILE for adaptive action space. The weights of the Q-network are shared between all instances.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "instruction": "Make first sentence more concise. Rewrite phrases, prefer short formulations and avoid we.", "revised_paragraph": " Revised paragraph:\n\nListwise RL (CDQN): Following Chen et al. (2019a)'s Cascaded DQN (CDQN) framework, we address the combinatorial action space problem of listwise actions. Building the entire list at once is impractical due to its intractably large size. Instead, we construct the list incrementally, one action at a time. Each list index is treated as a separate non-combinatorial action, trainable via RL. We substitute CDQN's Q-network with AGILE for a variable action space. Weights of cascaded Q-networks are shared. Algorithm 1 presents detailed listwise AGILE implementation.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.06", "instruction": "Make first sentence more concise. Rewrite phrases, prefer short formulations and avoid we.", "revised_paragraph": " Revised paragraph:\n\nListwise RL (using AGILE in CDQN): The combinatorial action space problem of listwise actions is addressed by adhering to the CDQN framework of Chen et al. (2019a). Due to the infeasibility of generating the full list at once, we construct the list incrementally through individual actions. Each list index is therefore treated as a separate non-combinatorial action for RL training. To accommodate the varying action space, we replace CDQN's Q-network with AGILE. Weights are shared among the cascaded Q-networks. Algorithm 1 outlines the complete details of listwise AGILE.", "type_approach": "instruction-annot_2"}
