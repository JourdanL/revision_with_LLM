{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Generally, these statistical notions can be expressed in terms of various conditional independence statements between the involved random variables, as demonstrated by Barocas et al. (2019): specifically, equations (5), (6-7), and (8-9) illustrate the relationships between y, s, and their conditional counterparts. If the training set lacks any positive outcomes for the demographic group s = 0, i.e., M y =1,s =0 is empty, the true positive rate for this group will be compromised, making it unlikely to satisfy, among other criteria, the equality of true positive rates (as expressed in equation 6)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Generally, these statistical notions can be expressed in terms of various conditional independence statements between the involved random variables, as demonstrated by Barocas et al. (2019): specifically, equations (5), (6-7), and (8-9) illustrate the relationships between y, s, and their conditional counterparts. If the training set lacks any positive outcomes for the demographic group s = 0, i.e., M y =1,s =0 is empty, the true positive rate for this group will be compromised, making it unlikely to satisfy, among other criteria, the equality of true positive rates (as expressed in equation 6)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Generally, these statistical notions can be expressed in terms of various conditional independence statements between the involved random variables, as demonstrated by Barocas et al. (2019): specifically, equations (5), (6-7), and (8-9) illustrate the relationships between y, s, and their conditional counterparts. If the training set lacks any positive outcomes for the demographic group s = 0, i.e., M y =1,s =0 is empty, the true positive rate for this group will be compromised, making it unlikely to satisfy, among other criteria, the equality of true positive rates (as expressed in equation 6)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Generally, these statistical notions can be expressed in terms of various conditional independence statements between the involved random variables, as demonstrated by Barocas et al. (2019): specifically, equations (5), (6-7), and (8-9) illustrate the relationships between y, s, and their conditional counterparts. If the training set lacks any positive outcomes for the demographic group s = 0, i.e., M y =1,s =0 is empty, the true positive rate for this group will be compromised, making it unlikely to satisfy, among other criteria, the equality of true positive rates (as expressed in equation 6)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Generally, these statistical notions can be expressed in terms of various conditional independence statements between the involved random variables, as demonstrated by Barocas et al. (2019): specifically, equations (5), (6-7), and (8-9) illustrate the relationships between y, s, and their conditional counterparts. If the training set lacks any positive outcomes for the demographic group s = 0, i.e., M y =1,s =0 is empty, the true positive rate for this group will be compromised, making it unlikely to satisfy, among other criteria, the equality of true positive rates (as expressed in equation 6)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Generally, these statistical notions can be expressed in terms of various conditional independence statements between the involved random variables, as demonstrated by Barocas et al. (2019): specifically, equations (5), (6-7), and (8-9) illustrate the relationships between y, s, and their conditional counterparts. If the training set lacks any positive outcomes for the demographic group s = 0, i.e., M y =1,s =0 is empty, the true positive rate for this group will be compromised, making it unlikely to satisfy, among other criteria, the equality of true positive rates (as expressed in equation 6)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Generally, these statistical notions can be expressed in terms of various conditional independence statements between the involved random variables, as demonstrated by Barocas et al. (2019): specifically, equations (5), (6-7), and (8-9) illustrate the relationships between y, s, and their conditional counterparts. If the training set lacks any positive outcomes for the demographic group s = 0, i.e., M y =1,s =0 is empty, the true positive rate for this group will be compromised, making it unlikely to satisfy, among other criteria, the equality of true positive rates (as expressed in equation 6)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Generally, these statistical notions can be expressed in terms of various conditional independence statements between the involved random variables, as demonstrated by Barocas et al. (2019): specifically, equations (5), (6-7), and (8-9) illustrate the relationships between y, s, and their conditional counterparts. If the training set lacks any positive outcomes for the demographic group s = 0, i.e., M y =1,s =0 is empty, the true positive rate for this group will be compromised, making it unlikely to satisfy, among other criteria, the equality of true positive rates (as expressed in equation 6)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "instruction": "Prefer extended forms over abbreviations of words.", "revised_paragraph": "Revised paragraph: Generally, statistical notions can be expressed in terms of different conditional independence statements between the involved random variables (Barocas et al., 2019): the independence of y from s (equation 5), the independence of y from s given y (equations 6-7), and the independence of y from s given the absence of y (equations 8-9). If our training set contains no positive outcomes for the demographic group s = 0, i.e., the set M y =1, s =0 is empty, the true positive rate for this group will suffer, and therefore we will likely not be able to satisfy, among others, the equality of true positive rate (equation 6).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "KUhhOtV2Yw.nPdxbHsbU.00", "instruction": "Write the abbreviation in their full form.", "revised_paragraph": "Revised paragraph: Generally, those statistical notions can be expressed in terms of different conditional independence statements between the involved random variables (Barocas et al., 2019): y bar is independent of s (equation 5), y bar is independent of s given y (equations 6-7), and y is independent of s given y bar (equations 8-9). If our training set has no positive outcome for the demographic s = 0, i.e., the set of instances where y = 1 and s = 0 is empty, the true positive rate for this group will suffer, and therefore we will likely not be able to satisfy, among others, the equality of true positive rates (equation 6).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the practical utility of exclusive multiset-equivariance (Subsection 4.1), the contrast between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). For further clarity, we provide a detailed description of the experimental procedure in Appendix D, offer example inputs and outputs in Appendix E, and make the code openly available at https://github.com/<redacted>/<redacted> to enable reproducibility of all experiments."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the utility of exclusive multiset-equivariance (Subsection 4.1), the disparities between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). Additionally, we provide a detailed overview of the experimental procedure in Appendix D, illustrate example inputs and outputs in Appendix E, and make our code openly available to reproduce all experiments at https://github.com/<redacted>/<redacted>."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the utility of exclusive multiset-equivariance (Subsection 4.1), the disparities between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). Additionally, we provide a detailed overview of the experimental procedure in Appendix D, illustrate example inputs and outputs in Appendix E, and make our code openly available to reproduce all experiments at https://github.com/<redacted>/<redacted>."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the utility of exclusive multiset-equivariance (Subsection 4.1), the disparities between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). Additionally, we provide a detailed overview of the experimental procedure in Appendix D, illustrate example inputs and outputs in Appendix E, and make our code openly available to reproduce all experiments at https://github.com/<redacted>/<redacted>."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the practical utility of exclusive multiset-equivariance (Subsection 4.1), the contrast between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). For further clarity, we provide a detailed description of the experimental procedure in Appendix D, offer example inputs and outputs in Appendix E, and make the code openly available at https://github.com/<redacted>/<redacted> to enable reproducibility of all experiments."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the utility of exclusive multiset-equivariance (Subsection 4.1), the disparities between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). Additionally, we provide a detailed overview of the experimental procedure in Appendix D, illustrate example inputs and outputs in Appendix E, and make our code openly available to reproduce all experiments at https://github.com/<redacted>/<redacted>."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the practical utility of exclusive multiset-equivariance (Subsection 4.1), the contrast between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). For further clarity, we provide a detailed description of the experimental procedure in Appendix D, offer example inputs and outputs in Appendix E, and make the code openly available at https://github.com/<redacted>/<redacted> to enable reproducibility of all experiments."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we evaluate the significance of our contributions by highlighting three key aspects: the practical applicability of exclusive multiset-equivariance (Subsection 4.1), the distinction between our implicit and automatic differentiation methods (Subsection 4.2), and the scalability of iDSPN to larger-scale datasets (Subsection 4.3). To facilitate understanding, we provide a comprehensive description of the experimental procedure in Appendix D, offer example inputs and outputs in Appendix E, and make the code openly available at https://github.com/<redacted>/<redacted> to enable reproducibility of all experiments."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the utility of exclusive multiset-equivariance (Subsection 4.1), the disparities between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). Additionally, we provide a detailed overview of the experimental procedure in Appendix D, illustrate example inputs and outputs in Appendix E, and make our code openly available to reproduce all experiments at https://github.com/<redacted>/<redacted>."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the utility of exclusive multiset-equivariance (Subsection 4.1), the disparities between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). Additionally, we provide a detailed overview of the experimental procedure in Appendix D, illustrate example inputs and outputs in Appendix E, and make our code openly available to reproduce all experiments at https://github.com/<redacted>/<redacted>."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three distinct aspects: the practical utility of exclusive multiset-equivariance (Subsection 4.1), the contrast between our implicit and automatic differentiation approaches (Subsection 4.2), and the scalability of iDSPN to a larger-scale dataset (Subsection 4.3). For further clarity, we provide a detailed description of the experimental procedure in Appendix D, offer example inputs and outputs in Appendix E, and make the code openly available at https://github.com/<redacted>/<redacted> to enable reproducibility of all experiments."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we evaluate the significance of our contributions by highlighting three key aspects: the practical applicability of exclusive multiset-equivariance (Subsection 4.1), the distinction between our implicit and automatic differentiation methods (Subsection 4.2), and the scalability of iDSPN to larger-scale datasets (Subsection 4.3). To facilitate understanding, we provide a comprehensive description of the experimental procedure in Appendix D, offer example inputs and outputs in Appendix E, and make the code openly available at https://github.com/<redacted>/<redacted> to enable reproducibility of all experiments."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "instruction": "Be clear about references.", "revised_paragraph": "Revised paragraph: \"In this section, we assess the significance of our contributions by examining three distinct aspects: the utility of exclusive multiset-equivariance (Subsection 4.1), the disparities between our implicit and automatic differentiation methods (Subsection 4.2), and the scalability of iDSPN to a larger dataset (Subsection 4.3). Detailed information on the experimental procedure can be found in Appendix D, while example inputs and outputs are presented in Appendix E. Additionally, the open-source code used to reproduce all experiments is available at https://github.com/<redacted>/<redacted> [1].\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.13", "instruction": "Lightly clarify the text. Add a reference to appendix at the end.", "revised_paragraph": "Revised paragraph: In this section, we assess the significance of our contributions by examining three key aspects: the utility of exclusive multiset-equivariance (Subsection 4.1), the distinction between our implicit and automatic differentiation methods (Subsection 4.2), and the scalability of iDSPN to larger datasets (Subsection 4.3). For further details on the experimental procedure, please refer to Appendix D, which provides a comprehensive overview. Additionally, example inputs and outputs can be found in Appendix E, and the open-source code used to reproduce all experiments is available at https://github.com/<redacted>/<redacted> (Khan et al., 2022, Appendix D-E).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The experimental system utilized a 23.8-inch display with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. A Logitech gaming mouse (G-PPD-002WLr) with a 1600 DPI optical sensor was used, and the mouse-cursor speed was set to the middle of the slider in the control display, with the \"Enhance pointer precision\" setting enabled to match the participants' usual settings. The system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The experimental setup consisted of a 23.8-inch monitor with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. For input devices, we employed an optical mouse (Logitech G-PPD-002WLr) with a 1600 DPI sensor. The mouse cursor speed was set to the default middle position in the operating system's control panel, with the \"Enhance pointer precision\" feature enabled to match the participants' typical settings. The experimental system was implemented using a Hot Soup processor 3.6 and operated in full-screen mode."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The experimental setup consisted of a 23.8-inch monitor with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. For input devices, we employed an optical mouse (Logitech G-PPD-002WLr) with a 1600 DPI sensor. The mouse cursor speed was set to the default middle position in the operating system's control panel, with the \"Enhance pointer precision\" feature enabled to match the participants' typical settings. The experimental system was implemented using a Hot Soup processor 3.6 and operated in full-screen mode."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The experimental setup consisted of a 23.8-inch monitor with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. For input devices, we employed an optical mouse (Logitech G-PPD-002WLr) with a 1600 DPI sensor. The mouse cursor speed was set to the default middle position in the operating system's control panel, with the \"Enhance pointer precision\" feature enabled to match the participants' typical settings. The experimental system was implemented using a Hot Soup processor 3.6 and operated in full-screen mode."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The experimental system utilized a 23.8-inch display with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. A Logitech gaming mouse (G-PPD-002WLr) with a 1600 DPI optical sensor was used, and the mouse-cursor speed was set to the middle of the slider in the control display, with the \"Enhance pointer precision\" setting enabled to match the participants' usual settings. The system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The experimental setup consisted of a 23.8-inch monitor with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. For input devices, we employed an optical mouse (Logitech G-PPD-002WLr) with a 1600 DPI sensor. The mouse cursor speed was set to the default middle position in the operating system's control panel, with the \"Enhance pointer precision\" feature enabled to match the participants' typical settings. The experimental system was implemented using a Hot Soup processor 3.6 and operated in full-screen mode."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The experimental system utilized a 23.8-inch display with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. A Logitech gaming mouse (G-PPD-002WLr) with a 1600 DPI optical sensor was used, and the mouse-cursor speed was set to the middle of the slider in the control display, with the \"Enhance pointer precision\" setting enabled to match the participants' usual settings. The system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The experimental setup employed a 23.8-inch display with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. A Logitech gaming mouse (G-PPD-002WLr) with a 1600 DPI optical sensor was utilized, and the mouse-cursor speed was set to the middle of the slider in the control display, with the \"Enhance pointer precision\" setting enabled to match the participants' typical settings. The system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The experimental setup consisted of a 23.8-inch monitor with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. For input devices, we employed an optical mouse (Logitech G-PPD-002WLr) with a 1600 DPI sensor. The mouse cursor speed was set to the default middle position in the operating system's control panel, with the \"Enhance pointer precision\" feature enabled to match the participants' typical settings. The experimental system was implemented using a Hot Soup processor 3.6 and operated in full-screen mode."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The experimental setup consisted of a 23.8-inch monitor with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. For input devices, we employed an optical mouse (Logitech G-PPD-002WLr) with a 1600 DPI sensor. The mouse cursor speed was set to the default middle position in the operating system's control panel, with the \"Enhance pointer precision\" feature enabled to match the participants' typical settings. The experimental system was implemented using a Hot Soup processor 3.6 and operated in full-screen mode."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The experimental system utilized a 23.8-inch display with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. A Logitech gaming mouse (G-PPD-002WLr) with a 1600 DPI optical sensor was used, and the mouse-cursor speed was set to the middle of the slider in the control display, with the \"Enhance pointer precision\" setting enabled to match the participants' usual settings. The system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The experimental setup employed a 23.8-inch display with a resolution of 1920 \u00d7 1080 pixels and a 75 Hz refresh rate. A Logitech gaming mouse (G-PPD-002WLr) with a 1600 DPI optical sensor was utilized, and the mouse-cursor speed was set to the middle of the slider in the control display, with the \"Enhance pointer precision\" setting enabled to match the participants' typical settings. The system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "instruction": "Improve the English of this paragraph", "revised_paragraph": "Revised paragraph: \"The experimental setup consisted of a 23.8-inch monitor with a resolution of 1920 \u00d7 1080 pixels and a refresh rate of 75 Hz. A Logitech gaming mouse (G-PPD-002WLr) with a resolution of 1600 DPI was used, and the mouse-cursor speed was set to the middle of the slider in the control display, with the \"Enhance pointer precision\" setting enabled to match the participants' usual settings. The experimental system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "instruction": "Slightly revise the liking between phrases.", "revised_paragraph": "Revised paragraph: The experimental setup consisted of a 23.8\u201d diagonal display (VZ249HR; 1920 \u00d7 1080 pixels) with a 75 Hz refresh rate. For input devices, we employed an optical mouse (Logitech gaming mouse, G-PPD-002WLr; 1600 DPI) and adjusted the mouse-cursor speed via the OS setting to the middle of the slider in the control display, with the \"Enhance pointer precision\" feature enabled to match the participants' usual settings. The experimental system was implemented using Hot soup processor 3.6 and operated in full-screen mode.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, respectively, are denoted by P_T and \u03c8(r). These distributions are induced by the map r = \u03c8(x), which represents the relationship between the input x and the output r. The discrepancy between these distributions can be minimized by updating the representation map \u03c8 using gradient-based optimizers, as it is differentiable with respect to \u03c8 (Flamary et al., 2021)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, respectively, are denoted by P_T and \u03c8(r). These distributions are induced by the map r = \u03c8(x), which represents the relationship between the input x and the output r. The discrepancy between these distributions can be minimized by updating the representation map \u03c8 using gradient-based optimizers, as it is differentiable with respect to \u03c8 (Flamary et al., 2021)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, respectively, are denoted by P_T and \u03c8(r). These distributions are induced by the map r = \u03c8(x), which represents the relationship between the input x and the output r. The discrepancy between these distributions can be minimized by updating the representation map \u03c8 using gradient-based optimizers, as it is differentiable with respect to \u03c8 (Flamary et al., 2021)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, respectively, are denoted by P_T and \u03c8(r). These distributions are induced by the map r = \u03c8(x), which represents the relationship between the input x and the output r. The discrepancy between these distributions can be minimized by updating the representation map \u03c8 using gradient-based optimizers, as it is differentiable with respect to \u03c8 (Flamary et al., 2021)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, respectively, are denoted by P_T and \u03c8(r). These distributions are induced by the map r = \u03c8(x), which represents the relationship between the input x and the output r. The discrepancy between these distributions can be minimized by updating the representation map \u03c8 using gradient-based optimizers, as it is differentiable with respect to \u03c8 (Flamary et al., 2021)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, respectively, are denoted by P_T and \u03c8(r). These distributions are induced by the map r = \u03c8(x), which represents the relationship between the input x and the output r. The discrepancy between these distributions can be minimized by updating the representation map \u03c8 using gradient-based optimizers, as it is differentiable with respect to \u03c8 (Flamary et al., 2021)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, respectively, are denoted by P_T and \u03c8(r). These distributions are induced by the map r = \u03c8(x), which represents the relationship between the input x and the output r. The discrepancy between these distributions can be minimized by updating the representation map \u03c8 using gradient-based optimizers, as it is differentiable with respect to \u03c8 (Flamary et al., 2021)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, respectively, are denoted by P_T and \u03c8(r). These distributions are induced by the map r = \u03c8(x), which represents the relationship between the input x and the output r. The discrepancy between these distributions can be minimized by updating the representation map \u03c8 using gradient-based optimizers, as it is differentiable with respect to \u03c8 (Flamary et al., 2021)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "instruction": "Brush up the sentence for readability", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, P_T and P_UT, are induced by the map r = \u03c8(x), where \u03c8(x) is the representation function. The discrepancy between these distributions can be minimized by updating the representation map \u03c8 using gradient-based optimizers, as \u03c8 is differentiable with respect to \u03c8 (Flamary et al., 2021).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.07", "instruction": "Reorganize the paragraph to make it more logical. Improve the language.", "revised_paragraph": "Revised paragraph: The representation distributions under treated and untreated groups, P_T and P_U, respectively, are induced by the map r = \u03c8 (x), where \u03c8 (r) represents the representation distribution. The discrepancy between P_T and P_U can be minimized by updating the representation map \u03c8 using gradient-based optimizers, which are applicable since \u03c8 is differentiable with respect to \u03c8, as shown in Flamary et al. (2021).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The d-dimensional torus can be viewed as points with d torsional angles. We model the distribution on this torus by modeling the joint distribution of d variables on the unit circle S1. Specifically, we adopt the coupling layer technique, updating one dimension at a time using a bijective function for S1, conditioned on the other dimensions and the hidden representation of the amino acid (Figure 2B).\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Rotamers with d torsional angles can be viewed as points on the d-dimensional torus, which is the product of d circles. We model the distribution on this torus by modeling the joint distribution of d variables on each circle. Specifically, we use the coupling layer technique (Dinh et al., 2016), where each layer updates one dimension using a bijective function for the circle, while keeping the other dimensions fixed and using them along with the amino acid's hidden representation as conditioning.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The d-dimensional torus can be viewed as points with d torsional angles. We model the distribution on this torus by modeling the joint distribution of d variables on the unit circle S1. Specifically, we adopt the coupling layer technique, updating one dimension at a time using a bijective function for S1, conditioned on the other dimensions and the hidden representation of the amino acid (Figure 2B).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Rotamers with d torsional angles can be viewed as points on the d-dimensional torus, which is the product of d circles. We model the distribution on this torus by modeling the joint distribution of d variables on each circle. Specifically, we use the coupling layer technique (Dinh et al., 2016), where each layer updates one dimension using a bijective function for the circle, while keeping the other dimensions fixed and using them along with the amino acid's hidden representation as conditioning.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The d-dimensional torus can be viewed as points with d torsional angles. We model the distribution on this torus by modeling the joint distribution of d variables on the unit circle S1. Specifically, we adopt the coupling layer technique, updating one dimension at a time using a bijective function for S1, conditioned on the other dimensions and the hidden representation of the amino acid (Figure 2B).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We model the distribution on the d-dimensional torus by jointly modeling d variables on the unit circle S1. We employ the coupling layer technique, updating each dimension sequentially using a bijective function for S1, conditioned on other dimensions and the hidden representation of the amino acid (Figure 2B).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The d-dimensional torus can be viewed as points with d torsional angles. We model the distribution on this torus by modeling the joint distribution of d variables on the unit circle S1. Specifically, we adopt the coupling layer technique, updating one dimension at a time using a bijective function for S1, conditioned on the other dimensions and the hidden representation of the amino acid (Figure 2B).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Rotamers with d torsional angles can be viewed as points on the d-dimensional torus, which is the product of d circles. We model the distribution on this torus by modeling the joint distribution of d variables on each circle. Specifically, we use the coupling layer technique (Dinh et al., 2016), where each layer updates one dimension using a bijective function for the circle, while keeping the other dimensions fixed and using them along with the amino acid's hidden representation as conditioning.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "instruction": "Please, remove unnecessary details of this paragraph", "revised_paragraph": "Revised paragraph: \"The distribution on the d-dimensional torus can be modelled by jointly modelling D variables on S1. We adopt the coupling layer technique to model the joint distribution, as proposed by Dinh et al. (2016). Each coupling layer updates one dimension while keeping the others fixed, using the hidden representation of the amino acid as a condition to parameterize the bijective mapping.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.15", "instruction": "Make this paragraph shorter.", "revised_paragraph": "Revised paragraph: Rotamers with d torsional angles can be viewed as points on the d-dimensional torus, which is the product of d circles. We model the distribution on this torus by modeling the joint distribution of d variables on each circle. Specifically, we adopt the coupling layer technique (Dinh et al., 2016), where each layer updates one dimension while keeping the others fixed, using the hidden representation of the amino acid as a condition.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Sequence-based methods for single proteins are insufficient for protein-protein interactions, as they lack evolutionary information. Protein-protein interactions involve multiple chains, which may belong to different species and lack co-evolution. This renders sequence databases, including powerful tools like multiple sequence alignments and protein language models, ineffective for predicting mutational effects. As a result, current approaches rely on structural information rather than sequences alone to predict mutational effects on binding.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Sequence-based methods for single proteins are insufficient for protein-protein interactions, as they lack evolutionary information. Protein-protein interactions involve multiple chains, which may belong to different species and lack co-evolution. This renders sequence databases, including powerful tools like multiple sequence alignments and protein language models, ineffective for predicting mutational effects. As a result, current approaches rely on structural information rather than sequences alone to predict mutational effects on binding.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Sequence-based methods for single proteins are insufficient for protein-protein interactions, as they lack evolutionary information. Protein-protein interactions involve multiple chains, which may belong to different species and lack co-evolution. This renders sequence databases, including powerful tools like multiple sequence alignments and protein language models, ineffective for predicting mutational effects. As a result, current approaches rely on structural information rather than sequences alone to predict mutational effects on binding.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Sequence-based methods for single proteins are insufficient for protein-protein interactions, as they lack evolutionary information. Protein-protein interactions involve multiple chains, which may belong to different species and lack co-evolution. This renders sequence databases, including powerful tools like multiple sequence alignments and protein language models, ineffective for predicting mutational effects. As a result, current approaches rely on structural information rather than sequences alone to predict mutational effects on binding.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Sequence-based methods for single proteins are insufficient for protein-protein interactions, as they lack evolutionary information. Protein-protein interactions involve multiple chains, which may belong to different species and lack co-evolution. This renders sequence databases, including powerful tools like multiple sequence alignments and protein language models, ineffective for predicting mutational effects. As a result, current approaches rely on structural information rather than sequences alone to predict mutational effects on binding.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Sequence-based methods for single proteins are insufficient for protein-protein interactions, as they lack evolutionary information. Protein-protein interactions involve multiple chains, which may belong to different species and lack co-evolution. This renders sequence databases, including powerful tools like multiple sequence alignments and protein language models, ineffective for predicting mutational effects. As a result, current approaches rely on structural information rather than sequences alone to predict mutational effects on binding.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Sequence-based methods for single proteins are insufficient for protein-protein interactions, as they lack evolutionary information. Protein-protein interactions involve multiple chains, which may belong to different species and lack co-evolution. This renders sequence databases, including powerful tools like multiple sequence alignments and protein language models, ineffective for predicting mutational effects. As a result, current approaches rely on structural information rather than sequences alone to predict mutational effects on binding.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Sequence-based methods for single proteins are insufficient for protein-protein interactions, as they lack evolutionary information. Protein-protein interactions involve multiple chains, which may belong to different species and lack co-evolution. This renders sequence databases, including powerful tools like multiple sequence alignments and protein language models, ineffective for predicting mutational effects. As a result, current approaches rely on structural information rather than sequences alone to predict mutational effects on binding.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "instruction": "Remove unnnecesary examples.", "revised_paragraph": "Revised paragraph: We argue that sequence-based methods for single proteins are inadequate for protein-protein interactions due to the limited availability of evolutionary information. Protein-protein interactions involve multiple chains that may belong to different species, making inter-chain co-evolution unlikely in many cases. This limitation renders sequence-based approaches, such as multiple sequence alignments and protein language models, ineffective for predicting mutational effects. Consequently, predicting mutational effects on binding is currently more feasible using structural information rather than sequence data alone.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.10", "instruction": "Rewrite this paragraph to make it shorter while keeping all the informations.", "revised_paragraph": "Revised paragraph: \"Sequence-based methods for single proteins are not applicable to protein-protein interactions due to the lack of evolutionary information. This is because protein-protein interactions involve multiple chains, which may belong to different species and may not exhibit co-evolution. As a result, predicting mutational effects via sequence analysis is infeasible. Instead, effective methods rely on structural information.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nOur method comprises three primary components. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environmental context (Section 3.2). The second component is an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). The final component demonstrates how to utilize the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u2206\u2206G) upon mutation, as well as how to leverage neural networks to predict \u2206\u2206G more accurately using the unsupervised representations from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be divided into two distinct groups. Each group contains at least one protein chain, and each chain is composed of multiple amino acids. For a protein complex containing n amino acids, we number them from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2286 {1,..., n}. An amino acid is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th (i \u2208 {1,..., n}) amino acid as a_i \u2208 {1,..., 20}, p_i \u2208 R^3, and O_i \u2208 SO(3), respectively. The sidechain conformation of an amino acid is referred to as a rotamer. As the conformational degree of freedom of the sidechain is defined by rotatable bonds, a rotamer can be sufficiently parameterized by torsional angles with respect to the rotatable bonds. The number of torsional angles varies between 0 and 4, depending on the amino acid type. For an amino acid with d torsional angles, we denote the k-th (k \u2208 {1,..., 4}) torsional angle by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all the torsional angles are denoted by a vector \u03c7_i = (\u220f(k)_i)dk=1. Geometrically, an angle can be represented by a point on the unit circle S^1. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus T_d = (S^1)^d."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nOur method comprises three primary components. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environmental context (Section 3.2). The second component is an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). The final component demonstrates how to utilize the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u2206\u2206G) upon mutation, as well as how to leverage neural networks to predict \u2206\u2206G more accurately using the unsupervised representations from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be divided into two distinct groups. Each group contains at least one protein chain, and each chain is composed of multiple amino acids. For a protein complex containing n amino acids, we number them from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2286 {1,..., n}. An amino acid is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th (i \u2208 {1,..., n}) amino acid as a_i \u2208 {1,..., 20}, p_i \u2208 R^3, and O_i \u2208 SO(3), respectively. The sidechain conformation of an amino acid is referred to as a rotamer. As the conformational degree of freedom of the sidechain is defined by rotatable bonds, a rotamer can be sufficiently parameterized by torsional angles with respect to the rotatable bonds. The number of torsional angles varies between 0 and 4, depending on the amino acid type. For an amino acid with d torsional angles, we denote the k-th (k \u2208 {1,..., 4}) torsional angle by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all the torsional angles are denoted by a vector \u03c7_i = (\u220f(k)_i)dk=1. Geometrically, an angle can be represented by a point on the unit circle S^1. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus T_d = (S^1)^d."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nOur method comprises three primary components. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environmental context (Section 3.2). The second component is an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). The final component demonstrates how to utilize the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u2206\u2206G) upon mutation, as well as how to leverage neural networks to predict \u2206\u2206G more accurately using the unsupervised representations from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be divided into two distinct groups. Each group contains at least one protein chain, and each chain is composed of multiple amino acids. For a protein complex containing n amino acids, we number them from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2286 {1,..., n}. An amino acid is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th (i \u2208 {1,..., n}) amino acid as a_i \u2208 {1,..., 20}, p_i \u2208 R^3, and O_i \u2208 SO(3), respectively. The sidechain conformation of an amino acid is referred to as a rotamer. As the conformational degree of freedom of the sidechain is defined by rotatable bonds, a rotamer can be sufficiently parameterized by torsional angles with respect to the rotatable bonds. The number of torsional angles varies between 0 and 4, depending on the amino acid type. For an amino acid with d torsional angles, we denote the k-th (k \u2208 {1,..., 4}) torsional angle by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all the torsional angles are denoted by a vector \u03c7_i = (\u220f(k)_i)dk=1. Geometrically, an angle can be represented by a point on the unit circle S^1. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus T_d = (S^1)^d."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nOur method comprises three primary components. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environmental context (Section 3.2). The second component is an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). The final component demonstrates how to utilize the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u2206\u2206G) upon mutation, as well as how to leverage neural networks to predict \u2206\u2206G more accurately using the unsupervised representations from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be divided into two distinct groups. Each group contains at least one protein chain, and each chain is composed of multiple amino acids. For a protein complex containing n amino acids, we number them from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2286 {1,..., n}. An amino acid is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th (i \u2208 {1,..., n}) amino acid as a_i \u2208 {1,..., 20}, p_i \u2208 R^3, and O_i \u2208 SO(3), respectively. The sidechain conformation of an amino acid is referred to as a rotamer. As the conformational degree of freedom of the sidechain is defined by rotatable bonds, a rotamer can be sufficiently parameterized by torsional angles with respect to the rotatable bonds. The number of torsional angles varies between 0 and 4, depending on the amino acid type. For an amino acid with d torsional angles, we denote the k-th (k \u2208 {1,..., 4}) torsional angle by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all the torsional angles are denoted by a vector \u03c7_i = (\u220f(k)_i)dk=1. Geometrically, an angle can be represented by a point on the unit circle S^1. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus T_d = (S^1)^d."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nOur method comprises three primary components. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environmental context (Section 3.2). The second component is an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). The final component demonstrates how to utilize the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u2206\u2206G) upon mutation, as well as how to leverage neural networks to predict \u2206\u2206G more accurately using the unsupervised representations from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be divided into two distinct groups. Each group contains at least one protein chain, and each chain is composed of multiple amino acids. For a protein complex containing n amino acids, we number them from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2286 {1,..., n}. An amino acid is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th (i \u2208 {1,..., n}) amino acid as a_i \u2208 {1,..., 20}, p_i \u2208 R^3, and O_i \u2208 SO(3), respectively. The sidechain conformation of an amino acid is referred to as a rotamer. As the conformational degree of freedom of the sidechain is defined by rotatable bonds, a rotamer can be sufficiently parameterized by torsional angles with respect to the rotatable bonds. The number of torsional angles varies between 0 and 4, depending on the amino acid type. For an amino acid with d torsional angles, we denote the k-th (k \u2208 {1,..., 4}) torsional angle by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all the torsional angles are denoted by a vector \u03c7_i = (\u220f(k)_i)dk=1. Geometrically, an angle can be represented by a point on the unit circle S^1. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus T_d = (S^1)^d."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nOur method comprises three primary components. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environmental context (Section 3.2). The second component is an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). The final component demonstrates how to utilize the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u2206\u2206G) upon mutation, as well as how to leverage neural networks to predict \u2206\u2206G more accurately using the unsupervised representations from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be divided into two distinct groups. Each group contains at least one protein chain, and each chain is composed of multiple amino acids. For a protein complex containing n amino acids, we number them from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2286 {1,..., n}. An amino acid is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th (i \u2208 {1,..., n}) amino acid as a_i \u2208 {1,..., 20}, p_i \u2208 R^3, and O_i \u2208 SO(3), respectively. The sidechain conformation of an amino acid is referred to as a rotamer. As the conformational degree of freedom of the sidechain is defined by rotatable bonds, a rotamer can be sufficiently parameterized by torsional angles with respect to the rotatable bonds. The number of torsional angles varies between 0 and 4, depending on the amino acid type. For an amino acid with d torsional angles, we denote the k-th (k \u2208 {1,..., 4}) torsional angle by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all the torsional angles are denoted by a vector \u03c7_i = (\u220f(k)_i)dk=1. Geometrically, an angle can be represented by a point on the unit circle S^1. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus T_d = (S^1)^d."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nOur method comprises three primary components. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environmental context (Section 3.2). The second component is an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). The final component demonstrates how to utilize the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u2206\u2206G) upon mutation, as well as how to leverage neural networks to predict \u2206\u2206G more accurately using the unsupervised representations from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be divided into two distinct groups. Each group contains at least one protein chain, and each chain is composed of multiple amino acids. For a protein complex containing n amino acids, we number them from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2286 {1,..., n}. An amino acid is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th (i \u2208 {1,..., n}) amino acid as a_i \u2208 {1,..., 20}, p_i \u2208 R^3, and O_i \u2208 SO(3), respectively. The sidechain conformation of an amino acid is referred to as a rotamer. As the conformational degree of freedom of the sidechain is defined by rotatable bonds, a rotamer can be sufficiently parameterized by torsional angles with respect to the rotatable bonds. The number of torsional angles varies between 0 and 4, depending on the amino acid type. For an amino acid with d torsional angles, we denote the k-th (k \u2208 {1,..., 4}) torsional angle by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all the torsional angles are denoted by a vector \u03c7_i = (\u220f(k)_i)dk=1. Geometrically, an angle can be represented by a point on the unit circle S^1. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus T_d = (S^1)^d."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nOur method comprises three primary components. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the amino acid type and environmental context (Section 3.2). The second component is an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). The final component demonstrates how to utilize the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u2206\u2206G) upon mutation, as well as how to leverage neural networks to predict \u2206\u2206G more accurately using the unsupervised representations from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be divided into two distinct groups. Each group contains at least one protein chain, and each chain is composed of multiple amino acids. For a protein complex containing n amino acids, we number them from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2286 {1,..., n}. An amino acid is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th (i \u2208 {1,..., n}) amino acid as a_i \u2208 {1,..., 20}, p_i \u2208 R^3, and O_i \u2208 SO(3), respectively. The sidechain conformation of an amino acid is referred to as a rotamer. As the conformational degree of freedom of the sidechain is defined by rotatable bonds, a rotamer can be sufficiently parameterized by torsional angles with respect to the rotatable bonds. The number of torsional angles varies between 0 and 4, depending on the amino acid type. For an amino acid with d torsional angles, we denote the k-th (k \u2208 {1,..., 4}) torsional angle by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all the torsional angles are denoted by a vector \u03c7_i = (\u220f(k)_i)dk=1. Geometrically, an angle can be represented by a point on the unit circle S^1. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus T_d = (S^1)^d."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "instruction": "Generate a more formal version of this paragraph", "revised_paragraph": "Revised paragraph: \n\nOur methodology is comprised of three distinct components. The core element is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) conditioned on the amino acid type and environmental factors (Section 3.2). This is followed by an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). Finally, we demonstrate how to utilize the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u0394\u0394G) upon mutation, and how to leverage neural networks to predict \u0394\u0394G more accurately using the unsupervised representations derived from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be partitioned into two distinct groups. Each group comprises at least one protein chain, and each chain is composed of multiple amino acids. For a protein complex containing n amino acids, we assign a unique identifier to each amino acid, ranging from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2286 {1,..., n}. An amino acid is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th amino acid (i \u2208 {1,..., n}) as a_i \u2208 {1,..., 20}, p_i \u2208 \u211d\u00b3, and O_i \u2208 SO(3), respectively. The sidechain conformation of an amino acid is referred to as a rotamer. The conformational degree of freedom of the sidechain is defined by rotatable bonds, and a rotamer can be sufficiently parameterized by torsional angles relative to the rotatable bonds. The number of torsional angles varies between 0 and 4, depending on the amino acid type. For an amino acid with d torsional angles, we denote the k-th torsional angle (k \u2208 {1,..., 4}) by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all torsional angles are denoted by a vector \u03c7_i = (\u220fk=1\u03c7(k)_i). In geometric terms, an angle can be represented by a point on the unit circle S\u00b9. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus TD = (S\u00b9)D.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.11", "instruction": "Replace all mentions of amino acid by 'residue'. Revise this paragraph for clarity.", "revised_paragraph": "Revised paragraph: Our method comprises three components. The core component is the rotamer density estimator (RDE), a conditional normalizing flow that models the probability density of sidechain conformations (rotamers) given the residue type and environments (Section 3.2). The RDE is followed by an algorithm for estimating the entropy of the distribution parameterized by the normalizing flow (Section 3.3). Finally, we demonstrate how to use the entropy of the mutated and wild-type protein-protein interfaces at both bound and unbound states to estimate the change in binding free energy (\u0394\u0394G) upon mutation, and how to leverage neural networks to predict \u0394\u0394G more accurately using the unsupervised representations from the RDE (Section 3.4). A protein-protein complex is a multi-chain protein structure that can be divided into two groups. Each group contains at least one protein chain and each chain consists of multiple residues. For a protein complex containing n residues, we number them from 1 to n. The two groups of the complex can be represented by two disjoint sets of indices A, B \u2282 {1,..., n}. A residue is characterized by its type, position, orientation, and sidechain conformation. We denote the type, position, and orientation of the i-th (i \u2208 {1,..., n}) residue as a_i \u2208 {1,..., 20}, p_i \u2208 R^3, and O_i \u2208 SO(3) respectively. The sidechain conformation of a residue is called a rotamer. The conformational degree of freedom of the sidechain is defined by rotatable bonds, and a rotamer can be sufficiently parameterized by torsional angles with respect to the rotatable bonds. The number of torsional angles varies between 0 to 4 depending on the residue type. For a residue with d torsional angles, we denote the k-th (k \u2208 {1,..., 4}) torsional angle by \u03c7(k)_i \u2208 [0, 2\u03c0). Collectively, all the torsional angles are denoted by a vector \u03c7_i = (\u03c7(k)_i)_{k=1}^d. Using the language of geometry, an angle can be represented by a point on the unit circle S^1. A vector consisting of d angular values resides on the product of d unit circles, known as the d-dimensional torus T^d = (S^1)^d.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The NVIDIA Dynamic Hand Gesture Dataset, also known as NVGesture (Molchanov et al., 2015), comprises 1,532 video clips, consisting of 1,050 training samples and 482 test samples, across 25 distinct hand gesture classes. We randomly select 20% of the training samples as a validation set and utilize both depth and RGB modalities. For data preparation, we adopt the configuration proposed by Joze et al. (2020) and employ the I3D architecture (Carreira & Zisserman, 2017) as uni-modal branches, along with MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The NVIDIA Dynamic Hand Gesture Dataset, also known as NVGesture (Molchanov et al., 2015), comprises 1,532 video clips, consisting of 1,050 training samples and 482 test samples, across 25 distinct hand gesture classes. We randomly select 20% of the training samples as a validation set and utilize both depth and RGB modalities. For data preparation, we adopt the configuration proposed by Joze et al. (2020) and employ the I3D architecture (Carreira & Zisserman, 2017) as uni-modal branches, along with MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The NVIDIA Dynamic Hand Gesture Dataset, also known as NVGesture (Molchanov et al., 2015), comprises 1,532 video clips, consisting of 1,050 training samples and 482 test samples, across 25 distinct hand gesture classes. We randomly select 20% of the training samples as a validation set and utilize both depth and RGB modalities. For data preparation, we adopt the configuration proposed by Joze et al. (2020) and employ the I3D architecture (Carreira & Zisserman, 2017) as uni-modal branches, along with MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The NVIDIA Dynamic Hand Gesture Dataset, also known as NVGesture (Molchanov et al., 2015), comprises 1,532 video clips, consisting of 1,050 training samples and 482 test samples, across 25 distinct hand gesture classes. We randomly select 20% of the training samples as a validation set and utilize both depth and RGB modalities. For data preparation, we adopt the configuration proposed by Joze et al. (2020) and employ the I3D architecture (Carreira & Zisserman, 2017) as uni-modal branches, along with MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The NVIDIA Dynamic Hand Gesture Dataset, also known as NVGesture (Molchanov et al., 2015), comprises 1,532 video clips, consisting of 1,050 training samples and 482 test samples, across 25 distinct hand gesture classes. We randomly select 20% of the training samples as a validation set and utilize both depth and RGB modalities. For data preparation, we adopt the configuration proposed by Joze et al. (2020) and employ the I3D architecture (Carreira & Zisserman, 2017) as uni-modal branches, along with MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The NVIDIA Dynamic Hand Gesture Dataset, also known as NVGesture (Molchanov et al., 2015), comprises 1,532 video clips, consisting of 1,050 training samples and 482 test samples, across 25 distinct hand gesture classes. We randomly select 20% of the training samples as a validation set and utilize both depth and RGB modalities. For data preparation, we adopt the configuration proposed by Joze et al. (2020) and employ the I3D architecture (Carreira & Zisserman, 2017) as uni-modal branches, along with MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The NVIDIA Dynamic Hand Gesture Dataset, also known as NVGesture (Molchanov et al., 2015), comprises 1,532 video clips, consisting of 1,050 training samples and 482 test samples, across 25 distinct hand gesture classes. We randomly select 20% of the training samples as a validation set and utilize both depth and RGB modalities. For data preparation, we adopt the configuration proposed by Joze et al. (2020) and employ the I3D architecture (Carreira & Zisserman, 2017) as uni-modal branches, along with MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The NVIDIA Dynamic Hand Gesture Dataset, also known as NVGesture (Molchanov et al., 2015), comprises 1,532 video clips, consisting of 1,050 training samples and 482 test samples, across 25 distinct hand gesture classes. We randomly select 20% of the training samples as a validation set and utilize both depth and RGB modalities. For data preparation, we adopt the configuration proposed by Joze et al. (2020) and employ the I3D architecture (Carreira & Zisserman, 2017) as uni-modal branches, along with MMTMs as fusion modules in the six final inception modules.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "instruction": "Check the citation mark format and rewrite", "revised_paragraph": "Revised paragraph: The NVIDIA Dynamic Hand Gesture Dataset, also referred to as NVGesture (Molchanov et al., 2015), comprises 1,532 video clips, comprising 1,050 training and 482 test samples, categorized into 25 classes. We randomly select 20% of the training samples as the validation set and utilize both depth and RGB modalities. Following the data preparation configuration outlined by Joze et al. (2020), we employ the I3D architecture (Carreira & Zisserman, 2017) as the uni-modal branches and MMTMs as fusion modules in the six final inception modules.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.13", "instruction": "Make the paragraph slightly more precise.", "revised_paragraph": "Revised paragraph: The NVIDIA Dynamic Hand Gesture Dataset, or NVGesture in short (Molchanov et al., 2015), comprises 1,532 video clips, divided into 1,050 training samples and 482 test samples, spanning 25 distinct hand gesture classes. To facilitate model evaluation, we allocate 20% of the training set as a validation set. The dataset is presented in two modalities: depth and RGB. Following the data preparation configuration proposed by Joze et al. (2020), we employ the I3D architecture (Carreira & Zisserman, 2017) as the uni-modal branches and MMTMs as fusion modules in the six final inception modules.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) shows the occupancy grids as heightmaps, obtained by multiplying each voxel's occupancy value by its height coordinate and taking the maximum along the height axis. The visualizations demonstrate the occupancy module's ability to fill partial views and effectively imagine the complete 3D scene.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) presents a visualization of the occupancy grids, which we generate by converting them into heightmaps. This process involves multiplying each voxel's occupancy value by its corresponding height coordinate in the grid, followed by a max operation along the grid's height axis. The resulting visualizations demonstrate that the occupancy module is capable of filling in the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) shows the occupancy grids as heightmaps, obtained by multiplying each voxel's occupancy value by its height coordinate and taking the maximum along the height axis. The visualizations demonstrate the occupancy module's ability to fill partial views and effectively imagine the complete 3D scene.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) presents a visualization of the occupancy grids, which we generate by converting them into heightmaps. This process involves multiplying each voxel's occupancy value by its corresponding height coordinate in the grid, followed by a max operation along the grid's height axis. The resulting visualizations demonstrate that the occupancy module is capable of filling in the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) shows the occupancy grids as heightmaps, obtained by multiplying each voxel's occupancy value by its height coordinate and taking the maximum along the height axis. The visualizations demonstrate the occupancy module's ability to fill partial views and effectively imagine the complete 3D scene.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) presents a visualization of the occupancy grids, which we generate by converting them into heightmaps. This process involves multiplying each voxel's occupancy value by its corresponding height coordinate in the grid, followed by a max operation along the grid's height axis. The resulting visualizations demonstrate that the occupancy module is capable of filling in the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) shows the occupancy grids as heightmaps, obtained by multiplying each voxel's occupancy value by its height coordinate and taking the maximum along the height axis. The visualizations demonstrate the occupancy module's ability to fill partial views and effectively imagine the complete 3D scene.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) presents a visualization of the occupancy grids, which we generate by converting them into heightmaps. This process involves multiplying each voxel's occupancy value by its corresponding height coordinate in the grid, followed by a max operation along the grid's height axis. The resulting visualizations demonstrate that the occupancy module is capable of filling in the \"holes\" of the partial view, effectively imagining the complete 3D scene.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) shows the occupancy grids as heightmaps, obtained by multiplying each voxel's occupancy value by its height coordinate and taking the maximum along the height axis. The visualizations demonstrate the occupancy module's ability to fill partial views and effectively imagine the complete 3D scene.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) presents the occupancy grids as heightmaps, which are generated by multiplying each voxel's occupancy value by its height coordinate and then taking the maximum along the height axis. This visualization effectively illustrates the occupancy module's capability to fill partial views and accurately reconstruct the complete 3D scene.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) shows the occupancy grids as heightmaps, obtained by multiplying each voxel's occupancy value by its height coordinate and taking the maximum along the height axis. The visualizations demonstrate the occupancy module's ability to fill partial views and effectively imagine the complete 3D scene.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) presents the occupancy grids as heightmaps, which are generated by multiplying each voxel's occupancy value by its height coordinate and then taking the maximum along the height axis. This visualization effectively illustrates the occupancy module's capability to fill partial views and accurately reconstruct the complete 3D scene.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) shows the occupancy grids as heightmaps, obtained by multiplying each voxel's occupancy value by its height coordinate and taking the maximum along the height axis. The visualizations demonstrate the occupancy module's ability to fill partial views and effectively imagine the complete 3D scene.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) presents the occupancy grids as heightmaps, which are generated by multiplying each voxel's occupancy value by its height coordinate and then taking the maximum along the height axis. This visualization effectively illustrates the occupancy module's capability to fill partial views and accurately reconstruct the complete 3D scene.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) shows the occupancy grids as heightmaps, obtained by multiplying each voxel's occupancy value by its height coordinate and taking the maximum along the height axis. The visualizations demonstrate the occupancy module's ability to fill partial views and effectively imagine the complete 3D scene.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 9 (right) presents the occupancy grids as heightmaps, which are generated by multiplying each voxel's occupancy value by its height coordinate and then taking the maximum along the height axis. This visualization effectively illustrates the occupancy module's capability to fill partial views and accurately reconstruct the complete 3D scene.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "instruction": "Remove second part of last sentence and Replace \"grids\" by \"volumes\" ", "revised_paragraph": "Revised paragraph: \"We show a visualization of the occupancy volumes in Figure 9 (right). We visualize the occupancy volumes by converting them to heightmaps. This is achieved by multiplying each voxel\u2019s occupancy value by its height coordinate in the volume, and then taking a max along the volume\u2019s height axis. The visualizations show that the occupancy module learns to fill the \u201choles\u201d of the partial view.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.03", "instruction": "Delete unnecessary details. Make the text more formal.", "revised_paragraph": "Revised paragraph: The occupancy grids are visualized in Figure 9 (right) as heightmaps. This is achieved by multiplying each voxel's occupancy value by its height coordinate and taking the maximum along the grid's height axis. The resulting visualizations demonstrate the occupancy module's ability to fill in gaps in the partial view, effectively reconstructing the complete 3D scene.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our method is the first to train sparse models directly without increasing the parameter footprint, achieving performance comparable to post-training compression of dense models. We introduced a dynamic reparameterization method for training convolutional networks, outperforming static ones and existing dynamic techniques while incurring lower computational costs."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our approach is the first systematic method to train sparse models directly without increasing the parameter footprint throughout the training process, while achieving performance comparable to post-training compression of dense models, which is the best result at a given sparsity level. We introduced the first dynamic reparameterization method for training convolutional networks, which outperformed static reparameterization methods significantly. Moreover, our method not only outperformed existing dynamic sparse reparameterization techniques but also incurred much lower computational costs."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our method is the first to train sparse models directly without increasing the parameter footprint, achieving performance comparable to post-training compression of dense models. We introduced a dynamic reparameterization method for training convolutional networks, outperforming static ones and existing dynamic techniques while incurring lower computational costs."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our method is the first to train sparse models directly without increasing the parameter footprint, achieving performance comparable to post-training compression of dense models. We introduced a dynamic reparameterization method for training convolutional networks, outperforming static ones and existing dynamic techniques while incurring lower computational costs."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our approach is the first systematic method to train sparse models directly without increasing the parameter footprint throughout the training process, while achieving performance comparable to post-training compression of dense models, which is the best result at a given sparsity level. We introduced the first dynamic reparameterization method for training convolutional networks, which outperformed static reparameterization methods significantly. Moreover, our method not only outperformed existing dynamic sparse reparameterization techniques but also incurred much lower computational costs."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Our method is the first to train sparse models directly without increasing the parameter footprint, achieving performance comparable to post-training compression of dense models. We introduced a dynamic reparameterization method for training convolutional networks, outperforming static ones and existing dynamic techniques while incurring lower computational costs."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our method is the first to train sparse models directly without increasing the parameter footprint, achieving performance comparable to post-training compression of dense models. We introduced a dynamic reparameterization method for training convolutional networks, outperforming static ones and existing dynamic techniques while incurring lower computational costs."}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our approach is innovative in that it directly trains sparse models without increasing the parameter footprint, thereby achieving performance comparable to post-training compression of dense models. Specifically, we introduced a dynamic reparameterization method for training convolutional networks, which outperformed both static methods and existing dynamic techniques while incurring lower computational costs."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our method is the first to train sparse models directly without increasing the parameter footprint, achieving performance comparable to post-training compression of dense models. We introduced a dynamic reparameterization method for training convolutional networks, outperforming static ones and existing dynamic techniques while incurring lower computational costs."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our method is the first to train sparse models directly without increasing the parameter footprint, achieving performance comparable to post-training compression of dense models. We introduced a dynamic reparameterization method for training convolutional networks, outperforming static ones and existing dynamic techniques while incurring lower computational costs."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our approach is the first systematic method to train sparse models directly without increasing the parameter footprint throughout the training process, while achieving performance comparable to post-training compression of dense models, which is the best result at a given sparsity level. We introduced the first dynamic reparameterization method for training convolutional networks, which outperformed static reparameterization methods significantly. Moreover, our method not only outperformed existing dynamic sparse reparameterization techniques but also incurred much lower computational costs."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our approach is the first systematic method to train sparse models directly without increasing the parameter footprint, achieving performance comparable to post-training compression of dense models. We introduced a dynamic reparameterization method for convolutional networks, outperforming static and existing dynamic sparse reparameterization techniques while incurring lower computational costs."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "instruction": "Rewrite this paragraph, removing any redundant information for a more concise version.", "revised_paragraph": "Revised paragraph: Our method is the first to train sparse models directly without increasing the parameter footprint throughout training, achieving performance comparable to post-training compression of dense models. We introduced the first dynamic reparameterization method for convolutional networks, which outperformed both static and existing dynamic sparse reparameterization techniques while incurring lower computational costs.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.01", "instruction": "Fully rewritte this paragraph in a more concise and direct way fitting the academic style.", "revised_paragraph": "Revised paragraph: Our method is the first to train sparse models directly without increasing the parameter footprint throughout training, matching the performance of post-training compression of dense models. We introduced a dynamic reparameterization technique for convolutional networks, which outperformed static approaches and incurred lower computational costs.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Hyperparameter tuning is a crucial step in our PHN method, where we select the optimal hyperparameters based on the Hyper Volume (HV) computed on a validation set. In contrast, selecting hyperparameters for the baselines is challenging due to the lack of a clear runtime-based criterion. To overcome this issue, we train each approach multiple times on a single ray and then apply the selected hyperparameters to all rays. Our selection criterion involves collecting all models trained with various hyperparameter configurations, filtering out dominated solutions, and ultimately choosing the combination with the highest uniformity."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Hyperparameter tuning is a crucial step in our PHN method, where we select the optimal hyperparameters based on the Hyper Volume (HV) computed on a validation set. In contrast, selecting hyperparameters for the baselines is challenging due to the lack of a clear runtime-based criterion. To overcome this issue, we train each approach multiple times on a single ray and then apply the selected hyperparameters to all rays. Our selection criterion involves collecting all models trained with various hyperparameter configurations, filtering out dominated solutions, and ultimately choosing the combination with the highest uniformity."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Hyperparameter tuning is a crucial step in our PHN method, where we select the optimal hyperparameters based on the Hyper Volume (HV) computed on a validation set. In contrast, selecting hyperparameters for the baselines is challenging due to the lack of a clear runtime-based criterion. To overcome this issue, we train each approach multiple times on a single ray and then apply the selected hyperparameters to all rays. Our selection criterion involves collecting all models trained with various hyperparameter configurations, filtering out dominated solutions, and ultimately choosing the combination with the highest uniformity."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Hyperparameter tuning is a crucial step in our PHN method, where we select the optimal hyperparameters based on the Hyper Volume (HV) computed on a validation set. In contrast, selecting hyperparameters for the baselines is challenging due to the lack of a clear runtime-based criterion. To overcome this issue, we train each approach multiple times on a single ray and then apply the selected hyperparameters to all rays. Our selection criterion involves collecting all models trained with various hyperparameter configurations, filtering out dominated solutions, and ultimately choosing the combination with the highest uniformity."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Hyperparameter tuning is a crucial step in our PHN method, where we select the optimal hyperparameters based on the Hyper Volume (HV) computed on a validation set. In contrast, selecting hyperparameters for the baselines is challenging due to the lack of a clear runtime-based criterion. To overcome this issue, we train each approach multiple times on a single ray and then apply the selected hyperparameters to all rays. Our selection criterion involves collecting all models trained with various hyperparameter configurations, filtering out dominated solutions, and ultimately choosing the combination with the highest uniformity."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Hyperparameter tuning is a crucial step in our PHN method, where we select the optimal hyperparameters based on the Hyper Volume (HV) computed on a validation set. In contrast, selecting hyperparameters for the baselines is challenging due to the lack of a clear runtime-based criterion. To overcome this issue, we train each approach multiple times on a single ray and then apply the selected hyperparameters to all rays. Our selection criterion involves collecting all models trained with various hyperparameter configurations, filtering out dominated solutions, and ultimately choosing the combination with the highest uniformity."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Hyperparameter tuning is a crucial step in our PHN method, where we select the optimal hyperparameters based on the Hyper Volume (HV) computed on a validation set. In contrast, selecting hyperparameters for the baselines is challenging due to the lack of a clear runtime-based criterion. To overcome this issue, we train each approach multiple times on a single ray and then apply the selected hyperparameters to all rays. Our selection criterion involves collecting all models trained with various hyperparameter configurations, filtering out dominated solutions, and ultimately choosing the combination with the highest uniformity."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Hyperparameter tuning is a crucial step in our PHN method, where we select the optimal hyperparameters based on the Hyper Volume (HV) computed on a validation set. In contrast, selecting hyperparameters for the baselines is challenging due to the lack of a clear runtime-based criterion. To overcome this issue, we train each approach multiple times on a single ray and then apply the selected hyperparameters to all rays. Our selection criterion involves collecting all models trained with various hyperparameter configurations, filtering out dominated solutions, and ultimately choosing the combination with the highest uniformity."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "instruction": "Make the sentence correct, put conjuctions in front of sentences.", "revised_paragraph": "Revised paragraph: While hyperparameter tuning is crucial for our PHN method, we select hyperparameters based on the HV computed on a validation set. In contrast, selecting hyperparameters for the baselines is non-trivial, as there is no clear criterion that is reasonable in terms of runtime; therefore, we employ a different approach. Specifically, each approach needs to be trained multiple times on all rays to select hyperparameters based on HV. To overcome this issue, we select hyperparameters based on a single ray and apply those for all rays. Our selection criterion is as follows: we collect all models trained using all hyperparameter configurations, filter out the dominated solutions, and finally select the combination of hyperparameters with the highest uniformity.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.03", "instruction": "Improve the English and the flow of this paragraph.", "revised_paragraph": "Revised paragraph: Hyperparameter tuning plays a crucial role in our PHN method, where we employ the harmonic variance (HV) computed on a validation set to select the optimal hyperparameters. In contrast, selecting hyperparameters for the baselines is challenging due to the lack of a clear, runtime-reasonable criterion. To address this issue, each approach requires training multiple times on all rays to determine the best hyperparameters based on HV. However, to reduce computational overhead, we select hyperparameters based on a single ray and apply them to all rays. Our selection criterion involves collecting all models trained using various hyperparameter configurations, filtering out dominated solutions, and ultimately choosing the combination of hyperparameters that yields the highest uniformity.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 2 shows the results. We observe that N. + emp + opt outperforms other methods, exploiting the fast spectral decay of the Gaussian kernel. Additionally, N. + emp and Thinning demonstrate a decent convergence rate, comparable to Herding and iid Bayes, without using expectation knowledge."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 2 shows the results. We observe that N. + emp + opt outperforms other methods, exploiting the fast spectral decay of the Gaussian kernel. Additionally, N. + emp and Thinning demonstrate a decent convergence rate, comparable to Herding and iid Bayes, without using expectation knowledge."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 2 shows the results. We observe that N. + emp + opt outperforms other methods, exploiting the fast spectral decay of the Gaussian kernel. Additionally, N. + emp and Thinning demonstrate a decent convergence rate, comparable to Herding and iid Bayes, without using expectation knowledge."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 2 shows the results. We observe that N. + emp + opt outperforms other methods, exploiting the fast spectral decay of the Gaussian kernel. Additionally, N. + emp and Thinning demonstrate a decent convergence rate, comparable to Herding and iid Bayes, without using expectation knowledge."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 2 shows the results. We observe that N. + emp + opt outperforms other methods, exploiting the fast spectral decay of the Gaussian kernel. Additionally, N. + emp and Thinning demonstrate a decent convergence rate, comparable to Herding and iid Bayes, without using expectation knowledge."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 2 shows the results. We observe that N. + emp + opt outperforms other methods, exploiting the fast spectral decay of the Gaussian kernel. Additionally, N. + emp and Thinning demonstrate a decent convergence rate, comparable to Herding and iid Bayes, without using expectation knowledge."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 2 shows the results. We observe that N. + emp + opt outperforms other methods, exploiting the fast spectral decay of the Gaussian kernel. Additionally, N. + emp and Thinning demonstrate a decent convergence rate, comparable to Herding and iid Bayes, without using expectation knowledge."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 2 shows the results. We observe that N. + emp + opt outperforms other methods, exploiting the fast spectral decay of the Gaussian kernel. Additionally, N. + emp and Thinning demonstrate a decent convergence rate, comparable to Herding and iid Bayes, without using expectation knowledge."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "instruction": "Make this paragraph shorter", "revised_paragraph": "Revised paragraph: Figure 2 shows the results, demonstrating that N. + emp + opt outperforms other methods by successfully exploiting the fast spectral decay of the Gaussian kernel. Notably, N. + emp and Thinning achieve a decent convergence rate comparable to Herding and iid Bayes, even without using expectation knowledge.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hoDIDL_gcF.NYncw25Z2M.00", "instruction": "Make this paragraph shorter.", "revised_paragraph": "Revised paragraph: Figure 2 shows the results, indicating that N. + emp + opt outperforms other methods by successfully exploiting the fast spectral decay of the Gaussian kernel. Notably, N. + emp and Thinning demonstrate a decent convergence rate comparable to Herding or iid Bayes, despite not utilizing expectation knowledge.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the PCC domain, the interpretability of machine learning models is closely tied to the availability of domain-specific knowledge. By converting a complex, black-box neural network into a transparent, symbolic rule, the congestion rule becomes more accessible and easier for network congestion practitioners to identify and modify or improve manually."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the PCC domain, the interpretability of machine learning models is closely tied to the availability of domain-specific knowledge. By converting a complex, black-box neural network into a transparent, symbolic rule, the congestion rule becomes more accessible and easier for network congestion practitioners to identify and modify or improve manually."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the PCC domain, the interpretability of machine learning models is closely tied to the availability of domain-specific knowledge. By converting a complex, black-box neural network into a transparent, symbolic rule, the congestion rule becomes more accessible and easier for network congestion practitioners to identify and modify or improve manually."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the PCC domain, the interpretability of machine learning models is closely tied to the availability of domain-specific knowledge. By converting a complex, black-box neural network into a transparent, symbolic rule, the congestion rule becomes more accessible and easier for network congestion practitioners to identify and modify or improve manually."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the PCC domain, the interpretability of machine learning models is closely tied to the availability of domain-specific knowledge. By converting a complex, black-box neural network into a transparent, symbolic rule, the congestion rule becomes more accessible and easier for network congestion practitioners to identify and modify or improve manually."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the PCC domain, the interpretability of machine learning models is closely tied to the availability of domain-specific knowledge. By converting a complex, black-box neural network into a transparent, symbolic rule, the congestion rule becomes more accessible and easier for network congestion practitioners to identify and modify or improve manually."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the PCC domain, the interpretability of machine learning models is closely tied to the availability of domain-specific knowledge. By converting a complex, black-box neural network into a transparent, symbolic rule, the congestion rule becomes more accessible and easier for network congestion practitioners to identify and modify or improve manually."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the PCC domain, the interpretability of machine learning models is closely tied to the availability of domain-specific knowledge. By converting a complex, black-box neural network into a transparent, symbolic rule, the congestion rule becomes more accessible and easier for network congestion practitioners to identify and modify or improve manually."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "instruction": "Rewrite the last sentence and make it easier to understand.", "revised_paragraph": "Revised paragraph: \"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model's interpretability is closely tied to the availability of domain-specific knowledge. By transforming a complex neural network into a transparent symbolic rule, it becomes easier for network congestion practitioners to identify and correct errors, or make targeted improvements.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.03", "instruction": "Rephrase the second part of the last sentence.", "revised_paragraph": "Revised paragraph: \"Interpretability \u2013 a universal boon for ML? In the PCC domain, the model's interpretability is closely tied to the availability of domain-specific knowledge. By transforming a complex neural network into a transparent symbolic representation, we enable network congestion practitioners to identify and rectify issues more efficiently.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The development of SRCNN was followed by the introduction of memory blocks in MemNet (Tai et al., 2017b) and simplification of residual blocks in Lim et al. (2017). Zhang et al. (2018b) proposed RCAN, which incorporated attention mechanisms in image SR. Liu et al. (2020) introduced FRANet, focusing residual features on critical spatial contents. Zhang et al. (2019) proposed residual non-local attention for image restoration, while Mei et al. (2020) combined local and non-local feature correlations in CSNLN. These advancements have achieved state-of-the-art results, but often at the cost of large model sizes and computation requirements."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nThe SRCNN was later improved by Tai et al. (2017b) who introduced memory blocks in MemNet, enabling the construction of deeper network structures. Lim et al. (2017) simplified the residual block, as proposed by He et al. (2016), and developed deeper and wider networks with a large number of parameters. Zhang et al. (2018b) further proposed the residual channel attention network (RCAN), which introduced the attention mechanism to image super-resolution for the first time. Liu et al. (2020) developed FRANet, which focused residual features on critical spatial contents. Zhang et al. (2019) later proposed residual non-local attention for image restoration, including image super-resolution. Mei et al. (2020) combined local, in-scale/cross-scale non-local feature correlations and external statistics to develop CSNLN. These advancements have achieved state-of-the-art results with deeper and wider networks, but are often limited by large model sizes (i.e., network parameter numbers) and/or heavy computational operations (i.e., FLOPs)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The development of SRCNN was followed by the introduction of memory blocks in MemNet (Tai et al., 2017b) and simplification of residual blocks in Lim et al. (2017). Zhang et al. (2018b) proposed RCAN, which incorporated attention mechanisms in image SR. Liu et al. (2020) introduced FRANet, focusing residual features on critical spatial contents. Zhang et al. (2019) proposed residual non-local attention for image restoration, while Mei et al. (2020) combined local and non-local feature correlations in CSNLN. These advancements have achieved state-of-the-art results, but often at the cost of large model sizes and computation requirements."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The development of SRCNN was followed by the introduction of memory blocks in MemNet (Tai et al., 2017b) and simplification of residual blocks in Lim et al. (2017). Zhang et al. (2018b) proposed RCAN, which incorporated attention mechanisms in image SR. Liu et al. (2020) introduced FRANet, focusing residual features on critical spatial contents. Zhang et al. (2019) proposed residual non-local attention for image restoration, while Mei et al. (2020) combined local and non-local feature correlations in CSNLN. These advancements have achieved state-of-the-art results, but often at the cost of large model sizes and computation requirements."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nThe SRCNN was later improved by Tai et al. (2017b) who introduced memory blocks in MemNet, enabling the construction of deeper network structures. Lim et al. (2017) simplified the residual block, as proposed by He et al. (2016), and developed deeper and wider networks with a large number of parameters. Zhang et al. (2018b) further proposed the residual channel attention network (RCAN), which introduced the attention mechanism to image super-resolution for the first time. Liu et al. (2020) developed FRANet, which focused residual features on critical spatial contents. Zhang et al. (2019) later proposed residual non-local attention for image restoration, including image super-resolution. Mei et al. (2020) combined local, in-scale/cross-scale non-local feature correlations and external statistics to develop CSNLN. These advancements have achieved state-of-the-art results with deeper and wider networks, but are often limited by large model sizes (i.e., network parameter numbers) and/or heavy computational operations (i.e., FLOPs)."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: The development of SRCNN was followed by the introduction of memory blocks in MemNet (Tai et al., 2017b) and simplification of residual blocks in Lim et al. (2017). Zhang et al. (2018b) proposed RCAN, which incorporated attention mechanisms in image SR. Liu et al. (2020) introduced FRANet, focusing residual features on critical spatial contents. Zhang et al. (2019) proposed residual non-local attention for image restoration, while Mei et al. (2020) combined local and non-local feature correlations in CSNLN. These advancements have achieved state-of-the-art results, but often at the cost of large model sizes and computation requirements."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The development of SRCNN was followed by the introduction of memory blocks in MemNet (Tai et al., 2017b) and simplification of residual blocks in Lim et al. (2017). Zhang et al. (2018b) proposed RCAN, which incorporated attention mechanisms in image SR. Liu et al. (2020) introduced FRANet, focusing residual features on critical spatial contents. Zhang et al. (2019) proposed residual non-local attention for image restoration, while Mei et al. (2020) combined local and non-local feature correlations in CSNLN. These advancements have achieved state-of-the-art results, but often at the cost of large model sizes and computation requirements."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The development of SRCNN was followed by the introduction of memory blocks in MemNet (Tai et al., 2017b) and the simplification of residual blocks in Lim et al. (2017). Zhang et al. (2018b) then proposed RCAN, which incorporated attention mechanisms into image super-resolution (SR). Liu et al. (2020) introduced FRANet, focusing residual features on critical spatial contents. Zhang et al. (2019) proposed residual non-local attention for image restoration, while Mei et al. (2020) combined local and non-local feature correlations in CSNLN. These advancements have achieved state-of-the-art results, often at the cost of large model sizes and increased computational requirements."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The development of SRCNN was followed by the introduction of memory blocks in MemNet (Tai et al., 2017b) and simplification of residual blocks in Lim et al. (2017). Zhang et al. (2018b) proposed RCAN, which incorporated attention mechanisms in image SR. Liu et al. (2020) introduced FRANet, focusing residual features on critical spatial contents. Zhang et al. (2019) proposed residual non-local attention for image restoration, while Mei et al. (2020) combined local and non-local feature correlations in CSNLN. These advancements have achieved state-of-the-art results, but often at the cost of large model sizes and computation requirements."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The development of SRCNN was followed by the introduction of memory blocks in MemNet (Tai et al., 2017b) and simplification of residual blocks in Lim et al. (2017). Zhang et al. (2018b) proposed RCAN, which incorporated attention mechanisms in image SR. Liu et al. (2020) introduced FRANet, focusing residual features on critical spatial contents. Zhang et al. (2019) proposed residual non-local attention for image restoration, while Mei et al. (2020) combined local and non-local feature correlations in CSNLN. These advancements have achieved state-of-the-art results, but often at the cost of large model sizes and computation requirements."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nThe SRCNN was later improved by Tai et al. (2017b) who introduced memory blocks in MemNet, enabling the construction of deeper network structures. Lim et al. (2017) simplified the residual block, as proposed by He et al. (2016), and developed deeper and wider networks with a large number of parameters. Zhang et al. (2018b) further proposed the residual channel attention network (RCAN), which introduced the attention mechanism to image super-resolution for the first time. Liu et al. (2020) developed FRANet, which focused residual features on critical spatial contents. Zhang et al. (2019) later proposed residual non-local attention for image restoration, including image super-resolution. Mei et al. (2020) combined local, in-scale/cross-scale non-local feature correlations and external statistics to develop CSNLN. These advancements have achieved state-of-the-art results with deeper and wider networks, but are often limited by large model sizes (i.e., network parameter numbers) and/or heavy computational operations (i.e., FLOPs)."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nThe SRCNN was improved by Tai et al. (2017b) with the introduction of memory blocks in MemNet, enabling deeper network structures. Lim et al. (2017) simplified residual blocks and developed deeper and wider networks. Zhang et al. (2018b) proposed RCAN, introducing attention to image super-resolution, while Liu et al. (2020) focused on residual features for critical spatial contents. These advancements achieved state-of-the-art results, but are often limited by large model sizes and heavy computational operations."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "instruction": "Be more concise.", "revised_paragraph": "Revised paragraph: The development of deep neural networks for image super-resolution (SR) has been rapid, with several notable contributions. Tai et al. (2017b) introduced memory blocks in MemNet, while Lim et al. (2017) simplified residual blocks and constructed deeper and wider networks. Zhang et al. (2018b) proposed the residual channel attention network (RCAN), which incorporated attention mechanisms in image SR. Liu et al. (2020) introduced FRANet, focusing residual features on critical spatial contents, and Zhang et al. (2019) proposed residual non-local attention for image restoration. Mei et al. (2020) combined local and non-local feature correlations with external statistics in CSNLN. While these models have achieved state-of-the-art results, they are often accompanied by large model sizes and computationally expensive operations.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.04", "instruction": "Use shorter formulations to make some sentences more concise.", "revised_paragraph": "Revised paragraph: \n\nTai et al. (2017b) introduced memory blocks in MemNet, enabling deeper network structures. Lim et al. (2017) simplified residual blocks (He et al., 2016) and constructed deeper and wider networks with a large number of parameters. Zhang et al. (2018b) proposed RCAN, introducing the attention mechanism in image SR. Liu et al. (2020) focused residual features on critical spatial contents with FRANet. Zhang et al. (2019) introduced residual non-local attention for image restoration, including SR. Mei et al. (2020) combined local and non-local feature correlations with CSNLN. These methods achieved state-of-the-art results, but at the cost of large model sizes and heavy computation operations.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L model boasts the smallest number of parameters among recent works, including MemNet, CARN, and IMDN. Moreover, when setting the output size to 3 \u00d7 1280 \u00d7 720, we demonstrate that SRPN-L requires fewer Mult-Adds operations compared to most other methods. These findings suggest that the SRP approach efficiently reduces both the number of parameters and operations."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L model demonstrates efficiency in both parameter count and computational operations. In comparison to recent works such as MemNet, CARN, and IMDN, our model boasts the lowest number of parameters. Furthermore, when setting the output size to 3 \u00d7 1280 \u00d7 720, our SRPN-L model requires fewer mult-adds operations compared to most other methods. These comparisons highlight the effectiveness of SRP in reducing both parameters and computational operations."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L model demonstrates efficiency in both parameter count and computational operations. In comparison to recent works such as MemNet, CARN, and IMDN, our model boasts the lowest number of parameters. Furthermore, when setting the output size to 3 \u00d7 1280 \u00d7 720, our SRPN-L model requires fewer mult-adds operations compared to most other methods. These comparisons highlight the effectiveness of SRP in reducing both parameters and computational operations."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L model boasts the smallest number of parameters among recent works, including MemNet, CARN, and IMDN. Moreover, when setting the output size to 3 \u00d7 1280 \u00d7 720, we demonstrate that SRPN-L requires fewer Mult-Adds operations compared to most other methods. These findings suggest that the SRP approach efficiently reduces both the number of parameters and operations."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L model boasts the smallest number of parameters among recent works, including MemNet, CARN, and IMDN. Moreover, when setting the output size to 3 \u00d7 1280 \u00d7 720, we demonstrate that SRPN-L requires fewer Mult-Adds operations compared to most other methods. These findings suggest that the SRP approach efficiently reduces both the number of parameters and operations."}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L model stands out for its minimal parameter count among recent works, including MemNet, CARN, and IMDN. Furthermore, when configured to produce an output of 3 \u00d7 1280 \u00d7 720, our model exhibits a reduced number of Mult-Adds operations compared to most other methods. These findings collectively indicate that the SRP approach effectively minimizes both the number of parameters and computational operations, making it an efficient solution."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L model demonstrates efficiency in both parameter count and computational operations. In comparison to recent works such as MemNet, CARN, and IMDN, our model boasts the lowest number of parameters. Furthermore, when setting the output size to 3 \u00d7 1280 \u00d7 720, our SRPN-L model requires fewer mult-adds operations compared to most other methods. These comparisons highlight the effectiveness of SRP in reducing both parameters and computational operations."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L model boasts the smallest number of parameters among recent works, including MemNet, CARN, and IMDN. Moreover, when setting the output size to 3 \u00d7 1280 \u00d7 720, we demonstrate that SRPN-L requires fewer Mult-Adds operations compared to most other methods. These findings suggest that the SRP approach efficiently reduces both the number of parameters and operations."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "instruction": "Give me a more formal version of ths paragraph", "revised_paragraph": "Revised paragraph: \"In comparison to recent studies, such as MemNet, CARN, and IMDN, our proposed SRPN-L model exhibits the lowest parameter count. Furthermore, when considering the output size of 3 \u00d7 1280 \u00d7 720, our SRPN-L model demonstrates a reduced number of Multiply-Accumulate (Mult-Adds) operations compared to most of the evaluated methods. These findings suggest that the SRPN architecture effectively minimizes both parameters and operations.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.20", "instruction": "Rephrase the text and change SRPN-L to SRPN-Lite", "revised_paragraph": "Revised paragraph: \"Model Size and Mult-Adds. Compared to recent works, such as MemNet, CARN, and IMDN, our SRPN-Lite has the smallest parameter count. We also report the number of operations with Mult-Adds, assuming an output size of 3 \u00d7 1280 \u00d7 720. Our SRPN-Lite performs fewer Mult-Adds than most compared methods, demonstrating the efficiency of SRPN in reducing parameters and operations.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The Bayesian framework iterations of the ADO algorithm are presented in Section 3.3 and Appendix A.3. Following the estimation of the posterior distribution, the predictive uncertainty can be quantified by evaluating the identified system with an ensemble of parameters. To enhance the prediction capability, particularly for chaotic systems, we propose the integration of data assimilation techniques, as illustrated in the green box and discussed in Section 3.4 and Appendix A.5.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The Bayesian framework iterations of the ADO algorithm are presented in Section 3.3 and Appendix A.3. Following the estimation of the posterior distribution, the predictive uncertainty can be quantified by evaluating the identified system with an ensemble of parameters. To enhance the prediction capability, particularly for chaotic systems, we propose the integration of data assimilation techniques, as illustrated in the green box and discussed in Section 3.4 and Appendix A.5.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The Bayesian framework iterations of the ADO algorithm are presented in Section 3.3 and Appendix A.3. Following the estimation of the posterior distribution, the predictive uncertainty can be quantified by evaluating the identified system with an ensemble of parameters. To enhance the prediction capability, particularly for chaotic systems, we propose the integration of data assimilation techniques, as illustrated in the green box and discussed in Section 3.4 and Appendix A.5.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The Bayesian framework iterations of the ADO algorithm are presented in Section 3.3 and Appendix A.3. Following the estimation of the posterior distribution, the predictive uncertainty can be quantified by evaluating the identified system with an ensemble of parameters. To enhance the prediction capability, particularly for chaotic systems, we propose the integration of data assimilation techniques, as illustrated in the green box and discussed in Section 3.4 and Appendix A.5.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The Bayesian framework iterations of the ADO algorithm are presented in Section 3.3 and Appendix A.3. Following the estimation of the posterior distribution, the predictive uncertainty can be quantified by evaluating the identified system with an ensemble of parameters. To enhance the prediction capability, particularly for chaotic systems, we propose the integration of data assimilation techniques, as illustrated in the green box and discussed in Section 3.4 and Appendix A.5.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The Bayesian framework iterations of the ADO algorithm are presented in Section 3.3 and Appendix A.3. Following the estimation of the posterior distribution, the predictive uncertainty can be quantified by evaluating the identified system with an ensemble of parameters. To enhance the prediction capability, particularly for chaotic systems, we propose the integration of data assimilation techniques, as illustrated in the green box and discussed in Section 3.4 and Appendix A.5.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The Bayesian framework iterations of the ADO algorithm are presented in Section 3.3 and Appendix A.3. Following the estimation of the posterior distribution, the predictive uncertainty can be quantified by evaluating the identified system with an ensemble of parameters. To enhance the prediction capability, particularly for chaotic systems, we propose the integration of data assimilation techniques, as illustrated in the green box and discussed in Section 3.4 and Appendix A.5.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The Bayesian framework iterations of the ADO algorithm are presented in Section 3.3 and Appendix A.3. Following the estimation of the posterior distribution, the predictive uncertainty can be quantified by evaluating the identified system with an ensemble of parameters. To enhance the prediction capability, particularly for chaotic systems, we propose the integration of data assimilation techniques, as illustrated in the green box and discussed in Section 3.4 and Appendix A.5.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "instruction": "Use \"supplemental materials\" instead of \"Appendix\"", "revised_paragraph": "Revised paragraph: ADO iterations in the Bayesian framework are shown in Sec. 3.3 and supplemental materials A.3. Finally, with the estimated posterior, the predictive uncertainty can be quantified by evaluating the identified system with an ensemble of parameters. To further improve the prediction capability, especially for chaotic systems, we propose to leverage data assimilation techniques, which is shown in the green box and discussed in Sec. 3.4 and supplemental materials A.5.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "E2pFUCGYZ1.5hMS4Fg2b_b.00", "instruction": "Lightly revise for readability.", "revised_paragraph": "Revised paragraph: \"The Bayesian framework is illustrated in Sec. 3.3 and Appendix A.3, where ADO iterations are demonstrated. Using the estimated posterior, the predictive uncertainty can be quantified by evaluating the system with an ensemble of parameters. To enhance prediction capability, particularly for chaotic systems, we suggest incorporating data assimilation techniques, as discussed in Sec. 3.4 and Appendix A.5, as shown in the green box.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches use a learning rate of 10^-3 on a fixed batch of 10^3 episodes with 10% non-optimal transitions. For multi-step approaches, we set the rollout length to 4."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches use a learning rate of 10^-3 on a fixed batch of 10^3 episodes with 10% non-optimal transitions. For multi-step approaches, we set the rollout length to 4."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches use a learning rate of 10^-3 on a fixed batch of 10^3 episodes with 10% non-optimal transitions. For multi-step approaches, we set the rollout length to 4."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches use a learning rate of 10^-3 on a fixed batch of 10^3 episodes with 10% non-optimal transitions. For multi-step approaches, we set the rollout length to 4."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches use a learning rate of 10^-3 on a fixed batch of 10^3 episodes with 10% non-optimal transitions. For multi-step approaches, we set the rollout length to 4."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches use a learning rate of 10^-3 on a fixed batch of 10^3 episodes with 10% non-optimal transitions. For multi-step approaches, we set the rollout length to 4."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches use a learning rate of 10^-3 on a fixed batch of 10^3 episodes with 10% non-optimal transitions. For multi-step approaches, we set the rollout length to 4."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches use a learning rate of 10^-3 on a fixed batch of 10^3 episodes with 10% non-optimal transitions. For multi-step approaches, we set the rollout length to 4."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "instruction": "I want to remove the last sentence.", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10 \u2212 3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 \u2212 and the Truncated Q-functions with a learning rate of 10 \u2212 3.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "S1AJ47hjr.B1E3IvnsH.00", "instruction": "Delete the last sentence.", "revised_paragraph": "Revised paragraph: Results for K = 20 are depicted in Figure 2b. All approaches update the Q-function with a learning rate of 10 \u2212 3 on the same fixed batch of 10 3 episodes with a percentage of 10% non-optimal transitions. For the multi-step approaches, we set rollout length n = 4. Since there is no generalization among states in the tabular setting, we update the Shifted Q-function with a learning rate of 10 \u2212 and the Truncated Q-functions with a learning rate of 10 \u2212 3.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: In the experiment, we found that AGILE outperformed ablations in CREATE and Grid World by correctly utilizing action relations in decision-making, whereas it failed to do so in RecSim. We hypothesized that the complex relations between actions in the environment, such as tools and activators in CREATE, inject complex action relations. To test this, we implemented pre-defined pairings among items in RecSim, allowing clicks only when correct pairs were recommended. Figure 14 shows AGILE beating baselines, while Figures 16 and 14 demonstrate its ability to model action relations correctly and converge faster than ablations."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the experiment depicted in Fig. 5, we observed that while AGILE failed to outperform ablations in RecSim due to the simplicity of item relationships, it successfully outperformed ablations in CREATE and Grid World by leveraging action relationships in decision-making. We hypothesized that the presence of complex action relationships in the environment (e.g., tool-activator pairs in CREATE) injects complexity into the action relationships. For instance, the appropriate pairing of an activator and tool in CREATE depends on the situation. To test this hypothesis, we implemented pre-defined pairings among items in RecSim, allowing clicks only when the correct pairs were recommended. Given the complexity of action relationships, we expected AGILE to outperform ablations. As shown in Figs. 14 and 16, AGILE consistently outperforms baselines and ablations, demonstrating its ability to model action relationships correctly and converge faster than AGILE-Only-Action, which highlights the importance of intermediate list information for efficient learning."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: In Fig. 5, we found that AGILE outperformed ablations in CREATE and Grid World by leveraging action relations in decision-making, whereas it failed to do so in RecSim. We hypothesized that complex action relations in the environment, such as tool and activator pairings in CREATE, are critical for AGILE's success. To test this, we implemented pre-defined pairings in RecSim, allowing clicks only when correct item pairs are recommended. As expected, AGILE outperformed baselines and ablations in Figs. 14 and 16, demonstrating its ability to model action relations correctly and converge faster than baselines."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the experiment depicted in Fig. 5, we observed that while AGILE failed to outperform ablations in RecSim due to the simplicity of item relationships, it successfully outperformed ablations in CREATE and Grid World by leveraging action relationships in decision-making. We hypothesized that the presence of complex action relationships in the environment (e.g., tool-activator pairs in CREATE) injects complexity into the action relationships. For instance, the appropriate pairing of an activator and tool in CREATE depends on the situation. To test this hypothesis, we implemented pre-defined pairings among items in RecSim, allowing clicks only when the correct pairs were recommended. Given the complexity of action relationships, we expected AGILE to outperform ablations. As shown in Figs. 14 and 16, AGILE consistently outperforms baselines and ablations, demonstrating its ability to model action relationships correctly and converge faster than AGILE-Only-Action, which highlights the importance of intermediate list information for efficient learning."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: In the experiment, we found that AGILE outperformed ablations in CREATE and Grid World by correctly utilizing action relations in decision-making, whereas it failed to do so in RecSim. We hypothesized that the complex relations between actions in the environment, such as tools and activators in CREATE, inject complex action relations. To test this, we implemented pre-defined pairings among items in RecSim, allowing clicks only when correct pairs were recommended. Figure 14 shows AGILE beating baselines, while Figures 16 and 14 demonstrate its ability to model action relations correctly and converge faster than ablations."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: In Fig. 5, we found that AGILE outperformed ablations in CREATE and Grid World by leveraging action relations in decision-making, whereas it failed to do so in RecSim. We hypothesized that complex action relations in the environment, such as tool and activator pairings in CREATE, are critical for AGILE's success. To test this, we implemented pre-defined pairings in RecSim, allowing clicks only when correct item pairs are recommended. As expected, AGILE outperformed baselines and ablations in Figs. 14 and 16, demonstrating its ability to model action relations correctly and converge faster than baselines."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: In the experiment, we found that AGILE outperformed ablations in CREATE and Grid World by correctly utilizing action relations in decision-making, whereas it failed to do so in RecSim. We hypothesized that the complex relations between actions in the environment, such as tools and activators in CREATE, inject complex action relations. To test this, we implemented pre-defined pairings among items in RecSim, allowing clicks only when correct pairs were recommended. Figure 14 shows AGILE beating baselines, while Figures 16 and 14 demonstrate its ability to model action relations correctly and converge faster than ablations."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In our experiment, we observed that AGILE outperformed ablations in CREATE and Grid World by effectively utilizing action relations in decision-making, whereas it struggled to do so in RecSim. We hypothesized that the intricate relationships between actions in the environment, such as tools and activators in CREATE, contribute to the complexity of action relations. To test this, we introduced predefined pairings among items in RecSim, allowing clicks only when correct pairs were recommended. The results, depicted in Figures 14, 16, and 17, demonstrate that AGILE surpasses baselines and accurately models action relations, converging faster than ablations."}, {"depth": 3, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our experiment showed that AGILE outperformed ablations in CREATE and Grid World by leveraging action relations in decision-making, while struggling in RecSim. We attributed this to the complex relationships between actions in the environment, such as tools and activators in CREATE. By introducing predefined pairings in RecSim, we enabled AGILE to accurately model action relations, converging faster than ablations, as depicted in Figures 14, 16, and 17."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In the experiment depicted in Fig. 5, we observed that while AGILE failed to outperform ablations in RecSim due to the simplicity of item relationships, it successfully outperformed ablations in CREATE and Grid World by leveraging action relationships in decision-making. We hypothesized that the presence of complex action relationships in the environment (e.g., tool-activator pairs in CREATE) injects complexity into the action relationships. For instance, the appropriate pairing of an activator and tool in CREATE depends on the situation. To test this hypothesis, we implemented pre-defined pairings among items in RecSim, allowing clicks only when the correct pairs were recommended. Given the complexity of action relationships, we expected AGILE to outperform ablations. As shown in Figs. 14 and 16, AGILE consistently outperforms baselines and ablations, demonstrating its ability to model action relationships correctly and converge faster than AGILE-Only-Action, which highlights the importance of intermediate list information for efficient learning."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: In the experiment, we observed that AGILE outperformed ablations in CREATE and Grid World by leveraging action relationships in decision-making, but failed to do so in RecSim due to the simplicity of item relationships. We hypothesized that complex action relationships in the environment, such as tool-activator pairs in CREATE, inject complexity into action relationships. As shown in Figs. 14 and 16, AGILE consistently outperformed baselines and ablations, demonstrating its ability to model action relationships correctly and converge faster than AGILE-Only-Action, highlighting the importance of intermediate list information for efficient learning."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: In Fig. 5, we found that AGILE outperformed ablations in CREATE and Grid World by leveraging action relations in decision-making, whereas it failed to do so in RecSim. We hypothesized that complex action relations in the environment, such as tool and activator pairings in CREATE, are critical for AGILE's success. To test this, we implemented pre-defined pairings in RecSim, allowing clicks only when correct item pairs are recommended. As expected, AGILE outperformed baselines and ablations in Figs. 14 and 16, demonstrating its ability to model action relations correctly and converge faster than baselines."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "instruction": "Make this paragraph shorter and easier to understand", "revised_paragraph": "Revised paragraph: In the experiment, we found that AGILE outperformed ablations in CREATE and Grid World by effectively utilizing action relations in decision-making. In contrast, AGILE did not outperform ablations in RecSim, where the item relations are simple. We hypothesized that the complex action relations in CREATE and Grid World enable AGILE to learn and utilize these relations. To test this, we implemented pre-defined pairings in RecSim, ensuring that only correct item pairs were recommended. Our results show that AGILE consistently outperformed ablations, demonstrating its ability to model complex action relations correctly.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.21", "instruction": "Simplify the less essential ideas of the paragraph to make it more concise.", "revised_paragraph": "Revised paragraph: \"In Fig. 5, we observed that AGILE outperformed ablations in CREATE and Grid World by effectively utilizing action relations in decision-making, whereas it was unable to surpass ablations in RecSim due to the simplicity of item relations. We hypothesized that the complexity of action relations in the environment, such as tool and activator pairs in CREATE, enables AGILE to excel. To test this, we implemented pre-defined pairings in RecSim, restricting clicks to correct item combinations. As action relations are complex, AGILE's ability to model them correctly is expected to yield better performance. Figures 14, 16, and 14 demonstrate AGILE's superiority over baselines and ablations, indicating the importance of intermediate list information for efficient learning.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, widely used in various fields. For example, application managers impose marketing strategies on randomly sampled users to evaluate their impact on click-through rates, while drug developers conduct clinical A/B tests to assess drug effects. Although RCTs are the gold standard for causal inference, they are often too expensive to conduct. As a result, researchers have turned to observational data, which can be acquired without intervention."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, with applications in e-commerce, education, and healthcare (Betlei et al., 2021; Cordero et al., 2018; Schwab et al., 2020). However, RCTs are often too expensive to conduct, leading to the use of observational data as a shortcut. For instance, drug developers may assess drug effects with post-marketing monitoring reports instead of clinical A/B trials. With increasing access to observational data, estimating ITE from observational data has garnered significant research attention.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Estimating individual treatment effects (ITE) using randomized controlled trials (RCTs) is a widespread practice in causal inference, with applications in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018), and healthcare (Schwab et al., 2020). For instance, application managers might impose a marketing strategy on randomly sampled users to assess its potential impact on click-through rates, while drug developers would conduct clinical A/B tests to evaluate drug effects. Although RCTs are considered the gold standard for causal inference (Judea & Dana, 2018), they are often too costly to conduct. Consequently, observational data, which can be acquired without intervention, has become a tempting alternative. For example, drug developers often assess drug effects using post-marketing monitoring reports instead of clinical A/B trials. With the increasing availability of observational data, estimating ITE from observational data has garnered significant research attention."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, widely used in various fields. For example, application managers impose marketing strategies on randomly sampled users to evaluate their impact on click-through rates, while drug developers conduct clinical A/B tests to assess drug effects. Although RCTs are the gold standard for causal inference, they are often too expensive to conduct. As a result, researchers have turned to observational data, which can be acquired without intervention."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Estimating individual treatment effects (ITE) using randomized controlled trials (RCTs) is a widespread practice in causal inference, with applications in e-commerce (Betlei et al., 2021), education (Cordero et al., 2018), and healthcare (Schwab et al., 2020). For instance, application managers might impose a marketing strategy on randomly sampled users to assess its potential impact on click-through rates, while drug developers would conduct clinical A/B tests to evaluate drug effects. Although RCTs are considered the gold standard for causal inference (Judea & Dana, 2018), they are often too costly to conduct. Consequently, observational data, which can be acquired without intervention, has become a tempting alternative. For example, drug developers often assess drug effects using post-marketing monitoring reports instead of clinical A/B trials. With the increasing availability of observational data, estimating ITE from observational data has garnered significant research attention."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, with applications in e-commerce, education, and healthcare (Betlei et al., 2021; Cordero et al., 2018; Schwab et al., 2020). However, RCTs are often too expensive to conduct, leading to the use of observational data as a shortcut. For instance, drug developers may assess drug effects with post-marketing monitoring reports instead of clinical A/B trials. With increasing access to observational data, estimating ITE from observational data has garnered significant research attention.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, widely used in various fields. For example, application managers impose marketing strategies on randomly sampled users to evaluate their impact on click-through rates, while drug developers conduct clinical A/B tests to assess drug effects. Although RCTs are the gold standard for causal inference, they are often too expensive to conduct. As a result, researchers have turned to observational data, which can be acquired without intervention."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Estimating individual treatment effects with randomized controlled trials (RCTs) is a common practice in causal inference, widely used in various fields. RCTs are the gold standard for causal inference, but they can be too expensive to conduct. As a result, researchers have turned to observational data, which can be acquired without intervention."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Estimating individual treatment effects with randomized controlled trials (RCTs) is a widely employed practice in causal inference, with applications across various fields. RCTs are considered the gold standard for causal inference, yet their high cost can limit their feasibility. Consequently, researchers have turned to observational data, which can be readily acquired without the need for intervention."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, widely used in various fields. For example, application managers impose marketing strategies on randomly sampled users to evaluate their impact on click-through rates, while drug developers conduct clinical A/B tests to assess drug effects. Although RCTs are the gold standard for causal inference, they are often too expensive to conduct. As a result, researchers have turned to observational data, which can be acquired without intervention."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Estimating individual treatment effects (ITEs) using randomized controlled trials (RCTs) is a widespread practice in causal inference, with applications across various fields. For instance, application managers randomly assign marketing strategies to sampled users to evaluate their impact on click-through rates, while drug developers conduct clinical A/B tests to assess the effects of their drugs. Although RCTs are considered the gold standard for causal inference, they are often prohibitively expensive to conduct. Consequently, researchers have turned to observational data, which can be acquired without intervening in the underlying processes."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects (ITE) with randomized controlled trials (RCTs) is a common practice in causal inference, with applications in e-commerce, education, and healthcare (Betlei et al., 2021; Cordero et al., 2018; Schwab et al., 2020). However, RCTs are often too expensive to conduct, leading to the use of observational data as a shortcut. For instance, drug developers may assess drug effects with post-marketing monitoring reports instead of clinical A/B trials. With increasing access to observational data, estimating ITE from observational data has garnered significant research attention.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "instruction": "Remove the part of the sentence that talks about application managers. Improve the english of this paragraph.", "revised_paragraph": "Revised paragraph: Estimating individual treatment effect (ITE) with randomized controlled trials (RCTs) is a widely practiced approach in causal inference, having been employed in various fields, including e-commerce (Betlei et al., 2021), education (Cordero et al., 2018), and healthcare (Schwab et al., 2020). For instance, researchers might impose a marketing strategy on randomly sampled users to assess its potential impact on click-through rates, or evaluate the effects of a new drug through clinical A/B tests. Although RCTs are considered the gold standard for causal inference (Judea & Dana, 2018), conducting randomized experiments can be prohibitively expensive. As a result, observational data, which can be acquired without intervention, has become a tempting alternative. For example, drug developers often rely on post-marketing monitoring reports to assess drug effects rather than conducting clinical A/B trials. With the increasing availability of observational data, estimating ITE from observational data has garnered significant research attention.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.01", "instruction": "Make the sentence 2 more concise. Make the sentence 3 more formal.", "revised_paragraph": "Revised paragraph: Estimating individual treatment effects (ITE) with randomized controlled trials (RCTs) is a widely applied method in causal inference, having been utilized in various fields, including e-commerce, education, and healthcare. For instance, application managers may implement a marketing strategy on a randomly selected user group to assess its impact on click-through rates, while drug developers may conduct A/B tests to evaluate drug efficacy. Although RCTs are considered the gold standard for causal inference, they are often prohibitively expensive. Consequently, observational data, which can be acquired without intervention, has become an attractive alternative. For example, drug developers may rely on post-marketing monitoring reports to assess drug effects rather than conducting clinical A/B trials. As access to observational data has increased, estimating ITE from observational data has garnered significant research attention.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we employ a stacking approach to enable more complex transformations. The derivative of the composite function can be computed efficiently using the chain rule. At inference time, the inverse mapping f\u22121(y) can be computed efficiently, as demonstrated by Rezende et al. (2020). To find the solution of f\u22121(y), the first step is to identify the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to solving the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in the interval [xk, xk+1], which has a closed-form solution."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we employ a stacking approach to enable more complex transformations. The derivative of the composite function can be computed efficiently using the chain rule. At inference time, the inverse mapping f\u22121(y) can be computed efficiently, as demonstrated by Rezende et al. (2020). To find the solution of f\u22121(y), the first step is to identify the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to solving the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in the interval [xk, xk+1], which has a closed-form solution."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we employ a stacking approach to enable more complex transformations. The derivative of the composite function can be computed efficiently using the chain rule. At inference time, the inverse mapping f\u22121(y) can be computed efficiently, as demonstrated by Rezende et al. (2020). To find the solution of f\u22121(y), the first step is to identify the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to solving the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in the interval [xk, xk+1], which has a closed-form solution."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we employ a stacking approach to enable more complex transformations. The derivative of the composite function can be computed efficiently using the chain rule. At inference time, the inverse mapping f\u22121(y) can be computed efficiently, as demonstrated by Rezende et al. (2020). To find the solution of f\u22121(y), the first step is to identify the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to solving the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in the interval [xk, xk+1], which has a closed-form solution."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we employ a stacking approach to enable more complex transformations. The derivative of the composite function can be computed efficiently using the chain rule. At inference time, the inverse mapping f\u22121(y) can be computed efficiently, as demonstrated by Rezende et al. (2020). To find the solution of f\u22121(y), the first step is to identify the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to solving the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in the interval [xk, xk+1], which has a closed-form solution."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we employ a stacking approach to enable more complex transformations. The derivative of the composite function can be computed efficiently using the chain rule. At inference time, the inverse mapping f\u22121(y) can be computed efficiently, as demonstrated by Rezende et al. (2020). To find the solution of f\u22121(y), the first step is to identify the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to solving the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in the interval [xk, xk+1], which has a closed-form solution."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we employ a stacking approach to enable more complex transformations. The derivative of the composite function can be computed efficiently using the chain rule. At inference time, the inverse mapping f\u22121(y) can be computed efficiently, as demonstrated by Rezende et al. (2020). To find the solution of f\u22121(y), the first step is to identify the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to solving the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in the interval [xk, xk+1], which has a closed-form solution."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we employ a stacking approach to enable more complex transformations. The derivative of the composite function can be computed efficiently using the chain rule. At inference time, the inverse mapping f\u22121(y) can be computed efficiently, as demonstrated by Rezende et al. (2020). To find the solution of f\u22121(y), the first step is to identify the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to solving the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in the interval [xk, xk+1], which has a closed-form solution."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "instruction": "Please, review this paragraph, modify only if necessary", "revised_paragraph": "Revised paragraph: \"In practice, we stack multiple bijections to enable more complex transformations. The derivative of the composite can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f^(-1)(y) can be computed efficiently (Rezende et al., 2020). To find the solution of f^(-1)(y), the first step is to locate the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to finding the root of the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in [xk, xk+1], whose solution is closed-form.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.14", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "Revised paragraph: In practice, we stack multiple bijections to enable more complex transformations. The derivative of the composite function can be computed efficiently by applying the chain rule. At inference time, the inverse mapping f^(-1)(y) can be computed efficiently, as demonstrated by Rezende et al. (2020). To find the solution of f^(-1)(y), the first step is to locate the unique bin that contains y. Assuming y belongs to the k-th bin, finding its corresponding x amounts to solving the quadratic equation fk(x|xk,k+1, yk,k+1, \u03b4k,k+1) = y in the interval [xk, xk+1], which has a closed-form solution.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We utilize the open-sourced RecSim simulator (Ie et al., 2019a) to enable agents to interact with simulated users through item recommendations. In each episode, the agent is presented with 20 items from a base action set of 250 train items and 250 test items, and must recommend a list of size 6. The state is defined as the user's preference vector, while the environment provides ground truth action representations. To incorporate contextual preferences, we boost the probability of user clicks on items in proportion to their CPR values, simulating a scenario where user preferences are influenced by the entire list. An optimal agent should identify the most common category in the available action set and prioritize recommending items from that category, requiring an understanding of relationships between candidate items from the same category. Our goal is to train CDQN-based models to maximize the number of clicks in a user session."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We utilize the open-sourced RecSim simulator (Ie et al., 2019a) to enable agents to interact with simulated users through item recommendations. In each episode, the agent is presented with 20 items from a base action set of 250 train items and 250 test items, and must recommend a list of size 6. The state is defined as the user's preference vector, while the environment provides ground truth action representations. To incorporate contextual preferences, we boost the probability of user clicks on items in proportion to their CPR values, simulating a scenario where user preferences are influenced by the entire list. An optimal agent should identify the most common category in the available action set and prioritize recommending items from that category, requiring an understanding of relationships between candidate items from the same category. Our goal is to train CDQN-based models to maximize the number of clicks in a user session."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We utilize the open-sourced RecSim simulator (Ie et al., 2019a) to enable agents to interact with simulated users through item recommendations. In each episode, the agent is presented with 20 items from a base action set of 250 train items and 250 test items, and must recommend a list of size 6. The state is defined as the user's preference vector, while the environment provides ground truth action representations. To incorporate contextual preferences, we boost the probability of user clicks on items in proportion to their CPR values, simulating a scenario where user preferences are influenced by the entire list. An optimal agent should identify the most common category in the available action set and prioritize recommending items from that category, requiring an understanding of relationships between candidate items from the same category. Our goal is to train CDQN-based models to maximize the number of clicks in a user session."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We utilize the open-sourced RecSim simulator (Ie et al., 2019a) to enable agents to interact with simulated users through item recommendations. In each episode, the agent is presented with 20 items from a base action set of 250 train items and 250 test items, and must recommend a list of size 6. The state is defined as the user's preference vector, while the environment provides ground truth action representations. To incorporate contextual preferences, we boost the probability of user clicks on items in proportion to their CPR values, simulating a scenario where user preferences are influenced by the entire list. An optimal agent should identify the most common category in the available action set and prioritize recommending items from that category, requiring an understanding of relationships between candidate items from the same category. Our goal is to train CDQN-based models to maximize the number of clicks in a user session."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We utilize the open-sourced RecSim simulator (Ie et al., 2019a) to enable agents to interact with simulated users through item recommendations. In each episode, the agent is presented with 20 items from a base action set of 250 train items and 250 test items, and must recommend a list of size 6. The state is defined as the user's preference vector, while the environment provides ground truth action representations. To incorporate contextual preferences, we boost the probability of user clicks on items in proportion to their CPR values, simulating a scenario where user preferences are influenced by the entire list. An optimal agent should identify the most common category in the available action set and prioritize recommending items from that category, requiring an understanding of relationships between candidate items from the same category. Our goal is to train CDQN-based models to maximize the number of clicks in a user session."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We utilize the open-sourced RecSim simulator (Ie et al., 2019a) to enable agents to interact with simulated users through item recommendations. In each episode, the agent is presented with 20 items from a base action set of 250 train items and 250 test items, and must recommend a list of size 6. The state is defined as the user's preference vector, while the environment provides ground truth action representations. To incorporate contextual preferences, we boost the probability of user clicks on items in proportion to their CPR values, simulating a scenario where user preferences are influenced by the entire list. An optimal agent should identify the most common category in the available action set and prioritize recommending items from that category, requiring an understanding of relationships between candidate items from the same category. Our goal is to train CDQN-based models to maximize the number of clicks in a user session."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We utilize the open-sourced RecSim simulator (Ie et al., 2019a) to enable agents to interact with simulated users through item recommendations. In each episode, the agent is presented with 20 items from a base action set of 250 train items and 250 test items, and must recommend a list of size 6. The state is defined as the user's preference vector, while the environment provides ground truth action representations. To incorporate contextual preferences, we boost the probability of user clicks on items in proportion to their CPR values, simulating a scenario where user preferences are influenced by the entire list. An optimal agent should identify the most common category in the available action set and prioritize recommending items from that category, requiring an understanding of relationships between candidate items from the same category. Our goal is to train CDQN-based models to maximize the number of clicks in a user session."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We utilize the open-sourced RecSim simulator (Ie et al., 2019a) to enable agents to interact with simulated users through item recommendations. In each episode, the agent is presented with 20 items from a base action set of 250 train items and 250 test items, and must recommend a list of size 6. The state is defined as the user's preference vector, while the environment provides ground truth action representations. To incorporate contextual preferences, we boost the probability of user clicks on items in proportion to their CPR values, simulating a scenario where user preferences are influenced by the entire list. An optimal agent should identify the most common category in the available action set and prioritize recommending items from that category, requiring an understanding of relationships between candidate items from the same category. Our goal is to train CDQN-based models to maximize the number of clicks in a user session."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "instruction": "Rewrite the sentences, making them shorter and more connected.", "revised_paragraph": "Revised paragraph: We utilize the RecSim simulator (Ie et al., 2019a) to develop a scenario where an agent interacts with simulated users by recommending a list of items. The agent receives a list of 20 items in each episode and must recommend 6 items. We use user preference vectors as the state and ground truth action representations from the environment. To incorporate context-aware behavior, we boost the probability of user clicks based on the Contextual Preference Ratio (CPR). This simulates a scenario where the user preference model is influenced by the entire list. Our goal is to train CDQN-based models to maximize the number of clicks in a user session by identifying the most common category and recommending items from it, while considering the relationships with other candidate items from the same category.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.10", "instruction": "Rewrite the sentences of this paragraph for better readability and fitting to the academic style.", "revised_paragraph": "Revised paragraph: In this study, we utilize the open-sourced RecSim simulator (Ie et al., 2019a) to develop a simulated environment where an agent interacts with users by recommending a list of items. The simulator is equipped with a base action set comprising 250 training items and 250 testing items, with each episode featuring 20 items presented to the agent. The agent is tasked with recommending a list of six items. We adopt a Markov decision process (MDP) framework, where the state is represented by user preference vectors and ground truth action representations are obtained from the environment. To incorporate context-aware preference ranking (CPR), we boost the probability of a user clicking an item in proportion to its CPR score. This simulation scenario mimics a situation where a user's preference model is influenced by the entire list of available items. An optimal agent should identify the most common category in the action set and strive to recommend items from that category. This requires understanding the relationships between candidate items from the same category. To achieve this, we train CDQN-based models to maximize the number of clicks in a user session.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Sequence-based models poorly predict \u2206\u2206G for protein-protein binding, as discussed in Section 2.2. Figure 3 illustrates the distribution of per-complex correlation coefficients, with additional results and discussion available in Section B of the appendix."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"As discussed in Section 2.2, sequence-based models fail to accurately predict \u2206\u2206G values for protein-protein binding. Figure 3 illustrates the distribution of per-complex correlation coefficients. For additional results and discussion, please refer to Section B of the appendix.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"As discussed in Section 2.2, sequence-based models fail to accurately predict \u2206\u2206G values for protein-protein binding. Figure 3 illustrates the distribution of per-complex correlation coefficients. For additional results and discussion, please refer to Section B of the appendix.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"As discussed in Section 2.2, sequence-based models fail to accurately predict \u2206\u2206G values for protein-protein binding. Figure 3 illustrates the distribution of per-complex correlation coefficients. For additional results and discussion, please refer to Section B of the appendix.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Sequence-based models poorly predict \u2206\u2206G for protein-protein binding, as discussed in Section 2.2. Figure 3 illustrates the distribution of per-complex correlation coefficients, with additional results and discussion available in Section B of the appendix."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"As discussed in Section 2.2, sequence-based models fail to accurately predict \u2206\u2206G values for protein-protein binding. Figure 3 illustrates the distribution of per-complex correlation coefficients. For additional results and discussion, please refer to Section B of the appendix.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Sequence-based models poorly predict \u2206\u2206G for protein-protein binding, as discussed in Section 2.2. Figure 3 illustrates the distribution of per-complex correlation coefficients, with additional results and discussion available in Section B of the appendix."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Sequence-based models have been shown to poorly predict the free energy change (\u2206\u2206G) for protein-protein binding, as discussed in Section 2.2. Figure 3 presents the distribution of per-complex correlation coefficients, with further results and discussion available in Section B of the appendix."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"As discussed in Section 2.2, sequence-based models fail to accurately predict \u2206\u2206G values for protein-protein binding. Figure 3 illustrates the distribution of per-complex correlation coefficients. For additional results and discussion, please refer to Section B of the appendix.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"As discussed in Section 2.2, sequence-based models fail to accurately predict \u2206\u2206G values for protein-protein binding. Figure 3 illustrates the distribution of per-complex correlation coefficients. For additional results and discussion, please refer to Section B of the appendix.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Sequence-based models struggle to accurately predict \u2206\u2206G values for protein-protein binding, as shown in Figure 3. For further details, see Section B of the appendix.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"As discussed in Section 2.2, sequence-based models fail to accurately predict \u2206\u2206G values for protein-protein binding. Figure 3 illustrates the distribution of per-complex correlation coefficients. For additional results and discussion, please refer to Section B of the appendix.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "instruction": "Simplify the English of this paragraph.", "revised_paragraph": "Revised paragraph: \"Sequence-based models struggle to accurately predict the binding energy of protein-protein interactions, as discussed earlier. Figure 3 shows the distribution of correlation coefficients for each complex. For more results and discussion, please see Section B of the appendix.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "instruction": "Improve the English in this paragraph.", "revised_paragraph": "Revised paragraph: \"As discussed in Section 2.2, sequence-based models fail to accurately predict \u0394\u0394G for protein-protein binding. Figure 3 illustrates the distribution of per-complex correlation coefficients. For additional results and a detailed discussion, please refer to Section B of the appendix.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have gained significant attention in recent years. Researchers have proposed various approaches to design lightweight architectures, leveraging recursive learning and channel splitting. Notable examples include the recursive learning in DRCN (Kim et al., 2016b), the cascading mechanism in CARN (Ahn et al., 2018), and the lightweight information multi-distillation network (Hui et al., 2019). Moreover, neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020), have been explored. While these efforts have achieved significant progress, there is still a need to investigate further for more efficient image SR models."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recent years have seen a growing interest in developing lightweight image super-resolution (SR) models. These approaches aim to design compact architectures that leverage recursive learning and channel splitting to reduce computational complexity. Notable contributions in this area include Kim et al.'s introduction of recursive learning in DRCN (Kim et al., 2016b) to decrease model size, Ahn et al.'s cascading mechanism on a residual network in CARN (Ahn et al., 2018), Hui et al.'s lightweight information multi-distillation network (IMDN) (Hui et al., 2019), and Luo et al.'s lattice block with butterfly structures (Luo et al., 2020). Moreover, researchers have explored neural architecture search for image SR in FALSR (Chu et al., 2019a) and model compression techniques, such as knowledge distillation, for efficient image SR. For instance, He et al. proposed knowledge distillation-based feature-affinity for efficient image SR (He et al., 2020), while Lee et al. trained a teacher network to distill its knowledge to a student network (Lee et al., 2020). Despite the progress made with lightweight networks, further investigation is needed to develop even more efficient image SR models."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have gained significant attention in recent years. Researchers have proposed various approaches to design lightweight architectures, leveraging recursive learning and channel splitting. Notable examples include the recursive learning in DRCN (Kim et al., 2016b), the cascading mechanism in CARN (Ahn et al., 2018), and the lightweight information multi-distillation network (Hui et al., 2019). Moreover, neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020), have been explored. While these efforts have achieved significant progress, there is still a need to investigate further for more efficient image SR models."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recent years have seen a growing interest in developing lightweight image super-resolution (SR) models. These approaches aim to design compact architectures that leverage recursive learning and channel splitting to reduce computational complexity. Notable contributions in this area include Kim et al.'s introduction of recursive learning in DRCN (Kim et al., 2016b) to decrease model size, Ahn et al.'s cascading mechanism on a residual network in CARN (Ahn et al., 2018), Hui et al.'s lightweight information multi-distillation network (IMDN) (Hui et al., 2019), and Luo et al.'s lattice block with butterfly structures (Luo et al., 2020). Moreover, researchers have explored neural architecture search for image SR in FALSR (Chu et al., 2019a) and model compression techniques, such as knowledge distillation, for efficient image SR. For instance, He et al. proposed knowledge distillation-based feature-affinity for efficient image SR (He et al., 2020), while Lee et al. trained a teacher network to distill its knowledge to a student network (Lee et al., 2020). Despite the progress made with lightweight networks, further investigation is needed to develop even more efficient image SR models."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have gained significant attention in recent years. Researchers have proposed various approaches to design lightweight architectures, leveraging recursive learning and channel splitting. Notable examples include the recursive learning in DRCN (Kim et al., 2016b), the cascading mechanism in CARN (Ahn et al., 2018), and the lightweight information multi-distillation network (Hui et al., 2019). Moreover, neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020), have been explored. While these efforts have achieved significant progress, there is still a need to investigate further for more efficient image SR models."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have gained significant attention in recent years. Researchers have proposed various approaches to design lightweight architectures, leveraging recursive learning and channel splitting. Notable examples include the recursive learning in DRCN (Kim et al., 2016b), the cascading mechanism in CARN (Ahn et al., 2018), and the lightweight information multi-distillation network (Hui et al., 2019). Moreover, neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020), have been explored. While these efforts have achieved significant progress, there is still a need to investigate further for more efficient image SR models."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have gained significant attention in recent years. Researchers have proposed various approaches to design lightweight architectures, leveraging recursive learning and channel splitting. Notable examples include the recursive learning in DRCN (Kim et al., 2016b), the cascading mechanism in CARN (Ahn et al., 2018), and the lightweight information multi-distillation network (Hui et al., 2019). Moreover, neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020), have been explored. While these efforts have achieved significant progress, there is still a need to investigate further for more efficient image SR models."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have garnered significant attention in recent years, with researchers proposing various approaches to design efficient architectures. Notable examples of these efforts include the recursive learning in DRCN (Kim et al., 2016b), the cascading mechanism in CARN (Ahn et al., 2018), and the lightweight information multi-distillation network (Hui et al., 2019). Furthermore, researchers have explored neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020). Despite the progress made, there is still a need to investigate further to develop even more efficient image SR models."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have gained significant attention in recent years. Researchers have proposed various approaches to design lightweight architectures, leveraging recursive learning and channel splitting. Notable examples include the recursive learning in DRCN (Kim et al., 2016b), the cascading mechanism in CARN (Ahn et al., 2018), and the lightweight information multi-distillation network (Hui et al., 2019). Moreover, neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020), have been explored. While these efforts have achieved significant progress, there is still a need to investigate further for more efficient image SR models."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recent years have seen a growing interest in developing lightweight image super-resolution (SR) models. These approaches aim to design compact architectures that leverage recursive learning and channel splitting to reduce computational complexity. Notable contributions in this area include Kim et al.'s introduction of recursive learning in DRCN (Kim et al., 2016b) to decrease model size, Ahn et al.'s cascading mechanism on a residual network in CARN (Ahn et al., 2018), Hui et al.'s lightweight information multi-distillation network (IMDN) (Hui et al., 2019), and Luo et al.'s lattice block with butterfly structures (Luo et al., 2020). Moreover, researchers have explored neural architecture search for image SR in FALSR (Chu et al., 2019a) and model compression techniques, such as knowledge distillation, for efficient image SR. For instance, He et al. proposed knowledge distillation-based feature-affinity for efficient image SR (He et al., 2020), while Lee et al. trained a teacher network to distill its knowledge to a student network (Lee et al., 2020). Despite the progress made with lightweight networks, further investigation is needed to develop even more efficient image SR models."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Recent years have seen growing interest in developing lightweight image super-resolution (SR) models. Notable contributions include Kim et al.'s recursive learning in DRCN (Kim et al., 2016b), Ahn et al.'s cascading mechanism in CARN (Ahn et al., 2018), and Luo et al.'s lattice block with butterfly structures (Luo et al., 2020). Researchers have also explored neural architecture search and model compression techniques, such as knowledge distillation, for efficient image SR. Despite progress, further investigation is needed to develop even more efficient image SR models."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have gained significant attention in recent years. Researchers have proposed various approaches to design lightweight architectures, leveraging recursive learning and channel splitting. Notable examples include the recursive learning in DRCN (Kim et al., 2016b), the cascading mechanism in CARN (Ahn et al., 2018), and the lightweight information multi-distillation network (Hui et al., 2019). Moreover, neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020), have been explored. While these efforts have achieved significant progress, there is still a need to investigate further for more efficient image SR models."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "instruction": "Can you make my paragraph more concise?", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have garnered significant attention in recent years, focusing on designing compact architectures that leverage recursive learning and channel splitting. Notable examples include recursive learning in DRCN (Kim et al., 2016b), cascading mechanisms in CARN (Ahn et al., 2018), and lightweight information multi-distillation networks (Hui et al., 2019). More recently, neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020), have been explored. Despite the progress made, further research is needed to develop more efficient image SR models.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.05", "instruction": "Use shorter formulations and more direct language to make the paragraph more concise.", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) models have gained attention in recent years. To achieve this, researchers have designed lightweight architectures, leveraging recursive learning and channel splitting. Kim et al. (2016b) introduced recursive learning in DRCN, while Ahn et al. (2018) designed a cascading mechanism for CARN. Other approaches include the lightweight information multi-distillation network (Hui et al., 2019) and lattice block with butterfly structures (Luo et al., 2020). Neural architecture search (Chu et al., 2019a) and model compression techniques, such as knowledge distillation (He et al., 2020; Lee et al., 2020), have also been explored. While these efforts have shown promise, further research is needed to develop more efficient image SR models.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Similar to standard recursive state-space models, the dynamics of our model are conditionally linear given a leaf node zt. It is reasonable to assume that nearby regions in the latent space have similar dynamics, as this is supported by the tree-structured stick breaking partitions that share a common parent. To explicitly model this, we enforce a hierarchical tree-structured prior on the dynamics, ensuring that the model captures this expected similarity."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Similar to standard recursive state-space models, the dynamics of our model are conditionally linear given a leaf node zt. It is reasonable to assume that nearby regions in the latent space have similar dynamics, as this is supported by the tree-structured stick breaking partitions that share a common parent. To explicitly model this, we enforce a hierarchical tree-structured prior on the dynamics, ensuring that the model captures this expected similarity."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Similar to standard recursive state-space models, the dynamics of our model are conditionally linear given a leaf node zt. It is reasonable to assume that nearby regions in the latent space have similar dynamics, as this is supported by the tree-structured stick breaking partitions that share a common parent. To explicitly model this, we enforce a hierarchical tree-structured prior on the dynamics, ensuring that the model captures this expected similarity."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Similar to standard recursive state-space models, the dynamics of our model are conditionally linear given a leaf node zt. It is reasonable to assume that nearby regions in the latent space have similar dynamics, as this is supported by the tree-structured stick breaking partitions that share a common parent. To explicitly model this, we enforce a hierarchical tree-structured prior on the dynamics, ensuring that the model captures this expected similarity."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Similar to standard recursive state-space models, the dynamics of our model are conditionally linear given a leaf node zt. It is reasonable to assume that nearby regions in the latent space have similar dynamics, as this is supported by the tree-structured stick breaking partitions that share a common parent. To explicitly model this, we enforce a hierarchical tree-structured prior on the dynamics, ensuring that the model captures this expected similarity."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Similar to standard recursive state-space models, the dynamics of our model are conditionally linear given a leaf node zt. It is reasonable to assume that nearby regions in the latent space have similar dynamics, as this is supported by the tree-structured stick breaking partitions that share a common parent. To explicitly model this, we enforce a hierarchical tree-structured prior on the dynamics, ensuring that the model captures this expected similarity."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Similar to standard recursive state-space models, the dynamics of our model are conditionally linear given a leaf node zt. It is reasonable to assume that nearby regions in the latent space have similar dynamics, as this is supported by the tree-structured stick breaking partitions that share a common parent. To explicitly model this, we enforce a hierarchical tree-structured prior on the dynamics, ensuring that the model captures this expected similarity."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Similar to standard recursive state-space models, the dynamics of our model are conditionally linear given a leaf node zt. It is reasonable to assume that nearby regions in the latent space have similar dynamics, as this is supported by the tree-structured stick breaking partitions that share a common parent. To explicitly model this, we enforce a hierarchical tree-structured prior on the dynamics, ensuring that the model captures this expected similarity."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "instruction": "Rephrase the paragraph", "revised_paragraph": "Revised paragraph: \"The dynamics of the tree-structured stick breaking partitions are conditionally linear given a leaf node zt, mirroring the standard rSLDS framework. It is logical to assume that nearby regions in latent space exhibit similar dynamics, and this expectation is reinforced by the tree-structured architecture, where partitions sharing a common parent should have analogous dynamic patterns. To capture this hierarchical relationship, we introduce a tree-structured prior on the dynamics, explicitly modeling the similarity in behavior across neighboring partitions.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "S1qImCcFQ.Ske132uA7.00", "instruction": "Make the paragraph more formal.", "revised_paragraph": "Revised paragraph: \"In a manner analogous to traditional rSLDS, the dynamics of the model are conditionally linear given a leaf node z_t. It is reasonable to assume that neighboring regions in the latent space exhibit similar dynamics. Furthermore, in the context of the tree-structured stick-breaking partitions, it is expected that partitions sharing a common parent node will exhibit similar dynamics. To formalize this intuition, we introduce a hierarchical tree-structured prior on the dynamics, which explicitly models this relationship.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We modified the EDSR baseline (Lim et al., 2017) by removing the final convolutional layer to reduce parameters. The reconstruction was performed within the pixel-shuffle layer (Shi et al., 2016). We set the channel number to 256 and then pruned it to 45, resulting in a compressed model named SRPN-L that has 609K parameters, a reduction from 19.5M.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We modified the EDSR baseline (Lim et al., 2017) by removing the final convolutional layer to reduce parameters. The reconstruction was performed within the pixel-shuffle layer (Shi et al., 2016). We set the channel number to 256 and then pruned it to 45, resulting in a compressed model named SRPN-L that has 609K parameters, a reduction from 19.5M.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We modified the EDSR baseline (Lim et al., 2017) by removing the final convolutional layer to reduce parameters. The reconstruction was performed within the pixel-shuffle layer (Shi et al., 2016). We set the channel number to 256 and then pruned it to 45, resulting in a compressed model named SRPN-L that has 609K parameters, a reduction from 19.5M.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We modified the EDSR baseline (Lim et al., 2017) by removing the final convolutional layer to reduce parameters. The reconstruction was performed within the pixel-shuffle layer (Shi et al., 2016). We set the channel number to 256 and then pruned it to 45, resulting in a compressed model named SRPN-L that has 609K parameters, a reduction from 19.5M.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We modified the EDSR baseline (Lim et al., 2017) by removing the final convolutional layer to reduce parameters. The reconstruction was performed within the pixel-shuffle layer (Shi et al., 2016). We set the channel number to 256 and then pruned it to 45, resulting in a compressed model named SRPN-L that has 609K parameters, a reduction from 19.5M.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We modified the EDSR baseline (Lim et al., 2017) by removing the final convolutional layer to reduce parameters. The reconstruction was performed within the pixel-shuffle layer (Shi et al., 2016). We set the channel number to 256 and then pruned it to 45, resulting in a compressed model named SRPN-L that has 609K parameters, a reduction from 19.5M.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We modified the EDSR baseline (Lim et al., 2017) by removing the final convolutional layer to reduce parameters. The reconstruction was performed within the pixel-shuffle layer (Shi et al., 2016). We set the channel number to 256 and then pruned it to 45, resulting in a compressed model named SRPN-L that has 609K parameters, a reduction from 19.5M.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We modified the EDSR baseline (Lim et al., 2017) by removing the final convolutional layer to reduce parameters. The reconstruction was performed within the pixel-shuffle layer (Shi et al., 2016). We set the channel number to 256 and then pruned it to 45, resulting in a compressed model named SRPN-L that has 609K parameters, a reduction from 19.5M.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "instruction": "Please, remove the clarifications that do are not necessary for the development of the idea:", "revised_paragraph": "Revised paragraph: We revised the EDSR baseline by removing the final Conv layer to reduce parameters. The reconstruction was performed within the pixel-shuffle layer, similar to IMDN (Hui et al., 2019). We set the channel number to 256 and then pruned it to 45. This compression resulted in a reduction of parameters from 19.5M to 609K for the \u00d7 2 model, which we named SRPN-L.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.13", "instruction": "Remove Hui et al. citation and improve writing of the paragraph", "revised_paragraph": "Revised paragraph: To reduce the computational cost and memory requirements of the EDSR baseline, we modified the architecture by removing the final convolutional layer, similar to previous works (Lim et al., 2017). The reconstruction process was implemented within the pixel-shuffle layer, as proposed by Shi et al. (2016). We set the channel number in the revised EDSR baseline to 256 and then pruned it to 45. This compression resulted in a significant reduction of parameters from 19.5 million to 609 thousand, and we refer to this compressed model as SRPN-L.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric, with neural network estimators outperforming linear and random forest methods due to their ability to capture non-linear relationships in the data. Notably, TARNet achieves superior overall performance compared to other statistical estimators by combining the strengths of both T-learner and S-learner (R et al., 2019). Nevertheless, the presence of treatment selection bias in these estimators leads to biased results, ultimately compromising their performance."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric, with neural network estimators outperforming linear and random forest methods due to their ability to capture non-linear relationships in the data. Notably, TARNet achieves superior overall performance compared to other statistical estimators by combining the strengths of both T-learner and S-learner (R et al., 2019). Nevertheless, the presence of treatment selection bias in these estimators leads to biased results, ultimately compromising their performance."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric, with neural network estimators outperforming linear and random forest methods due to their ability to capture non-linear relationships in the data. Notably, TARNet achieves superior overall performance compared to other statistical estimators by combining the strengths of both T-learner and S-learner (R et al., 2019). Nevertheless, the presence of treatment selection bias in these estimators leads to biased results, ultimately compromising their performance."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric, with neural network estimators outperforming linear and random forest methods due to their ability to capture non-linear relationships in the data. Notably, TARNet achieves superior overall performance compared to other statistical estimators by combining the strengths of both T-learner and S-learner (R et al., 2019). Nevertheless, the presence of treatment selection bias in these estimators leads to biased results, ultimately compromising their performance."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric, with neural network estimators outperforming linear and random forest methods due to their ability to capture non-linear relationships in the data. Notably, TARNet achieves superior overall performance compared to other statistical estimators by combining the strengths of both T-learner and S-learner (R et al., 2019). Nevertheless, the presence of treatment selection bias in these estimators leads to biased results, ultimately compromising their performance."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric, with neural network estimators outperforming linear and random forest methods due to their ability to capture non-linear relationships in the data. Notably, TARNet achieves superior overall performance compared to other statistical estimators by combining the strengths of both T-learner and S-learner (R et al., 2019). Nevertheless, the presence of treatment selection bias in these estimators leads to biased results, ultimately compromising their performance."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric, with neural network estimators outperforming linear and random forest methods due to their ability to capture non-linear relationships in the data. Notably, TARNet achieves superior overall performance compared to other statistical estimators by combining the strengths of both T-learner and S-learner (R et al., 2019). Nevertheless, the presence of treatment selection bias in these estimators leads to biased results, ultimately compromising their performance."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric, with neural network estimators outperforming linear and random forest methods due to their ability to capture non-linear relationships in the data. Notably, TARNet achieves superior overall performance compared to other statistical estimators by combining the strengths of both T-learner and S-learner (R et al., 2019). Nevertheless, the presence of treatment selection bias in these estimators leads to biased results, ultimately compromising their performance."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "instruction": "The second sentence is too complicated. Make it more understandable. Also brush up the rest.", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric. Specifically, neural network estimators outperform linear and random forest methods because they can effectively capture non-linear relationships in the data. TARNet achieves better overall performance than other statistical estimators by combining the strengths of T-learner and S-learner (R et al., 2019). However, the treatment selection bias introduces a significant limitation, as it leads to biased estimates and sub-optimal performance.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.14", "instruction": "Reorganize the ideas in the sentences to improve the logical flow of the text.", "revised_paragraph": "Revised paragraph: Statistical estimators demonstrate competitive performance on the PEHE metric, with neural network estimators outperforming linear and random forest methods due to their ability to capture nonlinearity in data. Notably, TARNet achieves better overall performance by combining the advantages of T-learner and S-learner (R et al., 2019). However, the treatment selection bias inherent in these estimators leads to biased results, ultimately compromising their performance.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This paper provides generalization error bounds for deep ReLU networks on the Besov space and its variant with mixed smoothness, which encompasses the H\u00a8older space, Sobolev space, and function class with total variation as special cases. We show that deep learning achieves the minimax optimal rate on the Besov space, outperforming linear estimators like kernel ridge regression, and can avoid the curse of dimensionality on the mixed smooth Besov space."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This paper provides generalization error bounds for deep ReLU networks on the Besov space and its variant with mixed smoothness, which encompasses the H\u00a8older space, Sobolev space, and function class with total variation as special cases. We show that deep learning achieves the minimax optimal rate on the Besov space, outperforming linear estimators like kernel ridge regression, and can avoid the curse of dimensionality on the mixed smooth Besov space."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This paper provides generalization error bounds for deep ReLU networks on the Besov space and its variant with mixed smoothness, which encompasses the H\u00a8older space, Sobolev space, and function class with total variation as special cases. We show that deep learning achieves the minimax optimal rate on the Besov space, outperforming linear estimators like kernel ridge regression, and can avoid the curse of dimensionality on the mixed smooth Besov space."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This paper provides generalization error bounds for deep ReLU networks on the Besov space and its variant with mixed smoothness, which encompasses the H\u00a8older space, Sobolev space, and function class with total variation as special cases. We show that deep learning achieves the minimax optimal rate on the Besov space, outperforming linear estimators like kernel ridge regression, and can avoid the curse of dimensionality on the mixed smooth Besov space."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This paper provides generalization error bounds for deep ReLU networks on the Besov space and its variant with mixed smoothness, which encompasses the H\u00a8older space, Sobolev space, and function class with total variation as special cases. We show that deep learning achieves the minimax optimal rate on the Besov space, outperforming linear estimators like kernel ridge regression, and can avoid the curse of dimensionality on the mixed smooth Besov space."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This paper provides generalization error bounds for deep ReLU networks on the Besov space and its variant with mixed smoothness, which encompasses the H\u00a8older space, Sobolev space, and function class with total variation as special cases. We show that deep learning achieves the minimax optimal rate on the Besov space, outperforming linear estimators like kernel ridge regression, and can avoid the curse of dimensionality on the mixed smooth Besov space."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This paper provides generalization error bounds for deep ReLU networks on the Besov space and its variant with mixed smoothness, which encompasses the H\u00a8older space, Sobolev space, and function class with total variation as special cases. We show that deep learning achieves the minimax optimal rate on the Besov space, outperforming linear estimators like kernel ridge regression, and can avoid the curse of dimensionality on the mixed smooth Besov space."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This paper provides generalization error bounds for deep ReLU networks on the Besov space and its variant with mixed smoothness, which encompasses the H\u00a8older space, Sobolev space, and function class with total variation as special cases. We show that deep learning achieves the minimax optimal rate on the Besov space, outperforming linear estimators like kernel ridge regression, and can avoid the curse of dimensionality on the mixed smooth Besov space."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "instruction": "Remove unnecessary details.", "revised_paragraph": "Revised paragraph: \"This paper provides generalization error bounds for deep ReLU networks on the Besov space and its variant with mixed smoothness, which encompasses the H\u00a8older space, Sobolev space, and function class with total variation as special cases. We show that deep learning achieves the minimax optimal rate on the Besov space, outperforming linear estimators like kernel ridge regression, and avoids the curse of dimensionality on the mixed smooth Besov space. Our work addresses a gap in existing literature, as previous approximation error analyses, such as those by Mhaskar & Micchelli (1992) and Pinkus (1999), excluded ReLU activation and did not provide comprehensive analyses for the Besov space. This paper therefore clarifies whether ReLU neural networks can outperform representative methods like kernel methods.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "Skrry_KpQ.rJKpSniHN.00", "instruction": "The end of the paragraph is too long, remove the part that fit the less in it.", "revised_paragraph": "Revised paragraph: In this paper, we give generalization error bounds of deep ReLU networks for a Besov space and its variant with mixed smoothness, which includes the H\u00a8older space, the Sobolev space, and the function class with total variation as special cases. By doing so, we show that deep learning achieves the minimax optimal rate on the Besov space and notably it outperforms any linear estimator such as the kernel ridge regression.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The primary issue arises from the mass preservation constraint, which forces units that are outliers at the mini-batch level to be transported, as illustrated in Figure 1. This constraint hinders the transport of normal units and makes the group discrepancy susceptible to the sampling effect, particularly when the batch size is small."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The primary issue arises from the mass preservation constraint, which forces units that are outliers at the mini-batch level to be transported, as illustrated in Figure 1. This constraint hinders the transport of normal units and makes the group discrepancy susceptible to the sampling effect, particularly when the batch size is small."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The primary issue arises from the mass preservation constraint, which forces units that are outliers at the mini-batch level to be transported, as illustrated in Figure 1. This constraint hinders the transport of normal units and makes the group discrepancy susceptible to the sampling effect, particularly when the batch size is small."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The primary issue arises from the mass preservation constraint, which forces units that are outliers at the mini-batch level to be transported, as illustrated in Figure 1. This constraint hinders the transport of normal units and makes the group discrepancy susceptible to the sampling effect, particularly when the batch size is small."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The primary issue arises from the mass preservation constraint, which forces units that are outliers at the mini-batch level to be transported, as illustrated in Figure 1. This constraint hinders the transport of normal units and makes the group discrepancy susceptible to the sampling effect, particularly when the batch size is small."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The primary issue arises from the mass preservation constraint, which forces units that are outliers at the mini-batch level to be transported, as illustrated in Figure 1. This constraint hinders the transport of normal units and makes the group discrepancy susceptible to the sampling effect, particularly when the batch size is small."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The primary issue arises from the mass preservation constraint, which forces units that are outliers at the mini-batch level to be transported, as illustrated in Figure 1. This constraint hinders the transport of normal units and makes the group discrepancy susceptible to the sampling effect, particularly when the batch size is small."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The primary issue arises from the mass preservation constraint, which forces units that are outliers at the mini-batch level to be transported, as illustrated in Figure 1. This constraint hinders the transport of normal units and makes the group discrepancy susceptible to the sampling effect, particularly when the batch size is small."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "instruction": "Rewrite so that it looks more organized", "revised_paragraph": "Revised paragraph: The mass preservation constraint is the primary source of this issue. Specifically, as shown in Figure 1, units that act as outliers at the mini-batch level are forced to be transported by this constraint, which hinders the transport of normal units and makes the group discrepancy vulnerable to the sampling effect. Furthermore, this issue is exacerbated by the small batch size.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "instruction": "Rewrite this paragraph to make it more easily readable.", "revised_paragraph": "Revised paragraph: The main challenge arises from the mass preservation constraint, which has a significant impact on the transportation of units. As shown in Figure 1, units that are outliers at the mini-batch level are forced to be transported, which hinders the movement of normal units and makes the group discrepancy more susceptible to sampling errors. Furthermore, the issue is exacerbated by the small batch size, leading to a more pronounced effect.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a random set Y0 drawn from a normal distribution with mean 0 and variance I/10. Alternatively, we can employ a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer when comparing the performance of iDSPN and DSPN in Subsection 4.2."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a randomly sampled set Y0 \u223c N(0, I/10). Alternatively, we can leverage a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer in Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer in Equation 6 to provide a gradient for Y0, as proposed by Rajeswaran et al. (2019), specifically \u03bb\u2016Y - Y\u20162. We will utilize this regularizer when comparing the performance of iDSPN to DSPN in Subsection 4.2."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a random set Y0 drawn from a normal distribution with mean 0 and variance I/10. Alternatively, we can employ a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer when comparing the performance of iDSPN and DSPN in Subsection 4.2."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a random set Y0 drawn from a normal distribution with mean 0 and variance I/10. Alternatively, we can employ a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer when comparing the performance of iDSPN and DSPN in Subsection 4.2."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a randomly sampled set Y0 \u223c N(0, I/10). Alternatively, we can leverage a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer in Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer in Equation 6 to provide a gradient for Y0, as proposed by Rajeswaran et al. (2019), specifically \u03bb\u2016Y - Y\u20162. We will utilize this regularizer when comparing the performance of iDSPN to DSPN in Subsection 4.2."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a random set Y0 drawn from a normal distribution with mean 0 and variance I/10. Alternatively, we can employ a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer when comparing the performance of iDSPN and DSPN in Subsection 4.2."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a random set Y0 drawn from a normal distribution with mean 0 and variance I/10. Alternatively, we can employ a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer when comparing the performance of iDSPN and DSPN in Subsection 4.2."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: By default, the optimization process is initialized with a random set Y0 drawn from a normal distribution with a mean of 0 and a variance of 1/10. Alternatively, we can utilize a learned initial set Y0 to commence the optimization closer to a solution, similar to the approach employed by DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this limitation, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer in our comparison of the performance of iDSPN and DSPN in Subsection 4.2."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a random set Y0 drawn from a normal distribution with mean 0 and variance I/10. Alternatively, we can employ a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer when comparing the performance of iDSPN and DSPN in Subsection 4.2."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a random set Y0 drawn from a normal distribution with mean 0 and variance I/10. Alternatively, we can employ a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer when comparing the performance of iDSPN and DSPN in Subsection 4.2."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: By default, the optimization process is initialized with a random set Y0 drawn from a normal distribution with a mean of 0 and a variance of 1/10. Alternatively, we can utilize a learned initial set Y0 to commence the optimization closer to a solution, similar to the approach employed by DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this limitation, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer in our comparison of the performance of iDSPN and DSPN in Subsection 4.2."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: By default, we initialize the optimization process with a random set Y0 drawn from a normal distribution with mean 0 and variance I/10. Alternatively, we can employ a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the use of gradient information for Y0. To address this, we incorporate a regularizer into Equation 6, as proposed by Rajeswaran et al. (2019), which provides a gradient for Y0. We will utilize this regularizer when comparing the performance of iDSPN and DSPN in Subsection 4.2."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "instruction": "Clarify your last sentence.", "revised_paragraph": "Revised paragraph: By default, we sample a random initial set Y0 \u223c N(0, I/10) to initiate the optimization process. Alternatively, we can utilize a learned initial set Y0 to start the optimization closer to a solution, similar to DSPN. However, implicit differentiation treats the optimizer of Equation 7 as a black box, precluding the availability of a gradient signal for Y0. To address this, we incorporate a regularizer in Equation 6, such as the one proposed by Rajeswaran et al. (2019), \u03bb||Y-Y||2, to provide a gradient for Y0. This regularizer will be employed in Subsection 4.2 when comparing the performance of iDSPN to DSPN.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.11", "instruction": "Make the last sentence more precise.", "revised_paragraph": "Revised paragraph: By default, we sample a random initial set Y0 \u223c N(0, I/10) to start the optimization process. Similar to DSPN, we can also employ a learned initial set Y0 to initiate the optimization closer to a solution. However, implicit differentiation treats the optimizer of Equation 7 as a black box, rendering unavailable the gradient signal for Y0. To address this, we incorporate a regularizer in Equation 6 to provide a gradient for Y0, specifically the one proposed by Rajeswaran et al. (2019): \u03bb ||Y - Y||2. We will utilize this regularizer when comparing iDSPN to DSPN performance in Subsection 4.2.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We conducted experiments on the MNIST dataset with 1000 training images, disabling all external regularization schemes except learning rate decay and batch normalization. We compared full-batch gradient descent (GD) with various learning rates and full-batch gradient descent with momentum (GD+M) with a fixed step-size. Our results show that GD+M outperformed GD, achieving a test accuracy of 96% compared to 95%. This suggests that the implicit regularization effect of momentum outweighs the sharpness effect, leading to better test accuracy.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: The MNIST dataset with 1000 training images was used, with all regularization schemes except learning rate decay and batch normalization disabled. We compared full-batch gradient descent (GD) with various learning rates and momentum (GD+M) with different \u03b2 values. The best test accuracy for GD was 95% (Figure 2), while for GD+M it was 96% (Figure 3). Our results show that GD+M outperformed GD, despite GD's ability to increase sharpness and enter a sharper region before becoming unstable, as previously observed by Cohen et al. (2021). We attribute this to the implicit regularization provided by momentum, which outweighs the sharpness effect in achieving better test accuracy."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The MNIST dataset with 1000 training images was used, with all regularization schemes except learning rate decay and batch normalization disabled. We compared full-batch gradient descent (GD) with various learning rates and momentum (GD+M) with different \u03b2 values. The best test accuracy for GD was 95% (Figure 2), while for GD+M it was 96% (Figure 3). Our results show that GD+M outperformed GD, despite GD's ability to increase sharpness and enter a sharper region before becoming unstable, as previously observed by Cohen et al. (2021). We attribute this to the implicit regularization provided by momentum, which outweighs the sharpness effect in achieving better test accuracy."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We conducted experiments on the MNIST dataset with 1000 training images, disabling all external regularization schemes except learning rate decay and batch normalization. We compared full-batch gradient descent (GD) with various learning rates and full-batch gradient descent with momentum (GD+M) with a fixed step-size. Our results show that GD+M outperformed GD, achieving a test accuracy of 96% compared to 95%. This suggests that the implicit regularization effect of momentum outweighs the sharpness effect, leading to better test accuracy.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: The MNIST dataset with 1000 training images was used, with all regularization schemes except learning rate decay and batch normalization disabled. We compared full-batch gradient descent (GD) with various learning rates and momentum (GD+M) with different \u03b2 values. The best test accuracy for GD was 95% (Figure 2), while for GD+M it was 96% (Figure 3). Our results show that GD+M outperformed GD, despite GD's ability to increase sharpness and enter a sharper region before becoming unstable, as previously observed by Cohen et al. (2021). We attribute this to the implicit regularization provided by momentum, which outweighs the sharpness effect in achieving better test accuracy."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The MNIST dataset with 1000 training images was used, with all regularization schemes except learning rate decay and batch normalization disabled. We compared full-batch gradient descent (GD) with various learning rates and momentum (GD+M) with different \u03b2 values. The best test accuracy for GD was 95% (Figure 2), while for GD+M it was 96% (Figure 3). Our results show that GD+M outperformed GD, despite GD's ability to increase sharpness and enter a sharper region before becoming unstable, as previously observed by Cohen et al. (2021). We attribute this to the implicit regularization provided by momentum, which outweighs the sharpness effect in achieving better test accuracy."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We conducted experiments on the MNIST dataset with 1000 training images, disabling all external regularization schemes except learning rate decay and batch normalization. We compared full-batch gradient descent (GD) with various learning rates and full-batch gradient descent with momentum (GD+M) with a fixed step-size. Our results show that GD+M outperformed GD, achieving a test accuracy of 96% compared to 95%. This suggests that the implicit regularization effect of momentum outweighs the sharpness effect, leading to better test accuracy.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimented with the MNIST dataset, using 1000 training images and disabling all external regularization schemes except learning rate decay and batch normalization. We compared full-batch gradient descent (GD) with various learning rates to GD with momentum (GD+M), using a fixed step-size. Results showed that GD+M outperformed GD, achieving 96% test accuracy compared to 95%, indicating that momentum's implicit regularization effect outweighs the sharpness effect.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The MNIST dataset with 1000 training images was used, with all regularization schemes except learning rate decay and batch normalization disabled. We compared full-batch gradient descent (GD) with various learning rates and momentum (GD+M) with different \u03b2 values. The best test accuracy for GD was 95% (Figure 2), while for GD+M it was 96% (Figure 3). Our results show that GD+M outperformed GD, despite GD's ability to increase sharpness and enter a sharper region before becoming unstable, as previously observed by Cohen et al. (2021). We attribute this to the implicit regularization provided by momentum, which outweighs the sharpness effect in achieving better test accuracy."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We conducted experiments on the MNIST dataset with 1000 training images, disabling all external regularization schemes except learning rate decay and batch normalization. We compared full-batch gradient descent (GD) with various learning rates and full-batch gradient descent with momentum (GD+M) with a fixed step-size. Our results show that GD+M outperformed GD, achieving a test accuracy of 96% compared to 95%. This suggests that the implicit regularization effect of momentum outweighs the sharpness effect, leading to better test accuracy.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimented with the MNIST dataset, using 1000 training images and disabling all external regularization schemes except learning rate decay and batch normalization. We compared full-batch gradient descent (GD) with various learning rates to GD with momentum (GD+M), using a fixed step-size. Results showed that GD+M outperformed GD, achieving 96% test accuracy compared to 95%, indicating that momentum's implicit regularization effect outweighs the sharpness effect.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The MNIST dataset with 1000 training images was used, with all regularization schemes except learning rate decay and batch normalization disabled. We compared full-batch gradient descent (GD) with various learning rates and momentum (GD+M) with different \u03b2 values. The best test accuracy for GD was 95% (Figure 2), while for GD+M it was 96% (Figure 3). Our results show that GD+M outperformed GD, despite GD's ability to increase sharpness and enter a sharper region before becoming unstable, as previously observed by Cohen et al. (2021). We attribute this to the implicit regularization provided by momentum, which outweighs the sharpness effect in achieving better test accuracy."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "instruction": "Summarize heavily the results and explanations obtained. Fix any typos.", "revised_paragraph": "Revised paragraph: \n\nThe MNIST dataset with 1000 training images was used to compare the performance of full-batch gradient descent (GD) and GD with momentum (GD+M). GD was run with various learning rates, achieving a best test accuracy of 95% (Figure 2). GD+M was run with various momentum values, fixed at a step-size of 0.1, achieving a best test accuracy of 96% (Figure 3). Notably, the best performance of GD was outperformed by the best performance of GD+M. This contradicts the expectation that the greater allowable sharpness of GD+M would result in better test accuracy, as suggested by Cohen et al. (2021). Instead, we propose that the implicit regularization provided by momentum in GD+M outweighs the sharpness effect, leading to improved test accuracy.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "instruction": "Summarize the second half of the paragraph to make the paragraph shorter.", "revised_paragraph": "Revised paragraph: \"We performed experiments on the MNIST dataset with 1000 training images, disabling all external regularization schemes except learning rate decay and batch normalization. We compared full-batch gradient descent (GD) with various learning rates and full-batch gradient descent with momentum (GD+M) with a fixed step-size. Our results show that GD+M outperforms GD, with a best test accuracy of 96%. This suggests that the implicit regularization provided by momentum outweighs the sharpness effect, leading to better test accuracy, contrary to what is expected based on the edge of stability theory.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We developed a novel influence analysis to understand the effects of graph elements on GCN parameter changes without retraining the GCNs. Our method, based on Simple Graph Convolution, can approximate the changes in model parameters caused by edge or node removals from an attributed graph. We provided theoretical bounds on the estimation error and experimentally validated the accuracy and effectiveness of our influence functions. Our results show that our method can reliably identify edges and nodes with negative and positive influences on model performance, and can be applied to graph rectification and model attacks."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We developed a novel influence analysis to understand the effects of graph elements on GCN parameter changes without retraining the GCNs. Our method, based on Simple Graph Convolution, can approximate the changes in model parameters caused by edge or node removals from an attributed graph. We provided theoretical bounds on the estimation error and experimentally validated the accuracy and effectiveness of our influence functions. Our results show that our method can reliably identify edges and nodes with negative and positive influences on model performance, and can be applied to graph rectification and model attacks."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We developed a novel influence analysis to understand the effects of graph elements on GCN parameter changes without retraining the GCNs. Our method, based on Simple Graph Convolution, can approximate the changes in model parameters caused by edge or node removals from an attributed graph. We provided theoretical bounds on the estimation error and experimentally validated the accuracy and effectiveness of our influence functions. Our results show that our method can reliably identify edges and nodes with negative and positive influences on model performance, and can be applied to graph rectification and model attacks."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We developed a novel influence analysis to understand the effects of graph elements on GCN parameter changes without retraining the GCNs. Our method, based on Simple Graph Convolution, can approximate the changes in model parameters caused by edge or node removals from an attributed graph. We provided theoretical bounds on the estimation error and experimentally validated the accuracy and effectiveness of our influence functions. Our results show that our method can reliably identify edges and nodes with negative and positive influences on model performance, and can be applied to graph rectification and model attacks."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We developed a novel influence analysis to understand the effects of graph elements on GCN parameter changes without retraining the GCNs. Our method, based on Simple Graph Convolution, can approximate the changes in model parameters caused by edge or node removals from an attributed graph. We provided theoretical bounds on the estimation error and experimentally validated the accuracy and effectiveness of our influence functions. Our results show that our method can reliably identify edges and nodes with negative and positive influences on model performance, and can be applied to graph rectification and model attacks."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We developed a novel influence analysis to understand the effects of graph elements on GCN parameter changes without retraining the GCNs. Our method, based on Simple Graph Convolution, can approximate the changes in model parameters caused by edge or node removals from an attributed graph. We provided theoretical bounds on the estimation error and experimentally validated the accuracy and effectiveness of our influence functions. Our results show that our method can reliably identify edges and nodes with negative and positive influences on model performance, and can be applied to graph rectification and model attacks."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We developed a novel influence analysis to understand the effects of graph elements on GCN parameter changes without retraining the GCNs. Our method, based on Simple Graph Convolution, can approximate the changes in model parameters caused by edge or node removals from an attributed graph. We provided theoretical bounds on the estimation error and experimentally validated the accuracy and effectiveness of our influence functions. Our results show that our method can reliably identify edges and nodes with negative and positive influences on model performance, and can be applied to graph rectification and model attacks."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We developed a novel influence analysis to understand the effects of graph elements on GCN parameter changes without retraining the GCNs. Our method, based on Simple Graph Convolution, can approximate the changes in model parameters caused by edge or node removals from an attributed graph. We provided theoretical bounds on the estimation error and experimentally validated the accuracy and effectiveness of our influence functions. Our results show that our method can reliably identify edges and nodes with negative and positive influences on model performance, and can be applied to graph rectification and model attacks."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "instruction": "Remove the last sentence of this paragraph.", "revised_paragraph": "Revised paragraph: \"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by edge or node removals from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the edge and node influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "ydudDS_QrK.dSEEUtAQ1H.00", "instruction": "Delete the last sentence of this paragraph.", "revised_paragraph": "Revised paragraph: \"We have developed a novel influence analysis to understand the effects of graph elements on the parameter changes of GCNs without needing to retrain the GCNs. We chose Simple Graph Convolution due to its convexity and its competitive performance to non-linear GNNs on a variety of tasks. Our influence functions can be used to approximate the changes in model parameters caused by edge or node removals from an attributed graph. Moreover, we provided theoretical bounds on the estimation error of the edge and node influence on model parameters. We experimentally validated the accuracy and effectiveness of our influence functions by comparing its estimation with the actual influence obtained by model retraining. We showed in our experiments that our influence functions could be used to reliably identify edge and node with negative and positive influences on model performance.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: A main effect was observed for Position, with movement times significantly longer in the Inside position compared to the Outside position. Furthermore, a significant interaction was found between Intensity and Position. At the lowest intensity level (I = 0), movement times increased by approximately 11.8% in the Inside position and by approximately 4.93% in the Outside position, compared to the condition without a notch."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"A main effect of Position was observed, with movement time significantly longer for Position = Inside compared to Position = Outside. Furthermore, a significant interaction between I and Position was noted. At I = 0, movement time increased by approximately 11.8% in Position = Inside and 4.93% in Position = Outside, relative to the condition with no notch.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: A main effect was observed for Position, with movement times significantly longer in the Inside position compared to the Outside position. Furthermore, a significant interaction was found between Intensity and Position. At the lowest intensity level (I = 0), movement times increased by approximately 11.8% in the Inside position and by approximately 4.93% in the Outside position, compared to the condition without a notch."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"A main effect of Position was observed, with movement time significantly longer for Position = Inside compared to Position = Outside. Furthermore, a significant interaction between I and Position was noted. At I = 0, movement time increased by approximately 11.8% in Position = Inside and 4.93% in Position = Outside, relative to the condition with no notch.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: A main effect was observed for Position, with movement times significantly longer in the Inside position compared to the Outside position. Furthermore, a significant interaction was found between Intensity and Position. At the lowest intensity level (I = 0), movement times increased by approximately 11.8% in the Inside position and by approximately 4.93% in the Outside position, compared to the condition without a notch."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: A significant main effect was observed for Position, with movement times significantly longer in the Inside position compared to the Outside position. Additionally, a significant interaction was found between Intensity and Position. At the lowest intensity level (I = 0), movement times increased by approximately 11.8% in the Inside position and by approximately 4.93% in the Outside position, relative to the condition without a notch."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: A main effect was observed for Position, with movement times significantly longer in the Inside position compared to the Outside position. Furthermore, a significant interaction was found between Intensity and Position. At the lowest intensity level (I = 0), movement times increased by approximately 11.8% in the Inside position and by approximately 4.93% in the Outside position, compared to the condition without a notch."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"A main effect of Position was observed, with movement time significantly longer for Position = Inside compared to Position = Outside. Furthermore, a significant interaction between I and Position was noted. At I = 0, movement time increased by approximately 11.8% in Position = Inside and 4.93% in Position = Outside, relative to the condition with no notch.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "instruction": "Modify the first sentence", "revised_paragraph": "Revised paragraph: The analysis revealed a significant main effect of Position, with movement times being longer when the notch was located inside the object (Position = Inside) compared to when it was located outside (Position = Outside). Furthermore, a significant interaction was observed between the notch's initial position (I) and Position, indicating that the movement time was influenced by both factors. Specifically, at I = 0, movement times increased by approximately 11.8% in Position = Inside and 4.93% in Position = Outside, compared to the condition with no notch.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.14", "instruction": "Revise this text to make it more readable and direct.", "revised_paragraph": "Revised paragraph: Our analysis revealed a significant main effect of Position, with movement times significantly longer in the Inside position compared to the Outside position. Furthermore, we found a significant interaction between Intensity and Position. Specifically, when Intensity was set to 0, movement times increased by approximately 11.8% in the Inside position and 4.93% in the Outside position, relative to the condition with no notch.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our results are presented in Table 2. Notably, iDSPN is able to solve the problem at any training set size, thanks to its exclusive multiset-equivariant architecture, which is similar to DSPN. As expected, set-equivariant models are unable to solve this task, as they cannot map equal input elements to distinct output elements. This limitation applies to transformers with random position embeddings, which, like TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020), rely on noise to differentiate between elements. In contrast, transformers with position encoding and BiLSTM require significantly more training samples (at least 100 times more) to achieve comparable performance to iDSPN. This is because they lack the correct structural bias, failing to disregard the order of elements, which makes them less sample-efficient. Moreover, non-equivariant models are unlikely to benefit significantly from additional training data, as they overfit on smaller datasets but not on larger ones."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our results are presented in Table 2. Notably, iDSPN is able to solve the problem at any training set size, thanks to its exclusive multiset-equivariant architecture, which is similar to DSPN. As expected, set-equivariant models are unable to solve this task, as they cannot map equal input elements to distinct output elements. This limitation applies to transformers with random position embeddings, which, like TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020), rely on noise to differentiate between elements. In contrast, transformers with position encoding and BiLSTM require significantly more training samples (at least 100 times more) to achieve comparable performance to iDSPN. This is because they lack the correct structural bias, failing to disregard the order of elements, which makes them less sample-efficient. Moreover, non-equivariant models are unlikely to benefit significantly from additional training data, as they overfit on smaller datasets but not on larger ones."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our results are presented in Table 2. Notably, iDSPN is able to solve the problem at any training set size, thanks to its exclusive multiset-equivariant architecture, which is similar to DSPN. As expected, set-equivariant models are unable to solve this task, as they cannot map equal input elements to distinct output elements. This limitation applies to transformers with random position embeddings, which, like TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020), rely on noise to differentiate between elements. In contrast, transformers with position encoding and BiLSTM require significantly more training samples (at least 100 times more) to achieve comparable performance to iDSPN. This is because they lack the correct structural bias, failing to disregard the order of elements, which makes them less sample-efficient. Moreover, non-equivariant models are unlikely to benefit significantly from additional training data, as they overfit on smaller datasets but not on larger ones."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our results are presented in Table 2. Notably, iDSPN is able to solve the problem at any training set size, thanks to its exclusive multiset-equivariant architecture, which is similar to DSPN. As expected, set-equivariant models are unable to solve this task, as they cannot map equal input elements to distinct output elements. This limitation applies to transformers with random position embeddings, which, like TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020), rely on noise to differentiate between elements. In contrast, transformers with position encoding and BiLSTM require significantly more training samples (at least 100 times more) to achieve comparable performance to iDSPN. This is because they lack the correct structural bias, failing to disregard the order of elements, which makes them less sample-efficient. Moreover, non-equivariant models are unlikely to benefit significantly from additional training data, as they overfit on smaller datasets but not on larger ones."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our results are presented in Table 2. Notably, iDSPN is able to solve the problem at any training set size, thanks to its exclusive multiset-equivariant architecture, which is similar to DSPN. As expected, set-equivariant models are unable to solve this task, as they cannot map equal input elements to distinct output elements. This limitation applies to transformers with random position embeddings, which, like TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020), rely on noise to differentiate between elements. In contrast, transformers with position encoding and BiLSTM require significantly more training samples (at least 100 times more) to achieve comparable performance to iDSPN. This is because they lack the correct structural bias, failing to disregard the order of elements, which makes them less sample-efficient. Moreover, non-equivariant models are unlikely to benefit significantly from additional training data, as they overfit on smaller datasets but not on larger ones."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our results are presented in Table 2. Notably, iDSPN is able to solve the problem at any training set size, thanks to its exclusive multiset-equivariant architecture, which is similar to DSPN. As expected, set-equivariant models are unable to solve this task, as they cannot map equal input elements to distinct output elements. This limitation applies to transformers with random position embeddings, which, like TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020), rely on noise to differentiate between elements. In contrast, transformers with position encoding and BiLSTM require significantly more training samples (at least 100 times more) to achieve comparable performance to iDSPN. This is because they lack the correct structural bias, failing to disregard the order of elements, which makes them less sample-efficient. Moreover, non-equivariant models are unlikely to benefit significantly from additional training data, as they overfit on smaller datasets but not on larger ones."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our results are presented in Table 2. Notably, iDSPN is able to solve the problem at any training set size, thanks to its exclusive multiset-equivariant architecture, which is similar to DSPN. As expected, set-equivariant models are unable to solve this task, as they cannot map equal input elements to distinct output elements. This limitation applies to transformers with random position embeddings, which, like TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020), rely on noise to differentiate between elements. In contrast, transformers with position encoding and BiLSTM require significantly more training samples (at least 100 times more) to achieve comparable performance to iDSPN. This is because they lack the correct structural bias, failing to disregard the order of elements, which makes them less sample-efficient. Moreover, non-equivariant models are unlikely to benefit significantly from additional training data, as they overfit on smaller datasets but not on larger ones."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our results are presented in Table 2. Notably, iDSPN is able to solve the problem at any training set size, thanks to its exclusive multiset-equivariant architecture, which is similar to DSPN. As expected, set-equivariant models are unable to solve this task, as they cannot map equal input elements to distinct output elements. This limitation applies to transformers with random position embeddings, which, like TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020), rely on noise to differentiate between elements. In contrast, transformers with position encoding and BiLSTM require significantly more training samples (at least 100 times more) to achieve comparable performance to iDSPN. This is because they lack the correct structural bias, failing to disregard the order of elements, which makes them less sample-efficient. Moreover, non-equivariant models are unlikely to benefit significantly from additional training data, as they overfit on smaller datasets but not on larger ones."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "instruction": "Simplify the second sentence.", "revised_paragraph": "Revised paragraph: \"Results Table 2 shows our results. Our model, iDSPN, is effective at solving the problem, even with small training sets, due to its multiset-equivariant design. In contrast, set-equivariant models struggle to solve this task because they cannot distinguish between equal input elements. This limitation also applies to transformers with random position embeddings, which, like TSPN and Slot Attention, use noise to make elements distinct. Meanwhile, transformers with position encoding and BiLSTM require significantly more training samples to approach iDSPN's performance, likely due to their reliance on element order. Note that non-equivariant models are unlikely to improve significantly with additional training data, as they overfit on smaller datasets.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.14", "instruction": "Rewrite the 2nd sentence to make it easier to read and less confusing.", "revised_paragraph": "Revised paragraph: Results Table 2 displays our findings. Our model, iDSPN, demonstrates exceptional performance by being exclusively multiset-equivariant, similar to DSPN. In contrast, set-equivariant models struggle to solve this task due to their inability to differentiate between identical input elements. This limitation applies to transformers with random position embeddings, which, like TSPN (Kosiorek et al., 2020) and Slot Attention (Locatello et al., 2020), rely on noise to distinguish between elements. Meanwhile, transformers with position encoding and BiLSTM require significantly more training samples (at least 100 times more) to approach the performance of iDSPN. This is because they lack the structural bias that iDSPN possesses, which makes them less sample-efficient. Note that non-equivariant models are unlikely to benefit significantly from additional training data, as they tend to overfit on smaller datasets.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our framework considers two types of constraints: fixed constraints, where the constraint functions are the same across time and do not need to be known when making decisions; and adversarial constraints, where the constraint function is unknown and can be arbitrarily chosen, as in [14, 17, 29, 33, 24, 20, 30]."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our framework considers two types of constraints: fixed constraints, where the constraint functions are the same across time and do not need to be known when making decisions; and adversarial constraints, where the constraint function is unknown and can be arbitrarily chosen, as in [14, 17, 29, 33, 24, 20, 30]."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our framework considers two types of constraints: fixed constraints, where the constraint functions are the same across time and do not need to be known when making decisions; and adversarial constraints, where the constraint function is unknown and can be arbitrarily chosen, as in [14, 17, 29, 33, 24, 20, 30]."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our framework considers two types of constraints: fixed constraints, where the constraint functions are the same across time and do not need to be known when making decisions; and adversarial constraints, where the constraint function is unknown and can be arbitrarily chosen, as in [14, 17, 29, 33, 24, 20, 30]."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our framework considers two types of constraints: fixed constraints, where the constraint functions are the same across time and do not need to be known when making decisions; and adversarial constraints, where the constraint function is unknown and can be arbitrarily chosen, as in [14, 17, 29, 33, 24, 20, 30]."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our framework considers two types of constraints: fixed constraints, where the constraint functions are the same across time and do not need to be known when making decisions; and adversarial constraints, where the constraint function is unknown and can be arbitrarily chosen, as in [14, 17, 29, 33, 24, 20, 30]."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our framework considers two types of constraints: fixed constraints, where the constraint functions are the same across time and do not need to be known when making decisions; and adversarial constraints, where the constraint function is unknown and can be arbitrarily chosen, as in [14, 17, 29, 33, 24, 20, 30]."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our framework considers two types of constraints: fixed constraints, where the constraint functions are the same across time and do not need to be known when making decisions; and adversarial constraints, where the constraint function is unknown and can be arbitrarily chosen, as in [14, 17, 29, 33, 24, 20, 30]."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "instruction": "Make paragraph more concise", "revised_paragraph": "Revised paragraph: \"Our framework considers two types of constraints. First, fixed constraints g t p x q \u201c g p x q, @ t, where the constraint functions are identical across time and do not need to be known at decision-making time t. This setting is a special case of ours, as shown in [14, 17, 29, 33]. Second, adversarial constraints g t p x q, where the constraint function g t p x q is unknown and can be arbitrarily chosen at time t, similar to [24, 20, 30].\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.00", "instruction": "Make this paragraph shorter.", "revised_paragraph": "Revised paragraph: Our framework allows for both fixed and adversarial constraints. In the former case, the constraint functions are the same across time, but need not be known when making decisions at round t. This setting is a special case of ours, as seen in [14, 17, 29, 33]. In the latter case, the constraint function can be arbitrarily and adversarially chosen, as in [24, 20, 30].", "type_approach": "instruction-annot_2"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our algorithms differ from existing ones in several ways. Unlike ESTR [17] and -FALB [15], our approach is designed for nonlinear reward frameworks. Compared to LowGLOC [26], our algorithms achieve better regret bounds, can handle varying action sets, and are computationally feasible. We extend GLM-UCB [11] with a regularization technique and novel methods to propose G-ESTS, a simple and easily implementable algorithm. When combined with efficient algorithms like SGD-TS [9], G-ESTS's total time complexity scales as O(Tr(d1+d2))."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our algorithms differ from existing methods in several key ways. Unlike ESTR [17] and -FALB [15], our approach is designed for nonlinear reward frameworks. Compared to LowGLOC [26], our algorithms not only achieve a better regret bound but also accommodate varying action sets and are computationally efficient. Building upon GLM-UCB [11], we extend G-ESTT via a regularization technique and introduce novel methods. Our proposed G-ESTS is straightforward to implement using any generalized linear bandit algorithm. When combined with efficient algorithms, such as SGD-TS [9], the total time complexity after a warm-up stage scales as O(Tr(d1+d2)). Notably, G-ESTT and G-ESTS are the first algorithms to achieve the optimal regret bound of O((d1+d2)r\u221aT) for low-rank matrix bandit problems, up to logarithmic terms."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Compared to existing methods such as ESTR [17], -FALB [15], and LowESTR [], our algorithms are specifically designed for nonlinear reward frameworks. In contrast to LowGLOC [26], our algorithms not only achieve a better regret bound but also operate effectively with varying action sets and are computationally efficient. Building upon GLM-UCB [11], we extend G-ESTT by incorporating a regularization technique and novel methods. Our proposed G-ESTS is straightforward to implement using state-of-the-art generalized linear bandit algorithms. When combined with efficient algorithms, such as SGD-TS [9], the total time complexity after a warm-up phase scales as O(Tr(d1 + d2)). Notably, G-ESTT and G-ESTS are the first algorithms to attain the optimal regret bound of O((d1 + d2)r\u221aT) for low-rank matrix bandit problems, up to logarithmic terms."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Compared to existing methods such as ESTR [17], -FALB [15], and LowESTR [], our algorithms are specifically designed for nonlinear reward frameworks. In contrast to LowGLOC [26], our algorithms not only achieve a better regret bound but also operate effectively with varying action sets and are computationally efficient. Building upon GLM-UCB [11], we extend G-ESTT by incorporating a regularization technique and novel methods. Our proposed G-ESTS is straightforward to implement using state-of-the-art generalized linear bandit algorithms. When combined with efficient algorithms, such as SGD-TS [9], the total time complexity after a warm-up phase scales as O(Tr(d1 + d2)). Notably, G-ESTT and G-ESTS are the first algorithms to attain the optimal regret bound of O((d1 + d2)r\u221aT) for low-rank matrix bandit problems, up to logarithmic terms."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Our algorithms differ from existing ones in several ways. Unlike ESTR [17] and -FALB [15], our approach is designed for nonlinear reward frameworks. Compared to LowGLOC [26], our algorithms achieve better regret bounds, can handle varying action sets, and are computationally feasible. We extend GLM-UCB [11] with a regularization technique and novel methods to propose G-ESTS, a simple and easily implementable algorithm. When combined with efficient algorithms like SGD-TS [9], G-ESTS's total time complexity scales as O(Tr(d1+d2))."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our algorithms differ from existing methods in several key ways. Unlike ESTR [17] and -FALB [15], our approach is designed for nonlinear reward frameworks. Compared to LowGLOC [26], our algorithms not only achieve a better regret bound but also accommodate varying action sets and are computationally efficient. Building upon GLM-UCB [11], we extend G-ESTT via a regularization technique and introduce novel methods. Our proposed G-ESTS is straightforward to implement using any generalized linear bandit algorithm. When combined with efficient algorithms, such as SGD-TS [9], the total time complexity after a warm-up stage scales as O(Tr(d1+d2)). Notably, G-ESTT and G-ESTS are the first algorithms to achieve the optimal regret bound of O((d1+d2)r\u221aT) for low-rank matrix bandit problems, up to logarithmic terms."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our algorithms differ from existing ones in several ways. Unlike ESTR [17] and -FALB [15], our approach is designed for nonlinear reward frameworks. Compared to LowGLOC [26], our algorithms achieve better regret bounds, can handle varying action sets, and are computationally feasible. We extend GLM-UCB [11] with a regularization technique and novel methods to propose G-ESTS, a simple and easily implementable algorithm. When combined with efficient algorithms like SGD-TS [9], G-ESTS's total time complexity scales as O(Tr(d1+d2))."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our algorithms stand out from existing ones in several key ways. Unlike ESTR [17] and -FALB [15], our approach is specifically designed for nonlinear reward frameworks. In contrast to LowGLOC [26], our algorithms not only achieve better regret bounds but also handle varying action sets and are computationally efficient. We have extended GLM-UCB [11] by incorporating a regularization technique and innovative methods, resulting in G-ESTS, a simple and easily implementable algorithm. When combined with efficient algorithms like SGD-TS [9], G-ESTS's total time complexity scales as O(Tr(d1+d2)), making it a practical solution."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our algorithms differ from existing ones in several key aspects. While ESTR [17] and -FALB [15] are designed for specific linear reward frameworks, our approach is tailored to nonlinear reward settings. In contrast to LowGLOC [26], our algorithms not only yield better regret bounds but also handle varying action sets and are computationally efficient. We have built upon GLM-UCB [11] by incorporating a regularization technique and innovative methods, resulting in G-ESTS, a simple and easily implementable algorithm. When combined with efficient algorithms like SGD-TS [9], G-ESTS's total time complexity is O(Tr(d1+d2)), making it a practical solution."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Compared to existing methods such as ESTR [17], -FALB [15], and LowESTR [], our algorithms are specifically designed for nonlinear reward frameworks. In contrast to LowGLOC [26], our algorithms not only achieve a better regret bound but also operate effectively with varying action sets and are computationally efficient. Building upon GLM-UCB [11], we extend G-ESTT by incorporating a regularization technique and novel methods. Our proposed G-ESTS is straightforward to implement using state-of-the-art generalized linear bandit algorithms. When combined with efficient algorithms, such as SGD-TS [9], the total time complexity after a warm-up phase scales as O(Tr(d1 + d2)). Notably, G-ESTT and G-ESTS are the first algorithms to attain the optimal regret bound of O((d1 + d2)r\u221aT) for low-rank matrix bandit problems, up to logarithmic terms."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our algorithms are specifically designed for nonlinear reward frameworks, outperforming existing methods like ESTR, -FALB, and LowESTR. Unlike LowGLOC, our algorithms achieve a better regret bound, operate effectively with varying action sets, and are computationally efficient. Building upon GLM-UCB, we extend G-ESTT by incorporating a regularization technique and novel methods. Notably, G-ESTT and G-ESTS are the first to attain the optimal regret bound of O((d1 + d2)r\u221aT) for low-rank matrix bandit problems, up to logarithmic terms."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our algorithms differ from existing methods in several key ways. Unlike ESTR [17] and -FALB [15], our approach is designed for nonlinear reward frameworks. Compared to LowGLOC [26], our algorithms not only achieve a better regret bound but also accommodate varying action sets and are computationally efficient. Building upon GLM-UCB [11], we extend G-ESTT via a regularization technique and introduce novel methods. Our proposed G-ESTS is straightforward to implement using any generalized linear bandit algorithm. When combined with efficient algorithms, such as SGD-TS [9], the total time complexity after a warm-up stage scales as O(Tr(d1+d2)). Notably, G-ESTT and G-ESTS are the first algorithms to achieve the optimal regret bound of O((d1+d2)r\u221aT) for low-rank matrix bandit problems, up to logarithmic terms."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "instruction": "Improve the English of this paragraph", "revised_paragraph": "Revised paragraph: Compared with existing algorithms, such as ESTR [17], -FALB [15], and LowESTR [], our proposed algorithms are designed to operate within a nonlinear reward framework. In contrast to LowGLOC [26], our algorithms not only achieve a better regret bound but also accommodate varying action sets and are computationally efficient. Building upon the GLM-UCB algorithm [11], we extend G-ESTT through a regularization technique and novel methods. Our proposed G-ESTS algorithm is simple and can be easily implemented based on any state-of-the-art generalized linear bandit algorithm. When combined with efficient algorithms, such as SGD-TS [9], the total time complexity after a warm-up stage scales as O(Tr(d1 + d2)). Notably, G-ESTT and G-ESTS are the first algorithms to attain the optimal regret bound of O((d1 + d2)r\u221aT) for low-rank matrix bandit problems, up to logarithmic terms.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "oH-CV7Qprn.l7-CEr3ki.00", "instruction": "Rewrite the first part of the paragraph to make it more convincing.", "revised_paragraph": "Revised paragraph: In contrast to existing algorithms such as ESTR [17], -FALB [15], and LowESTR [ ], our proposed algorithms are specifically designed to tackle nonlinear reward frameworks, offering a significant departure from previous work. When compared to LowGLOC [26], our algorithms not only achieve a superior regret bound but also demonstrate the ability to operate with varying action sets and computational feasibility. Building upon the GLM-UCB algorithms [11], we extend the G-ESTT framework via a regularization technique and introduce novel innovations. Our proposed G-ESTS algorithm is remarkably simple and can be easily integrated with any state-of-the-art generalized linear bandit algorithms. Furthermore, when combined with efficient algorithms such as SGD-TS [9], the total time complexity after a warm-up stage scales as O(Tr(d1+d2)). Notably, G-ESTT and G-ESTS are the first algorithms to achieve the optimal regret bound of O((d1+d2)r\u221aT) for low-rank matrix bandit problems, up to logarithmic terms.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Evaluating the ground-truth propensity score estimation and homogeneity effect (PEHE) over observational benchmarks is hindered by the lack of counterfactual data. Therefore, we follow the approach of Liuyi et al. (2017) and Uri et al. (2017), and conduct experiments on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant cognitive scores, with 747 observations and 25 covariates. The ACIC dataset, which originates from the collaborative perinatal project (Niswander & Gordon, 1972), consists of 4802 observations and 58 covariates.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Evaluating the ground-truth propensity score estimation and homogeneity effect (PEHE) over observational benchmarks is hindered by the lack of counterfactual data. Therefore, we follow the approach of Liuyi et al. (2017) and Uri et al. (2017), and conduct experiments on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant cognitive scores, with 747 observations and 25 covariates. The ACIC dataset, which originates from the collaborative perinatal project (Niswander & Gordon, 1972), consists of 4802 observations and 58 covariates.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Evaluating the ground-truth propensity score estimation and homogeneity effect (PEHE) over observational benchmarks is hindered by the lack of counterfactual data. Therefore, we follow the approach of Liuyi et al. (2017) and Uri et al. (2017), and conduct experiments on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant cognitive scores, with 747 observations and 25 covariates. The ACIC dataset, which originates from the collaborative perinatal project (Niswander & Gordon, 1972), consists of 4802 observations and 58 covariates.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Evaluating the ground-truth propensity score estimation and homogeneity effect (PEHE) over observational benchmarks is hindered by the lack of counterfactual data. Therefore, we follow the approach of Liuyi et al. (2017) and Uri et al. (2017), and conduct experiments on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant cognitive scores, with 747 observations and 25 covariates. The ACIC dataset, which originates from the collaborative perinatal project (Niswander & Gordon, 1972), consists of 4802 observations and 58 covariates.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Evaluating the ground-truth propensity score estimation and homogeneity effect (PEHE) over observational benchmarks is hindered by the lack of counterfactual data. Therefore, we follow the approach of Liuyi et al. (2017) and Uri et al. (2017), and conduct experiments on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant cognitive scores, with 747 observations and 25 covariates. The ACIC dataset, which originates from the collaborative perinatal project (Niswander & Gordon, 1972), consists of 4802 observations and 58 covariates.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Evaluating the ground-truth propensity score estimation and homogeneity effect (PEHE) over observational benchmarks is hindered by the lack of counterfactual data. Therefore, we follow the approach of Liuyi et al. (2017) and Uri et al. (2017), and conduct experiments on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant cognitive scores, with 747 observations and 25 covariates. The ACIC dataset, which originates from the collaborative perinatal project (Niswander & Gordon, 1972), consists of 4802 observations and 58 covariates.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Evaluating the ground-truth propensity score estimation and homogeneity effect (PEHE) over observational benchmarks is hindered by the lack of counterfactual data. Therefore, we follow the approach of Liuyi et al. (2017) and Uri et al. (2017), and conduct experiments on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant cognitive scores, with 747 observations and 25 covariates. The ACIC dataset, which originates from the collaborative perinatal project (Niswander & Gordon, 1972), consists of 4802 observations and 58 covariates.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Evaluating the ground-truth propensity score estimation and homogeneity effect (PEHE) over observational benchmarks is hindered by the lack of counterfactual data. Therefore, we follow the approach of Liuyi et al. (2017) and Uri et al. (2017), and conduct experiments on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant cognitive scores, with 747 observations and 25 covariates. The ACIC dataset, which originates from the collaborative perinatal project (Niswander & Gordon, 1972), consists of 4802 observations and 58 covariates.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "instruction": "Add a citation in the last sentence and modify the rest so that the total length of the paragraph remains the same. ", "revised_paragraph": "Revised paragraph: Datasets. The absence of counterfactual data makes it challenging to evaluate the ground-truth propensity score estimation and heterogeneous effect estimation (PEHE) over observational benchmarks. Following Liuyi et al. and Uri et al. (2017), experiments are conducted on two semi-synthetic benchmarks. Specifically, the IHDP benchmark aims to estimate the effect of specialist home visits on infant's future cognitive scores, with 747 observations and 25 covariates; the ACIC dataset comes from the collaborative perinatal project (Niswander & Gordon, 1972), with 4802 observations and 58 covariates (Uri et al., 2017).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.12", "instruction": "Improve the language in this text.", "revised_paragraph": "Revised paragraph: \"The evaluation of the ground-truth propensity score estimation and handling of heterogeneous effects (PEHE) is hindered by the absence of counterfactual data in observational datasets. To overcome this limitation, we conduct experiments on two semi-synthetic benchmarks, as suggested by Liuyi et al. and Uri et al. (2017). The IHDP benchmark, which aims to estimate the effect of specialist home visits on infant cognitive scores, consists of 747 observations and 25 covariates. The ACIC dataset, drawn from the Collaborative Perinatal Project (Niswander & Gordon, 1972), comprises 4802 observations and 58 covariates.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"In practice, we do not have access to the true distribution p w and instead work with a corpus { w p w n } N n =1 assumed to be sampled i.i.d. from p w. To address this, we derive statistical estimators (cid:98) \u2206 that approximate \u2206 using this corpus. Two common strategies are Monte Carlo estimation and plug-in estimation. We focus on the former, using our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we do not have direct access to the true distribution pw. Instead, we are typically provided with a corpus {wpwn}Nn=1, comprising instances that we assume are independently and identically distributed (i.i.d.) samples from pw. To address this limitation, researchers often derive a statistical estimator (\u2206) that approximates \u2206 using this corpus. Two common strategies for building such estimators are Monte Carlo estimation and plug-in estimation. Monte Carlo estimation, which is feasible under the i.i.d. assumption wpw \u223c pw, enables the derivation of a Monte Carlo estimator for certain divergences, starting with the forward KL divergence, which is present in both \u2206\u2192 and \u2206exp."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"In practice, we do not have access to the true distribution p w and instead work with a corpus { w p w n } N n =1 assumed to be sampled i.i.d. from p w. To address this, we derive statistical estimators (cid:98) \u2206 that approximate \u2206 using this corpus. Two common strategies are Monte Carlo estimation and plug-in estimation. We focus on the former, using our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"In practice, we do not have access to the true distribution p w and instead work with a corpus { w p w n } N n =1 assumed to be sampled i.i.d. from p w. To address this, we derive statistical estimators (cid:98) \u2206 that approximate \u2206 using this corpus. Two common strategies are Monte Carlo estimation and plug-in estimation. We focus on the former, using our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"In practice, we do not have access to the true distribution p w and instead work with a corpus { w p w n } N n =1 assumed to be sampled i.i.d. from p w. To address this, we derive statistical estimators (cid:98) \u2206 that approximate \u2206 using this corpus. Two common strategies are Monte Carlo estimation and plug-in estimation. We focus on the former, using our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In practice, we do not have direct access to the true distribution pw. Instead, we are typically provided with a corpus {wpwn}Nn=1, comprising instances that we assume are independently and identically distributed (i.i.d.) samples from pw. To address this limitation, researchers often derive a statistical estimator (\u2206) that approximates \u2206 using this corpus. Two common strategies for building such estimators are Monte Carlo estimation and plug-in estimation. Monte Carlo estimation, which is feasible under the i.i.d. assumption wpw \u223c pw, enables the derivation of a Monte Carlo estimator for certain divergences, starting with the forward KL divergence, which is present in both \u2206\u2192 and \u2206exp."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"In practice, we do not have access to the true distribution p w and instead work with a corpus { w p w n } N n =1 assumed to be sampled i.i.d. from p w. To address this, we derive statistical estimators (cid:98) \u2206 that approximate \u2206 using this corpus. Two common strategies are Monte Carlo estimation and plug-in estimation. We focus on the former, using our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In practice, we do not have direct access to the true distribution p(w) and instead work with a corpus {w, p(w), n} comprising N samples, assumed to be independently and identically distributed (i.i.d.) from p(w). To address this limitation, we develop statistical estimators (\u2206) that approximate \u2206 using this corpus. Two common approaches are Monte Carlo estimation and plug-in estimation. We focus on the former, leveraging our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward Kullback-Leibler divergence.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"In practice, we do not have access to the true distribution p w and instead work with a corpus { w p w n } N n =1 assumed to be sampled i.i.d. from p w. To address this, we derive statistical estimators (cid:98) \u2206 that approximate \u2206 using this corpus. Two common strategies are Monte Carlo estimation and plug-in estimation. We focus on the former, using our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"In practice, we do not have access to the true distribution p w and instead work with a corpus { w p w n } N n =1 assumed to be sampled i.i.d. from p w. To address this, we derive statistical estimators (cid:98) \u2206 that approximate \u2206 using this corpus. Two common strategies are Monte Carlo estimation and plug-in estimation. We focus on the former, using our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"In practice, we do not have access to the true distribution p w and instead work with a corpus { w p w n } N n =1 assumed to be sampled i.i.d. from p w. To address this, we derive statistical estimators (cid:98) \u2206 that approximate \u2206 using this corpus. Two common strategies are Monte Carlo estimation and plug-in estimation. We focus on the former, using our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In practice, we do not have direct access to the true distribution p(w) and instead work with a corpus {w, p(w), n} comprising N samples, assumed to be independently and identically distributed (i.i.d.) from p(w). To address this limitation, we develop statistical estimators (\u2206) that approximate \u2206 using this corpus. Two common approaches are Monte Carlo estimation and plug-in estimation. We focus on the former, leveraging our i.i.d. assumption to derive a Monte Carlo estimator for certain divergences, starting with the forward Kullback-Leibler divergence.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "instruction": "Fix formatting issues and simplify the wording of the paragraph.", "revised_paragraph": "Revised paragraph: In practice, we do not have direct access to the true distribution p(w). Instead, we are typically provided with a corpus {w, p(w), n} of N instances, assumed to be independently and identically distributed (i.i.d.) from p(w). To address this limitation, we often derive a statistical estimator \u2206 that uses this corpus to approximate \u2206. Two common strategies for building such estimators are Monte Carlo estimation and plug-in estimation. We begin by discussing Monte Carlo estimation, which is possible due to our i.i.d. assumption regarding the samples w \u223c p(w). Specifically, we can derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence, which is relevant for both \u2206\u2192 and \u2206exp.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "instruction": "Fix the caplocks problem. Slightly shorten the paragraph.", "revised_paragraph": "Revised paragraph: \"In practice, we lack access to the true distribution p w. Instead, we typically work with a corpus { w p w n } N n =1, assumed to be sampled i.i.d. from p w. To address this limitation, we often derive a statistical estimator (cid:98) \u2206 that approximates \u2206 using this corpus. Two common strategies for building such estimators are Monte Carlo estimation and plug-in estimation. We can derive a Monte Carlo estimator for certain divergences, starting with the forward KL divergence, using our i.i.d. assumption w.r.t. samples w p w \u223c p w.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\n\"A fully connected neural network with two hidden layers, comprising 60 neurons in each layer, has been chosen to learn the representation map \u03c8 and the factual outcome map \u03d5 for the ESCFR and other neural network-based baselines. To ensure a fair comparison, all neural models are trained for 400 epochs using the Adam optimizer (Kingma & Ba, 2015), with a learning rate and weight decay set to 1 \u00d7 10^(-3). The other optimizer settings follow the guidelines provided by Kingma & Ba (2015). Hyperparameters are searched within the range depicted in Figure 5, and the validation performance is checkpointed every 2 epochs, with the best-performing model being exported and evaluated on the test dataset.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\n\"A fully connected neural network with two hidden layers, comprising 60 neurons in each layer, has been chosen to learn the representation map \u03c8 and the factual outcome map \u03d5 for the ESCFR and other neural network-based baselines. To ensure a fair comparison, all neural models are trained for 400 epochs using the Adam optimizer (Kingma & Ba, 2015), with a learning rate and weight decay set to 1 \u00d7 10^(-3). The other optimizer settings follow the guidelines provided by Kingma & Ba (2015). Hyperparameters are searched within the range depicted in Figure 5, and the validation performance is checkpointed every 2 epochs, with the best-performing model being exported and evaluated on the test dataset.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\n\"A fully connected neural network with two hidden layers, comprising 60 neurons in each layer, has been chosen to learn the representation map \u03c8 and the factual outcome map \u03d5 for the ESCFR and other neural network-based baselines. To ensure a fair comparison, all neural models are trained for 400 epochs using the Adam optimizer (Kingma & Ba, 2015), with a learning rate and weight decay set to 1 \u00d7 10^(-3). The other optimizer settings follow the guidelines provided by Kingma & Ba (2015). Hyperparameters are searched within the range depicted in Figure 5, and the validation performance is checkpointed every 2 epochs, with the best-performing model being exported and evaluated on the test dataset.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\n\"A fully connected neural network with two hidden layers, comprising 60 neurons in each layer, has been chosen to learn the representation map \u03c8 and the factual outcome map \u03d5 for the ESCFR and other neural network-based baselines. To ensure a fair comparison, all neural models are trained for 400 epochs using the Adam optimizer (Kingma & Ba, 2015), with a learning rate and weight decay set to 1 \u00d7 10^(-3). The other optimizer settings follow the guidelines provided by Kingma & Ba (2015). Hyperparameters are searched within the range depicted in Figure 5, and the validation performance is checkpointed every 2 epochs, with the best-performing model being exported and evaluated on the test dataset.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\n\"A fully connected neural network with two hidden layers, comprising 60 neurons in each layer, has been chosen to learn the representation map \u03c8 and the factual outcome map \u03d5 for the ESCFR and other neural network-based baselines. To ensure a fair comparison, all neural models are trained for 400 epochs using the Adam optimizer (Kingma & Ba, 2015), with a learning rate and weight decay set to 1 \u00d7 10^(-3). The other optimizer settings follow the guidelines provided by Kingma & Ba (2015). Hyperparameters are searched within the range depicted in Figure 5, and the validation performance is checkpointed every 2 epochs, with the best-performing model being exported and evaluated on the test dataset.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\n\"A fully connected neural network with two hidden layers, comprising 60 neurons in each layer, has been chosen to learn the representation map \u03c8 and the factual outcome map \u03d5 for the ESCFR and other neural network-based baselines. To ensure a fair comparison, all neural models are trained for 400 epochs using the Adam optimizer (Kingma & Ba, 2015), with a learning rate and weight decay set to 1 \u00d7 10^(-3). The other optimizer settings follow the guidelines provided by Kingma & Ba (2015). Hyperparameters are searched within the range depicted in Figure 5, and the validation performance is checkpointed every 2 epochs, with the best-performing model being exported and evaluated on the test dataset.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\n\"A fully connected neural network with two hidden layers, comprising 60 neurons in each layer, has been chosen to learn the representation map \u03c8 and the factual outcome map \u03d5 for the ESCFR and other neural network-based baselines. To ensure a fair comparison, all neural models are trained for 400 epochs using the Adam optimizer (Kingma & Ba, 2015), with a learning rate and weight decay set to 1 \u00d7 10^(-3). The other optimizer settings follow the guidelines provided by Kingma & Ba (2015). Hyperparameters are searched within the range depicted in Figure 5, and the validation performance is checkpointed every 2 epochs, with the best-performing model being exported and evaluated on the test dataset.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\n\"A fully connected neural network with two hidden layers, comprising 60 neurons in each layer, has been chosen to learn the representation map \u03c8 and the factual outcome map \u03d5 for the ESCFR and other neural network-based baselines. To ensure a fair comparison, all neural models are trained for 400 epochs using the Adam optimizer (Kingma & Ba, 2015), with a learning rate and weight decay set to 1 \u00d7 10^(-3). The other optimizer settings follow the guidelines provided by Kingma & Ba (2015). Hyperparameters are searched within the range depicted in Figure 5, and the validation performance is checkpointed every 2 epochs, with the best-performing model being exported and evaluated on the test dataset.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "instruction": "Rewrite for fluency (while keeping the original structure of the sentences)", "revised_paragraph": "Revised paragraph: \"A fully connected neural network with two hidden layers, comprising 60 neurons each, was chosen to generate the representation map \u03c8 and factual outcome map \u03d5 for ESCFR and other neural network-based baselines. To ensure a fair comparison, all neural models were trained for 400 epochs using the Adam optimizer, as proposed by Kingma and Ba (2015), with a learning rate and weight decay set to 1 \u00d7 10^-3. The other optimizer settings followed the recommendations of Kingma and Ba (2015). Hyperparameters were searched within the range depicted in Figure 5, and the validation performance was checkpointed every 2 epochs, with the best model exported for evaluation on the test dataset.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.13", "instruction": "Improve the language in this text and make it slightly more formal.", "revised_paragraph": "Revised paragraph: A training protocol was designed to ensure a fair comparison among neural network-based baselines, including the proposed ESCFR model. A fully connected neural network with two hidden layers, comprising 60 neurons each, was selected to realize the representation map \u03c8 and the factual outcome map \u03d5. To achieve this, all neural models were trained for 400 epochs using the Adam optimizer, as proposed by Kingma and Ba (2015), with a learning rate and weight decay set to 1 \u00d7 10^(-3). The hyperparameters were searched within the range depicted in Figure 5, and the validation performance was checkpointed every 2 epochs. The best-performing model was subsequently exported and evaluated on the test dataset.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We replaced the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy, highlighting the limitation of PLOT in the zero-shot setting. We attribute this to two reasons: (1) prompt engineering is based on the global feature and cosine distance, rather than OT distance with feature map; (2) selected prompts are close to the global feature and lack complementarity.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We replaced the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy, highlighting the limitation of PLOT in the zero-shot setting. We attribute this to two reasons: (1) prompt engineering is based on the global feature and cosine distance, rather than OT distance with feature map; (2) selected prompts are close to the global feature and lack complementarity.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We replaced the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy, highlighting the limitation of PLOT in the zero-shot setting. We attribute this to two reasons: (1) prompt engineering is based on the global feature and cosine distance, rather than OT distance with feature map; (2) selected prompts are close to the global feature and lack complementarity.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We replaced the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy, highlighting the limitation of PLOT in the zero-shot setting. We attribute this to two reasons: (1) prompt engineering is based on the global feature and cosine distance, rather than OT distance with feature map; (2) selected prompts are close to the global feature and lack complementarity.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We replaced the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy, highlighting the limitation of PLOT in the zero-shot setting. We attribute this to two reasons: (1) prompt engineering is based on the global feature and cosine distance, rather than OT distance with feature map; (2) selected prompts are close to the global feature and lack complementarity.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We replaced the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy, highlighting the limitation of PLOT in the zero-shot setting. We attribute this to two reasons: (1) prompt engineering is based on the global feature and cosine distance, rather than OT distance with feature map; (2) selected prompts are close to the global feature and lack complementarity.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We replaced the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy, highlighting the limitation of PLOT in the zero-shot setting. We attribute this to two reasons: (1) prompt engineering is based on the global feature and cosine distance, rather than OT distance with feature map; (2) selected prompts are close to the global feature and lack complementarity.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We replaced the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy, highlighting the limitation of PLOT in the zero-shot setting. We attribute this to two reasons: (1) prompt engineering is based on the global feature and cosine distance, rather than OT distance with feature map; (2) selected prompts are close to the global feature and lack complementarity.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "instruction": "Remove any information that is not essential to the main points of the paragraph.", "revised_paragraph": "Revised paragraph: \"We replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy. This limitation is due to the PLOT's need for few-shot data for optimization, which cannot be directly applied in the zero-shot setting. We attribute this to two reasons: the prompts are selected based on the global feature and cosine distance, rather than OT distance with the feature map, and the selected prompts are close to the global feature, lacking complementarity.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "instruction": "I do not want to mention a limitation.", "revised_paragraph": "Revised paragraph: In this section, we replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy. We argue that there are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are close to the global feature and lack the complementarity.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of segments from images with overlapping object categories, such as sofa. These segments are included in O+ if they match the same category, otherwise they are considered negative segments O-. This approach enhances global regularization on pixel embeddings without requiring localization annotations or cues.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of image segments belonging to overlapping object categories. For instance, if a pixel i is labeled as a sofa in one image, and another image also contains a sofa, all segments from the latter image are included in O+, whereas those from other images are considered negative segments O-. This semantic context relationship enables higher-level regularization on pixel embeddings without requiring localization annotations or cues, thereby enhancing global regularization.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of segments from images with overlapping object categories, such as sofa. These segments are included in O+ if they match the same category, otherwise they are considered negative segments O-. This approach enhances global regularization on pixel embeddings without requiring localization annotations or cues.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of segments from images with overlapping object categories, such as sofa. These segments are included in O+ if they match the same category, otherwise they are considered negative segments O-. This approach enhances global regularization on pixel embeddings without requiring localization annotations or cues.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of segments from images with overlapping object categories, such as sofa. These segments are included in O+ if they match the same category, otherwise they are considered negative segments O-. This approach enhances global regularization on pixel embeddings without requiring localization annotations or cues.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of image segments belonging to overlapping object categories. For instance, if a pixel i is labeled as a sofa in one image, and another image also contains a sofa, all segments from the latter image are included in O+, whereas those from other images are considered negative segments O-. This semantic context relationship enables higher-level regularization on pixel embeddings without requiring localization annotations or cues, thereby enhancing global regularization.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of segments from images with overlapping object categories, such as sofa. These segments are included in O+ if they match the same category, otherwise they are considered negative segments O-. This approach enhances global regularization on pixel embeddings without requiring localization annotations or cues.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of image segments belonging to overlapping object categories, such as sofas. These segments are assigned to O+ if they correspond to the same category, whereas those that do not match are considered negative segments, O-. This approach enables global regularization of pixel embeddings without necessitating localization annotations or cues.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of segments from images with overlapping object categories, such as sofa. These segments are included in O+ if they match the same category, otherwise they are considered negative segments O-. This approach enhances global regularization on pixel embeddings without requiring localization annotations or cues.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of segments from images with overlapping object categories, such as sofa. These segments are included in O+ if they match the same category, otherwise they are considered negative segments O-. This approach enhances global regularization on pixel embeddings without requiring localization annotations or cues.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of segments from images with overlapping object categories, such as sofa. These segments are included in O+ if they match the same category, otherwise they are considered negative segments O-. This approach enhances global regularization on pixel embeddings without requiring localization annotations or cues.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We define O+ as the set of image segments belonging to overlapping object categories, such as sofas. These segments are assigned to O+ if they correspond to the same category, whereas those that do not match are considered negative segments, O-. This approach enables global regularization of pixel embeddings without necessitating localization annotations or cues.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "instruction": "Rewrite this paragraph to be more concise.", "revised_paragraph": "Revised paragraph: We denote O+ as the set of segments from images with overlapping object categories. For instance, if an image contains a sofa, all its segments are included in O+, while those from other images are considered negative (O-). This semantic relationship enhances global and higher-level regularization on pixel embeddings without requiring localization annotations or cues.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.10", "instruction": "Make it more concise.", "revised_paragraph": "Revised paragraph: We denote O+ as the set of segments from images with overlapping object categories. For instance, if pixel i is labeled as sofa, all segments from an image with a sofa are included in O+, while those from an image without a sofa are considered negative segments O-. This approach leverages semantic context without requiring localization annotations, enhancing global and higher-level regularization on pixel embeddings.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we aim to elucidate the intricacies of the DeepONet's complexity, specifically with regards to approximation A and reconstruction R, as theorized by Galanti and Wolf (2020). Moreover, by leveraging the upper bound on the complexity of hypernetworks established by Galanti and Wolf (2020), we will demonstrate that the HyperDeepONet exhibits a relatively lower complexity compared to the DeepONet."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we aim to elucidate the intricacies of the DeepONet's complexity in approximating A and reconstructing R, as posited by Galanti and Wolf (2020). By leveraging the upper bound results on the complexity of hypernetworks reported by Galanti and Wolf (2020), we demonstrate that the HyperDeepONet exhibits a significantly lower complexity compared to the DeepONet."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we aim to elucidate the intricacies of the DeepONet's complexity, specifically with regards to approximation A and reconstruction R, as theorized by Galanti and Wolf (2020). Moreover, by leveraging the upper bound on the complexity of hypernetworks established by Galanti and Wolf (2020), we will demonstrate that the HyperDeepONet exhibits a relatively lower complexity compared to the DeepONet."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we aim to elucidate the intricacies of the DeepONet's complexity in approximating A and reconstructing R, as posited by Galanti and Wolf (2020). By leveraging the upper bound results on the complexity of hypernetworks reported by Galanti and Wolf (2020), we demonstrate that the HyperDeepONet exhibits a significantly lower complexity compared to the DeepONet."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we aim to elucidate the intricacies of the DeepONet's complexity, specifically with regards to approximation A and reconstruction R, as theorized by Galanti and Wolf (2020). Moreover, by leveraging the upper bound on the complexity of hypernetworks established by Galanti and Wolf (2020), we will demonstrate that the HyperDeepONet exhibits a relatively lower complexity compared to the DeepONet."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: This section delves into the intricacies of the DeepONet's complexity, focusing on approximation A and reconstruction R, as previously theorized by Galanti and Wolf (2020). Furthermore, by building upon the upper bound on the complexity of hypernetworks established by Galanti and Wolf (2020), we demonstrate that the HyperDeepONet exhibits a relatively lower complexity compared to the DeepONet."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we aim to elucidate the intricacies of the DeepONet's complexity, specifically with regards to approximation A and reconstruction R, as theorized by Galanti and Wolf (2020). Moreover, by leveraging the upper bound on the complexity of hypernetworks established by Galanti and Wolf (2020), we will demonstrate that the HyperDeepONet exhibits a relatively lower complexity compared to the DeepONet."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we aim to elucidate the intricacies of the DeepONet's complexity in approximating A and reconstructing R, as posited by Galanti and Wolf (2020). By leveraging the upper bound results on the complexity of hypernetworks reported by Galanti and Wolf (2020), we demonstrate that the HyperDeepONet exhibits a significantly lower complexity compared to the DeepONet."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "instruction": "Use correct citation format.", "revised_paragraph": "Revised paragraph: According to Galanti & Wolf (2020), the complexity of the DeepONet for approximation A and reconstruction R is multifaceted. By applying the theoretical framework presented in Galanti & Wolf (2020), we demonstrate that the HyperDeepONet exhibits a relatively lower complexity compared to the DeepONet, as inferred from the upper bound results on hypernetwork complexity provided by Galanti & Wolf (2020).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.00", "instruction": "Reorder the last sentence.", "revised_paragraph": "Revised paragraph: Furthermore, using the results on the upper bound for the complexity of hypernetwork Galanti & Wolf (2020), we will show that the HyperDeepONet entails a relatively lower complexity than the DeepONet. In this section, we would like to clarify the complexity of the DeepONet required for the approximation A and reconstruction R based on the theory in Galanti & Wolf (2020).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"This sampler produces diverse batches similar to a k-DPP. As shown in Figure 1, switching between the two samplers improves computational performance without affecting statistical performance. For more details, see Appendix G.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This simple sampler produces batches with diverse characteristics, similar to a k-DPP. As illustrated in Figure 1, switching between the two samplers does not impact the active learner's statistical performance, but significantly improves its computational efficiency. A comprehensive comparison of the running times and test accuracies of k-MEANS++ and k-DPP based gradient embedding sampling can be found in Appendix G."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This simple sampler produces batches with diverse characteristics, similar to a k-DPP. As illustrated in Figure 1, switching between the two samplers does not impact the active learner's statistical performance, but significantly improves its computational efficiency. A comprehensive comparison of the running times and test accuracies of k-MEANS++ and k-DPP based gradient embedding sampling can be found in Appendix G."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This simple sampler produces batches with diverse characteristics, similar to a k-DPP. As illustrated in Figure 1, switching between the two samplers does not impact the active learner's statistical performance, but significantly improves its computational efficiency. A comprehensive comparison of the running times and test accuracies of k-MEANS++ and k-DPP based gradient embedding sampling can be found in Appendix G."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"This sampler produces diverse batches similar to a k-DPP. As shown in Figure 1, switching between the two samplers improves computational performance without affecting statistical performance. For more details, see Appendix G.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This simple sampler produces batches with diverse characteristics, similar to a k-DPP. As illustrated in Figure 1, switching between the two samplers does not impact the active learner's statistical performance, but significantly improves its computational efficiency. A comprehensive comparison of the running times and test accuracies of k-MEANS++ and k-DPP based gradient embedding sampling can be found in Appendix G."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"This sampler produces diverse batches similar to a k-DPP. As shown in Figure 1, switching between the two samplers improves computational performance without affecting statistical performance. For more details, see Appendix G.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The sampler generates diverse batches, akin to a k-DPP. As illustrated in Figure 1, switching between the two samplers enhances computational efficiency without compromising statistical accuracy. Further information is provided in Appendix G.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This simple sampler produces batches with diverse characteristics, similar to a k-DPP. As illustrated in Figure 1, switching between the two samplers does not impact the active learner's statistical performance, but significantly improves its computational efficiency. A comprehensive comparison of the running times and test accuracies of k-MEANS++ and k-DPP based gradient embedding sampling can be found in Appendix G."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This simple sampler produces batches with diverse characteristics, similar to a k-DPP. As illustrated in Figure 1, switching between the two samplers does not impact the active learner's statistical performance, but significantly improves its computational efficiency. A comprehensive comparison of the running times and test accuracies of k-MEANS++ and k-DPP based gradient embedding sampling can be found in Appendix G."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"This sampler produces diverse batches similar to a k-DPP. As shown in Figure 1, switching between the two samplers improves computational performance without affecting statistical performance. For more details, see Appendix G.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The sampler generates diverse batches, akin to a k-DPP. As illustrated in Figure 1, switching between the two samplers enhances computational efficiency without compromising statistical accuracy. Further information is provided in Appendix G.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "instruction": "Simplify the wording of this paragraph.", "revised_paragraph": "Revised paragraph: This sampler produces diverse batches similar to a k-DPP. As Figure 1 shows, switching between the two samplers does not impact the active learner's performance, but significantly improves computational efficiency. For more information, see Appendix G, which compares the running times and test accuracies of k-MEANS++ and k-DPP based gradient embedding sampling.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "HkfoEihoH.QdgynxJz5.00", "instruction": "Make the last sentence more concise.", "revised_paragraph": "Revised paragraph: \"This simple sampler tends to produce diverse batches similar to a k-DPP. As shown in Figure 1, switching between the two samplers does not affect the active learner's statistical performance, but significantly improves computational performance. Details on running times and test accuracies can be found in Appendix G.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Table 1, our RDE-Network significantly outperforms all baselines, demonstrating its reliability in practical applications. Notably, RDE-Network achieves a substantial improvement in per-structure correlations, indicating that it is more effective than other methods. This advantage over MIF-Network suggests that representations obtained by fitting rotamer densities are more effective for protein binding, as RDE-Network accurately captures the conformation of sidechain atoms, which is critical for modeling atomic interactions driving protein binding."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Table 1, our RDE-Network significantly outperforms all baselines, demonstrating its reliability in practical applications. Notably, RDE-Network achieves a substantial improvement in per-structure correlations, indicating that it is more effective than other methods. This advantage over MIF-Network suggests that representations obtained by fitting rotamer densities are more effective for protein binding, as RDE-Network accurately captures the conformation of sidechain atoms, which is critical for modeling atomic interactions driving protein binding."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Table 1, our RDE-Network significantly outperforms all baselines, demonstrating its reliability in practical applications. Notably, RDE-Network achieves a substantial improvement in per-structure correlations, indicating that it is more effective than other methods. This advantage over MIF-Network suggests that representations obtained by fitting rotamer densities are more effective for protein binding, as RDE-Network accurately captures the conformation of sidechain atoms, which is critical for modeling atomic interactions driving protein binding."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Table 1, our RDE-Network significantly outperforms all baselines, demonstrating its reliability in practical applications. Notably, RDE-Network achieves a substantial improvement in per-structure correlations, indicating that it is more effective than other methods. This advantage over MIF-Network suggests that representations obtained by fitting rotamer densities are more effective for protein binding, as RDE-Network accurately captures the conformation of sidechain atoms, which is critical for modeling atomic interactions driving protein binding."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Table 1, our RDE-Network significantly outperforms all baselines, demonstrating its reliability in practical applications. Notably, RDE-Network achieves a substantial improvement in per-structure correlations, indicating that it is more effective than other methods. This advantage over MIF-Network suggests that representations obtained by fitting rotamer densities are more effective for protein binding, as RDE-Network accurately captures the conformation of sidechain atoms, which is critical for modeling atomic interactions driving protein binding."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Table 1, our RDE-Network significantly outperforms all baselines, demonstrating its reliability in practical applications. Notably, RDE-Network achieves a substantial improvement in per-structure correlations, indicating that it is more effective than other methods. This advantage over MIF-Network suggests that representations obtained by fitting rotamer densities are more effective for protein binding, as RDE-Network accurately captures the conformation of sidechain atoms, which is critical for modeling atomic interactions driving protein binding."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Table 1, our RDE-Network significantly outperforms all baselines, demonstrating its reliability in practical applications. Notably, RDE-Network achieves a substantial improvement in per-structure correlations, indicating that it is more effective than other methods. This advantage over MIF-Network suggests that representations obtained by fitting rotamer densities are more effective for protein binding, as RDE-Network accurately captures the conformation of sidechain atoms, which is critical for modeling atomic interactions driving protein binding."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Table 1, our RDE-Network significantly outperforms all baselines, demonstrating its reliability in practical applications. Notably, RDE-Network achieves a substantial improvement in per-structure correlations, indicating that it is more effective than other methods. This advantage over MIF-Network suggests that representations obtained by fitting rotamer densities are more effective for protein binding, as RDE-Network accurately captures the conformation of sidechain atoms, which is critical for modeling atomic interactions driving protein binding."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "instruction": "Paraphrase this paragraph using formal language", "revised_paragraph": "Revised paragraph: According to Table 1, our RDE-Network exhibits superior performance compared to all baselines. Notably, the RDE-Network demonstrates a substantial improvement in per-structure correlations, thereby indicating its increased reliability for practical applications. The advantage of the RDE-Network over the MIF-Network suggests that the representations generated by fitting rotamer densities are more effective than those obtained through masked inverse folding, as protein binding is primarily driven by atomic interactions, which the RDE-Network captures well by modeling the conformation of sidechain atoms.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.19", "instruction": "Revise this paragraph in a more academic style.", "revised_paragraph": "Revised paragraph: According to the results presented in Table 1, our RDE-Network exhibits superior performance compared to all baseline models. Notably, the RDE-Network demonstrates a substantial improvement in per-structure correlations, indicating a significantly higher reliability for practical applications. A comparison with the MIF-Network reveals that representations generated by fitting rotamer densities are more effective, as protein binding is primarily driven by atomic interactions, which the RDE-Network captures well by modeling the conformation of sidechain atoms.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To enhance the efficiency of our point cloud processing, we have optimized our window-based operations to take advantage of the natural sparsity of point clouds. Specifically, we have implemented window center searching, window gathering, and balanced window sampling using CUDA operations, which rely on a hash map that maps coordinate space to voxel indices [23]. For instance, during the window gathering operation, we query each potential position within the window relative to a given center, and retrieve corresponding features if the position is a valid key in the pre-built hash map. Further details on these operations can be found in the supplementary materials."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To enhance efficiency, we leveraged the natural sparsity of point clouds by implementing our window center searching, window gathering, and balanced window sampling operations in CUDA. These operations rely on a hash map that maps coordinate space to voxel indices [23]. Specifically, during the window gathering operation, we query each possible position within the window relative to the given center and retrieve corresponding features if the position is a valid key in the pre-built hash map. Further details are provided in the supplementary materials."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To enhance efficiency, we leveraged the natural sparsity of point clouds by implementing our window center searching, window gathering, and balanced window sampling operations in CUDA. These operations rely on a hash map that maps coordinate space to voxel indices [23]. Specifically, during the window gathering operation, we query each possible position within the window relative to the given center and retrieve corresponding features if the position is a valid key in the pre-built hash map. Further details are provided in the supplementary materials."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To enhance the efficiency of our point cloud processing, we have optimized our window-based operations to take advantage of the natural sparsity of point clouds. Specifically, we have implemented window center searching, window gathering, and balanced window sampling using CUDA operations, which rely on a hash map that maps coordinate space to voxel indices [23]. For instance, during the window gathering operation, we query each potential position within the window relative to a given center, and retrieve corresponding features if the position is a valid key in the pre-built hash map. Further details on these operations can be found in the supplementary materials."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To enhance the efficiency of our point cloud processing, we have optimized our window-based operations to take advantage of the natural sparsity of point clouds. Specifically, we have implemented window center searching, window gathering, and balanced window sampling using CUDA operations, which rely on a hash map that maps coordinate space to voxel indices [23]. For instance, during the window gathering operation, we query each potential position within the window relative to a given center, and retrieve corresponding features if the position is a valid key in the pre-built hash map. Further details on these operations can be found in the supplementary materials."}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To improve the efficiency of our point cloud processing, we have leveraged the natural sparsity of point clouds by optimizing our window-based operations. Specifically, we have implemented a range of CUDA-based operations, including window center searching, gathering, and balanced sampling, which utilize a hash map that maps coordinate space to voxel indices [23]. For example, during window gathering, we query each potential position within the window relative to a given center, and retrieve corresponding features if the position corresponds to a valid key in the pre-built hash map. Further details on these operations can be found in the supplementary materials."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To enhance efficiency, we leveraged the natural sparsity of point clouds by implementing our window center searching, window gathering, and balanced window sampling operations in CUDA. These operations rely on a hash map that maps coordinate space to voxel indices [23]. Specifically, during the window gathering operation, we query each possible position within the window relative to the given center and retrieve corresponding features if the position is a valid key in the pre-built hash map. Further details are provided in the supplementary materials."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To enhance the efficiency of our point cloud processing, we have optimized our window-based operations to take advantage of the natural sparsity of point clouds. Specifically, we have implemented window center searching, window gathering, and balanced window sampling using CUDA operations, which rely on a hash map that maps coordinate space to voxel indices [23]. For instance, during the window gathering operation, we query each potential position within the window relative to a given center, and retrieve corresponding features if the position is a valid key in the pre-built hash map. Further details on these operations can be found in the supplementary materials."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "instruction": "Revise this paragraph for better readability.", "revised_paragraph": "Revised paragraph: To improve the efficiency of our algorithm, we leveraged the natural sparsity of point clouds by implementing our window center searching, gathering, and balanced sampling operations in CUDA. These operations rely on a hash map that maps coordinate space to voxel indices [23]. For instance, in the window gathering operation, we query each possible position relative to the given center within the window and retrieve corresponding features if the position is a valid key in the pre-built hash map. Further details on this implementation can be found in the supplementary materials.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.05", "instruction": "Improve the flow of ideas for better readability.", "revised_paragraph": "Revised paragraph: To enhance the efficiency of our method, we leverage the natural sparsity of point clouds by implementing our window center searching, window gathering, and balanced window sampling operations in a sparse manner using CUDA. These operations rely on a hash map that maps coordinate space to voxel indices [23]. Specifically, during the window gathering operation, we query each possible position within the window relative to the given center and retrieve corresponding features if the position is a valid key in the pre-built hash map. Further details can be found in the supplementary materials.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The development of deep CNNs has led to significant improvements in image super-resolution (SR). While SRCNN (Dong et al., 2014) was a pioneer in this field, its limited depth hindered its performance. Subsequent works, such as VDSR (Kim et al., 2016a), EDSR (Lim et al., 2017), and RCAN (Zhang et al., 2018b), have increased the network depth and achieved remarkable SR results. However, these very deep networks suffer from heavy model parameters, computational complexity, and inference time, making them unsuitable for deployment on resource-limited platforms.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Deep convolutional neural networks (CNNs) have been widely utilized for image super-resolution (SR) tasks, with SRCNN (Dong et al., 2014) being one of the pioneering works. However, SRCNN's limited depth, consisting of only three convolutional layers, hinders its performance. To address this limitation, subsequent works such as VDSR (Kim et al., 2016a) and EDSR (Lim et al., 2017) have increased the network depth using residual learning and simplified residual blocks, respectively. The most recent advancements in SR have led to the development of extremely deep networks, such as RCAN (Zhang et al., 2018b), which have achieved remarkable SR performance. Nevertheless, these deep networks come with a significant increase in model parameters, computational complexity, and inference time, making it impractical to deploy them on resource-constrained platforms without specialized hardware or memory."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Deep convolutional neural networks (CNNs) have been widely utilized for image super-resolution (SR) tasks, with SRCNN (Dong et al., 2014) being one of the pioneering works. However, SRCNN's limited depth, consisting of only three convolutional layers, hinders its performance. To address this limitation, subsequent works such as VDSR (Kim et al., 2016a) and EDSR (Lim et al., 2017) have increased the network depth using residual learning and simplified residual blocks, respectively. The most recent advancements in SR have led to the development of extremely deep networks, such as RCAN (Zhang et al., 2018b), which have achieved remarkable SR performance. Nevertheless, these deep networks come with a significant increase in model parameters, computational complexity, and inference time, making it impractical to deploy them on resource-constrained platforms without specialized hardware or memory."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Deep convolutional neural networks (CNNs) have been widely utilized for image super-resolution (SR) tasks, with SRCNN (Dong et al., 2014) being one of the pioneering works. However, SRCNN's limited depth, consisting of only three convolutional layers, hinders its performance. To address this limitation, subsequent works such as VDSR (Kim et al., 2016a) and EDSR (Lim et al., 2017) have increased the network depth using residual learning and simplified residual blocks, respectively. The most recent advancements in SR have led to the development of extremely deep networks, such as RCAN (Zhang et al., 2018b), which have achieved remarkable SR performance. Nevertheless, these deep networks come with a significant increase in model parameters, computational complexity, and inference time, making it impractical to deploy them on resource-constrained platforms without specialized hardware or memory."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The development of deep CNNs has led to significant improvements in image super-resolution (SR). While SRCNN (Dong et al., 2014) was a pioneer in this field, its limited depth hindered its performance. Subsequent works, such as VDSR (Kim et al., 2016a), EDSR (Lim et al., 2017), and RCAN (Zhang et al., 2018b), have increased the network depth and achieved remarkable SR results. However, these very deep networks suffer from heavy model parameters, computational complexity, and inference time, making them unsuitable for deployment on resource-limited platforms.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Deep convolutional neural networks (CNNs) have been widely utilized for image super-resolution (SR) tasks, with SRCNN (Dong et al., 2014) being one of the pioneering works. However, SRCNN's limited depth, consisting of only three convolutional layers, hinders its performance. To address this limitation, subsequent works such as VDSR (Kim et al., 2016a) and EDSR (Lim et al., 2017) have increased the network depth using residual learning and simplified residual blocks, respectively. The most recent advancements in SR have led to the development of extremely deep networks, such as RCAN (Zhang et al., 2018b), which have achieved remarkable SR performance. Nevertheless, these deep networks come with a significant increase in model parameters, computational complexity, and inference time, making it impractical to deploy them on resource-constrained platforms without specialized hardware or memory."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The development of deep CNNs has led to significant improvements in image super-resolution (SR). While SRCNN (Dong et al., 2014) was a pioneer in this field, its limited depth hindered its performance. Subsequent works, such as VDSR (Kim et al., 2016a), EDSR (Lim et al., 2017), and RCAN (Zhang et al., 2018b), have increased the network depth and achieved remarkable SR results. However, these very deep networks suffer from heavy model parameters, computational complexity, and inference time, making them unsuitable for deployment on resource-limited platforms.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The development of deep convolutional neural networks (CNNs) has led to substantial advancements in image super-resolution (SR). While SRCNN, introduced by Dong et al. in 2014, was a pioneering work in this field, its limited depth constrained its performance. Subsequent studies, such as VDSR (Kim et al., 2016a), EDSR (Lim et al., 2017), and RCAN (Zhang et al., 2018b), have increased the network depth, resulting in remarkable SR outcomes. However, these very deep networks are hindered by heavy model parameters, high computational complexity, and slow inference times, making them unsuitable for deployment on resource-constrained platforms.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Deep convolutional neural networks (CNNs) have been widely utilized for image super-resolution (SR) tasks, with SRCNN (Dong et al., 2014) being one of the pioneering works. However, SRCNN's limited depth, consisting of only three convolutional layers, hinders its performance. To address this limitation, subsequent works such as VDSR (Kim et al., 2016a) and EDSR (Lim et al., 2017) have increased the network depth using residual learning and simplified residual blocks, respectively. The most recent advancements in SR have led to the development of extremely deep networks, such as RCAN (Zhang et al., 2018b), which have achieved remarkable SR performance. Nevertheless, these deep networks come with a significant increase in model parameters, computational complexity, and inference time, making it impractical to deploy them on resource-constrained platforms without specialized hardware or memory."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Deep convolutional neural networks (CNNs) have been widely utilized for image super-resolution (SR) tasks, with SRCNN (Dong et al., 2014) being one of the pioneering works. However, SRCNN's limited depth, consisting of only three convolutional layers, hinders its performance. To address this limitation, subsequent works such as VDSR (Kim et al., 2016a) and EDSR (Lim et al., 2017) have increased the network depth using residual learning and simplified residual blocks, respectively. The most recent advancements in SR have led to the development of extremely deep networks, such as RCAN (Zhang et al., 2018b), which have achieved remarkable SR performance. Nevertheless, these deep networks come with a significant increase in model parameters, computational complexity, and inference time, making it impractical to deploy them on resource-constrained platforms without specialized hardware or memory."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The development of deep CNNs has led to significant improvements in image super-resolution (SR). While SRCNN (Dong et al., 2014) was a pioneer in this field, its limited depth hindered its performance. Subsequent works, such as VDSR (Kim et al., 2016a), EDSR (Lim et al., 2017), and RCAN (Zhang et al., 2018b), have increased the network depth and achieved remarkable SR results. However, these very deep networks suffer from heavy model parameters, computational complexity, and inference time, making them unsuitable for deployment on resource-limited platforms.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The development of deep convolutional neural networks (CNNs) has led to substantial advancements in image super-resolution (SR). While SRCNN, introduced by Dong et al. in 2014, was a pioneering work in this field, its limited depth constrained its performance. Subsequent studies, such as VDSR (Kim et al., 2016a), EDSR (Lim et al., 2017), and RCAN (Zhang et al., 2018b), have increased the network depth, resulting in remarkable SR outcomes. However, these very deep networks are hindered by heavy model parameters, high computational complexity, and slow inference times, making them unsuitable for deployment on resource-constrained platforms.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "instruction": "Can you make the last sentence simple?", "revised_paragraph": "Revised paragraph: \"Deep CNN is first utilized for image SR in SRCNN (Dong et al., 2014) and has shown promising SR performance. However, SRCNN has only three convolutional layers, limiting its performance. Later, researchers increased the network depth in VDSR (Kim et al., 2016a) and EDSR (Lim et al., 2017) using residual learning, achieving notable improvements. RCAN (Zhang et al., 2018b) is one of the deepest networks in SR. While these very deep networks have achieved remarkable SR performance, they also have heavy model parameters, number of operations, and inference time, making them impractical for resource-limited platforms.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.02", "instruction": "Use shorter, more direct formulations to make this paragraph more concise. Rewrite the last two sentences to make them more understandable.", "revised_paragraph": "Revised paragraph: \n\nThe Deep CNN has been employed for image super-resolution (SR) in SRCNN (Dong et al., 2014), showcasing promising SR performance. However, SRCNN's limited three convolutional layers hinder its performance. To address this, researchers have increased network depth in VDSR (Kim et al., 2016a) with residual learning, and in EDSR (Lim et al., 2017) and RCAN (Zhang et al., 2018b) using simplified residual blocks. While these deeper networks achieve remarkable SR performance, they are impractical for resource-limited platforms without dedicated hardware, due to their large model parameters, computational costs, and inference times (Lee et al., 2020).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our method achieves 42.6% in terms of the mIoU values on the MS COCO 2014 validation set, surpassing the baseline IRN [1] by 1.2% and outperforming other recent methods by a large margin."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Our method achieves 42.6% mIoU values on the MS COCO 2014 validation set, surpassing the baseline IRN [1] by 1.2% and outperforming other recent methods [8, 56, 49, 1] by a large margin. Compared to IRN [1] and CONTA [56], our method achieves a 1.2% mIoU improvement."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The segmentation performance of our method on the MS COCO 2014 dataset is presented in Table 2, which demonstrates a significant improvement over existing methods. Our approach achieves a mIoU value of 42.6% on the validation set, surpassing the IRN method [1] by 1.2% and outperforming other recent competitive methods [8, 56, 49, 1] by a substantial margin. Notably, we replicate the results of IRN [1] using CONTA [56], achieving a mIoU value of 41.4%. To facilitate comparison, we highlight the relative improvements: CONTA achieves a 0.8% mIoU improvement over IRN (32.6 to 33.4), while our method achieves a 1.2% mIoU improvement (41.4 to 42.6)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our method achieves 42.6% in terms of the mIoU values on the MS COCO 2014 validation set, surpassing the baseline IRN [1] by 1.2% and outperforming other recent methods by a large margin."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The segmentation performance of our method on the MS COCO 2014 dataset is presented in Table 2, which demonstrates a significant improvement over existing methods. Our approach achieves a mIoU value of 42.6% on the validation set, surpassing the IRN method [1] by 1.2% and outperforming other recent competitive methods [8, 56, 49, 1] by a substantial margin. Notably, we replicate the results of IRN [1] using CONTA [56], achieving a mIoU value of 41.4%. To facilitate comparison, we highlight the relative improvements: CONTA achieves a 0.8% mIoU improvement over IRN (32.6 to 33.4), while our method achieves a 1.2% mIoU improvement (41.4 to 42.6)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our method achieves 42.6% mIoU values on the MS COCO 2014 validation set, surpassing the baseline IRN [1] by 1.2% and outperforming other recent methods [8, 56, 49, 1] by a large margin. Compared to IRN [1] and CONTA [56], our method achieves a 1.2% mIoU improvement."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our method achieves 42.6% in terms of the mIoU values on the MS COCO 2014 validation set, surpassing the baseline IRN [1] by 1.2% and outperforming other recent methods by a large margin."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our method outperforms the baseline IRN [1] by 1.2% and achieves 42.6% mIoU on the MS COCO 2014 validation set, exceeding other recent methods."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our method significantly outperforms the baseline IRN [1], boasting a 1.2% improvement and achieving a remarkable 42.6% mean IoU (mIoU) on the MS COCO 2014 validation set, thereby surpassing other recent methods."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our method achieves 42.6% in terms of the mIoU values on the MS COCO 2014 validation set, surpassing the baseline IRN [1] by 1.2% and outperforming other recent methods by a large margin."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our method surpasses the baseline IRN [1] by 1.2% and achieves a significantly higher mIoU value of 42.6% on the MS COCO 2014 validation set, outperforming other recent methods by a substantial margin."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our method achieves 42.6% mIoU values on the MS COCO 2014 validation set, surpassing the baseline IRN [1] by 1.2% and outperforming other recent methods [8, 56, 49, 1] by a large margin. Compared to IRN [1] and CONTA [56], our method achieves a 1.2% mIoU improvement."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "instruction": "Remove unnecessary details and make my numbers clear.", "revised_paragraph": "Revised paragraph: \"Our method outperforms the IRN [1] and other recent competitive methods [8, 56, 49, 1] on the MS COCO 2014 dataset, achieving 42.6% mIoU values on the validation set, a 1.2% improvement over the baseline. In comparison, CONTA [56] achieves a 0.8% mIoU improvement over IRN (32.6 to 33.4), while our method achieves a 1.2% improvement (41.4 to 42.6).\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.01", "instruction": "Remove the sentence about reproduction", "revised_paragraph": "Revised paragraph: Our method achieves 42.6% in terms of the mIoU values on the validation set, surpassing the IRN [1] by 1.2% and outperforming other recent competitive methods [8, 56, 49, 1] by a large margin.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutating amino acids, which can lead to unknown rotamers for the mutated amino acids and inaccurate ones for nearby residues. We define our probability density over the d-dimensional torus TD = (S1)D, and propose a flow-based architecture to model it, which we detail below.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutations occur in the protein complex. For instance, if we introduce mutations to some amino acids, the rotamers of the mutated residues are unknown, and those of nearby residues are inaccurate due to the mutation's influence. Our proposed flow-based architecture models the probability density over the d-dimensional torus Td = (S1)d, which is defined over this space."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutations occur in the protein complex. For instance, if we introduce mutations to some amino acids, the rotamers of the mutated residues are unknown, and those of nearby residues are inaccurate due to the mutation's influence. Our proposed flow-based architecture models the probability density over the d-dimensional torus Td = (S1)d, which is defined over this space."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutations occur in the protein complex. For instance, if we introduce mutations to some amino acids, the rotamers of the mutated residues are unknown, and those of nearby residues are inaccurate due to the mutation's influence. Our proposed flow-based architecture models the probability density over the d-dimensional torus Td = (S1)d, which is defined over this space."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutating amino acids, which can lead to unknown rotamers for the mutated amino acids and inaccurate ones for nearby residues. We define our probability density over the d-dimensional torus TD = (S1)D, and propose a flow-based architecture to model it, which we detail below.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutations occur in the protein complex. For instance, if we introduce mutations to some amino acids, the rotamers of the mutated residues are unknown, and those of nearby residues are inaccurate due to the mutation's influence. Our proposed flow-based architecture models the probability density over the d-dimensional torus Td = (S1)d, which is defined over this space."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutating amino acids, which can lead to unknown rotamers for the mutated amino acids and inaccurate ones for nearby residues. We define our probability density over the d-dimensional torus TD = (S1)D, and propose a flow-based architecture to model it, which we detail below.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Previous rotamer predictions (\u03c7j) are often inaccurate or unknown, especially when mutating amino acids, which can result in unknown rotamers for the mutated residues and inaccurate predictions for nearby residues. We define a probability density function over the d-dimensional torus TD = (S1)D and propose a flow-based architecture to model it, which is described in detail below.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutations occur in the protein complex. For instance, if we introduce mutations to some amino acids, the rotamers of the mutated residues are unknown, and those of nearby residues are inaccurate due to the mutation's influence. Our proposed flow-based architecture models the probability density over the d-dimensional torus Td = (S1)d, which is defined over this space."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutations occur in the protein complex. For instance, if we introduce mutations to some amino acids, the rotamers of the mutated residues are unknown, and those of nearby residues are inaccurate due to the mutation's influence. Our proposed flow-based architecture models the probability density over the d-dimensional torus Td = (S1)d, which is defined over this space."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Prior rotamers \u03c7j are often inaccurate or unknown, particularly when mutating amino acids, which can lead to unknown rotamers for the mutated amino acids and inaccurate ones for nearby residues. We define our probability density over the d-dimensional torus TD = (S1)D, and propose a flow-based architecture to model it, which we detail below.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Previous rotamer predictions (\u03c7j) are often inaccurate or unknown, especially when mutating amino acids, which can result in unknown rotamers for the mutated residues and inaccurate predictions for nearby residues. We define a probability density function over the d-dimensional torus TD = (S1)D and propose a flow-based architecture to model it, which is described in detail below.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "instruction": "Replace every apparition of \"\"amino acids\" or \"amino acids in the protein complex\" by \"residues\"", "revised_paragraph": "Revised paragraph: The prior rotamers \u03c7j are inaccurate or unknown in many cases. For example, if we mutate some residues in the protein complex, the rotamers of the mutated residues are unknown, and the rotamers of residues nearby the mutated ones are inaccurate because they are affected by the mutation. The probability density is defined over the d-dimensional torus TD = (S1)D, and we show below our proposed flow-based architecture to model the density.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.12", "instruction": "Replace occurrences of amino acids by residues. Make this paragraph a lit bit more concise.", "revised_paragraph": "Revised paragraph: \"The prior rotamers \u03c7j are often inaccurate or unknown. For instance, when mutating residues in a protein complex, the rotamers of the mutated residues are unknown, while those of nearby residues are inaccurate due to the mutation. Our proposed flow-based architecture models the probability density over the d-dimensional torus TD = (S1)D.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). The inverse GCN can be written as, recalling the input of GDN in Section 3.2.2: smoothed representations H and recovered structure A."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Meanwhile, a feature transformation can be applied to enhance the filter strength, as suggested by Li et al. (2019b). To recap, the input to the GDN, as discussed in Section 3.2.2, consists of the smoothed representations H and the recovered structure A. This allows the inverse version of the GCN to be written as:"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). The inverse GCN can be written as, recalling the input of GDN in Section 3.2.2: smoothed representations H and recovered structure A."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Meanwhile, a feature transformation can be applied to enhance the filter strength, as suggested by Li et al. (2019b). To recap, the input to the GDN, as discussed in Section 3.2.2, consists of the smoothed representations H and the recovered structure A. This allows the inverse version of the GCN to be written as:"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). The inverse GCN can be written as, recalling the input of GDN in Section 3.2.2: smoothed representations H and recovered structure A."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Meanwhile, a feature transformation can be applied to enhance the filter strength, as suggested by Li et al. (2019b). To recap, the input to the GDN, as discussed in Section 3.2.2, consists of the smoothed representations H and the recovered structure A. This allows the inverse version of the GCN to be written as:"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). The inverse GCN can be written as, recalling the input of GDN in Section 3.2.2: smoothed representations H and recovered structure A."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Meanwhile, a feature transformation can be applied to enhance the filter strength, as suggested by Li et al. (2019b). To recap, the input to the GDN, as discussed in Section 3.2.2, consists of the smoothed representations H and the recovered structure A. This allows the inverse version of the GCN to be written as:"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). The inverse GCN can be written as, recalling the input of GDN in Section 3.2.2: smoothed representations H and recovered structure A."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can improve the effectiveness of filters, as demonstrated by Li et al. (2019b). Specifically, the inverse GCN can be represented as, building upon the input of GDN described in Section 3.2.2, where smoothed representations H and recovered structure A are considered."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). The inverse GCN can be written as, recalling the input of GDN in Section 3.2.2: smoothed representations H and recovered structure A."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can improve the effectiveness of filters, as demonstrated by Li et al. (2019b). Specifically, the inverse GCN can be represented as, building upon the input of GDN described in Section 3.2.2, where smoothed representations H and recovered structure A are considered."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). The inverse GCN can be written as, recalling the input of GDN in Section 3.2.2: smoothed representations H and recovered structure A."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can improve the effectiveness of filters, as demonstrated by Li et al. (2019b). Specifically, the inverse GCN can be represented as, building upon the input of GDN described in Section 3.2.2, where smoothed representations H and recovered structure A are considered."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). The inverse GCN can be written as, recalling the input of GDN in Section 3.2.2: smoothed representations H and recovered structure A."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can improve the effectiveness of filters, as demonstrated by Li et al. (2019b). Specifically, the inverse GCN can be represented as, building upon the input of GDN described in Section 3.2.2, where smoothed representations H and recovered structure A are considered."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "instruction": "Make the text more concise by describing concepts more high-level.", "revised_paragraph": "Revised paragraph: Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). Building on Section 3.2.2, the input to GDN consists of smoothed representations H and recovered structure A, which can be inverted to derive the GCN inverse.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "instruction": "Make the text more direct and concise.", "revised_paragraph": "Revised paragraph: Meanwhile, a feature transformation can be used to enhance filter strength, as suggested by Li et al. (2019b). Recall that GDN's input in Section 3.2.2 consists of smoothed representations H and recovered structure A. The inverse GCN can be written as:", "type_approach": "instruction-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe present a proactive multi-camera collaboration framework, grounded in multi-agent reinforcement learning (MARL), for real-time, distributed adjustments of multi-camera formations in 3D human pose estimation (HPE) within a human crowd. In our approach, multiple camera agents seamlessly collaborate to achieve successful reconstructions of 3D human poses. Notably, this decentralized framework offers flexibility in formation size and eliminates the need for a control hierarchy or centralized entity. Crucially, we emphasize the importance of our model's ability to anticipate human motions and future environmental states. To incorporate these properties into state representations, we integrate World Dynamics Learning into our model's training, involving five auxiliary tasks to predict target position, pedestrian positions, self-state, teammates' states, and team reward."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe present a proactive multi-camera collaboration framework, grounded in multi-agent reinforcement learning (MARL), for real-time, distributed adjustments of multi-camera formations in 3D human pose estimation (HPE) within a human crowd. In our approach, multiple camera agents seamlessly collaborate to achieve successful reconstructions of 3D human poses. Notably, this decentralized framework offers flexibility in formation size and eliminates the need for a control hierarchy or centralized entity. Crucially, we emphasize the importance of our model's ability to anticipate human motions and future environmental states. To incorporate these properties into state representations, we integrate World Dynamics Learning into our model's training, involving five auxiliary tasks to predict target position, pedestrian positions, self-state, teammates' states, and team reward."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe present a proactive multi-camera collaboration framework, grounded in multi-agent reinforcement learning (MARL), for real-time, distributed adjustments of multi-camera formations in 3D human pose estimation (HPE) within a human crowd. In our approach, multiple camera agents seamlessly collaborate to achieve successful reconstructions of 3D human poses. Notably, this decentralized framework offers flexibility in formation size and eliminates the need for a control hierarchy or centralized entity. Crucially, we emphasize the importance of our model's ability to anticipate human motions and future environmental states. To incorporate these properties into state representations, we integrate World Dynamics Learning into our model's training, involving five auxiliary tasks to predict target position, pedestrian positions, self-state, teammates' states, and team reward."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe present a proactive multi-camera collaboration framework, grounded in multi-agent reinforcement learning (MARL), for real-time, distributed adjustments of multi-camera formations in 3D human pose estimation (HPE) within a human crowd. In our approach, multiple camera agents seamlessly collaborate to achieve successful reconstructions of 3D human poses. Notably, this decentralized framework offers flexibility in formation size and eliminates the need for a control hierarchy or centralized entity. Crucially, we emphasize the importance of our model's ability to anticipate human motions and future environmental states. To incorporate these properties into state representations, we integrate World Dynamics Learning into our model's training, involving five auxiliary tasks to predict target position, pedestrian positions, self-state, teammates' states, and team reward."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe present a proactive multi-camera collaboration framework, grounded in multi-agent reinforcement learning (MARL), for real-time, distributed adjustments of multi-camera formations in 3D human pose estimation (HPE) within a human crowd. In our approach, multiple camera agents seamlessly collaborate to achieve successful reconstructions of 3D human poses. Notably, this decentralized framework offers flexibility in formation size and eliminates the need for a control hierarchy or centralized entity. Crucially, we emphasize the importance of our model's ability to anticipate human motions and future environmental states. To incorporate these properties into state representations, we integrate World Dynamics Learning into our model's training, involving five auxiliary tasks to predict target position, pedestrian positions, self-state, teammates' states, and team reward."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe present a proactive multi-camera collaboration framework, grounded in multi-agent reinforcement learning (MARL), for real-time, distributed adjustments of multi-camera formations in 3D human pose estimation (HPE) within a human crowd. In our approach, multiple camera agents seamlessly collaborate to achieve successful reconstructions of 3D human poses. Notably, this decentralized framework offers flexibility in formation size and eliminates the need for a control hierarchy or centralized entity. Crucially, we emphasize the importance of our model's ability to anticipate human motions and future environmental states. To incorporate these properties into state representations, we integrate World Dynamics Learning into our model's training, involving five auxiliary tasks to predict target position, pedestrian positions, self-state, teammates' states, and team reward."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe present a proactive multi-camera collaboration framework, grounded in multi-agent reinforcement learning (MARL), for real-time, distributed adjustments of multi-camera formations in 3D human pose estimation (HPE) within a human crowd. In our approach, multiple camera agents seamlessly collaborate to achieve successful reconstructions of 3D human poses. Notably, this decentralized framework offers flexibility in formation size and eliminates the need for a control hierarchy or centralized entity. Crucially, we emphasize the importance of our model's ability to anticipate human motions and future environmental states. To incorporate these properties into state representations, we integrate World Dynamics Learning into our model's training, involving five auxiliary tasks to predict target position, pedestrian positions, self-state, teammates' states, and team reward."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe present a proactive multi-camera collaboration framework, grounded in multi-agent reinforcement learning (MARL), for real-time, distributed adjustments of multi-camera formations in 3D human pose estimation (HPE) within a human crowd. In our approach, multiple camera agents seamlessly collaborate to achieve successful reconstructions of 3D human poses. Notably, this decentralized framework offers flexibility in formation size and eliminates the need for a control hierarchy or centralized entity. Crucially, we emphasize the importance of our model's ability to anticipate human motions and future environmental states. To incorporate these properties into state representations, we integrate World Dynamics Learning into our model's training, involving five auxiliary tasks to predict target position, pedestrian positions, self-state, teammates' states, and team reward."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "instruction": "Rephrase the text", "revised_paragraph": "Revised paragraph: \n\nWe present a novel multi-camera collaboration framework, grounded in multi-agent reinforcement learning (MARL), for real-time, distributed adjustments of multi-camera formations to facilitate 3D human pose estimation (HPE) in crowded environments. Our approach enables seamless collaboration among multiple camera agents to achieve successful 3D human pose reconstructions. Notably, this decentralized framework offers flexibility in formation size and eliminates the need for a centralized control hierarchy or entity. To address the first challenge, we emphasize the critical importance of the model's ability to anticipate human motions and future environmental states. To incorporate these properties into state representations, we integrate World Dynamics Learning into our model's training, utilizing five auxiliary tasks to predict target position, pedestrian positions, self-state, teammate states, and team reward.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.00", "instruction": "Remove redundant words.", "revised_paragraph": "Revised paragraph: We introduce a proactive multi-camera collaboration framework based on multi-agent reinforcement learning (MARL) for real-time distributive adjustments of multi-camera formation for 3D HPE in a human crowd. Multiple camera agents collaborate seamlessly for successful 3D human pose reconstructions. The decentralized framework offers flexibility in formation size and eliminates the need for a control hierarchy or centralized entity. We emphasize the importance of anticipating human motions and future environmental states. To model these properties, we incorporate World Dynamics Learning into our model's training, using five auxiliary tasks to predict target and pedestrian positions, self and teammate states, and team rewards.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Shan et al. (2022) discovered five single-point mutations on a human antibody against SARS-CoV-2 that significantly enhance its neutralization capabilities. There are a total of 494 possible single-point mutations on the heavy chain CDR region of the antibody. We employed the most competitive methods, as benchmarked in Section 4.1, to predict the free energy changes (\u0394\u0394G) for all mutations and ranked them in ascending order, with the lowest \u0394\u0394G values at the top. A predictor is considered more effective if it correctly identifies and ranks more favorable mutations in the top positions. As shown in Table 2, RDE-Network and DDGPred successfully identified three mutations, with RDE-Network ranking them higher among the top 10%."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Shan et al. (2022) identified five single-point mutations on a human antibody against SARS-CoV-2 that enhance its neutralization effectiveness. Of the 494 possible single-point mutations on the heavy chain CDR region of the antibody, we used the most competitive methods benchmarked in Section 4.1 to predict the \u0394\u0394G values for all mutations and ranked them in ascending order, from lowest to highest. A predictor is considered more effective if it correctly identifies and ranks more favorable mutations at the top of the list. As shown in Table 2, RDE-Network and DDGPred successfully identified three mutations, with RDE-Network ranking them higher."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Shan et al. (2022) discovered five single-point mutations on a human antibody against SARS-CoV-2 that significantly enhance its neutralization capabilities. There are a total of 494 possible single-point mutations on the heavy chain CDR region of the antibody. We employed the most competitive methods, as benchmarked in Section 4.1, to predict the free energy changes (\u0394\u0394G) for all mutations and ranked them in ascending order, with the lowest \u0394\u0394G values at the top. A predictor is considered more effective if it correctly identifies and ranks more favorable mutations in the top positions. As shown in Table 2, RDE-Network and DDGPred successfully identified three mutations, with RDE-Network ranking them higher among the top 10%."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Shan et al. (2022) identified five single-point mutations on a human antibody against SARS-CoV-2 that enhance its neutralization effectiveness. Of the 494 possible single-point mutations on the heavy chain CDR region of the antibody, we used the most competitive methods benchmarked in Section 4.1 to predict the \u0394\u0394G values for all mutations and ranked them in ascending order, from lowest to highest. A predictor is considered more effective if it correctly identifies and ranks more favorable mutations at the top of the list. As shown in Table 2, RDE-Network and DDGPred successfully identified three mutations, with RDE-Network ranking them higher."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Shan et al. (2022) discovered five single-point mutations on a human antibody against SARS-CoV-2 that significantly enhance its neutralization capabilities. There are a total of 494 possible single-point mutations on the heavy chain CDR region of the antibody. We employed the most competitive methods, as benchmarked in Section 4.1, to predict the free energy changes (\u0394\u0394G) for all mutations and ranked them in ascending order, with the lowest \u0394\u0394G values at the top. A predictor is considered more effective if it correctly identifies and ranks more favorable mutations in the top positions. As shown in Table 2, RDE-Network and DDGPred successfully identified three mutations, with RDE-Network ranking them higher among the top 10%."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Shan et al. (2022) identified five single-point mutations on a human antibody against SARS-CoV-2 that significantly enhance its neutralization capabilities. The heavy chain CDR region of the antibody contains 494 possible single-point mutations, which we investigated using the most competitive methods, as benchmarked in Section 4.1. We calculated the free energy changes (\u0394\u0394G) for all mutations and ranked them in ascending order, with the lowest \u0394\u0394G values at the top. A predictor's effectiveness is measured by its ability to correctly identify and rank more favorable mutations in the top positions. As shown in Table 2, RDE-Network and DDGPred demonstrated success in identifying three mutations, with RDE-Network ranking them higher among the top 10%."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Shan et al. (2022) discovered five single-point mutations on a human antibody against SARS-CoV-2 that significantly enhance its neutralization capabilities. There are a total of 494 possible single-point mutations on the heavy chain CDR region of the antibody. We employed the most competitive methods, as benchmarked in Section 4.1, to predict the free energy changes (\u0394\u0394G) for all mutations and ranked them in ascending order, with the lowest \u0394\u0394G values at the top. A predictor is considered more effective if it correctly identifies and ranks more favorable mutations in the top positions. As shown in Table 2, RDE-Network and DDGPred successfully identified three mutations, with RDE-Network ranking them higher among the top 10%."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Shan et al. (2022) identified five single-point mutations on a human antibody against SARS-CoV-2 that enhance its neutralization effectiveness. Of the 494 possible single-point mutations on the heavy chain CDR region of the antibody, we used the most competitive methods benchmarked in Section 4.1 to predict the \u0394\u0394G values for all mutations and ranked them in ascending order, from lowest to highest. A predictor is considered more effective if it correctly identifies and ranks more favorable mutations at the top of the list. As shown in Table 2, RDE-Network and DDGPred successfully identified three mutations, with RDE-Network ranking them higher."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "instruction": "Fluidify this paragraph.", "revised_paragraph": "Revised paragraph: Shan et al. (2022) discovered that five specific single-point mutations on a human antibody against SARS-CoV-2 significantly enhance its neutralization capabilities. Of the 494 possible single-point mutations in the heavy chain CDR region of the antibody, we employed the most competitive prediction methods, as benchmarked in Section 4.1, to calculate the free energy changes (\u2206\u2206G) for each mutation and ranked them in ascending order from lowest to highest. A predictor's effectiveness is gauged by its ability to identify more favorable mutations in the top-ranked positions. As shown in Table 2, RDE-Network and DDGPred demonstrated success in identifying three mutations (ranking \u2264 10%), with RDE-Network achieving higher rankings for these mutations.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.22", "instruction": "Improve the English in this paragraph in an academic style.", "revised_paragraph": "Revised paragraph: Shan et al. (2022) discovered five single-point mutations on a human antibody against SARS-CoV-2 that significantly enhance its neutralization capabilities. The heavy chain CDR region of the antibody contains a total of 494 possible single-point mutations. Utilizing the most competitive methods benchmarked in Section 4.1, we predicted the \u2206\u2206G values for all mutations and ranked them in ascending order, with the lowest \u2206\u2206G values occupying the top positions. A predictor is deemed more effective if it accurately ranks more favorable mutations in the top tier. As demonstrated in Table 2, RDE-Network and DDGPred successfully identified three mutations, with RDE-Network achieving a higher ranking for these mutations, indicating a ranking of \u2264 10%.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The task was designed in accordance with previous research [25]. Figure 3 illustrates the task's schematic design. The task presented a pink circular start area (251-pixel radius) and a green target on a gray background. The trial began with participants clicking on the start area, after which the cursor was fixed at the center. To minimize the impact of initial cursor position on performance, the starting position was strictly controlled. Participants then aimed at the target and ended the trial with a subsequent click. The start area disappeared as a visual cue indicating the trial's commencement. Successful trials were marked by a correct click on the target, while incorrect clicks resulted in a failure (error). Following each trial, participants received an auditory feedback signal indicating success or failure."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The task was designed in accordance with previous research [25]. Figure 3 illustrates the task's schematic design. The task presented a pink circular start area (251-pixel radius) and a green target on a gray background. The trial began with participants clicking on the start area, after which the cursor was fixed at the center. To minimize the impact of initial cursor position on performance, the starting position was strictly controlled. Participants then aimed at the target and ended the trial with a subsequent click. The start area disappeared as a visual cue indicating the trial's commencement. Successful trials were marked by a correct click on the target, while incorrect clicks resulted in a failure (error). Following each trial, participants received an auditory feedback signal indicating success or failure."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The task was designed in accordance with previous research [25]. Figure 3 illustrates the task's schematic design. The task presented a pink circular start area (251-pixel radius) and a green target on a gray background. The trial began with participants clicking on the start area, after which the cursor was fixed at the center. To minimize the impact of initial cursor position on performance, the starting position was strictly controlled. Participants then aimed at the target and ended the trial with a subsequent click. The start area disappeared as a visual cue indicating the trial's commencement. Successful trials were marked by a correct click on the target, while incorrect clicks resulted in a failure (error). Following each trial, participants received an auditory feedback signal indicating success or failure."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The task was designed in accordance with previous research [25]. Figure 3 illustrates the task's schematic design. The task presented a pink circular start area (251-pixel radius) and a green target on a gray background. The trial began with participants clicking on the start area, after which the cursor was fixed at the center. To minimize the impact of initial cursor position on performance, the starting position was strictly controlled. Participants then aimed at the target and ended the trial with a subsequent click. The start area disappeared as a visual cue indicating the trial's commencement. Successful trials were marked by a correct click on the target, while incorrect clicks resulted in a failure (error). Following each trial, participants received an auditory feedback signal indicating success or failure."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The task was designed in accordance with previous research [25]. Figure 3 illustrates the task's schematic design. The task presented a pink circular start area (251-pixel radius) and a green target on a gray background. The trial began with participants clicking on the start area, after which the cursor was fixed at the center. To minimize the impact of initial cursor position on performance, the starting position was strictly controlled. Participants then aimed at the target and ended the trial with a subsequent click. The start area disappeared as a visual cue indicating the trial's commencement. Successful trials were marked by a correct click on the target, while incorrect clicks resulted in a failure (error). Following each trial, participants received an auditory feedback signal indicating success or failure."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The task was designed in accordance with previous research [25]. Figure 3 illustrates the task's schematic design. The task presented a pink circular start area (251-pixel radius) and a green target on a gray background. The trial began with participants clicking on the start area, after which the cursor was fixed at the center. To minimize the impact of initial cursor position on performance, the starting position was strictly controlled. Participants then aimed at the target and ended the trial with a subsequent click. The start area disappeared as a visual cue indicating the trial's commencement. Successful trials were marked by a correct click on the target, while incorrect clicks resulted in a failure (error). Following each trial, participants received an auditory feedback signal indicating success or failure."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The task was designed in accordance with previous research [25]. Figure 3 illustrates the task's schematic design. The task presented a pink circular start area (251-pixel radius) and a green target on a gray background. The trial began with participants clicking on the start area, after which the cursor was fixed at the center. To minimize the impact of initial cursor position on performance, the starting position was strictly controlled. Participants then aimed at the target and ended the trial with a subsequent click. The start area disappeared as a visual cue indicating the trial's commencement. Successful trials were marked by a correct click on the target, while incorrect clicks resulted in a failure (error). Following each trial, participants received an auditory feedback signal indicating success or failure."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The task was designed in accordance with previous research [25]. Figure 3 illustrates the task's schematic design. The task presented a pink circular start area (251-pixel radius) and a green target on a gray background. The trial began with participants clicking on the start area, after which the cursor was fixed at the center. To minimize the impact of initial cursor position on performance, the starting position was strictly controlled. Participants then aimed at the target and ended the trial with a subsequent click. The start area disappeared as a visual cue indicating the trial's commencement. Successful trials were marked by a correct click on the target, while incorrect clicks resulted in a failure (error). Following each trial, participants received an auditory feedback signal indicating success or failure."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "instruction": "Rewrite the middle part of the paragraph to make it more better. Replace some words in the paragraph.", "revised_paragraph": "Revised paragraph: The task was designed with consideration of previous research [25]. Figure 3 illustrates the task's layout. A pink circular start area (251-pixel radius) and a green target were displayed on a gray background. Participants initiated the trial by clicking on the start area, which then fixed the cursor at its center. To minimize the impact of initial cursor position on performance, we enforced a consistent starting position for each trial. Following this, participants aimed for the target, terminating the trial with their next click. The start area's disappearance served as feedback for the trial's commencement. If participants successfully clicked the target, the trial was marked as successful; otherwise, it was recorded as an error. A corresponding auditory feedback was provided for both successful and unsuccessful trials.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.09", "instruction": "Slightly revise for readability, you can reorganise ideas in sentences if necessary.", "revised_paragraph": "Revised paragraph: The task was designed with reference to a previous study [25]. Figure 3 illustrates the task's schematic. On a gray background, a pink circular start area (251-pixel radius) and a green target were displayed. To ensure consistency, the cursor was fixed at the center of the start area after participants clicked on it. This was done to eliminate the potential impact of the initial cursor position on the cursor path and performance. Upon fixing the starting position, the start area disappeared, serving as a feedback signal for the trial's initiation. Participants then aimed for the target and ended the trial with a subsequent click. Successful trials were marked when participants correctly clicked on the target, while errors were recorded for failed attempts. A sound feedback was provided in response to the outcome of each trial.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: As shown in Figure 3, |d_util(f)| increases along \u03bb, especially when log(\u03bb) \u2265 \u22125, and is positively correlated with R(f). This confirms the second conjecture, which states that stronger regularization leads to a larger imbalance in utilization between modalities, making the multi-modal learning process greedier. The trend is consistent for |d_speed|, supporting the choice of using conditional learning speed to predict conditional utilization rate."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: As shown in Figure 3, the absolute value of the utilization imbalance (|d_util(f)|) increases along with the regularization parameter \u03bb, particularly when log(\u03bb) is greater than or equal to -5. Furthermore, |d_util(f)| is positively correlated with the regularization strength (R(f)). This suggests that the stronger the regularization, the more pronounced the imbalance in utilization between modalities becomes, confirming our second conjecture in \u00a73.2. Interestingly, the trend of |d_speed| follows a similar pattern to that of |d_util|, supporting our decision to use the conditional learning speed to predict the conditional utilization rate."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Results show that |d util(f)| increases with \u03bb, particularly when log(\u03bb) \u2265 \u22125, and is positively correlated with R(f). Stronger regularization leads to a larger imbalance in utilization between modalities, confirming our conjecture that regularization makes the multi-modal learning process greedier. This trend is consistent for both |d util(f)| and |d speed|, supporting our choice of using conditional learning speed to predict conditional utilization rate.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results As depicted in Figure 3, the magnitude of |d_util(f)| increases with \u03bb, particularly when log(\u03bb) is greater than or equal to -5. Notably, |d_util(f)| is positively correlated with R(f). This suggests that the stronger the regularization, the more pronounced the imbalance in utilization between modalities becomes. This finding confirms the second conjecture presented in \u00a73.2, which posits that increasing regularization strength leads to a greedier multi-modal learning process. Furthermore, |d_speed| follows a similar trend to |d_util|, providing additional support for our decision to use conditional learning speed to predict conditional utilization rate.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: As shown in Figure 3, |d_util(f)| increases along \u03bb, especially when log(\u03bb) \u2265 \u22125, and is positively correlated with R(f). This confirms the second conjecture, which states that stronger regularization leads to a larger imbalance in utilization between modalities, making the multi-modal learning process greedier. The trend is consistent for |d_speed|, supporting the choice of using conditional learning speed to predict conditional utilization rate."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: As shown in Figure 3, the absolute value of the utilization imbalance (|d_util(f)|) increases along with the regularization parameter \u03bb, particularly when log(\u03bb) is greater than or equal to -5. Furthermore, |d_util(f)| is positively correlated with the regularization strength (R(f)). This suggests that the stronger the regularization, the more pronounced the imbalance in utilization between modalities becomes, confirming our second conjecture in \u00a73.2. Interestingly, the trend of |d_speed| follows a similar pattern to that of |d_util|, supporting our decision to use the conditional learning speed to predict the conditional utilization rate."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Results show that |d util(f)| increases with \u03bb, particularly when log(\u03bb) \u2265 \u22125, and is positively correlated with R(f). Stronger regularization leads to a larger imbalance in utilization between modalities, confirming our conjecture that regularization makes the multi-modal learning process greedier. This trend is consistent for both |d util(f)| and |d speed|, supporting our choice of using conditional learning speed to predict conditional utilization rate.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results As depicted in Figure 3, the magnitude of |d_util(f)| increases with \u03bb, particularly when log(\u03bb) is greater than or equal to -5. Notably, |d_util(f)| is positively correlated with R(f). This suggests that the stronger the regularization, the more pronounced the imbalance in utilization between modalities becomes. This finding confirms the second conjecture presented in \u00a73.2, which posits that increasing regularization strength leads to a greedier multi-modal learning process. Furthermore, |d_speed| follows a similar trend to |d_util|, providing additional support for our decision to use conditional learning speed to predict conditional utilization rate.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: As shown in Figure 3, |d_util(f)| increases along \u03bb, especially when log(\u03bb) \u2265 \u22125, and is positively correlated with R(f). This confirms the second conjecture, which states that stronger regularization leads to a larger imbalance in utilization between modalities, making the multi-modal learning process greedier. The trend is consistent for |d_speed|, supporting the choice of using conditional learning speed to predict conditional utilization rate."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: As illustrated in Figure 3, the absolute difference in utilization between modalities, |d_util(f)|, exhibits a significant increase as the regularization parameter \u03bb increases, particularly when log(\u03bb) is greater than or equal to -5. Moreover, this trend is positively correlated with the model's performance, R(f), which supports the second conjecture. This conjecture suggests that stronger regularization leads to a larger imbalance in utilization between modalities, resulting in a greedier multi-modal learning process. Consistently, the same trend is observed for |d_speed|, validating the choice of using conditional learning speed to predict the conditional utilization rate."}, {"depth": 3, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 3 shows that the absolute difference in utilization between modalities increases significantly as the regularization parameter \u03bb increases, particularly when log(\u03bb) \u2265 -5. This trend is positively correlated with the model's performance, supporting the conjecture that stronger regularization leads to a larger imbalance in utilization between modalities, resulting in a greedier multi-modal learning process."}, {"depth": 4, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 3 illustrates a significant increase in the absolute difference in utilization between modalities as the regularization parameter \u03bb increases, particularly when log(\u03bb) is greater than or equal to -5. This trend is positively correlated with the model's performance, providing evidence that stronger regularization leads to a larger imbalance in utilization between modalities, ultimately resulting in a greedier multi-modal learning process."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: As shown in Figure 3, |d_util(f)| increases along \u03bb, especially when log(\u03bb) \u2265 \u22125, and is positively correlated with R(f). This confirms the second conjecture, which states that stronger regularization leads to a larger imbalance in utilization between modalities, making the multi-modal learning process greedier. The trend is consistent for |d_speed|, supporting the choice of using conditional learning speed to predict conditional utilization rate."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: As illustrated in Figure 3, the absolute difference in utilization between modalities, |d_util(f)|, exhibits a significant increase as the regularization parameter \u03bb increases, particularly when log(\u03bb) is greater than or equal to -5. Moreover, this trend is positively correlated with the model's performance, R(f), which supports the second conjecture. This conjecture suggests that stronger regularization leads to a larger imbalance in utilization between modalities, resulting in a greedier multi-modal learning process. Consistently, the same trend is observed for |d_speed|, validating the choice of using conditional learning speed to predict the conditional utilization rate."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Results show that |d util(f)| increases with \u03bb, particularly when log(\u03bb) \u2265 \u22125, and is positively correlated with R(f). Stronger regularization leads to a larger imbalance in utilization between modalities, confirming our conjecture that regularization makes the multi-modal learning process greedier. This trend is consistent for both |d util(f)| and |d speed|, supporting our choice of using conditional learning speed to predict conditional utilization rate.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The results indicate that the magnitude of the difference in utilization (|d util(f)|) increases with the regularization parameter \u03bb, particularly when log(\u03bb) is greater than or equal to -5. Moreover, |d util(f)| is positively correlated with the rate of convergence (R(f)). As regularization strength increases, a larger imbalance in utilization between modalities emerges, consistent with our hypothesis that regularization promotes a greedier multi-modal learning process. This trend is observed for both |d util(f)| and |d speed|, providing evidence for the validity of using conditional learning speed to predict conditional utilization rate.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "instruction": "Split first sentence in two and delete the third sentence", "revised_paragraph": "Revised paragraph: \"Results show that | d util ( f ) | increases along \u03bb, especially when log( \u03bb ) \u2265 \u2212 5. This increase is positively correlated with R ( f ). | d speed | follows the same trend as | d util |, supporting our choice of using the conditional learning speed to predict the conditional utilization rate.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.19", "instruction": "Exclude redundant expression.", "revised_paragraph": "Revised paragraph: As shown in Figure 3, the magnitude of the utilization imbalance between modalities, |dutil(f)|, increases with \u03bb, particularly when log(\u03bb) \u2265 -5. This trend is positively correlated with R(f), indicating that stronger regularization leads to a greater imbalance in utilization. This finding confirms the second conjecture in \u00a73.2, which suggests that stronger regularization yields a greedier multi-modal learning process. Interestingly, the trend for |dspeed| parallels that of |dutil|, supporting the choice of using conditional learning speed to predict conditional utilization rate.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To investigate each task described in \u00a75.1, we created a dataset by duplicating one of the modalities as the second input modality, in addition to the original dataset. For instance, in the MNIST task, we predicted digit classes using two identical gray-scale images. We then trained a multi-modal deep neural network (DNN) on each dataset for each task, as explained below."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To investigate each task described in \u00a75.1, we created a dataset by duplicating one of the modalities as the second input modality, in addition to the original dataset. For instance, in the MNIST task, we predicted digit classes using two identical gray-scale images. We then trained a multi-modal deep neural network (DNN) on each dataset for each task, as explained below."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To investigate each task described in \u00a75.1, we created a dataset by duplicating one of the modalities as the second input modality, in addition to the original dataset. For instance, in the MNIST task, we predicted digit classes using two identical gray-scale images. We then trained a multi-modal deep neural network (DNN) on each dataset for each task, as explained below."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To investigate each task described in \u00a75.1, we created a dataset by duplicating one of the modalities as the second input modality, in addition to the original dataset. For instance, in the MNIST task, we predicted digit classes using two identical gray-scale images. We then trained a multi-modal deep neural network (DNN) on each dataset for each task, as explained below."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To investigate each task described in \u00a75.1, we created a dataset by duplicating one of the modalities as the second input modality, in addition to the original dataset. For instance, in the MNIST task, we predicted digit classes using two identical gray-scale images. We then trained a multi-modal deep neural network (DNN) on each dataset for each task, as explained below."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To investigate each task described in \u00a75.1, we created a dataset by duplicating one of the modalities as the second input modality, in addition to the original dataset. For instance, in the MNIST task, we predicted digit classes using two identical gray-scale images. We then trained a multi-modal deep neural network (DNN) on each dataset for each task, as explained below."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To investigate each task described in \u00a75.1, we created a dataset by duplicating one of the modalities as the second input modality, in addition to the original dataset. For instance, in the MNIST task, we predicted digit classes using two identical gray-scale images. We then trained a multi-modal deep neural network (DNN) on each dataset for each task, as explained below."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To investigate each task described in \u00a75.1, we created a dataset by duplicating one of the modalities as the second input modality, in addition to the original dataset. For instance, in the MNIST task, we predicted digit classes using two identical gray-scale images. We then trained a multi-modal deep neural network (DNN) on each dataset for each task, as explained below."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "instruction": "Improve the understandability of the entire paragraph", "revised_paragraph": "Revised paragraph: \"In this study, we designed a dataset duplication approach for each task presented in \u00a75.1. Specifically, we created a new dataset by duplicating one of the input modalities, in addition to the original dataset. For instance, in the MNIST task, we used two identical gray-scale images to predict the digit class. We then trained a multi-modal deep neural network (DNN) on each of these datasets, following the procedures outlined below.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "instruction": "The wording in this paragraph is confusing, please improve the readability.", "revised_paragraph": "Revised paragraph: To investigate the performance of our multi-modal deep neural network (DNN), we designed a series of tasks (\u00a75.1) and created corresponding datasets. For each task, we duplicated one of the modalities and used it as an additional input, in addition to the original dataset. For instance, in the MNIST task, we trained the model to predict digit classes using two identical gray-scale images. We then trained a multi-modal DNN on each dataset, following the procedure explained below.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The diameter of state spaces has been extensively studied in model checking and planning, particularly due to its tight topological properties. While computing the diameter is \u03a0 P 2 -hard for factored transition systems and succinct digraphs, practical methods exist for compositionally computing upper bounds, as shown in previous studies (Baumgartner et al., 2002; Rintanen and Gretton, 2013; Abdulaziz et al.).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The diameter of state spaces has been extensively studied in model checking and planning, particularly due to its tight topological properties. While computing the diameter is \u03a0 P 2 -hard for factored transition systems and succinct digraphs, practical methods exist for compositionally computing upper bounds, as shown in previous studies (Baumgartner et al., 2002; Rintanen and Gretton, 2013; Abdulaziz et al.).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The diameter of state spaces has been extensively studied in model checking and planning, particularly due to its tight topological properties. While computing the diameter is \u03a0 P 2 -hard for factored transition systems and succinct digraphs, practical methods exist for compositionally computing upper bounds, as shown in previous studies (Baumgartner et al., 2002; Rintanen and Gretton, 2013; Abdulaziz et al.).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The diameter of state spaces has been extensively studied in model checking and planning, particularly due to its tight topological properties. While computing the diameter is \u03a0 P 2 -hard for factored transition systems and succinct digraphs, practical methods exist for compositionally computing upper bounds, as shown in previous studies (Baumgartner et al., 2002; Rintanen and Gretton, 2013; Abdulaziz et al.).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The diameter of state spaces has been extensively studied in model checking and planning, particularly due to its tight topological properties. While computing the diameter is \u03a0 P 2 -hard for factored transition systems and succinct digraphs, practical methods exist for compositionally computing upper bounds, as shown in previous studies (Baumgartner et al., 2002; Rintanen and Gretton, 2013; Abdulaziz et al.).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The diameter of state spaces has been extensively studied in model checking and planning, particularly due to its tight topological properties. While computing the diameter is \u03a0 P 2 -hard for factored transition systems and succinct digraphs, practical methods exist for compositionally computing upper bounds, as shown in previous studies (Baumgartner et al., 2002; Rintanen and Gretton, 2013; Abdulaziz et al.).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The diameter of state spaces has been extensively studied in model checking and planning, particularly due to its tight topological properties. While computing the diameter is \u03a0 P 2 -hard for factored transition systems and succinct digraphs, practical methods exist for compositionally computing upper bounds, as shown in previous studies (Baumgartner et al., 2002; Rintanen and Gretton, 2013; Abdulaziz et al.).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The diameter of state spaces has been extensively studied in model checking and planning, particularly due to its tight topological properties. While computing the diameter is \u03a0 P 2 -hard for factored transition systems and succinct digraphs, practical methods exist for compositionally computing upper bounds, as shown in previous studies (Baumgartner et al., 2002; Rintanen and Gretton, 2013; Abdulaziz et al.).\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "instruction": "Remove unnecessary details.", "revised_paragraph": "Revised paragraph: The diameter of a state space is the tightest topological property studied in model checking and planning literature. While computing the diameter for factored transition systems and succinct digraphs is \u03a0 P 2-hard, practical methods exist to compositionally compute upper bounds on the diameter.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.02", "instruction": "Concise by removing unnecessary details.", "revised_paragraph": "Revised paragraph: The diameter of a state space is a fundamental topological property that has been extensively studied in model checking and planning. While computing the diameter for a factored transition system is \u03a0 P 2-hard (Hemaspaandra et al., 2010), practical methods exist for compositionally computing upper bounds (Baumgartner et al., 2002; Rintanen and Gretton, 2013).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which ensures that, with sufficient computation, the generated Markov Chain produces correct samples from any target distribution, regardless of its complexity."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which allows it to generate correct samples from any target distribution, regardless of its complexity, provided sufficient computational resources are allocated.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which allows it to generate correct samples from any target distribution, regardless of its complexity, provided sufficient computational resources are allocated.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which allows it to generate correct samples from any target distribution, regardless of its complexity, provided sufficient computational resources are allocated.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which ensures that, with sufficient computation, the generated Markov Chain produces correct samples from any target distribution, regardless of its complexity."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which allows it to generate correct samples from any target distribution, regardless of its complexity, provided sufficient computational resources are allocated.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which ensures that, with sufficient computation, the generated Markov Chain produces correct samples from any target distribution, regardless of its complexity."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In Markov Chain Monte Carlo (MCMC), a transition kernel is chosen that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which guarantees that, with sufficient computation, the generated Markov Chain produces correct samples from any target distribution, regardless of its complexity."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which allows it to generate correct samples from any target distribution, regardless of its complexity, provided sufficient computational resources are allocated.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which allows it to generate correct samples from any target distribution, regardless of its complexity, provided sufficient computational resources are allocated.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which ensures that, with sufficient computation, the generated Markov Chain produces correct samples from any target distribution, regardless of its complexity."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In Markov Chain Monte Carlo (MCMC), a transition kernel is chosen that preserves the target distribution, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, which guarantees that, with sufficient computation, the generated Markov Chain produces correct samples from any target distribution, regardless of its complexity."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "instruction": "Rephrase the paragraph", "revised_paragraph": "Revised paragraph: \"In Markov Chain Monte Carlo (MCMC), a transition kernel is selected that preserves the target distribution's invariance, and a Markov Chain is constructed by iteratively applying the kernel. The MCMC method relies solely on the ergodicity assumption, allowing it to generate correct samples from any target distribution, regardless of its complexity, provided sufficient computation is performed.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "Rd7TGMaUy.dkY5HcKwZ1.00", "instruction": "Balance sentences length.", "revised_paragraph": "Revised paragraph: \"In MCMC, one selects a transition kernel that preserves the target distribution's invariance and constructs a Markov Chain by iteratively applying the kernel. This method relies solely on the ergodicity assumption, allowing it to generate correct samples from any target distribution, regardless of its complexity, as long as sufficient computation is performed.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: In this paper, we investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address the challenge of determining this optimal trade-off, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment. P3 overcomes the challenges of \"model exploitation\" and generalization to unseen states, outperforming recent baseline methods on the D4RL benchmark."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We find that model-based off-policy RL's performance relies on the trade-off between model return and uncertainty. To address the challenge of determining the optimal trade-off without access to the deployment environment, we develop Pareto policy pool (P3), an efficient method that produces a pool of diverse policies on the Pareto front. P3 provides a simple and effective approach to address the challenges of model exploitation and generalization, outperforming recent baseline methods on the D4RL benchmark over multiple tasks.\""}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: This paper reveals that the performance of model-based offline reinforcement learning (RL) critically depends on the trade-off between model return and its uncertainty. However, determining the optimal trade-off is often challenging or intractable without access to the environment where the learned policy will be deployed. To address this issue, we propose a bi-objective formulation for model-based offline RL and develop an efficient method, Pareto policy pool (P3), which generates a pool of diverse policies on the Pareto front, each representing a different level of trade-off. This approach provides the flexibility to select the best policy for each realistic environment from the pool, thereby addressing the two major challenges in model-based offline RL: model exploitation and generalization to unseen states. Our experiments on the D4RL benchmark demonstrate that P3 outperforms several recent baseline methods across multiple tasks, showcasing its potential for learning a generalizable policy even when pre-collected experiences are of low quality."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: In this paper, we investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address the challenge of determining this optimal trade-off, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment. P3 overcomes the challenges of \"model exploitation\" and generalization to unseen states, outperforming recent baseline methods on the D4RL benchmark."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: In this paper, we investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address the challenge of determining this optimal trade-off, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment. P3 overcomes the challenges of \"model exploitation\" and generalization to unseen states, outperforming recent baseline methods on the D4RL benchmark."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: This paper reveals that the performance of model-based offline reinforcement learning (RL) critically depends on the trade-off between model return and its uncertainty. However, determining the optimal trade-off is often challenging or intractable without access to the environment where the learned policy will be deployed. To address this issue, we propose a bi-objective formulation for model-based offline RL and develop an efficient method, Pareto policy pool (P3), which generates a pool of diverse policies on the Pareto front, each representing a different level of trade-off. This approach provides the flexibility to select the best policy for each realistic environment from the pool, thereby addressing the two major challenges in model-based offline RL: model exploitation and generalization to unseen states. Our experiments on the D4RL benchmark demonstrate that P3 outperforms several recent baseline methods across multiple tasks, showcasing its potential for learning a generalizable policy even when pre-collected experiences are of low quality."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: In this paper, we investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address the challenge of determining this optimal trade-off, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment. P3 overcomes the challenges of \"model exploitation\" and generalization to unseen states, outperforming recent baseline methods on the D4RL benchmark."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We find that model-based off-policy RL's performance relies on the trade-off between model return and uncertainty. To address the challenge of determining the optimal trade-off without access to the deployment environment, we develop Pareto policy pool (P3), an efficient method that produces a pool of diverse policies on the Pareto front. P3 provides a simple and effective approach to address the challenges of model exploitation and generalization, outperforming recent baseline methods on the D4RL benchmark over multiple tasks.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: In this paper, we investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address the challenge of determining this optimal trade-off, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment. P3 overcomes the challenges of \"model exploitation\" and generalization to unseen states, outperforming recent baseline methods on the D4RL benchmark."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address this challenge, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment."}, {"depth": 3, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: We investigate the performance of model-based offline reinforcement learning (RL) and identify a crucial trade-off between model return and uncertainty. To overcome this challenge, we introduce Pareto policy pool (P3), a novel method that efficiently generates a diverse set of policies on the Pareto front, enabling flexible selection of the best policy for each environment."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: In this paper, we investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address the challenge of determining this optimal trade-off, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment. P3 overcomes the challenges of \"model exploitation\" and generalization to unseen states, outperforming recent baseline methods on the D4RL benchmark."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: In this paper, we investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address the challenge of determining this optimal trade-off, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment. P3 overcomes the challenges of \"model exploitation\" and generalization to unseen states, outperforming recent baseline methods on the D4RL benchmark."}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: In this paper, we examine the performance of model-based offline reinforcement learning (RL), revealing that it hinges on a delicate balance between model return and uncertainty. To address the challenge of determining this optimal balance, we propose Pareto policy pool (P3), a novel method that efficiently generates a diverse pool of policies on the Pareto front, enabling flexible selection of the best policy for each environment. P3 successfully overcomes the challenges of model exploitation and generalization to unseen states, outperforming recent baseline methods on the D4RL benchmark."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: In this paper, we investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address the challenge of determining this optimal trade-off, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment. P3 overcomes the challenges of \"model exploitation\" and generalization to unseen states, outperforming recent baseline methods on the D4RL benchmark."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We investigate the performance of model-based offline RL, finding that it relies on a delicate trade-off between model return and uncertainty. To address this challenge, we develop Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexible selection of the best policy for each environment."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "instruction": "Make this paragraph more concise by rewriting the second half.", "revised_paragraph": "Revised paragraph: In this paper, we find that model-based offline RL's performance relies on the trade-off between model return and uncertainty. To address the challenge of determining this optimal trade-off, we develop Pareto policy pool (P3), a bi-objective method that generates a diverse pool of policies on the Pareto front, allowing for flexible policy selection for each environment. P3 addresses the key challenges of model-based offline RL, including model exploitation and generalization, and outperforms recent baselines on the D4RL benchmark.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aFWzpdwEna.MCecpd3utK.00", "instruction": "Make this paragraph shorter.", "revised_paragraph": "Revised paragraph: In this paper, we investigate the trade-off between model return and uncertainty in model-based offline RL, which is crucial for performance but challenging to determine without access to the deployment environment. To address this issue, we propose Pareto policy pool (P3), an efficient method that generates a diverse pool of policies on the Pareto front, allowing for flexibility in selecting the best policy for each environment. P3 outperforms recent baselines on the D4RL benchmark, demonstrating its potential for learning generalizable policies from low-quality pre-collected experiences.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image super-resolution (SR) is a fundamental computer vision problem, which involves recovering a high-resolution (HR) image from its low-resolution (LR) counterpart. Due to its many-to-one mapping nature, image SR is inherently ill-posed. To address this challenge, numerous deep convolutional neural networks (CNNs) have been developed to accurately map LR images to their HR targets, as demonstrated by studies such as Dong et al. (2014, 2016) and Kim et al. (2016b) and Tai et al. (2017b).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image super-resolution (SR) is a fundamental computer vision problem, which involves recovering a high-resolution (HR) image from its low-resolution (LR) counterpart. Due to its many-to-one mapping nature, image SR is inherently ill-posed. To address this challenge, numerous deep convolutional neural networks (CNNs) have been developed to accurately map LR images to their HR targets, as demonstrated by studies such as Dong et al. (2014, 2016) and Kim et al. (2016b) and Tai et al. (2017b).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image super-resolution (SR) is a fundamental computer vision problem, which involves recovering a high-resolution (HR) image from its low-resolution (LR) counterpart. Due to its many-to-one mapping nature, image SR is inherently ill-posed. To address this challenge, numerous deep convolutional neural networks (CNNs) have been developed to accurately map LR images to their HR targets, as demonstrated by studies such as Dong et al. (2014, 2016) and Kim et al. (2016b) and Tai et al. (2017b).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image super-resolution (SR) is a fundamental computer vision problem, which involves recovering a high-resolution (HR) image from its low-resolution (LR) counterpart. Due to its many-to-one mapping nature, image SR is inherently ill-posed. To address this challenge, numerous deep convolutional neural networks (CNNs) have been developed to accurately map LR images to their HR targets, as demonstrated by studies such as Dong et al. (2014, 2016) and Kim et al. (2016b) and Tai et al. (2017b).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image super-resolution (SR) is a fundamental computer vision problem, which involves recovering a high-resolution (HR) image from its low-resolution (LR) counterpart. Due to its many-to-one mapping nature, image SR is inherently ill-posed. To address this challenge, numerous deep convolutional neural networks (CNNs) have been developed to accurately map LR images to their HR targets, as demonstrated by studies such as Dong et al. (2014, 2016) and Kim et al. (2016b) and Tai et al. (2017b).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image super-resolution (SR) is a fundamental computer vision problem, which involves recovering a high-resolution (HR) image from its low-resolution (LR) counterpart. Due to its many-to-one mapping nature, image SR is inherently ill-posed. To address this challenge, numerous deep convolutional neural networks (CNNs) have been developed to accurately map LR images to their HR targets, as demonstrated by studies such as Dong et al. (2014, 2016) and Kim et al. (2016b) and Tai et al. (2017b).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image super-resolution (SR) is a fundamental computer vision problem, which involves recovering a high-resolution (HR) image from its low-resolution (LR) counterpart. Due to its many-to-one mapping nature, image SR is inherently ill-posed. To address this challenge, numerous deep convolutional neural networks (CNNs) have been developed to accurately map LR images to their HR targets, as demonstrated by studies such as Dong et al. (2014, 2016) and Kim et al. (2016b) and Tai et al. (2017b).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image super-resolution (SR) is a fundamental computer vision problem, which involves recovering a high-resolution (HR) image from its low-resolution (LR) counterpart. Due to its many-to-one mapping nature, image SR is inherently ill-posed. To address this challenge, numerous deep convolutional neural networks (CNNs) have been developed to accurately map LR images to their HR targets, as demonstrated by studies such as Dong et al. (2014, 2016) and Kim et al. (2016b) and Tai et al. (2017b).\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "instruction": "Replace the citation to (Tai et al., 2017b) with a citation to (Zhang et al., 2018c; 2020; 2021). Improve the english of this paragraph.", "revised_paragraph": "Revised paragraph: Image super-resolution (SR) is a fundamental computer vision task that seeks to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. Due to the many-to-one mapping nature of this problem, image SR is inherently ill-posed. To address this challenge, numerous deep convolutional neural networks (CNNs) have been proposed and investigated, including those by Dong et al. (2014; 2016), Kim et al. (2016b), and Zhang et al. (2018c; 2020; 2021), which have shown promise in achieving accurate mapping from LR images to their HR targets.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.01", "instruction": "Make the langage of this paragraph a bit more simple.", "revised_paragraph": "Revised paragraph: Image super-resolution is a key task in computer vision that aims to improve the quality of a low-resolution image to make it look like a high-resolution image. This task is difficult because there are often many possible high-resolution images that could be created from a single low-resolution image. To overcome this challenge, many deep neural networks have been developed to accurately convert low-resolution images into their high-resolution versions.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We compare AGILE with a GAT that only receives action features as input, not state. This limits learned relations to be fixed, not dependent on state. As shown in Figure 7, performance drops in Grid World and CREATE, where state-dependent action relations are crucial. In contrast, RecSim's CPR task is independent of user state, explaining the lack of performance decline.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We contrast the AGILE variant where the GAT receives only action features as input, without considering state information. In this scenario, the decision-choice remains aware of other actions, but the learned relationships are fixed and do not depend on the state. As Figure 7 illustrates, this approach leads to a decline in performance for Grid World and CREATE, where the relevant action relationships change dynamically based on the state. In contrast, RecSim does not exhibit a similar drop in performance, as the CPR task only requires knowledge of the most common category, which is independent of the user's state."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We contrast the AGILE variant where the GAT receives only action features as input, without considering state information. In this scenario, the decision-choice remains aware of other actions, but the learned relationships are fixed and do not depend on the state. As Figure 7 illustrates, this approach leads to a decline in performance for Grid World and CREATE, where the relevant action relationships change dynamically based on the state. In contrast, RecSim does not exhibit a similar drop in performance, as the CPR task only requires knowledge of the most common category, which is independent of the user's state."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We contrast the AGILE variant where the GAT receives only action features as input, without considering state information. In this scenario, the decision-choice remains aware of other actions, but the learned relationships are fixed and do not depend on the state. As Figure 7 illustrates, this approach leads to a decline in performance for Grid World and CREATE, where the relevant action relationships change dynamically based on the state. In contrast, RecSim does not exhibit a similar drop in performance, as the CPR task only requires knowledge of the most common category, which is independent of the user's state."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We compare AGILE with a GAT that only receives action features as input, not state. This limits learned relations to be fixed, not dependent on state. As shown in Figure 7, performance drops in Grid World and CREATE, where state-dependent action relations are crucial. In contrast, RecSim's CPR task is independent of user state, explaining the lack of performance decline.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We contrast the AGILE variant where the GAT receives only action features as input, without considering state information. In this scenario, the decision-choice remains aware of other actions, but the learned relationships are fixed and do not depend on the state. As Figure 7 illustrates, this approach leads to a decline in performance for Grid World and CREATE, where the relevant action relationships change dynamically based on the state. In contrast, RecSim does not exhibit a similar drop in performance, as the CPR task only requires knowledge of the most common category, which is independent of the user's state."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We compare AGILE with a GAT that only receives action features as input, not state. This limits learned relations to be fixed, not dependent on state. As shown in Figure 7, performance drops in Grid World and CREATE, where state-dependent action relations are crucial. In contrast, RecSim's CPR task is independent of user state, explaining the lack of performance decline.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We contrast AGILE with a GAT that only takes action features into account, excluding state information. This constraint restricts the learned relationships to be static, rather than dynamic and dependent on state. As illustrated in Figure 7, the performance of this approach decreases significantly in Grid World and CREATE, where the ability to adapt to changing state-dependent action relationships is essential. In contrast, the RecSim's CPR task does not rely on user state, which explains the absence of performance degradation.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We contrast the AGILE variant where the GAT receives only action features as input, without considering state information. In this scenario, the decision-choice remains aware of other actions, but the learned relationships are fixed and do not depend on the state. As Figure 7 illustrates, this approach leads to a decline in performance for Grid World and CREATE, where the relevant action relationships change dynamically based on the state. In contrast, RecSim does not exhibit a similar drop in performance, as the CPR task only requires knowledge of the most common category, which is independent of the user's state."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We contrast the AGILE variant where the GAT receives only action features as input, without considering state information. In this scenario, the decision-choice remains aware of other actions, but the learned relationships are fixed and do not depend on the state. As Figure 7 illustrates, this approach leads to a decline in performance for Grid World and CREATE, where the relevant action relationships change dynamically based on the state. In contrast, RecSim does not exhibit a similar drop in performance, as the CPR task only requires knowledge of the most common category, which is independent of the user's state."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We compare AGILE with a GAT that only receives action features as input, not state. This limits learned relations to be fixed, not dependent on state. As shown in Figure 7, performance drops in Grid World and CREATE, where state-dependent action relations are crucial. In contrast, RecSim's CPR task is independent of user state, explaining the lack of performance decline.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We contrast AGILE with a GAT that only takes action features into account, excluding state information. This constraint restricts the learned relationships to be static, rather than dynamic and dependent on state. As illustrated in Figure 7, the performance of this approach decreases significantly in Grid World and CREATE, where the ability to adapt to changing state-dependent action relationships is essential. In contrast, the RecSim's CPR task does not rely on user state, which explains the absence of performance degradation.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "instruction": "Rewrite the second sentence of the paragraph and improve the English in the remainder", "revised_paragraph": "Revised paragraph: \"We compare the version of AGILE where the GAT only receives action features as input and no state. In this scenario, the decision-choice is still informed by other actions, but the learned relationships are static and do not adapt to changes in the state. As illustrated in Figure 7, this limitation is particularly evident in Grid World and CREATE, where the relevant action relationships vary significantly depending on the state. In contrast, RecSim does not exhibit a performance drop, as the CPR task primarily requires identifying the most common category, which is independent of the user's state.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.18", "instruction": "Make this paragraph more concise, keeping the main points of each sentence.", "revised_paragraph": "Revised paragraph: We examine an AGILE variant where the GAT receives only action features as input, without considering state. This approach learns fixed action relations, unaffected by state. As shown in Figure 7, performance decreases in Grid World and CREATE, where state-dependent action relations are crucial. In contrast, RecSim performance remains unaffected, as the CPR task only requires identifying the most common category, which is independent of user state.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, making data-driven methods increasingly attractive (Rives et al., 2019; Jumper et al., 2021). However, significant challenges remain in developing deep learning-based models to predict the effects of mutations on protein-protein binding. One major obstacle is the limited availability of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity of data hinders supervised learning, as insufficient training data can lead to over-fitting. Another challenge is the lack of structural information on mutated protein-protein complexes. Mutating amino acids on a protein complex leads to changes in sidechain conformations (rotamers), which affect the binding free energy (Najmanovich et al., 2000; Gaudreault et al., 2012). Unfortunately, we lack a clear understanding of how exactly these conformation changes occur upon mutation."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, making data-driven methods increasingly attractive (Rives et al., 2019; Jumper et al., 2021). However, significant challenges remain in developing deep learning-based models to predict the effects of mutations on protein-protein binding. One major obstacle is the limited availability of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity of data hinders supervised learning, as insufficient training data can lead to over-fitting. Another challenge is the lack of structural information on mutated protein-protein complexes. Mutating amino acids on a protein complex leads to changes in sidechain conformations (rotamers), which affect the binding free energy (Najmanovich et al., 2000; Gaudreault et al., 2012). Unfortunately, we lack a clear understanding of how exactly these conformation changes occur upon mutation."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, making data-driven methods increasingly attractive (Rives et al., 2019; Jumper et al., 2021). However, significant challenges remain in developing deep learning-based models to predict the effects of mutations on protein-protein binding. One major obstacle is the limited availability of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity of data hinders supervised learning, as insufficient training data can lead to over-fitting. Another challenge is the lack of structural information on mutated protein-protein complexes. Mutating amino acids on a protein complex leads to changes in sidechain conformations (rotamers), which affect the binding free energy (Najmanovich et al., 2000; Gaudreault et al., 2012). Unfortunately, we lack a clear understanding of how exactly these conformation changes occur upon mutation."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, making data-driven methods increasingly attractive (Rives et al., 2019; Jumper et al., 2021). However, significant challenges remain in developing deep learning-based models to predict the effects of mutations on protein-protein binding. One major obstacle is the limited availability of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity of data hinders supervised learning, as insufficient training data can lead to over-fitting. Another challenge is the lack of structural information on mutated protein-protein complexes. Mutating amino acids on a protein complex leads to changes in sidechain conformations (rotamers), which affect the binding free energy (Najmanovich et al., 2000; Gaudreault et al., 2012). Unfortunately, we lack a clear understanding of how exactly these conformation changes occur upon mutation."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, making data-driven methods increasingly attractive (Rives et al., 2019; Jumper et al., 2021). However, significant challenges remain in developing deep learning-based models to predict the effects of mutations on protein-protein binding. One major obstacle is the limited availability of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity of data hinders supervised learning, as insufficient training data can lead to over-fitting. Another challenge is the lack of structural information on mutated protein-protein complexes. Mutating amino acids on a protein complex leads to changes in sidechain conformations (rotamers), which affect the binding free energy (Najmanovich et al., 2000; Gaudreault et al., 2012). Unfortunately, we lack a clear understanding of how exactly these conformation changes occur upon mutation."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, making data-driven methods increasingly attractive (Rives et al., 2019; Jumper et al., 2021). However, significant challenges remain in developing deep learning-based models to predict the effects of mutations on protein-protein binding. One major obstacle is the limited availability of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity of data hinders supervised learning, as insufficient training data can lead to over-fitting. Another challenge is the lack of structural information on mutated protein-protein complexes. Mutating amino acids on a protein complex leads to changes in sidechain conformations (rotamers), which affect the binding free energy (Najmanovich et al., 2000; Gaudreault et al., 2012). Unfortunately, we lack a clear understanding of how exactly these conformation changes occur upon mutation."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, making data-driven methods increasingly attractive (Rives et al., 2019; Jumper et al., 2021). However, significant challenges remain in developing deep learning-based models to predict the effects of mutations on protein-protein binding. One major obstacle is the limited availability of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity of data hinders supervised learning, as insufficient training data can lead to over-fitting. Another challenge is the lack of structural information on mutated protein-protein complexes. Mutating amino acids on a protein complex leads to changes in sidechain conformations (rotamers), which affect the binding free energy (Najmanovich et al., 2000; Gaudreault et al., 2012). Unfortunately, we lack a clear understanding of how exactly these conformation changes occur upon mutation."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, making data-driven methods increasingly attractive (Rives et al., 2019; Jumper et al., 2021). However, significant challenges remain in developing deep learning-based models to predict the effects of mutations on protein-protein binding. One major obstacle is the limited availability of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity of data hinders supervised learning, as insufficient training data can lead to over-fitting. Another challenge is the lack of structural information on mutated protein-protein complexes. Mutating amino acids on a protein complex leads to changes in sidechain conformations (rotamers), which affect the binding free energy (Najmanovich et al., 2000; Gaudreault et al., 2012). Unfortunately, we lack a clear understanding of how exactly these conformation changes occur upon mutation."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "instruction": "Rewrite the following paragraph using a more formal language.", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, rendering data-driven approaches increasingly attractive (Rives et al., 2019; Jumper et al., 2021). Nevertheless, obstacles persist in developing deep learning-based models to predict the effects of mutations on protein-protein binding. The primary challenge lies in the scarcity of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity hampers supervised learning, as the insufficiency of training data can lead to over-fitting. Additionally, the lack of structural information regarding mutated protein-protein complexes presents a significant difficulty. Mutating amino acids within a protein complex leads to alterations in sidechain conformations (rotamers) (Najmanovich et al., 2000; Gaudreault et al., 2012), which are critical for understanding changes in binding free energy. However, the exact nature of these conformational changes upon mutation remains unknown.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.02", "instruction": "Rewrite this paragraph for better readability.", "revised_paragraph": "Revised paragraph: Recently, deep learning has achieved significant success in modeling proteins, making data-driven methods increasingly attractive (Rives et al., 2019; Jumper et al., 2021). However, developing deep learning-based models to predict the effects of mutations on protein-protein binding remains a challenging task. A major obstacle is the limited availability of experimental data, with only a few thousand protein mutations annotated with changes in binding affinity publicly available (Geng et al., 2019b). This scarcity of training data can lead to over-fitting, hindering supervised learning. Furthermore, the lack of structural information about mutated protein-protein complexes poses another difficulty. Mutating amino acids on a protein complex can lead to changes in sidechain conformations (rotamers) (Najmanovich et al., 2000; Gaudreault et al., 2012), which are critical for understanding changes in binding free energy. Unfortunately, the exact mechanism by which conformation changes occur upon mutation remains unknown.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The results demonstrate that AGILE outperforms all baselines, underscoring the importance of relational knowledge about other available actions for an optimal policy. Consistent with CREATE, RecSim and Real RecSys exhibit similar trend patterns, albeit less pronounced for Real RecSys. Furthermore, our findings indicate that DQN-based architectures perform worse than CDQN-based architectures, likely due to the top-K greedy list action building approach's failure to account for list interdependence.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The results demonstrate that AGILE outperforms all baselines, underscoring the importance of relational knowledge about other available actions for an optimal policy. Consistent with CREATE, RecSim and Real RecSys exhibit similar trend patterns, albeit less pronounced for Real RecSys. Furthermore, our findings indicate that DQN-based architectures perform worse than CDQN-based architectures, likely due to the top-K greedy list action building approach's failure to account for list interdependence.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The results demonstrate that AGILE outperforms all baselines, underscoring the importance of relational knowledge about other available actions for an optimal policy. Consistent with CREATE, RecSim and Real RecSys exhibit similar trend patterns, albeit less pronounced for Real RecSys. Furthermore, our findings indicate that DQN-based architectures perform worse than CDQN-based architectures, likely due to the top-K greedy list action building approach's failure to account for list interdependence.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The results demonstrate that AGILE outperforms all baselines, underscoring the importance of relational knowledge about other available actions for an optimal policy. Consistent with CREATE, RecSim and Real RecSys exhibit similar trend patterns, albeit less pronounced for Real RecSys. Furthermore, our findings indicate that DQN-based architectures perform worse than CDQN-based architectures, likely due to the top-K greedy list action building approach's failure to account for list interdependence.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The results demonstrate that AGILE outperforms all baselines, underscoring the importance of relational knowledge about other available actions for an optimal policy. Consistent with CREATE, RecSim and Real RecSys exhibit similar trend patterns, albeit less pronounced for Real RecSys. Furthermore, our findings indicate that DQN-based architectures perform worse than CDQN-based architectures, likely due to the top-K greedy list action building approach's failure to account for list interdependence.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The results demonstrate that AGILE outperforms all baselines, underscoring the importance of relational knowledge about other available actions for an optimal policy. Consistent with CREATE, RecSim and Real RecSys exhibit similar trend patterns, albeit less pronounced for Real RecSys. Furthermore, our findings indicate that DQN-based architectures perform worse than CDQN-based architectures, likely due to the top-K greedy list action building approach's failure to account for list interdependence.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The results demonstrate that AGILE outperforms all baselines, underscoring the importance of relational knowledge about other available actions for an optimal policy. Consistent with CREATE, RecSim and Real RecSys exhibit similar trend patterns, albeit less pronounced for Real RecSys. Furthermore, our findings indicate that DQN-based architectures perform worse than CDQN-based architectures, likely due to the top-K greedy list action building approach's failure to account for list interdependence.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The results demonstrate that AGILE outperforms all baselines, underscoring the importance of relational knowledge about other available actions for an optimal policy. Consistent with CREATE, RecSim and Real RecSys exhibit similar trend patterns, albeit less pronounced for Real RecSys. Furthermore, our findings indicate that DQN-based architectures perform worse than CDQN-based architectures, likely due to the top-K greedy list action building approach's failure to account for list interdependence.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "instruction": "Remove unnecessary words and fix the words if they are not in the correct form", "revised_paragraph": "Revised paragraph: \"AGILE outperforms all baselines, demonstrating the importance of relational knowledge of other available actions for an optimal policy. The results are consistent with CREATE for RecSim, but less pronounced for Real RecSys. Moreover, DQN performs worse than CDQN-based architectures due to the greedy list action building method's neglect of list interdependence.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.14", "instruction": "Remove terms that might be considered biased. Make the writing more clear.", "revised_paragraph": "Revised paragraph: \"The results show that AGILE outperforms the baselines, indicating the importance of relational knowledge of other available actions for optimal policy design. The trends observed in RecSim and Real RecSys are consistent with those of CREATE, although the effect is less pronounced in Real RecSys. Furthermore, CDQN-based architectures outperform DQN, suggesting that ignoring list interdependence in the top-K greedy list action building is detrimental to performance.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our research makes a dual contribution to the field. Firstly, we introduce the concept of medication calendars that enable users to schedule their medication alongside daily activities, while also resolving potential scheduling conflicts that may arise from unsafe drug interactions due to prescription administration constraints. Secondly, we present the findings of a qualitative study involving twelve participants who interacted with our calendar designs. The results indicate that medication calendars can be designed to facilitate the integration of prescription medication and that users are generally receptive to using a calendar to manage their medication, provided the design is familiar and uncluttered. Furthermore, our study shows that calendars can effectively render conflicts arising from unsafe rescheduling. These findings inform five additional design goals for an integrated calendar, including the use of familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our research makes a dual contribution to the field. First, we introduce the concept of medication calendars, which enable users to schedule medication alongside daily activities and provide a mechanism for resolving scheduling conflicts that may arise from unsafe drug interactions. These conflicts can occur when users violate administration constraints specified in the prescription. Second, we present the findings of a qualitative study involving twelve participants who interacted with our calendar designs. The results indicate that calendars can effectively support the integration of medication prescriptions and that users generally prefer using a calendar to manage their medications, as long as the design is familiar and intuitive. Furthermore, our study shows that conflicts can be resolved within the calendars, providing valuable insights that inform five additional design goals for integrated calendars: incorporating familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our research makes a dual contribution to the field. First, we introduce the concept of medication calendars, which enable users to schedule medication alongside daily activities and provide a mechanism for resolving scheduling conflicts that may arise from unsafe drug interactions. These conflicts can occur when users violate administration constraints specified in the prescription. Second, we present the findings of a qualitative study involving twelve participants who interacted with our calendar designs. The results indicate that calendars can effectively support the integration of medication prescriptions and that users generally prefer using a calendar to manage their medications, as long as the design is familiar and intuitive. Furthermore, our study shows that conflicts can be resolved within the calendars, providing valuable insights that inform five additional design goals for integrated calendars: incorporating familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our research makes a dual contribution to the field. Firstly, we introduce the concept of medication calendars that enable users to schedule their medication alongside daily activities, while also resolving potential scheduling conflicts that may arise from unsafe drug interactions due to prescription administration constraints. Secondly, we present the findings of a qualitative study involving twelve participants who interacted with our calendar designs. The results indicate that medication calendars can be designed to facilitate the integration of prescription medication and that users are generally receptive to using a calendar to manage their medication, provided the design is familiar and uncluttered. Furthermore, our study shows that calendars can effectively render conflicts arising from unsafe rescheduling. These findings inform five additional design goals for an integrated calendar, including the use of familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our research makes a dual contribution to the field. Firstly, we introduce the concept of medication calendars that enable users to schedule their medication alongside daily activities, while also resolving potential scheduling conflicts that may arise from unsafe drug interactions due to prescription administration constraints. Secondly, we present the findings of a qualitative study involving twelve participants who interacted with our calendar designs. The results indicate that medication calendars can be designed to facilitate the integration of prescription medication and that users are generally receptive to using a calendar to manage their medication, provided the design is familiar and uncluttered. Furthermore, our study shows that calendars can effectively render conflicts arising from unsafe rescheduling. These findings inform five additional design goals for an integrated calendar, including the use of familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention."}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our research makes a dual contribution to the field, introducing the concept of medication calendars that enable users to schedule their medication alongside daily activities while resolving potential scheduling conflicts. This innovation is grounded in a qualitative study involving twelve participants who interacted with our calendar designs. The results indicate that medication calendars can facilitate the integration of prescription medication, and users are receptive to using a calendar to manage their medication provided the design is familiar and uncluttered. Moreover, our study demonstrates the effectiveness of calendars in rendering conflicts arising from unsafe rescheduling. These findings inform five additional design goals for an integrated calendar, including the use of familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our research makes a dual contribution to the field. First, we introduce the concept of medication calendars, which enable users to schedule medication alongside daily activities and provide a mechanism for resolving scheduling conflicts that may arise from unsafe drug interactions. These conflicts can occur when users violate administration constraints specified in the prescription. Second, we present the findings of a qualitative study involving twelve participants who interacted with our calendar designs. The results indicate that calendars can effectively support the integration of medication prescriptions and that users generally prefer using a calendar to manage their medications, as long as the design is familiar and intuitive. Furthermore, our study shows that conflicts can be resolved within the calendars, providing valuable insights that inform five additional design goals for integrated calendars: incorporating familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our research makes a dual contribution to the field. Firstly, we introduce the concept of medication calendars that enable users to schedule their medication alongside daily activities, while also resolving potential scheduling conflicts that may arise from unsafe drug interactions due to prescription administration constraints. Secondly, we present the findings of a qualitative study involving twelve participants who interacted with our calendar designs. The results indicate that medication calendars can be designed to facilitate the integration of prescription medication and that users are generally receptive to using a calendar to manage their medication, provided the design is familiar and uncluttered. Furthermore, our study shows that calendars can effectively render conflicts arising from unsafe rescheduling. These findings inform five additional design goals for an integrated calendar, including the use of familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "instruction": "Rewrite this paragraph for improved readability.", "revised_paragraph": "Revised paragraph: Our contribution is twofold. Firstly, we introduce a novel design for calendars that seamlessly integrate medication prescriptions. These calendars enable users to schedule medication alongside daily activities and provide a mechanism for resolving scheduling conflicts that may arise due to unsafe drug interactions. Secondly, we present the findings of a qualitative study involving twelve participants who interacted with our calendar designs. The results indicate that calendars can be designed to effectively support medication management and that users generally prefer using a calendar to manage their medications, provided the design is familiar and intuitive. Furthermore, our study shows that calendars can effectively render conflicts arising from unsafe rescheduling. These findings inform five key design goals for an integrated calendar: the use of familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.02", "instruction": "Rewrite this paragraph to make it more readable and fitting to the academic style.", "revised_paragraph": "Revised paragraph: Our research contributes to the development of medication management systems by proposing the design of calendars that integrate medication prescriptions with everyday activities. These calendars enable users to schedule medication administration alongside other daily tasks, while also resolving scheduling conflicts that may arise from unsafe drug interactions. The effectiveness of our design approach was evaluated through a qualitative study involving twelve participants, who interacted with the calendar designs. The results indicate that calendars can be designed to support the integration of medication prescriptions and that users are generally receptive to using a calendar to manage their medications, provided the design is familiar and intuitive. Furthermore, our study shows that conflicts arising from unsafe rescheduling can be resolved within the calendars. The findings of this study inform five additional design goals that an integrated calendar should address, including the use of familiar design, avoiding clutter, allowing for personalization, supporting personal reflection, and highlighting important information for user attention.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Under a supervised setting, we define positive and negative sets (C+ and C-) as same- and different-category pixels with respect to pixel i. However, this approach is not applicable in weakly- or unsupervised settings, where pixel labels are unknown. In weakly-supervised segmentation, sparse labeling leads to smaller C+ and C- sets and reduced learning efficiency."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: In a supervised setting, we can define the positive and negative sets (C+ and C-) as pixels with the same or different categories as pixel i. However, this approach is not applicable to weakly- or unsupervised settings, where the label at xi is unknown. Specifically, in weakly-supervised segmentation, we only have sparse labels in the image, resulting in significantly smaller sets of C+ and C- and reduced learning efficiency."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Under a supervised setting, we define positive and negative sets (C+ and C-) as same- and different-category pixels with respect to pixel i. However, this approach is not applicable in weakly- or unsupervised settings, where pixel labels are unknown. In weakly-supervised segmentation, sparse labeling leads to smaller C+ and C- sets and reduced learning efficiency."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Under a supervised setting, we define positive and negative sets (C+ and C-) as same- and different-category pixels with respect to pixel i. However, this approach is not applicable in weakly- or unsupervised settings, where pixel labels are unknown. In weakly-supervised segmentation, sparse labeling leads to smaller C+ and C- sets and reduced learning efficiency."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: In a supervised setting, we can define the positive and negative sets (C+ and C-) as pixels with the same or different categories as pixel i. However, this approach is not applicable to weakly- or unsupervised settings, where the label at xi is unknown. Specifically, in weakly-supervised segmentation, we only have sparse labels in the image, resulting in significantly smaller sets of C+ and C- and reduced learning efficiency."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Under a supervised setting, we define positive and negative sets (C+ and C-) as same- and different-category pixels with respect to pixel i. However, this approach is not applicable in weakly- or unsupervised settings, where pixel labels are unknown. In weakly-supervised segmentation, sparse labeling leads to smaller C+ and C- sets and reduced learning efficiency."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Under a supervised setting, we define positive and negative sets (C+ and C-) as same- and different-category pixels with respect to pixel i. However, this approach is not applicable in weakly- or unsupervised settings, where pixel labels are unknown. In weakly-supervised segmentation, sparse labeling leads to smaller C+ and C- sets and reduced learning efficiency."}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: In a supervised setting, we define positive and negative sets (C+ and C-) as same- and different-category pixels relative to pixel i, which enables accurate segmentation. However, this approach is not feasible in weakly- or unsupervised settings, where pixel labels are unknown. In weakly-supervised segmentation, the limited availability of sparse labels results in smaller C+ and C- sets, ultimately leading to reduced learning efficiency."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Under a supervised setting, we define positive and negative sets (C+ and C-) as same- and different-category pixels with respect to pixel i. However, this approach is not applicable in weakly- or unsupervised settings, where pixel labels are unknown. In weakly-supervised segmentation, sparse labeling leads to smaller C+ and C- sets and reduced learning efficiency."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Under a supervised setting, we define positive and negative sets (C+ and C-) as same- and different-category pixels with respect to pixel i. However, this approach is not applicable in weakly- or unsupervised settings, where pixel labels are unknown. In weakly-supervised segmentation, sparse labeling leads to smaller C+ and C- sets and reduced learning efficiency."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: In a supervised setting, we can define the positive and negative sets (C+ and C-) as pixels with the same or different categories as pixel i. However, this approach is not applicable to weakly- or unsupervised settings, where the label at xi is unknown. Specifically, in weakly-supervised segmentation, we only have sparse labels in the image, resulting in significantly smaller sets of C+ and C- and reduced learning efficiency."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: In supervised settings, we can define positive and negative sets (C+ and C-) as pixels with the same or different categories as pixel i. However, this approach is not applicable to weakly- or unsupervised settings, where the label at xi is unknown, due to the lack of sufficient labeled data."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "instruction": "Make this paragraph heavily more concise, keeping the main ideas.", "revised_paragraph": "Revised paragraph: \"In supervised settings, we define C+ and C- as same- and different-category pixels relative to pixel i. This approach is not applicable to weakly- or unsupervised settings, where pixel labels are unknown. In weakly-supervised segmentation, only sparse labels are available, leading to smaller C+ and C- sets and reduced learning efficiency.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.05", "instruction": "Concise and improve this explanation to make it more easy to understand.", "revised_paragraph": "Revised paragraph: \n\n\"In a supervised setting, we can define positive and negative sets (C+ and C-) as pixels with the same or different categories as pixel i. However, this approach is not applicable to weakly- or unsupervised settings where the label at x_i is unknown. In weakly-supervised segmentation, we only have sparse labels, leading to smaller C+ and C- sets and reduced learning efficiency.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Previous research has demonstrated the utility of GFlowNets in scenarios featuring multi-modal posteriors. This is particularly relevant to our work, as we often encounter situations where multiple admissible structures can equally well explain the observed data. In section 4, we present our GFlowNet-based solution, while section 5 discusses a toy system that exhibits multiple modes."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Previous research has demonstrated the utility of GFlowNets in scenarios involving multi-modal posteriors. This is particularly relevant to our work, where numerous admissible structures can equally well explain the observed data. We subsequently discuss a toy system featuring multiple modes in Section 5, before presenting our GFlowNet-based solution in Section 4.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Previous research has demonstrated the utility of GFlowNets in scenarios featuring multi-modal posteriors. This is particularly relevant to our work, as we often encounter situations where multiple admissible structures can equally well explain the observed data. In section 4, we present our GFlowNet-based solution, while section 5 discusses a toy system that exhibits multiple modes."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Previous research has demonstrated the utility of GFlowNets in scenarios involving multi-modal posteriors. This is particularly relevant to our work, where numerous admissible structures can equally well explain the observed data. We subsequently discuss a toy system featuring multiple modes in Section 5, before presenting our GFlowNet-based solution in Section 4.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Previous research has demonstrated the utility of GFlowNets in scenarios featuring multi-modal posteriors. This is particularly relevant to our work, as we often encounter situations where multiple admissible structures can equally well explain the observed data. In section 4, we present our GFlowNet-based solution, while section 5 discusses a toy system that exhibits multiple modes."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Previous research has shown the effectiveness of GFlowNets in scenarios involving multi-modal posteriors. This is particularly relevant to our study, as we frequently encounter situations where multiple admissible structures can equally well explain the observed data. In Section 4, we present our GFlowNet-based solution, while Section 5 discusses a toy system that exhibits multiple modes."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Previous research has demonstrated the utility of GFlowNets in scenarios featuring multi-modal posteriors. This is particularly relevant to our work, as we often encounter situations where multiple admissible structures can equally well explain the observed data. In section 4, we present our GFlowNet-based solution, while section 5 discusses a toy system that exhibits multiple modes."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Previous research has demonstrated the utility of GFlowNets in scenarios involving multi-modal posteriors. This is particularly relevant to our work, where numerous admissible structures can equally well explain the observed data. We subsequently discuss a toy system featuring multiple modes in Section 5, before presenting our GFlowNet-based solution in Section 4.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "instruction": "Make the citation in correct order.", "revised_paragraph": "Revised paragraph: \"Previous work has shown that GFlowNets are useful in settings with multi-modal posteriors (1). This is of particular interest to us, as many admissible structures can explain the observed data equally well. Next, we discuss a toy system with many modes in Section 5, and then present our GFlowNet-based solution in Section 4.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "instruction": "Revise this paragraph to present the sections in a coherent order.", "revised_paragraph": "Revised paragraph: Previous work has shown that GFlowNets are effective in settings with multi-modal posteriors, which is particularly relevant to our work where many admissible structures can explain the observed data equally well. In section 5, we present a toy system that exhibits many modes, and in section 4, we introduce our GFlowNet-based solution for addressing this challenge.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWe collected interaction data for one month to evaluate a listwise online campaign recommender system. The system represents users by attributes such as age, occupation, and localities, while items are characterized by text features, image features, and reward points of campaigns. To simulate a realistic reinforcement learning (RL) environment, we trained a reward model on a dataset of 68,775 users and 57 items to estimate the click likelihood of users (Appendix A.4). We then augmented the user reward model with the CPR reward to incentivize the agent to recommend high-CPR user-relevant items. To learn action representations, we trained a variational autoencoder (VAE) (Kingma & Welling, 2013) and used these representations as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. We report the test reward for models trained using the CDQN algorithm."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWe collected interaction data for one month to evaluate a listwise online campaign recommender system. The system represents users by attributes such as age, occupation, and localities, while items are characterized by text features, image features, and reward points of campaigns. To simulate a realistic reinforcement learning (RL) environment, we trained a reward model on a dataset of 68,775 users and 57 items to estimate the click likelihood of users (Appendix A.4). We then augmented the user reward model with the CPR reward to incentivize the agent to recommend high-CPR user-relevant items. To learn action representations, we trained a variational autoencoder (VAE) (Kingma & Welling, 2013) and used these representations as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. We report the test reward for models trained using the CDQN algorithm."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWe collected interaction data for one month to evaluate a listwise online campaign recommender system. The system represents users by attributes such as age, occupation, and localities, while items are characterized by text features, image features, and reward points of campaigns. To simulate a realistic reinforcement learning (RL) environment, we trained a reward model on a dataset of 68,775 users and 57 items to estimate the click likelihood of users (Appendix A.4). We then augmented the user reward model with the CPR reward to incentivize the agent to recommend high-CPR user-relevant items. To learn action representations, we trained a variational autoencoder (VAE) (Kingma & Welling, 2013) and used these representations as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. We report the test reward for models trained using the CDQN algorithm."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWe collected interaction data for one month to evaluate a listwise online campaign recommender system. The system represents users by attributes such as age, occupation, and localities, while items are characterized by text features, image features, and reward points of campaigns. To simulate a realistic reinforcement learning (RL) environment, we trained a reward model on a dataset of 68,775 users and 57 items to estimate the click likelihood of users (Appendix A.4). We then augmented the user reward model with the CPR reward to incentivize the agent to recommend high-CPR user-relevant items. To learn action representations, we trained a variational autoencoder (VAE) (Kingma & Welling, 2013) and used these representations as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. We report the test reward for models trained using the CDQN algorithm."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWe collected interaction data for one month to evaluate a listwise online campaign recommender system. The system represents users by attributes such as age, occupation, and localities, while items are characterized by text features, image features, and reward points of campaigns. To simulate a realistic reinforcement learning (RL) environment, we trained a reward model on a dataset of 68,775 users and 57 items to estimate the click likelihood of users (Appendix A.4). We then augmented the user reward model with the CPR reward to incentivize the agent to recommend high-CPR user-relevant items. To learn action representations, we trained a variational autoencoder (VAE) (Kingma & Welling, 2013) and used these representations as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. We report the test reward for models trained using the CDQN algorithm."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWe collected interaction data for one month to evaluate a listwise online campaign recommender system. The system represents users by attributes such as age, occupation, and localities, while items are characterized by text features, image features, and reward points of campaigns. To simulate a realistic reinforcement learning (RL) environment, we trained a reward model on a dataset of 68,775 users and 57 items to estimate the click likelihood of users (Appendix A.4). We then augmented the user reward model with the CPR reward to incentivize the agent to recommend high-CPR user-relevant items. To learn action representations, we trained a variational autoencoder (VAE) (Kingma & Welling, 2013) and used these representations as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. We report the test reward for models trained using the CDQN algorithm."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWe collected interaction data for one month to evaluate a listwise online campaign recommender system. The system represents users by attributes such as age, occupation, and localities, while items are characterized by text features, image features, and reward points of campaigns. To simulate a realistic reinforcement learning (RL) environment, we trained a reward model on a dataset of 68,775 users and 57 items to estimate the click likelihood of users (Appendix A.4). We then augmented the user reward model with the CPR reward to incentivize the agent to recommend high-CPR user-relevant items. To learn action representations, we trained a variational autoencoder (VAE) (Kingma & Welling, 2013) and used these representations as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. We report the test reward for models trained using the CDQN algorithm."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWe collected interaction data for one month to evaluate a listwise online campaign recommender system. The system represents users by attributes such as age, occupation, and localities, while items are characterized by text features, image features, and reward points of campaigns. To simulate a realistic reinforcement learning (RL) environment, we trained a reward model on a dataset of 68,775 users and 57 items to estimate the click likelihood of users (Appendix A.4). We then augmented the user reward model with the CPR reward to incentivize the agent to recommend high-CPR user-relevant items. To learn action representations, we trained a variational autoencoder (VAE) (Kingma & Welling, 2013) and used these representations as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. We report the test reward for models trained using the CDQN algorithm."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "instruction": "Rewrite the majority of the paragraph, avoiding we and writing in a more neutral tone.", "revised_paragraph": "Revised paragraph: The interaction data for a listwise online campaign recommender system was collected for one month. User attributes, including age, occupation, and localities, were represented, as were item attributes, such as text features, image features, and reward points of campaigns. A representative reinforcement learning environment was simulated by training a reward model on a set of 68,775 users and 57 items to estimate the click likelihood of users (Appendix A.4). The user reward model was augmented with the CPR reward to incentivize the agent to recommend high-CPR user-relevant items. A variational autoencoder (Kingma & Welling, 2013) was trained to learn action representations, which were provided as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. The test reward was reported for models trained using the CDQN algorithm.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.11", "instruction": "Rewrite and reorganize the paragraph to convey the ideas more clearly.", "revised_paragraph": "Revised paragraph: \n\nTo evaluate the performance of our listwise online campaign recommender system, we collected interaction data for one month from a representative set of 68,775 users and 57 items. We represented users by attributes such as age, occupation, and localities, while items were characterized by text features, image features, and reward points of campaigns. To simulate a realistic reinforcement learning (RL) environment, we trained a reward model to estimate the click likelihood of users, and then augmented it with a CPR reward to incentivize the agent to recommend high-CPR user-relevant items. We employed a variational autoencoder (VAE) to learn action representations, which were used as input to the RL agent. The test data consisted of 82,445 users and 58 items, with approximately 30 items shared with the training set. We report the test reward for models trained using the CDQN algorithm.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Medication entries should have a marker indicating the exact time a reminder is triggered, not a time range. Daily summaries on the calendar should provide an overview of medications to be administered, with the option to add or remove entries. In conflict scenarios, emphasis should be on the position of conflicting entries, rather than connectors. Users should be notified of impending conflicts before rescheduling, with normal, dismissible error messages displaying full conflict information. When rescheduling, cells with potential conflicts should be highlighted to guide the user, and users should be able to configure warning and error message settings."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nMedication reminders should have a specific trigger time, rather than a time range. The calendar should provide daily summaries of medications to be administered, allowing users to easily view their medication schedule. In cases of conflicts, the system should prioritize indicating the position of conflicting entries, rather than using connectors. The user should be notified of impending conflicts beforehand, rather than relying on on-calendar conflict representation. When rescheduling, cells with potential conflicts should be highlighted, and the user should be guided on possible moves to resolve the conflict."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nMedication entries should be accompanied by a marker that clearly indicates the exact time at which the reminder will be triggered. This marker should not display a time range, as was the case in all three designs, but rather a specific point in time, such as a minute, when the reminder is triggered. The calendar should provide daily summaries, which should provide an overview of the medications to be administered each day. These summaries should only include the name of the medication and should be designed to allow users to add or remove them from the display as needed. When dealing with conflicts, the focus should be on the position of the conflicting entries rather than the connectors. If present, lines connecting conflicting entries should be less prominent. On-calendar conflict representation should not be the primary indication of an error following a rescheduling activity. Instead, users should be notified of impending conflicts beforehand. Participants preferred to receive normal, dismissible error messages that provide full information about the conflicts introduced by the action. When rescheduling medication entries, cells that are either safe or unsafe should be highlighted using a color that indicates either success (e.g., green) or warning (e.g., yellow). Although some participants believed that the design should not allow scheduling entries in spaces likely to cause conflicts, there may be situations where this possibility is desirable. In such cases, users should be guided on possible moves that can resolve the conflict. This can be achieved by shading or outlining all cells to which an entry may be rescheduled to resolve the conflict, and allowing users to configure the amount of warnings and error messages they receive."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nMedication reminders should have a specific trigger time, rather than a time range. The calendar should provide daily summaries of medications to be administered, allowing users to easily view their medication schedule. In cases of conflicts, the system should prioritize indicating the position of conflicting entries, rather than using connectors. The user should be notified of impending conflicts beforehand, rather than relying on on-calendar conflict representation. When rescheduling, cells with potential conflicts should be highlighted, and the user should be guided on possible moves to resolve the conflict."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Medication entries should have a marker indicating the exact time a reminder is triggered, not a time range. Daily summaries on the calendar should provide an overview of medications to be administered, with the option to add or remove entries. In conflict scenarios, emphasis should be on the position of conflicting entries, rather than connectors. Users should be notified of impending conflicts before rescheduling, with normal, dismissible error messages displaying full conflict information. When rescheduling, cells with potential conflicts should be highlighted to guide the user, and users should be able to configure warning and error message settings."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nMedication reminders should have a specific trigger time, rather than a time range. The calendar should provide daily summaries of medications to be administered, allowing users to easily view their medication schedule. In cases of conflicts, the system should prioritize indicating the position of conflicting entries, rather than using connectors. The user should be notified of impending conflicts beforehand, rather than relying on on-calendar conflict representation. When rescheduling, cells with potential conflicts should be highlighted, and the user should be guided on possible moves to resolve the conflict."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nMedication reminders should have a specific trigger time, rather than a time range. The calendar should provide daily summaries of medications to be administered, allowing users to easily view their medication schedule. In cases of conflicts, the system should prioritize indicating the position of conflicting entries, rather than using connectors. The user should be notified of impending conflicts beforehand, rather than relying on on-calendar conflict representation. When rescheduling, cells with potential conflicts should be highlighted, and the user should be guided on possible moves to resolve the conflict."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nMedication entries should be accompanied by a marker that clearly indicates the exact time at which the reminder will be triggered. This marker should not display a time range, as was the case in all three designs, but rather a specific point in time, such as a minute, when the reminder is triggered. The calendar should provide daily summaries, which should provide an overview of the medications to be administered each day. These summaries should only include the name of the medication and should be designed to allow users to add or remove them from the display as needed. When dealing with conflicts, the focus should be on the position of the conflicting entries rather than the connectors. If present, lines connecting conflicting entries should be less prominent. On-calendar conflict representation should not be the primary indication of an error following a rescheduling activity. Instead, users should be notified of impending conflicts beforehand. Participants preferred to receive normal, dismissible error messages that provide full information about the conflicts introduced by the action. When rescheduling medication entries, cells that are either safe or unsafe should be highlighted using a color that indicates either success (e.g., green) or warning (e.g., yellow). Although some participants believed that the design should not allow scheduling entries in spaces likely to cause conflicts, there may be situations where this possibility is desirable. In such cases, users should be guided on possible moves that can resolve the conflict. This can be achieved by shading or outlining all cells to which an entry may be rescheduled to resolve the conflict, and allowing users to configure the amount of warnings and error messages they receive."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Medication entries should have a marker indicating the exact time a reminder is triggered, not a time range. Daily summaries on the calendar should provide an overview of medications to be administered, with the option to add or remove entries. In conflict scenarios, emphasis should be on the position of conflicting entries, rather than connectors. Users should be notified of impending conflicts before rescheduling, with normal, dismissible error messages displaying full conflict information. When rescheduling, cells with potential conflicts should be highlighted to guide the user, and users should be able to configure warning and error message settings."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Medication reminders should specify exact trigger times, not time ranges. Daily summaries on the calendar should provide an overview of medications to be administered, with options to add or remove entries. In conflict scenarios, conflicting entries should be prioritized, with users notified before rescheduling and able to configure warning and error message settings."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Medication reminders should provide precise trigger times, rather than time ranges, to ensure accurate administration. The daily summary feature on the calendar should offer a comprehensive overview of medications to be taken, allowing users to easily add or remove entries as needed. In cases of conflicting entries, the system should prioritize these conflicts, notify users before rescheduling, and enable them to customize warning and error message settings to suit their preferences."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nMedication reminders should have a specific trigger time, rather than a time range. The calendar should provide daily summaries of medications to be administered, allowing users to easily view their medication schedule. In cases of conflicts, the system should prioritize indicating the position of conflicting entries, rather than using connectors. The user should be notified of impending conflicts beforehand, rather than relying on on-calendar conflict representation. When rescheduling, cells with potential conflicts should be highlighted, and the user should be guided on possible moves to resolve the conflict."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Medication entries should have a marker indicating the exact time a reminder is triggered, not a time range. Daily summaries on the calendar should provide an overview of medications to be administered, with the option to add or remove entries. In conflict scenarios, emphasis should be on the position of conflicting entries, rather than connectors. Users should be notified of impending conflicts before rescheduling, with normal, dismissible error messages displaying full conflict information. When rescheduling, cells with potential conflicts should be highlighted to guide the user, and users should be able to configure warning and error message settings."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Medication reminders should specify exact trigger times, not time ranges. Daily summaries on the calendar should provide an overview of medications to be administered, with options to add or remove entries. In conflict scenarios, conflicting entries should be prioritized, with users notified before rescheduling and able to configure warning and error message settings."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nMedication reminders should have a specific trigger time, rather than a time range. The calendar should provide daily summaries of medications to be administered, allowing users to easily view their medication schedule. In cases of conflicts, the system should prioritize indicating the position of conflicting entries, rather than using connectors. The user should be notified of impending conflicts beforehand, rather than relying on on-calendar conflict representation. When rescheduling, cells with potential conflicts should be highlighted, and the user should be guided on possible moves to resolve the conflict."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nTo optimize medication reminders, it is recommended that the trigger time be specific rather than a range. The calendar should provide daily summaries of medications to be administered, enabling users to easily view their medication schedule. In instances of conflicts, the system should prioritize indicating the conflicting entries' positions, rather than using connectors. Furthermore, the user should be notified of impending conflicts beforehand, rather than relying solely on on-calendar conflict representation. When rescheduling, cells with potential conflicts should be highlighted, and the user should be guided on possible moves to resolve the conflict."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "instruction": "Heavily remove details from this paragraph to make it more concise.", "revised_paragraph": "Revised paragraph: Medication entries should have a specific trigger time, not a time range. The calendar should display daily summaries of medications to be administered, with the option to add or remove entries. When conflicts arise, the focus should be on the conflicting entries' positions, rather than connectors. The user should be notified of impending conflicts beforehand, and error messages should be displayed with full information. When rescheduling, cells should be highlighted to indicate safety or warning, and the user should be guided on possible moves to resolve conflicts.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "instruction": "Please condense my paragraph related to medication conflicts.", "revised_paragraph": "Revised paragraph:\n\nMedication entries should be marked with a specific trigger time, rather than a time range, to facilitate accurate reminder scheduling. The calendar should include daily summaries of medications to be administered, displaying only the medication name and allowing users to customize the display. When conflicts arise, emphasis should be placed on the position of conflicting entries rather than connectors. The calendar should not rely solely on visual indicators to represent conflicts, but instead notify users beforehand. Participants preferred dismissible error messages providing full conflict information. During rescheduling, cells with conflicting or safe entries should be highlighted in green (success) or yellow (warning) colors. Although some participants suggested prohibiting scheduling in conflict-prone spaces, the design should allow for this possibility, guiding users with possible moves to resolve conflicts by shading or outlining relevant cells. Users should also be able to configure warning and error message settings.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Delayed augmentation experiments were conducted to investigate its impact on generalization. The results, depicted in Figure 2(d) and Figure 2(e), demonstrate a rapid increase in generalization when augmentation was introduced at 10M and 20M. Notably, the augmentation still improved generalization, regardless of the timing of its introduction. In contrast to supervised learning, where delayed augmentation does not achieve the same level of improvement as using augmentation throughout training, as shown by Golatkar et al. [9], our results suggest that delayed augmentation can still lead to comparable improvements in generalization, as seen in (10, 25) and (0, 25). However, when augmentation significantly enhances training, as observed in Figure 2(e), delayed augmentation struggles to match the performance of earlier introduction, as seen in Figure 2(f). This is because reinforcement learning gradually improves the policy and trajectory through the Markov property. Additionally, the limited number of samples in reinforcement learning compared to supervised learning underscores the importance of using augmentation from the initial time if it aids training."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Delayed augmentation experiments were conducted to investigate its impact on generalization. The results, depicted in Figure 2(d) and Figure 2(e), demonstrate a rapid increase in generalization when augmentation was introduced at 10M and 20M. Notably, the augmentation still improved generalization, regardless of the timing of its introduction. In contrast to supervised learning, where delayed augmentation does not achieve the same level of improvement as using augmentation throughout training, as shown by Golatkar et al. [9], our results suggest that delayed augmentation can still lead to comparable improvements in generalization, as seen in (10, 25) and (0, 25). However, when augmentation significantly enhances training, as observed in Figure 2(e), delayed augmentation struggles to match the performance of earlier introduction, as seen in Figure 2(f). This is because reinforcement learning gradually improves the policy and trajectory through the Markov property. Additionally, the limited number of samples in reinforcement learning compared to supervised learning underscores the importance of using augmentation from the initial time if it aids training."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Delayed augmentation experiments were conducted to investigate its impact on generalization. The results, depicted in Figure 2(d) and Figure 2(e), demonstrate a rapid increase in generalization when augmentation was introduced at 10M and 20M. Notably, the augmentation still improved generalization, regardless of the timing of its introduction. In contrast to supervised learning, where delayed augmentation does not achieve the same level of improvement as using augmentation throughout training, as shown by Golatkar et al. [9], our results suggest that delayed augmentation can still lead to comparable improvements in generalization, as seen in (10, 25) and (0, 25). However, when augmentation significantly enhances training, as observed in Figure 2(e), delayed augmentation struggles to match the performance of earlier introduction, as seen in Figure 2(f). This is because reinforcement learning gradually improves the policy and trajectory through the Markov property. Additionally, the limited number of samples in reinforcement learning compared to supervised learning underscores the importance of using augmentation from the initial time if it aids training."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Delayed augmentation experiments were conducted to investigate its impact on generalization. The results, depicted in Figure 2(d) and Figure 2(e), demonstrate a rapid increase in generalization when augmentation was introduced at 10M and 20M. Notably, the augmentation still improved generalization, regardless of the timing of its introduction. In contrast to supervised learning, where delayed augmentation does not achieve the same level of improvement as using augmentation throughout training, as shown by Golatkar et al. [9], our results suggest that delayed augmentation can still lead to comparable improvements in generalization, as seen in (10, 25) and (0, 25). However, when augmentation significantly enhances training, as observed in Figure 2(e), delayed augmentation struggles to match the performance of earlier introduction, as seen in Figure 2(f). This is because reinforcement learning gradually improves the policy and trajectory through the Markov property. Additionally, the limited number of samples in reinforcement learning compared to supervised learning underscores the importance of using augmentation from the initial time if it aids training."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Delayed augmentation experiments were conducted to investigate its impact on generalization. The results, depicted in Figure 2(d) and Figure 2(e), demonstrate a rapid increase in generalization when augmentation was introduced at 10M and 20M. Notably, the augmentation still improved generalization, regardless of the timing of its introduction. In contrast to supervised learning, where delayed augmentation does not achieve the same level of improvement as using augmentation throughout training, as shown by Golatkar et al. [9], our results suggest that delayed augmentation can still lead to comparable improvements in generalization, as seen in (10, 25) and (0, 25). However, when augmentation significantly enhances training, as observed in Figure 2(e), delayed augmentation struggles to match the performance of earlier introduction, as seen in Figure 2(f). This is because reinforcement learning gradually improves the policy and trajectory through the Markov property. Additionally, the limited number of samples in reinforcement learning compared to supervised learning underscores the importance of using augmentation from the initial time if it aids training."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Delayed augmentation experiments were conducted to investigate its impact on generalization. The results, depicted in Figure 2(d) and Figure 2(e), demonstrate a rapid increase in generalization when augmentation was introduced at 10M and 20M. Notably, the augmentation still improved generalization, regardless of the timing of its introduction. In contrast to supervised learning, where delayed augmentation does not achieve the same level of improvement as using augmentation throughout training, as shown by Golatkar et al. [9], our results suggest that delayed augmentation can still lead to comparable improvements in generalization, as seen in (10, 25) and (0, 25). However, when augmentation significantly enhances training, as observed in Figure 2(e), delayed augmentation struggles to match the performance of earlier introduction, as seen in Figure 2(f). This is because reinforcement learning gradually improves the policy and trajectory through the Markov property. Additionally, the limited number of samples in reinforcement learning compared to supervised learning underscores the importance of using augmentation from the initial time if it aids training."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Delayed augmentation experiments were conducted to investigate its impact on generalization. The results, depicted in Figure 2(d) and Figure 2(e), demonstrate a rapid increase in generalization when augmentation was introduced at 10M and 20M. Notably, the augmentation still improved generalization, regardless of the timing of its introduction. In contrast to supervised learning, where delayed augmentation does not achieve the same level of improvement as using augmentation throughout training, as shown by Golatkar et al. [9], our results suggest that delayed augmentation can still lead to comparable improvements in generalization, as seen in (10, 25) and (0, 25). However, when augmentation significantly enhances training, as observed in Figure 2(e), delayed augmentation struggles to match the performance of earlier introduction, as seen in Figure 2(f). This is because reinforcement learning gradually improves the policy and trajectory through the Markov property. Additionally, the limited number of samples in reinforcement learning compared to supervised learning underscores the importance of using augmentation from the initial time if it aids training."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Delayed augmentation experiments were conducted to investigate its impact on generalization. The results, depicted in Figure 2(d) and Figure 2(e), demonstrate a rapid increase in generalization when augmentation was introduced at 10M and 20M. Notably, the augmentation still improved generalization, regardless of the timing of its introduction. In contrast to supervised learning, where delayed augmentation does not achieve the same level of improvement as using augmentation throughout training, as shown by Golatkar et al. [9], our results suggest that delayed augmentation can still lead to comparable improvements in generalization, as seen in (10, 25) and (0, 25). However, when augmentation significantly enhances training, as observed in Figure 2(e), delayed augmentation struggles to match the performance of earlier introduction, as seen in Figure 2(f). This is because reinforcement learning gradually improves the policy and trajectory through the Markov property. Additionally, the limited number of samples in reinforcement learning compared to supervised learning underscores the importance of using augmentation from the initial time if it aids training."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "instruction": "Use clearer expression, use concise words.", "revised_paragraph": "Revised paragraph: Delayed augmentation experiments demonstrate improved generalization when introduced at 10M and 20M, as evident in Figure 2(d) and Figure 2(e). Notably, the augmentation benefits generalize regardless of the timing of introduction, differing from the findings of Golatkar et al. [9], which suggest that delayed augmentation is less effective than continuous augmentation in supervised learning. In contrast, our results show that (10, 25) achieves comparable generalization to (0, 25), which uses augmentation throughout training. However, when augmentation significantly enhances training, as seen in Figure 2(e), delayed augmentation struggles to match the performance of earlier introduction, as the RL algorithm gradually refines the policy and trajectory. Furthermore, the limited sample size in RL makes it more crucial to introduce augmentation from the beginning, particularly when it significantly improves training.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.14", "instruction": "Revise this paragraph to use clearer and more precise words.", "revised_paragraph": "Revised paragraph: \n\nIn our experiments, we investigate the impact of delayed augmentation on generalization performance. As illustrated in Figure 2(d) and Figure 2(e), the generalization improves significantly after introducing augmentation at 10M and 20M. Notably, the benefits of augmentation are not limited to its early adoption, as it still enhances generalization even when applied later. In contrast to supervised learning, where delayed augmentation has been shown to be less effective [9], our results demonstrate that (10, 25) achieves comparable generalization improvements to (0, 25), which employs augmentation throughout training. However, when augmentation significantly enhances training, as seen in Figure 2(e), delayed augmentation lags behind earlier adoption, as depicted in Figure 2(f). This is because reinforcement learning (RL) gradually refines the policy and trajectory through the Markov property. Moreover, RL has limited sample availability, making early augmentation more crucial if it contributes to improved training outcomes.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in DSPN, it depends on the encoder choice. For example, a DeepSets encoder (Zaheer et al., 2017) based on sum pooling has the same gradients for equal elements, making DSPN set-equivariant. The exclusively multiset-equivariant gradient of sorting is what specifically achieves exclusive multiset-equivariance in DSPN.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in deep set prediction networks (DSPN), it depends on the specific choice of encoder. For example, a DeepSets encoder (Zaheer et al., 2017), which employs sum pooling, yields the same gradients for equal elements, thereby rendering DSPN set-equivariant. The exclusive multiset-equivariance of DSPN is, however, ensured by the use of the exclusively multiset-equivariant gradient of sorting.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in deep set prediction networks (DSPN), it depends on the specific choice of encoder. For example, a DeepSets encoder (Zaheer et al., 2017), which employs sum pooling, yields the same gradients for equal elements, thereby rendering DSPN set-equivariant. The exclusive multiset-equivariance of DSPN is, however, ensured by the use of the exclusively multiset-equivariant gradient of sorting.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in deep set prediction networks (DSPN), it depends on the specific choice of encoder. For example, a DeepSets encoder (Zaheer et al., 2017), which employs sum pooling, yields the same gradients for equal elements, thereby rendering DSPN set-equivariant. The exclusive multiset-equivariance of DSPN is, however, ensured by the use of the exclusively multiset-equivariant gradient of sorting.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in deep set prediction networks (DSPN), it depends on the specific choice of encoder. For example, a DeepSets encoder (Zaheer et al., 2017), which employs sum pooling, yields the same gradients for equal elements, thereby rendering DSPN set-equivariant. The exclusive multiset-equivariance of DSPN is, however, ensured by the use of the exclusively multiset-equivariant gradient of sorting.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in DSPN, it depends on the encoder choice. For example, a DeepSets encoder (Zaheer et al., 2017) based on sum pooling has the same gradients for equal elements, making DSPN set-equivariant. The exclusively multiset-equivariant gradient of sorting is what specifically achieves exclusive multiset-equivariance in DSPN.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in DSPN, it depends on the encoder choice. For example, a DeepSets encoder (Zaheer et al., 2017) based on sum pooling has the same gradients for equal elements, making DSPN set-equivariant. The exclusively multiset-equivariant gradient of sorting is what specifically achieves exclusive multiset-equivariance in DSPN.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not inherent to DSPN, it is contingent on the encoder selection. Specifically, a DeepSets encoder (Zaheer et al., 2017) that employs sum pooling exhibits set-equivariance, as it yields the same gradients for equal elements. The exclusive multiset-equivariance achieved through sorting is the key factor that enables DSPN to exhibit this property.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in deep set prediction networks (DSPN), it depends on the specific choice of encoder. For example, a DeepSets encoder (Zaheer et al., 2017), which employs sum pooling, yields the same gradients for equal elements, thereby rendering DSPN set-equivariant. The exclusive multiset-equivariance of DSPN is, however, ensured by the use of the exclusively multiset-equivariant gradient of sorting.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in deep set prediction networks (DSPN), it depends on the specific choice of encoder. For example, a DeepSets encoder (Zaheer et al., 2017), which employs sum pooling, yields the same gradients for equal elements, thereby rendering DSPN set-equivariant. The exclusive multiset-equivariance of DSPN is, however, ensured by the use of the exclusively multiset-equivariant gradient of sorting.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"While exclusive multiset-equivariance is not guaranteed in deep set prediction networks (DSPN), it depends on the specific choice of encoder. For example, a DeepSets encoder (Zaheer et al., 2017), which employs sum pooling, yields the same gradients for equal elements, thereby rendering DSPN set-equivariant. The exclusive multiset-equivariance of DSPN is, however, ensured by the use of the exclusively multiset-equivariant gradient of sorting.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Exclusive multiset-equivariance in deep set prediction networks (DSPN) depends on the encoder choice. For instance, the DeepSets encoder (Zaheer et al., 2017) with sum pooling ensures set-equivariance. The exclusively multiset-equivariant gradient of sorting, however, guarantees exclusive multiset-equivariance in DSPN.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "instruction": "Change the subject in the first sentence.", "revised_paragraph": "Revised paragraph: Note that not all neural networks achieve exclusive multiset-equivariance, as it depends on the specific architecture and choice of encoder. For instance, a DeepSets encoder (Zaheer et al., 2017) \u2013 which relies on sum pooling \u2013 exhibits set-equivariance due to its identical gradients for equal elements. It is the unique combination of the exclusively multiset-equivariant gradient of sorting that enables some neural networks to achieve exclusive multiset-equivariance.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.06", "instruction": "Lightly revise this paragraph for better readability while trying to make it a little shorter without loosing informations.", "revised_paragraph": "Revised paragraph: Note that exclusive multiset-equivariance in DSPN depends on the choice of encoder. For example, a DeepSets encoder (Zaheer et al., 2017) based on sum pooling has equal gradients for equal elements, making it set-equivariant. The use of exclusively multiset-equivariant sorting gradients distinguishes DSPN from set-equivariant models.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we introduce the greedy learner hypothesis as a means of explaining the challenges encountered during the training of multi-modal deep neural networks. Prior to presenting our hypothesis, we first outline the key assumptions underlying multi-modal data and summarize the preliminary observations reported in the literature on multi-modal learning."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we introduce the greedy learner hypothesis as a means of explaining the challenges encountered during the training of multi-modal deep neural networks. Prior to presenting our hypothesis, we first outline the key assumptions underlying multi-modal data and summarize the preliminary observations reported in the literature on multi-modal learning."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we introduce the greedy learner hypothesis as a means of explaining the challenges encountered during the training of multi-modal deep neural networks. Prior to presenting our hypothesis, we first outline the key assumptions underlying multi-modal data and summarize the preliminary observations reported in the literature on multi-modal learning."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we introduce the greedy learner hypothesis as a means of explaining the challenges encountered during the training of multi-modal deep neural networks. Prior to presenting our hypothesis, we first outline the key assumptions underlying multi-modal data and summarize the preliminary observations reported in the literature on multi-modal learning."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we introduce the greedy learner hypothesis as a means of explaining the challenges encountered during the training of multi-modal deep neural networks. Prior to presenting our hypothesis, we first outline the key assumptions underlying multi-modal data and summarize the preliminary observations reported in the literature on multi-modal learning."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we introduce the greedy learner hypothesis as a means of explaining the challenges encountered during the training of multi-modal deep neural networks. Prior to presenting our hypothesis, we first outline the key assumptions underlying multi-modal data and summarize the preliminary observations reported in the literature on multi-modal learning."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we introduce the greedy learner hypothesis as a means of explaining the challenges encountered during the training of multi-modal deep neural networks. Prior to presenting our hypothesis, we first outline the key assumptions underlying multi-modal data and summarize the preliminary observations reported in the literature on multi-modal learning."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this section, we introduce the greedy learner hypothesis as a means of explaining the challenges encountered during the training of multi-modal deep neural networks. Prior to presenting our hypothesis, we first outline the key assumptions underlying multi-modal data and summarize the preliminary observations reported in the literature on multi-modal learning."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "instruction": "Make expression concise.", "revised_paragraph": "Revised paragraph: We introduce the greedy learner hypothesis to explain challenges in training multi-modal DNNs. Prior to describing our hypothesis, we outline assumptions on multi-modal data and summarize preliminary observations from the literature on multi-modal learning.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.06", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "Revised paragraph: \"In this section, we present the greedy learner hypothesis as a framework to elucidate the challenges encountered in training multi-modal deep neural networks (DNNs). Prior to articulating our hypothesis, we first provide an overview of the assumptions underlying multi-modal data and summarize the key observations from the existing literature on multi-modal learning.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because the permutation-invariant property of g ensures that any ordering of the elements in Y yields the same value for L, the model can operate independently of the specific arrangement of these elements. During the forward pass, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass, as proposed by Zhang et al. (2019), the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder are computed by backpropagating through the gradient descent iterations."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because the permutation-invariant property of g ensures that any ordering of the elements in Y yields the same value for L, the model can operate independently of the specific arrangement of these elements. During the forward pass, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass, as proposed by Zhang et al. (2019), the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder are computed by backpropagating through the gradient descent iterations."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because the permutation-invariant property of g ensures that any ordering of the elements in Y yields the same value for L, the model can operate independently of the specific arrangement of these elements. During the forward pass, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass, as proposed by Zhang et al. (2019), the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder are computed by backpropagating through the gradient descent iterations."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because the permutation-invariant property of g ensures that any ordering of the elements in Y yields the same value for L, the model can operate independently of the specific arrangement of these elements. During the forward pass, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass, as proposed by Zhang et al. (2019), the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder are computed by backpropagating through the gradient descent iterations."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because the permutation-invariant property of g ensures that any ordering of the elements in Y yields the same value for L, the model can operate independently of the specific arrangement of these elements. During the forward pass, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass, as proposed by Zhang et al. (2019), the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder are computed by backpropagating through the gradient descent iterations."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because the permutation-invariant property of g ensures that any ordering of the elements in Y yields the same value for L, the model can operate independently of the specific arrangement of these elements. During the forward pass, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass, as proposed by Zhang et al. (2019), the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder are computed by backpropagating through the gradient descent iterations."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because the permutation-invariant property of g ensures that any ordering of the elements in Y yields the same value for L, the model can operate independently of the specific arrangement of these elements. During the forward pass, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass, as proposed by Zhang et al. (2019), the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder are computed by backpropagating through the gradient descent iterations."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because the permutation-invariant property of g ensures that any ordering of the elements in Y yields the same value for L, the model can operate independently of the specific arrangement of these elements. During the forward pass, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass, as proposed by Zhang et al. (2019), the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder are computed by backpropagating through the gradient descent iterations."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "instruction": "Add a sentence to explain the last sentence.", "revised_paragraph": "Revised paragraph: \"Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, the arg min is approximated by running a fixed number of gradient descent steps. In the backward pass, Zhang et al. (2019) backpropagate through the gradient descent iterations in order to compute the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder, thereby enabling the optimization of the model's parameters in an efficient manner.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.04", "instruction": "Improve the logical flow of the last half of the paragraph.", "revised_paragraph": "Revised paragraph: Because g is permutation-invariant, any ordering for the elements in Y has the same value for L. In the forward pass of the model, an approximation of the arg min is obtained by running a fixed number of gradient descent steps. This approximation is then used to compute the gradients of the training objective with respect to the input vector z and the parameters \u03b8 of the encoder during the backward pass, as described by Zhang et al. (2019), who backpropagate through the gradient descent iterations.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Since all figures in the FAUST dataset have the same mesh and orientation, relaxing gauge equivariance in higher layers can be advantageous. As demonstrated by Weiler and Cesa (2019), this can be achieved by treating non-invariant features as invariant features as input to the final 1x1 convolutional layer. This architecture ensures equivariance at lower levels while allowing orientation sensitivity in higher layers."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As all figures in the FAUST dataset are similarly meshed and oriented, exploiting the gauge equivariance in higher layers may not be beneficial. In contrast, breaking the gauge equivariance can be advantageous, as demonstrated by Weiler and Cesa (2019), who showed that non-invariant features can be treated as invariant features by feeding them into the final 1 \u00d7 1 convolution as input. This architecture is equivariant at lower levels while allowing orientation sensitivity at higher layers."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As all figures in the FAUST dataset are similarly meshed and oriented, exploiting the gauge equivariance in higher layers may not be beneficial. In contrast, breaking the gauge equivariance can be advantageous, as demonstrated by Weiler and Cesa (2019), who showed that non-invariant features can be treated as invariant features by feeding them into the final 1 \u00d7 1 convolution as input. This architecture is equivariant at lower levels while allowing orientation sensitivity at higher layers."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Since all figures in the FAUST dataset have the same mesh and orientation, relaxing gauge equivariance in higher layers can be advantageous. As demonstrated by Weiler and Cesa (2019), this can be achieved by treating non-invariant features as invariant features as input to the final 1x1 convolutional layer. This architecture ensures equivariance at lower levels while allowing orientation sensitivity in higher layers."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Since all figures in the FAUST dataset have the same mesh and orientation, relaxing gauge equivariance in higher layers can be advantageous. As demonstrated by Weiler and Cesa (2019), this can be achieved by treating non-invariant features as invariant features as input to the final 1x1 convolutional layer. This architecture ensures equivariance at lower levels while allowing orientation sensitivity in higher layers."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Since all figures in the FAUST dataset share the same mesh and orientation, relaxing gauge equivariance in higher layers can be beneficial. As demonstrated by Weiler and Cesa (2019), this can be achieved by treating non-invariant features as invariant features and feeding them as input to the final 1x1 convolutional layer. This architecture ensures equivariance at lower levels while enabling orientation sensitivity in higher layers."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As all figures in the FAUST dataset are similarly meshed and oriented, exploiting the gauge equivariance in higher layers may not be beneficial. In contrast, breaking the gauge equivariance can be advantageous, as demonstrated by Weiler and Cesa (2019), who showed that non-invariant features can be treated as invariant features by feeding them into the final 1 \u00d7 1 convolution as input. This architecture is equivariant at lower levels while allowing orientation sensitivity at higher layers."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Since all figures in the FAUST dataset have the same mesh and orientation, relaxing gauge equivariance in higher layers can be advantageous. As demonstrated by Weiler and Cesa (2019), this can be achieved by treating non-invariant features as invariant features as input to the final 1x1 convolutional layer. This architecture ensures equivariance at lower levels while allowing orientation sensitivity in higher layers."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "instruction": "Rephrase the paragraph", "revised_paragraph": "Revised paragraph: In the FAUST dataset, all figures are uniformly meshed and oriented, which allows for the beneficial breaking of gauge equivariance in higher layers. Research by Weiler and Cesa (2019) demonstrates that symmetry can be disrupted by treating non-invariant features as invariant features and feeding them into the final 1 \u00d7 1 convolution. This approach enables equivariance at lower levels while preserving orientation sensitivity in higher layers.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.03", "instruction": "Rephrase the first sentence.", "revised_paragraph": "Revised paragraph: As the FAUST data set consists of uniformly meshed and oriented figures, exploiting gauge equivariance can be counterproductive. In fact, research by Weiler & Cesa (2019) suggests that symmetry can be effectively broken by treating non-invariant features as invariant features as input to the final 1 \u00d7 1 convolution, thereby enabling equivariant architectures on lower levels and orientation sensitivity at higher layers.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Patrick et al. introduced the Mouse Ether technique, which was designed to address the issue of cursor loss when using multiple displays with varying resolutions [5]. Specifically, they found that when moving the cursor between displays, users often experienced unnatural movement, leading to cursor loss. The results of their study demonstrated that the technique significantly improved performance by up to 28%, by effectively preventing this unnatural warping when the cursor was moved between displays."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Patrick et al. introduced the Mouse Ether technique, which was designed to address the issue of cursor loss when using multiple displays with varying resolutions [5]. Specifically, they found that the natural movement of the cursor between displays was disrupted, resulting in a loss of cursor visibility. The technique was shown to significantly improve performance, with a notable increase of up to 28%, by preventing the unnatural warping of the cursor when it was moved between displays."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Patrick et al. introduced the Mouse Ether technique, which was designed to address the issue of cursor loss when using multiple displays with varying resolutions [5]. Specifically, they found that the natural movement of the cursor between displays was disrupted, resulting in a loss of cursor visibility. The technique was shown to significantly improve performance, with a notable increase of up to 28%, by preventing the unnatural warping of the cursor when it was moved between displays."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Patrick et al. introduced the Mouse Ether technique, which was designed to address the issue of cursor loss when using multiple displays with varying resolutions [5]. Specifically, they found that when moving the cursor between displays, users often experienced unnatural movement, leading to cursor loss. The results of their study demonstrated that the technique significantly improved performance by up to 28%, by effectively preventing this unnatural warping when the cursor was moved between displays."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Patrick et al. introduced the Mouse Ether technique, which was designed to address the issue of cursor loss when using multiple displays with varying resolutions [5]. Specifically, they found that when moving the cursor between displays, users often experienced unnatural movement, leading to cursor loss. The results of their study demonstrated that the technique significantly improved performance by up to 28%, by effectively preventing this unnatural warping when the cursor was moved between displays."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Patrick et al. introduced the Mouse Ether technique, which aimed to resolve the problem of cursor loss when using multiple displays with varying resolutions [5]. The authors observed that when moving the cursor between displays, users frequently encountered unnatural movement, resulting in cursor loss. Their study's findings revealed that the technique substantially improved performance by up to 28%, by effectively preventing the unnatural warping of the cursor when it was moved between displays."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Patrick et al. introduced the Mouse Ether technique, which was designed to address the issue of cursor loss when using multiple displays with varying resolutions [5]. Specifically, they found that the natural movement of the cursor between displays was disrupted, resulting in a loss of cursor visibility. The technique was shown to significantly improve performance, with a notable increase of up to 28%, by preventing the unnatural warping of the cursor when it was moved between displays."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Patrick et al. introduced the Mouse Ether technique, which was designed to address the issue of cursor loss when using multiple displays with varying resolutions [5]. Specifically, they found that when moving the cursor between displays, users often experienced unnatural movement, leading to cursor loss. The results of their study demonstrated that the technique significantly improved performance by up to 28%, by effectively preventing this unnatural warping when the cursor was moved between displays."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "instruction": "Improve the writing of this paragraph", "revised_paragraph": "Revised paragraph: Patrick et al. (as cited in [5]) discovered that when utilizing multiple displays with varying resolutions, users frequently experience cursor loss due to the unnatural movement of the cursor between displays. In response, the researchers proposed the Mouse Ether technique, which significantly improved performance by up to 28% by mitigating the issue of unnatural warping when the cursor is moved between displays.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.03", "instruction": "Modify the logical flow of ideas improve the readability of the paragraph.", "revised_paragraph": "Revised paragraph: Patrick et al.'s Mouse Ether technique was developed in response to the issue of cursor loss when using multiple displays with different resolutions, which causes unnatural cursor movement between displays [5]. The technique's effectiveness was demonstrated through significant performance improvements, with results showing a notable 28% increase in performance due to the prevention of unnatural warping when moving the cursor between displays.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The encoder network begins with two multi-layer perceptrons (MLPs) that generate embeddings for individual amino acids and pairs of amino acids. The first MLP encodes the type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e_i (i = 1 to n). The second MLP encodes the distance and relative position between two amino acids, resulting in a pair embedding vector z_ij (i, j = 1 to n). A self-attention-based network invariant to rotation and translation (Jumper et al., 2021) is then applied to transform the single embeddings {e_i} and pair embeddings {z_ij} into hidden representations {h_i}. The hidden representation h_i aims to capture both the information of the i-th amino acid itself and its structural environment, serving as an encoding of the condition {a_j, p_j, O_j, \u02dc\u03c7_j} for the probability density with respect to \u03c7_i."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The encoder network begins with two multi-layer perceptrons (MLPs) that generate embeddings for individual amino acids and pairs of amino acids. The first MLP encodes the type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e_i (i = 1 to n). The second MLP encodes the distance and relative position between two amino acids, resulting in a pair embedding vector z_ij (i, j = 1 to n). A self-attention-based network invariant to rotation and translation (Jumper et al., 2021) is then applied to transform the single embeddings {e_i} and pair embeddings {z_ij} into hidden representations {h_i}. The hidden representation h_i aims to capture both the information of the i-th amino acid itself and its structural environment, serving as an encoding of the condition {a_j, p_j, O_j, \u02dc\u03c7_j} for the probability density with respect to \u03c7_i."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The encoder network begins with two multi-layer perceptrons (MLPs) that generate embeddings for individual amino acids and pairs of amino acids. The first MLP encodes the type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e_i (i = 1 to n). The second MLP encodes the distance and relative position between two amino acids, resulting in a pair embedding vector z_ij (i, j = 1 to n). A self-attention-based network invariant to rotation and translation (Jumper et al., 2021) is then applied to transform the single embeddings {e_i} and pair embeddings {z_ij} into hidden representations {h_i}. The hidden representation h_i aims to capture both the information of the i-th amino acid itself and its structural environment, serving as an encoding of the condition {a_j, p_j, O_j, \u02dc\u03c7_j} for the probability density with respect to \u03c7_i."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The encoder network begins with two multi-layer perceptrons (MLPs) that generate embeddings for individual amino acids and pairs of amino acids. The first MLP encodes the type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e_i (i = 1 to n). The second MLP encodes the distance and relative position between two amino acids, resulting in a pair embedding vector z_ij (i, j = 1 to n). A self-attention-based network invariant to rotation and translation (Jumper et al., 2021) is then applied to transform the single embeddings {e_i} and pair embeddings {z_ij} into hidden representations {h_i}. The hidden representation h_i aims to capture both the information of the i-th amino acid itself and its structural environment, serving as an encoding of the condition {a_j, p_j, O_j, \u02dc\u03c7_j} for the probability density with respect to \u03c7_i."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The encoder network begins with two multi-layer perceptrons (MLPs) that generate embeddings for individual amino acids and pairs of amino acids. The first MLP encodes the type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e_i (i = 1 to n). The second MLP encodes the distance and relative position between two amino acids, resulting in a pair embedding vector z_ij (i, j = 1 to n). A self-attention-based network invariant to rotation and translation (Jumper et al., 2021) is then applied to transform the single embeddings {e_i} and pair embeddings {z_ij} into hidden representations {h_i}. The hidden representation h_i aims to capture both the information of the i-th amino acid itself and its structural environment, serving as an encoding of the condition {a_j, p_j, O_j, \u02dc\u03c7_j} for the probability density with respect to \u03c7_i."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The encoder network begins with two multi-layer perceptrons (MLPs) that generate embeddings for individual amino acids and pairs of amino acids. The first MLP encodes the type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e_i (i = 1 to n). The second MLP encodes the distance and relative position between two amino acids, resulting in a pair embedding vector z_ij (i, j = 1 to n). A self-attention-based network invariant to rotation and translation (Jumper et al., 2021) is then applied to transform the single embeddings {e_i} and pair embeddings {z_ij} into hidden representations {h_i}. The hidden representation h_i aims to capture both the information of the i-th amino acid itself and its structural environment, serving as an encoding of the condition {a_j, p_j, O_j, \u02dc\u03c7_j} for the probability density with respect to \u03c7_i."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The encoder network begins with two multi-layer perceptrons (MLPs) that generate embeddings for individual amino acids and pairs of amino acids. The first MLP encodes the type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e_i (i = 1 to n). The second MLP encodes the distance and relative position between two amino acids, resulting in a pair embedding vector z_ij (i, j = 1 to n). A self-attention-based network invariant to rotation and translation (Jumper et al., 2021) is then applied to transform the single embeddings {e_i} and pair embeddings {z_ij} into hidden representations {h_i}. The hidden representation h_i aims to capture both the information of the i-th amino acid itself and its structural environment, serving as an encoding of the condition {a_j, p_j, O_j, \u02dc\u03c7_j} for the probability density with respect to \u03c7_i."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The encoder network begins with two multi-layer perceptrons (MLPs) that generate embeddings for individual amino acids and pairs of amino acids. The first MLP encodes the type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e_i (i = 1 to n). The second MLP encodes the distance and relative position between two amino acids, resulting in a pair embedding vector z_ij (i, j = 1 to n). A self-attention-based network invariant to rotation and translation (Jumper et al., 2021) is then applied to transform the single embeddings {e_i} and pair embeddings {z_ij} into hidden representations {h_i}. The hidden representation h_i aims to capture both the information of the i-th amino acid itself and its structural environment, serving as an encoding of the condition {a_j, p_j, O_j, \u02dc\u03c7_j} for the probability density with respect to \u03c7_i."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "instruction": "Replace every apparition of \"\"amino acids\" or \"amino acids in the protein complex\" by \"residues\"", "revised_paragraph": "Revised paragraph: The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single residue and each pair of residues respectively. The MLP for single residue encodes the residue type, backbone dihedral angles, and local atom coordinates of each residue into a vector e i (i = 1... n). The other MLP for residue pairs mainly encodes the distance and relative position between two residues and we denote a pair embedding vector as z ij (i, j = 1... n). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings {e i} and pair embeddings {z ij} into hidden representations {h i}. The hidden representation h i is aimed at capturing the information of both the i-th residue itself and its structural environments. It serves as an encoding of the condition {a j, p j, O j, \u02dc \u03c7 j} nj=1 for the probability density w.r.t. \u03c7 i.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "instruction": "Replace all mentions of amino acid by 'residue'. Reorder sentences in a more logical order when needed.", "revised_paragraph": "Revised paragraph: The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single residue and each pair of residues respectively. The MLP for single residues encodes the residue type, backbone dihedral angles, and local atom coordinates of each residue into a vector e_i (i = 1...n). The other MLP for residue pairs mainly encodes the distance and relative position between two residues and we denote a pair embedding vector as z_ij (i, j = 1...n). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings {e_i} and pair embeddings {z_ij} into hidden representations {h_i}. The hidden representation h_i is aimed at capturing the information of both the i-th residue itself and its structural environments, serving as an encoding of the condition {a_j, p_j, O_j, \u02dc\u03c7_j}^nj=1 for the probability density w.r.t. \u03c7_i.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Further improvement in calibration is expected by selecting \u03b3 independently for each training sample, as demonstrated by Sample-Dependent Focal Loss (FLSD-53) in [19]. However, this approach relies on heuristics and lacks generalizability, as shown in this paper. To address this limitation, we propose AdaFocal, a calibration-aware adaptive focal loss that leverages the calibration properties of focal and inverse-focal loss. AdaFocal adaptively adjusts \u03b3t for different groups of samples based on two factors: the previous step's \u03b3t and the model's under/over-confidence. We evaluate AdaFocal on various image recognition and NLP tasks, covering diverse network architectures, to confirm its effectiveness in improving calibration while maintaining similar accuracy levels. Moreover, models trained with AdaFocal exhibit a significant boost in out-of-distribution detection capability."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Further improvement is anticipated by selecting \u03b3 independently for each training sample, as demonstrated by the Sample-Dependent Focal Loss (FLSD-53) proposed in [19]. However, this approach relies on heuristics and, as shown in this paper, does not generalize well. In contrast, we propose AdaFocal, a calibration-aware adaptive focal loss that leverages the calibration properties of focal (and inverse-focal loss) to adaptively modify \u03b3t for different groups of samples based on the model's previous \u03b3t and its under/over-confidence. We evaluate AdaFocal on various image recognition tasks and one NLP task, encompassing a range of network architectures, to confirm the improvement in calibration while maintaining similar levels of accuracy. Moreover, models trained with AdaFocal exhibit a significant boost in out-of-distribution detection capability."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Further improvement in calibration is expected by selecting \u03b3 independently for each training sample, as demonstrated by Sample-Dependent Focal Loss (FLSD-53) in [19]. However, this approach relies on heuristics and lacks generalizability, as shown in this paper. To address this limitation, we propose AdaFocal, a calibration-aware adaptive focal loss that leverages the calibration properties of focal and inverse-focal loss. AdaFocal adaptively adjusts \u03b3t for different groups of samples based on two factors: the previous step's \u03b3t and the model's under/over-confidence. We evaluate AdaFocal on various image recognition and NLP tasks, covering diverse network architectures, to confirm its effectiveness in improving calibration while maintaining similar accuracy levels. Moreover, models trained with AdaFocal exhibit a significant boost in out-of-distribution detection capability."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Further improvement is anticipated by selecting \u03b3 independently for each training sample, as demonstrated by the Sample-Dependent Focal Loss (FLSD-53) proposed in [19]. However, this approach relies on heuristics and, as shown in this paper, does not generalize well. In contrast, we propose AdaFocal, a calibration-aware adaptive focal loss that leverages the calibration properties of focal (and inverse-focal loss) to adaptively modify \u03b3t for different groups of samples based on the model's previous \u03b3t and its under/over-confidence. We evaluate AdaFocal on various image recognition tasks and one NLP task, encompassing a range of network architectures, to confirm the improvement in calibration while maintaining similar levels of accuracy. Moreover, models trained with AdaFocal exhibit a significant boost in out-of-distribution detection capability."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Further improvement in calibration is expected by selecting \u03b3 independently for each training sample, as demonstrated by Sample-Dependent Focal Loss (FLSD-53) in [19]. However, this approach relies on heuristics and lacks generalizability, as shown in this paper. To address this limitation, we propose AdaFocal, a calibration-aware adaptive focal loss that leverages the calibration properties of focal and inverse-focal loss. AdaFocal adaptively adjusts \u03b3t for different groups of samples based on two factors: the previous step's \u03b3t and the model's under/over-confidence. We evaluate AdaFocal on various image recognition and NLP tasks, covering diverse network architectures, to confirm its effectiveness in improving calibration while maintaining similar accuracy levels. Moreover, models trained with AdaFocal exhibit a significant boost in out-of-distribution detection capability."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Further improvements in calibration are anticipated by selecting \u03b3 independently for each training sample, as exemplified by Sample-Dependent Focal Loss (FLSD-53) in [19]. However, this approach relies on heuristics and lacks generalizability, as demonstrated in this study. To address this limitation, we propose AdaFocal, a calibration-aware adaptive focal loss that leverages the calibration properties of focal and inverse-focal loss. AdaFocal adaptively adjusts \u03b3t for different groups of samples based on two factors: the previous step's \u03b3t and the model's under- or over-confidence. We evaluate AdaFocal on various image recognition and NLP tasks, encompassing diverse network architectures, to confirm its effectiveness in improving calibration while maintaining similar accuracy levels. Moreover, models trained with AdaFocal exhibit a significant boost in out-of-distribution detection capability."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Further improvement in calibration is expected by selecting \u03b3 independently for each training sample, as demonstrated by Sample-Dependent Focal Loss (FLSD-53) in [19]. However, this approach relies on heuristics and lacks generalizability, as shown in this paper. To address this limitation, we propose AdaFocal, a calibration-aware adaptive focal loss that leverages the calibration properties of focal and inverse-focal loss. AdaFocal adaptively adjusts \u03b3t for different groups of samples based on two factors: the previous step's \u03b3t and the model's under/over-confidence. We evaluate AdaFocal on various image recognition and NLP tasks, covering diverse network architectures, to confirm its effectiveness in improving calibration while maintaining similar accuracy levels. Moreover, models trained with AdaFocal exhibit a significant boost in out-of-distribution detection capability."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Further improvement is anticipated by selecting \u03b3 independently for each training sample, as demonstrated by the Sample-Dependent Focal Loss (FLSD-53) proposed in [19]. However, this approach relies on heuristics and, as shown in this paper, does not generalize well. In contrast, we propose AdaFocal, a calibration-aware adaptive focal loss that leverages the calibration properties of focal (and inverse-focal loss) to adaptively modify \u03b3t for different groups of samples based on the model's previous \u03b3t and its under/over-confidence. We evaluate AdaFocal on various image recognition tasks and one NLP task, encompassing a range of network architectures, to confirm the improvement in calibration while maintaining similar levels of accuracy. Moreover, models trained with AdaFocal exhibit a significant boost in out-of-distribution detection capability."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "instruction": "Make the ideas in these paragraph more modular and easier to understand.", "revised_paragraph": "Revised paragraph: \n\nTo further improve the calibration of focal loss, we propose a novel approach called AdaFocal, which adapts the focal loss parameter \u03b3 to different groups of samples based on their calibration properties. Unlike Sample-Dependent Focal Loss (FLSD-53) [19], which relies on heuristics and lacks generalizability, AdaFocal utilizes the calibration properties of focal and inverse-focal loss to modify \u03b3 adaptively. This is achieved by combining two factors: the \u03b3 value from the previous step and the magnitude of the model's under/over-confidence. We evaluate the effectiveness of AdaFocal on various image recognition and NLP tasks, covering a range of network architectures, and demonstrate its ability to improve calibration while maintaining similar levels of accuracy. Moreover, models trained with AdaFocal exhibit a significant boost in out-of-distribution detection capability.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.00", "instruction": "Concise this academic paragraph a bit and smooth out the writing.", "revised_paragraph": "Revised paragraph: Further improvement is expected by selecting \u03b3 independently for each training sample, as demonstrated by Sample-Dependent Focal Loss (FLSD-53) in [19]. However, this approach lacks generalizability. In this paper, we propose AdaFocal, a calibration-aware adaptive focal loss that leverages the calibration properties of focal and inverse-focal loss. AdaFocal adaptively adjusts \u03b3 for different sample groups based on previous \u03b3 values and the model's confidence magnitude. We evaluate AdaFocal on various image recognition and NLP tasks, achieving improved calibration while maintaining accuracy. Additionally, models trained with AdaFocal exhibit enhanced out-of-distribution detection capabilities.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To illustrate the benefits of our approach, consider the semi-circular domain depicted in Figure 1, adapted from [3]. In this scenario, a 2-dimensional agent must navigate to a goal located anywhere on the semi-circle. Each task corresponds to a specific goal location, and the task distribution is uniformly distributed along the 1-dimensional semi-circle."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To illustrate the benefits of our approach, consider the semi-circular domain depicted in Figure 1, adapted from [3]. In this scenario, a 2-dimensional agent must navigate to a goal located anywhere on the semi-circle. Each task corresponds to a specific goal location, and the task distribution is uniformly distributed along the 1-dimensional semi-circle."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To illustrate the benefits of our approach, consider the semi-circular domain depicted in Figure 1, adapted from [3]. In this scenario, a 2-dimensional agent must navigate to a goal located anywhere on the semi-circle. Each task corresponds to a specific goal location, and the task distribution is uniformly distributed along the 1-dimensional semi-circle."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To illustrate the benefits of our approach, consider the semi-circular domain depicted in Figure 1, adapted from [3]. In this scenario, a 2-dimensional agent must navigate to a goal located anywhere on the semi-circle. Each task corresponds to a specific goal location, and the task distribution is uniformly distributed along the 1-dimensional semi-circle."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To illustrate the benefits of our approach, consider the semi-circular domain depicted in Figure 1, adapted from [3]. In this scenario, a 2-dimensional agent must navigate to a goal located anywhere on the semi-circle. Each task corresponds to a specific goal location, and the task distribution is uniformly distributed along the 1-dimensional semi-circle."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To illustrate the benefits of our approach, consider the semi-circular domain depicted in Figure 1, adapted from [3]. In this scenario, a 2-dimensional agent must navigate to a goal located anywhere on the semi-circle. Each task corresponds to a specific goal location, and the task distribution is uniformly distributed along the 1-dimensional semi-circle."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To illustrate the benefits of our approach, consider the semi-circular domain depicted in Figure 1, adapted from [3]. In this scenario, a 2-dimensional agent must navigate to a goal located anywhere on the semi-circle. Each task corresponds to a specific goal location, and the task distribution is uniformly distributed along the 1-dimensional semi-circle."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To illustrate the benefits of our approach, consider the semi-circular domain depicted in Figure 1, adapted from [3]. In this scenario, a 2-dimensional agent must navigate to a goal located anywhere on the semi-circle. Each task corresponds to a specific goal location, and the task distribution is uniformly distributed along the 1-dimensional semi-circle."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "instruction": "Use \"half\" instead of \"semi.\"", "revised_paragraph": "Revised paragraph: \"To visualize the advantage of our approach, consider the half-circle domain in Figure 1, adapted from [3]: a 2-dimensional agent must navigate to a goal, located somewhere on the half-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional half-circle.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nIRqrHmpIE.pL1E71anH.00", "instruction": "Replace all semi-circle by half-circle.", "revised_paragraph": "Revised paragraph: \"To visualize the advantage of our approach, consider the half-circle domain in Figure 1, adapted from [3]: a 2-dimensional agent must navigate to a goal, located somewhere on the half-circle. A task therefore corresponds to the goal location, and the task distribution is uniform on the 1-dimensional half-circle.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all designs. To represent conflicts, user-preferred indicators for medication entries involved in the conflict were used. Thin or dotted lines were employed for connectors, avoiding clutter, while line style was not used to indicate conflict nature due to potential similarity at a distance."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Conflicts were readily apparent across all designs. Users prefer to indicate medication entries involved in conflicts using visual indicators. To avoid clutter, connectors for conflicting pairs should utilize thin or dotted lines rather than thick solid lines. While lines effectively connect conflicting entries, they are less effective in conveying the nature of the conflict. Instead, line style should be used judiciously to imply an action, as different styles may appear similar at a distance and fail to communicate the intended message.\""}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all the designs, with a clear user-preferred approach to representation. This involves using indicators to denote the position of medication entries involved in conflicts, while connectors for conflicting pairs should use thin or dotted lines to avoid visual clutter. Although lines are effective in connecting conflicting entries, using line style to indicate the nature of the conflict is less effective, as different line styles may appear similar at a distance and fail to convey the intended message. Instead, line style should be carefully employed to imply an action, ensuring a clear and unambiguous visual representation of conflicts."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all designs. To represent conflicts, user-preferred indicators for medication entries involved in the conflict were used. Thin or dotted lines were employed for connectors, avoiding clutter, while line style was not used to indicate conflict nature due to potential similarity at a distance."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all the designs, with a clear user-preferred approach to representation. This involves using indicators to denote the position of medication entries involved in conflicts, while connectors for conflicting pairs should use thin or dotted lines to avoid visual clutter. Although lines are effective in connecting conflicting entries, using line style to indicate the nature of the conflict is less effective, as different line styles may appear similar at a distance and fail to convey the intended message. Instead, line style should be carefully employed to imply an action, ensuring a clear and unambiguous visual representation of conflicts."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all designs. To represent conflicts, user-preferred indicators for medication entries involved in the conflict were used. Thin or dotted lines were employed for connectors, avoiding clutter, while line style was not used to indicate conflict nature due to potential similarity at a distance."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all designs. To represent conflicts, user-preferred indicators for medication entries involved in the conflict were used. Thin or dotted lines were employed for connectors, avoiding clutter, while line style was not used to indicate conflict nature due to potential similarity at a distance."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Conflicts were readily apparent across all designs. Users prefer to indicate medication entries involved in conflicts using visual indicators. To avoid clutter, connectors for conflicting pairs should utilize thin or dotted lines rather than thick solid lines. While lines effectively connect conflicting entries, they are less effective in conveying the nature of the conflict. Instead, line style should be used judiciously to imply an action, as different styles may appear similar at a distance and fail to communicate the intended message.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all designs. To represent conflicts, user-preferred indicators for medication entries involved in the conflict were used. Thin or dotted lines were employed for connectors, avoiding clutter, while line style was not used to indicate conflict nature due to potential similarity at a distance."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Conflict overlays were readily apparent on all designs. To visualize conflicts, we utilized user-preferred indicators for medication entries involved in the conflict. Thin or dotted lines were employed for connectors to minimize clutter, and line style was not used to indicate the nature of the conflict due to the potential for similarity at a distance, which could lead to confusion."}, {"depth": 3, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To facilitate the visualization of conflicts, we employed user-preferred indicators for medication entries involved in the conflict. Specifically, we utilized thin or dotted lines for connectors to minimize clutter and avoid visual noise. Although we considered using line style to indicate the nature of the conflict, we ultimately decided against it to avoid potential confusion that could arise from similar line styles at a distance."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all designs. To represent conflicts, user-preferred indicators for medication entries involved in the conflict were used. Thin or dotted lines were employed for connectors, avoiding clutter, while line style was not used to indicate conflict nature due to potential similarity at a distance."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all the designs, with a clear user-preferred approach to representation. This involves using indicators to denote the position of medication entries involved in conflicts, while connectors for conflicting pairs should use thin or dotted lines to avoid visual clutter. Although lines are effective in connecting conflicting entries, using line style to indicate the nature of the conflict is less effective, as different line styles may appear similar at a distance and fail to convey the intended message. Instead, line style should be carefully employed to imply an action, ensuring a clear and unambiguous visual representation of conflicts."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all designs, with a clear user-preferred approach to representation. Indicators denote medication entry positions, while thin or dotted lines connect conflicting pairs to avoid visual clutter."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all designs. To represent conflicts, user-preferred indicators for medication entries involved in the conflict were used. Thin or dotted lines were employed for connectors, avoiding clutter, while line style was not used to indicate conflict nature due to potential similarity at a distance."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Conflict overlays were readily apparent on all designs. To visualize conflicts, we utilized user-preferred indicators for medication entries involved in the conflict. Thin or dotted lines were employed for connectors to minimize clutter, and line style was not used to indicate the nature of the conflict due to the potential for similarity at a distance, which could lead to confusion."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "instruction": "Rewrite this paragraph to be considerably more concise.", "revised_paragraph": "Revised paragraph: Conflict overlays were easily recognizable on all designs. To represent conflicts, user-preferred indicators were used for medication entries involved, with thin or dotted lines connecting conflicting pairs to avoid clutter. While lines effectively linked entries, line style was not used to indicate conflict, as it may be unclear at a distance.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.19", "instruction": "I want to trim my paragraph so that the readers can read more easily.", "revised_paragraph": "Revised paragraph: Conflict overlays were easily identifiable on all designs. To represent user-preferred conflicts, indicators were used to highlight medication entries involved in the conflict. Thin or dotted lines were employed for connectors to avoid clutter, while lines effectively connected conflicting entries. However, using line style to indicate conflict nature was found to be ineffective, as different styles may appear similar at a distance and fail to communicate the intended message.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nPrevious research on proactive motion capture has primarily focused on single-camera systems (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In contrast, numerous studies have investigated the control of multi-camera teams, often employing optimization techniques with various system designs, such as marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. Notably, all these methods address static occlusion sources or clean landscapes. Moreover, they share a commonality in using hand-crafted optimization objectives and fixed-form camera formations, which limits their adaptability to dynamic scenes with uncertainties. Recently, reinforcement learning-based methods have garnered attention due to their potential for dynamic formation adjustments. These works have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020) or Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. Among these, AirCapRL (Tallamraju et al., 2020) shares similarities with our work; however, it is restricted to coordinating between two cameras in clean landscapes without occlusion. In contrast, our study explores collaboration between multiple cameras and resolves the credit assignment issue using novel CTCR incentives. Furthermore, we consider a more challenging scenario with multiple distracting humans as dynamic occlusions, requiring dedicated algorithms to handle."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nPrevious research on proactive motion capture has primarily focused on single-camera systems (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In contrast, numerous studies have investigated the control of multi-camera teams, often employing optimization techniques with various system designs, such as marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. Notably, all these methods address static occlusion sources or clean landscapes. Moreover, they share a commonality in using hand-crafted optimization objectives and fixed-form camera formations, which limits their adaptability to dynamic scenes with uncertainties. Recently, reinforcement learning-based methods have garnered attention due to their potential for dynamic formation adjustments. These works have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020) or Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. Among these, AirCapRL (Tallamraju et al., 2020) shares similarities with our work; however, it is restricted to coordinating between two cameras in clean landscapes without occlusion. In contrast, our study explores collaboration between multiple cameras and resolves the credit assignment issue using novel CTCR incentives. Furthermore, we consider a more challenging scenario with multiple distracting humans as dynamic occlusions, requiring dedicated algorithms to handle."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nPrevious research on proactive motion capture has primarily focused on single-camera systems (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In contrast, numerous studies have investigated the control of multi-camera teams, often employing optimization techniques with various system designs, such as marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. Notably, all these methods address static occlusion sources or clean landscapes. Moreover, they share a commonality in using hand-crafted optimization objectives and fixed-form camera formations, which limits their adaptability to dynamic scenes with uncertainties. Recently, reinforcement learning-based methods have garnered attention due to their potential for dynamic formation adjustments. These works have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020) or Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. Among these, AirCapRL (Tallamraju et al., 2020) shares similarities with our work; however, it is restricted to coordinating between two cameras in clean landscapes without occlusion. In contrast, our study explores collaboration between multiple cameras and resolves the credit assignment issue using novel CTCR incentives. Furthermore, we consider a more challenging scenario with multiple distracting humans as dynamic occlusions, requiring dedicated algorithms to handle."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nPrevious research on proactive motion capture has primarily focused on single-camera systems (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In contrast, numerous studies have investigated the control of multi-camera teams, often employing optimization techniques with various system designs, such as marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. Notably, all these methods address static occlusion sources or clean landscapes. Moreover, they share a commonality in using hand-crafted optimization objectives and fixed-form camera formations, which limits their adaptability to dynamic scenes with uncertainties. Recently, reinforcement learning-based methods have garnered attention due to their potential for dynamic formation adjustments. These works have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020) or Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. Among these, AirCapRL (Tallamraju et al., 2020) shares similarities with our work; however, it is restricted to coordinating between two cameras in clean landscapes without occlusion. In contrast, our study explores collaboration between multiple cameras and resolves the credit assignment issue using novel CTCR incentives. Furthermore, we consider a more challenging scenario with multiple distracting humans as dynamic occlusions, requiring dedicated algorithms to handle."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nPrevious research on proactive motion capture has primarily focused on single-camera systems (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In contrast, numerous studies have investigated the control of multi-camera teams, often employing optimization techniques with various system designs, such as marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. Notably, all these methods address static occlusion sources or clean landscapes. Moreover, they share a commonality in using hand-crafted optimization objectives and fixed-form camera formations, which limits their adaptability to dynamic scenes with uncertainties. Recently, reinforcement learning-based methods have garnered attention due to their potential for dynamic formation adjustments. These works have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020) or Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. Among these, AirCapRL (Tallamraju et al., 2020) shares similarities with our work; however, it is restricted to coordinating between two cameras in clean landscapes without occlusion. In contrast, our study explores collaboration between multiple cameras and resolves the credit assignment issue using novel CTCR incentives. Furthermore, we consider a more challenging scenario with multiple distracting humans as dynamic occlusions, requiring dedicated algorithms to handle."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nPrevious research on proactive motion capture has primarily focused on single-camera systems (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In contrast, numerous studies have investigated the control of multi-camera teams, often employing optimization techniques with various system designs, such as marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. Notably, all these methods address static occlusion sources or clean landscapes. Moreover, they share a commonality in using hand-crafted optimization objectives and fixed-form camera formations, which limits their adaptability to dynamic scenes with uncertainties. Recently, reinforcement learning-based methods have garnered attention due to their potential for dynamic formation adjustments. These works have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020) or Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. Among these, AirCapRL (Tallamraju et al., 2020) shares similarities with our work; however, it is restricted to coordinating between two cameras in clean landscapes without occlusion. In contrast, our study explores collaboration between multiple cameras and resolves the credit assignment issue using novel CTCR incentives. Furthermore, we consider a more challenging scenario with multiple distracting humans as dynamic occlusions, requiring dedicated algorithms to handle."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nPrevious research on proactive motion capture has primarily focused on single-camera systems (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In contrast, numerous studies have investigated the control of multi-camera teams, often employing optimization techniques with various system designs, such as marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. Notably, all these methods address static occlusion sources or clean landscapes. Moreover, they share a commonality in using hand-crafted optimization objectives and fixed-form camera formations, which limits their adaptability to dynamic scenes with uncertainties. Recently, reinforcement learning-based methods have garnered attention due to their potential for dynamic formation adjustments. These works have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020) or Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. Among these, AirCapRL (Tallamraju et al., 2020) shares similarities with our work; however, it is restricted to coordinating between two cameras in clean landscapes without occlusion. In contrast, our study explores collaboration between multiple cameras and resolves the credit assignment issue using novel CTCR incentives. Furthermore, we consider a more challenging scenario with multiple distracting humans as dynamic occlusions, requiring dedicated algorithms to handle."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nPrevious research on proactive motion capture has primarily focused on single-camera systems (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In contrast, numerous studies have investigated the control of multi-camera teams, often employing optimization techniques with various system designs, such as marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. Notably, all these methods address static occlusion sources or clean landscapes. Moreover, they share a commonality in using hand-crafted optimization objectives and fixed-form camera formations, which limits their adaptability to dynamic scenes with uncertainties. Recently, reinforcement learning-based methods have garnered attention due to their potential for dynamic formation adjustments. These works have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020) or Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. Among these, AirCapRL (Tallamraju et al., 2020) shares similarities with our work; however, it is restricted to coordinating between two cameras in clean landscapes without occlusion. In contrast, our study explores collaboration between multiple cameras and resolves the credit assignment issue using novel CTCR incentives. Furthermore, we consider a more challenging scenario with multiple distracting humans as dynamic occlusions, requiring dedicated algorithms to handle."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "instruction": "Improve the english", "revised_paragraph": "Revised paragraph: \n\nPrevious research has primarily focused on proactive motion capture using a single mobile camera (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019). In contrast, many studies have investigated the control of a multi-camera team, often employing optimization techniques with various system designs, such as marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. Notably, all these methods have addressed static occlusion sources or clean landscapes. A commonality among these works is the use of hand-crafted optimization objectives and fixed-form camera formations, which has resulted in poor adaptability to dynamic scenes with uncertainties. Recently, reinforcement learning (RL)-based methods have garnered attention due to their potential for dynamic formation adjustments. These studies have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020) or Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. One notable example is AirCapRL (Tallamraju et al., 2020), which shares similarities with our work. However, it is limited to coordinating between two cameras in clean landscapes without occlusion. In contrast, our study investigates the collaboration between multiple cameras and addresses the credit assignment issue using novel CTCR incentives. Furthermore, we consider a more challenging scenario with multiple distracting humans as dynamic occlusions, which requires dedicated algorithms to handle.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.02", "instruction": "Use accurate words and expression.", "revised_paragraph": "Revised paragraph: \n\nProactive motion capture with a single mobile camera has been sparingly explored in previous works (Zhou et al., 2018; Cheng et al., 2018; Kiciroglu et al., 2019), whereas numerous studies have focused on controlling a team of cameras. Notably, many of these studies employ optimization techniques with various system designs, including marker-based (N\u00e4geli et al., 2018), RGBD-based (Xu et al., 2017), two-stage (Saini et al., 2019; Tallamraju et al., 2019), hierarchical (Ho et al., 2021), and others. It is essential to recognize that these methods typically address static occlusion sources or clean landscapes. Furthermore, they share a commonality in relying on hand-crafted optimization objectives and fixed camera formations. This has resulted in limited adaptability to dynamic scenes characterized by uncertainty. Recently, reinforcement learning-based methods have garnered attention due to their potential for dynamic formation adjustments. These studies have focused on active 3D human pose estimation in simulated environments, such as Gazebo (Tallamraju et al., 2020), and Panoptic dome (Joo et al., 2015; Pirinen et al., 2019; G\u00e4rtner et al., 2020), for active view selection. Notably, AirCapRL (Tallamraju et al., 2020) shares similarities with our work, but is restricted to coordinating between two cameras in clean landscapes without occlusion. In contrast, we investigate the collaboration between multiple cameras and address the credit assignment issue with novel CTCR incentives. Moreover, we consider a more challenging scenario featuring multiple distracting humans as dynamic occlusions, which necessitates dedicated algorithms to handle.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In addition, we combine our proposed OPS with EM to create a composed set of unlearnable examples. Since OPS only modifies a single pixel, its application to EM-perturbed images ensures the imperceptibility of the perturbations. We evaluate the effectiveness of this composing method under various training strategies and find that it consistently maintains its effectiveness. Notably, even when using adversarial training and strong data augmentation techniques like RandAugment, the composed noise can still significantly degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, a new benchmark dataset where all images are perturbed by the composed EM-OPS noise, allowing for evaluation of the ability to learn critical information under the disturbance of non-semantic representations."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In addition, we combine our proposed OPS with EM to create a composed set of unlearnable examples. Since OPS only modifies a single pixel, its application to EM-perturbed images ensures the imperceptibility of the perturbations. We evaluate the effectiveness of this composing method under various training strategies and find that it consistently maintains its effectiveness. Notably, even when using adversarial training and strong data augmentation techniques like RandAugment, the composed noise can still significantly degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, a new benchmark dataset where all images are perturbed by the composed EM-OPS noise, allowing for evaluation of the ability to learn critical information under the disturbance of non-semantic representations."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In addition, we combine our proposed OPS with EM to create a composed set of unlearnable examples. Since OPS only modifies a single pixel, its application to EM-perturbed images ensures the imperceptibility of the perturbations. We evaluate the effectiveness of this composing method under various training strategies and find that it consistently maintains its effectiveness. Notably, even when using adversarial training and strong data augmentation techniques like RandAugment, the composed noise can still significantly degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, a new benchmark dataset where all images are perturbed by the composed EM-OPS noise, allowing for evaluation of the ability to learn critical information under the disturbance of non-semantic representations."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In addition, we combine our proposed OPS with EM to create a composed set of unlearnable examples. Since OPS only modifies a single pixel, its application to EM-perturbed images ensures the imperceptibility of the perturbations. We evaluate the effectiveness of this composing method under various training strategies and find that it consistently maintains its effectiveness. Notably, even when using adversarial training and strong data augmentation techniques like RandAugment, the composed noise can still significantly degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, a new benchmark dataset where all images are perturbed by the composed EM-OPS noise, allowing for evaluation of the ability to learn critical information under the disturbance of non-semantic representations."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In addition, we combine our proposed OPS with EM to create a composed set of unlearnable examples. Since OPS only modifies a single pixel, its application to EM-perturbed images ensures the imperceptibility of the perturbations. We evaluate the effectiveness of this composing method under various training strategies and find that it consistently maintains its effectiveness. Notably, even when using adversarial training and strong data augmentation techniques like RandAugment, the composed noise can still significantly degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, a new benchmark dataset where all images are perturbed by the composed EM-OPS noise, allowing for evaluation of the ability to learn critical information under the disturbance of non-semantic representations."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In addition, we combine our proposed OPS with EM to create a composed set of unlearnable examples. Since OPS only modifies a single pixel, its application to EM-perturbed images ensures the imperceptibility of the perturbations. We evaluate the effectiveness of this composing method under various training strategies and find that it consistently maintains its effectiveness. Notably, even when using adversarial training and strong data augmentation techniques like RandAugment, the composed noise can still significantly degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, a new benchmark dataset where all images are perturbed by the composed EM-OPS noise, allowing for evaluation of the ability to learn critical information under the disturbance of non-semantic representations."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In addition, we combine our proposed OPS with EM to create a composed set of unlearnable examples. Since OPS only modifies a single pixel, its application to EM-perturbed images ensures the imperceptibility of the perturbations. We evaluate the effectiveness of this composing method under various training strategies and find that it consistently maintains its effectiveness. Notably, even when using adversarial training and strong data augmentation techniques like RandAugment, the composed noise can still significantly degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, a new benchmark dataset where all images are perturbed by the composed EM-OPS noise, allowing for evaluation of the ability to learn critical information under the disturbance of non-semantic representations."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In addition, we combine our proposed OPS with EM to create a composed set of unlearnable examples. Since OPS only modifies a single pixel, its application to EM-perturbed images ensures the imperceptibility of the perturbations. We evaluate the effectiveness of this composing method under various training strategies and find that it consistently maintains its effectiveness. Notably, even when using adversarial training and strong data augmentation techniques like RandAugment, the composed noise can still significantly degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, a new benchmark dataset where all images are perturbed by the composed EM-OPS noise, allowing for evaluation of the ability to learn critical information under the disturbance of non-semantic representations."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "instruction": "Change the idea of \"composition\" to \"ensemble\" if this paragraph. Fix any spelling mistake.", "revised_paragraph": "Revised paragraph: \"In addition, we combine EM and our proposed OPS together to craft a kind of ensemble unlearnable examples. Since OPS only modified a single pixel, after being applied to EM perturbed images, the imperceptibility can still be guaranteed. We evaluate the effectiveness of this ensemble method under different training strategies and find that it can always remain effective. Even if we use adversarial training and strong data augmentation like RandAugment, it is still able to degrade test accuracy to a relatively low level. Based on this property, we introduce CIFAR-10-S, where all the images are perturbed by the EM-OPS-composed noises. It can serve as a new benchmark to evaluate the ability to learn critical information under the disturbance of composed non-semantic representations.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "YCmehaMzt.kHwUIOFr_.00", "instruction": "Rewrite the first sentence. Improve English in this paragraph.", "revised_paragraph": "Revised paragraph: In this study, we integrate our proposed OPS with EM to generate a novel type of unlearnable examples, thereby enhancing the imperceptibility of perturbed images. By combining OPS with EM, we ensure that the perturbations are minimally detectable, even when applied to images already perturbed by EM. We investigate the effectiveness of this composition method under various training strategies and demonstrate that it consistently maintains its ability to degrade test accuracy to a relatively low level, regardless of the training approach employed. Notably, our method remains effective even when using adversarial training and strong data augmentation techniques, such as RandAugment. Building on this property, we introduce CIFAR-10-S, a new benchmark dataset comprising images perturbed by the composed noises generated through our EM-OPS approach. This dataset serves as a valuable tool for evaluating the ability of models to learn critical information in the presence of composed non-semantic representations.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: During training, the uni-modal branch primarily concentrates on the associated modality, generating feature representations specific to that modality. The fusion modules then combine cross-modal context information from these uni-modal branches and feed it back to them, allowing for the incorporation of inter-modal relationships. Both the output of the first branch (\u02c6y0) and the output of the second branch (\u02c6y1) rely on information from both modalities, enabling the model to capture complex relationships between the two. Ultimately, this process yields two distinct functions, f0 and f1, corresponding to the two uni-modal branches."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: During training, the unimodal branch primarily concentrates on its associated modality. The fusion modules extract cross-modal context information from the unimodal branches and feed it back to them. Both outputs, y0 and y1, rely on information from both modalities. Ultimately, we derive two functions, f0 and f1, corresponding to the two unimodal branches."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: During training, the uni-modal branch primarily concentrates on the associated modality, generating feature representations specific to that modality. The fusion modules then combine cross-modal context information from these uni-modal branches and feed it back to them, allowing for the incorporation of inter-modal relationships. Both the output of the first branch (\u02c6y0) and the output of the second branch (\u02c6y1) rely on information from both modalities, enabling the model to capture complex relationships between the two. Ultimately, this process yields two distinct functions, f0 and f1, corresponding to the two uni-modal branches."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: During training, the unimodal branch primarily concentrates on its associated modality. The fusion modules extract cross-modal context information from the unimodal branches and feed it back to them. Both outputs, y0 and y1, rely on information from both modalities. Ultimately, we derive two functions, f0 and f1, corresponding to the two unimodal branches."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: During training, the uni-modal branch primarily concentrates on the associated modality, generating feature representations specific to that modality. The fusion modules then combine cross-modal context information from these uni-modal branches and feed it back to them, allowing for the incorporation of inter-modal relationships. Both the output of the first branch (\u02c6y0) and the output of the second branch (\u02c6y1) rely on information from both modalities, enabling the model to capture complex relationships between the two. Ultimately, this process yields two distinct functions, f0 and f1, corresponding to the two uni-modal branches."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: During training, each uni-modal branch focuses primarily on its respective modality, generating feature representations unique to that modality. The fusion modules subsequently combine cross-modal context information from these uni-modal branches and feed it back to them, allowing for the incorporation of inter-modal relationships. The outputs of both branches, \u02c6y0 and \u02c6y1, rely on information from both modalities, thereby enabling the model to capture complex relationships between the two modalities. Ultimately, this process yields two distinct functions, f0 and f1, corresponding to the two uni-modal branches."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: During training, the uni-modal branch primarily concentrates on the associated modality, generating feature representations specific to that modality. The fusion modules then combine cross-modal context information from these uni-modal branches and feed it back to them, allowing for the incorporation of inter-modal relationships. Both the output of the first branch (\u02c6y0) and the output of the second branch (\u02c6y1) rely on information from both modalities, enabling the model to capture complex relationships between the two. Ultimately, this process yields two distinct functions, f0 and f1, corresponding to the two uni-modal branches."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: During training, the unimodal branch primarily concentrates on its associated modality. The fusion modules extract cross-modal context information from the unimodal branches and feed it back to them. Both outputs, y0 and y1, rely on information from both modalities. Ultimately, we derive two functions, f0 and f1, corresponding to the two unimodal branches."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "instruction": "Make the sentence understandable.", "revised_paragraph": "Revised paragraph: During training, the uni-modal branch primarily concentrates on its associated modality. The fusion modules extract cross-modal context information from the uni-modal branches and feed it back to them. Both output predictions, \u02c6 y 0 and \u02c6 y 1, rely on information from both modalities. This process ultimately yields two distinct functions, f 0 and f 1, which correspond to the two uni-modal branches.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.05", "instruction": "Improve the wording of this paragraph.", "revised_paragraph": "Revised paragraph: During training, the uni-modal branch primarily concentrates on its respective modality. The fusion modules extract and integrate cross-modal contextual information from the uni-modal branches, which is then fed back to them. Both outputs, \u02c6 y 0 and \u02c6 y 1, rely on information from both modalities. This process ultimately yields two distinct functions, f 0 and f 1, corresponding to each of the two uni-modal branches.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We hypothesize that trigger features are sparsely encoded in a few channels, whereas clean image features require encoding across many channels for effective classification. This difference in encoding patterns suggests that trigger features may behave differently in certain situations, which is the foundation of our main technical contribution.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We hypothesize that trigger features are sparsely encoded in a few channels, whereas clean image features require encoding across many channels for effective classification. This difference in encoding patterns suggests that trigger features may behave differently in certain situations, which is the foundation of our main technical contribution.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We hypothesize that trigger features are sparsely encoded in a few channels, whereas clean image features require encoding across many channels for effective classification. This difference in encoding patterns suggests that trigger features may behave differently in certain situations, which is the foundation of our main technical contribution.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We hypothesize that trigger features are sparsely encoded in a few channels, whereas clean image features require encoding across many channels for effective classification. This difference in encoding patterns suggests that trigger features may behave differently in certain situations, which is the foundation of our main technical contribution.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We hypothesize that trigger features are sparsely encoded in a few channels, whereas clean image features require encoding across many channels for effective classification. This difference in encoding patterns suggests that trigger features may behave differently in certain situations, which is the foundation of our main technical contribution.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We hypothesize that trigger features are sparsely encoded in a few channels, whereas clean image features require encoding across many channels for effective classification. This difference in encoding patterns suggests that trigger features may behave differently in certain situations, which is the foundation of our main technical contribution.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We hypothesize that trigger features are sparsely encoded in a few channels, whereas clean image features require encoding across many channels for effective classification. This difference in encoding patterns suggests that trigger features may behave differently in certain situations, which is the foundation of our main technical contribution.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We hypothesize that trigger features are sparsely encoded in a few channels, whereas clean image features require encoding across many channels for effective classification. This difference in encoding patterns suggests that trigger features may behave differently in certain situations, which is the foundation of our main technical contribution.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "instruction": "Make this paragraph more concise.", "revised_paragraph": "Revised paragraph: We hypothesize that trigger features are sparse, encoded in a few channels, whereas clean image features require multiple channels for effective classification. This distinction from normal data features, which are presumably evenly distributed across channels, suggests different behaviors in certain situations, leading to our main technical contribution.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "QSAQjBO0aj.srl-4uM-pl.00", "instruction": "Make this paragraph a bit shorter.", "revised_paragraph": "Revised paragraph: \"We hypothesize that trigger features are sparsely encoded in a few channels, whereas clean image features require encoding across many channels for effective classification. This difference in encoding is a key aspect of our research, suggesting that trigger features may behave differently than normal data features in certain situations, leading to our main technical contribution.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"We propose propagating labels from an annotated set to an unlabeled set through nearest neighbor search in the feature space, leveraging the assumption that semantic clusters emerge during training with sparse supervision, reinforced by the pixel-to-segment relationships mentioned earlier. This approach reinforces the learning of semantic clusters by propagating labels in the feature space.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"We propose propagating labels from an annotated set to an unlabeled set through nearest neighbor search in the feature space, leveraging the assumption that semantic clusters emerge during training with sparse supervision, reinforced by the pixel-to-segment relationships mentioned earlier. This approach reinforces the learning of semantic clusters by propagating labels in the feature space.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"We propose propagating labels from an annotated set to an unlabeled set through nearest neighbor search in the feature space, leveraging the assumption that semantic clusters emerge during training with sparse supervision, reinforced by the pixel-to-segment relationships mentioned earlier. This approach reinforces the learning of semantic clusters by propagating labels in the feature space.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"We propose propagating labels from an annotated set to an unlabeled set through nearest neighbor search in the feature space, leveraging the assumption that semantic clusters emerge during training with sparse supervision, reinforced by the pixel-to-segment relationships mentioned earlier. This approach reinforces the learning of semantic clusters by propagating labels in the feature space.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"We propose propagating labels from an annotated set to an unlabeled set through nearest neighbor search in the feature space, leveraging the assumption that semantic clusters emerge during training with sparse supervision, reinforced by the pixel-to-segment relationships mentioned earlier. This approach reinforces the learning of semantic clusters by propagating labels in the feature space.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"We propose propagating labels from an annotated set to an unlabeled set through nearest neighbor search in the feature space, leveraging the assumption that semantic clusters emerge during training with sparse supervision, reinforced by the pixel-to-segment relationships mentioned earlier. This approach reinforces the learning of semantic clusters by propagating labels in the feature space.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"We propose propagating labels from an annotated set to an unlabeled set through nearest neighbor search in the feature space, leveraging the assumption that semantic clusters emerge during training with sparse supervision, reinforced by the pixel-to-segment relationships mentioned earlier. This approach reinforces the learning of semantic clusters by propagating labels in the feature space.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"We propose propagating labels from an annotated set to an unlabeled set through nearest neighbor search in the feature space, leveraging the assumption that semantic clusters emerge during training with sparse supervision, reinforced by the pixel-to-segment relationships mentioned earlier. This approach reinforces the learning of semantic clusters by propagating labels in the feature space.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "instruction": "Rephrase this paragraph to make its goal and explanations much more clear.", "revised_paragraph": "Revised paragraph: \"Our approach aims to leverage the concept of feature affinity to propagate labels from a labeled dataset to an unlabeled dataset. Specifically, we employ a nearest neighbor search in the feature space to transfer labels from annotated samples to unannotated ones. This strategy is based on the assumption that semantic clusters emerge during training, facilitated by the sparse supervision and reinforced by the pixel-to-segment relationships established in the feature space. By propagating labels in this manner, we reinforce the learning of semantic clusters and improve the overall performance of our model.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.11", "instruction": "Rewrite this paragraph to bring the argument through the idea that the goal is to learn a pixel-wise feature for semantic segmentation.", "revised_paragraph": "Revised paragraph: The goal of our approach is to learn a pixel-wise feature that enables effective semantic segmentation by leveraging the pixel-to-segment relationships. To achieve this, we propose propagating labels from an annotated set to an unlabeled set through nearest neighbor search in the feature space, thereby reinforcing the emergence of semantic clusters during training with sparse supervision. By doing so, we aim to learn a feature that captures the semantic meaning of each pixel, ultimately improving the accuracy of semantic segmentation.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Bi-LSTM architecture processes the raw action representations of candidate actions in the following manner. First, the representations are fed into a 2-layer Multi-Layer Perceptron (MLP) with ReLU activation. The output of the MLP is then passed through a 2-layer bidirectional Long Short-Term Memory (LSTM) network, as proposed by Huang et al. (2015). Finally, the output of the LSTM is processed by another 2-layer MLP to generate the action-summary, which is subsequently used in the utility network."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The bi-directional long short-term memory (LSTM) network is employed to process the raw action representations. Specifically, the candidate actions are first fed into a two-layer multilayer perceptron (MLP) with rectified linear unit (ReLU) activation, followed by a two-layer bidirectional LSTM (Huang et al., 2015) and finally another two-layer MLP to generate the action summary, which is then utilized in the subsequent utility network.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Bi-LSTM architecture processes the raw action representations of candidate actions in the following manner. First, the representations are fed into a 2-layer Multi-Layer Perceptron (MLP) with ReLU activation. The output of the MLP is then passed through a 2-layer bidirectional Long Short-Term Memory (LSTM) network, as proposed by Huang et al. (2015). Finally, the output of the LSTM is processed by another 2-layer MLP to generate the action-summary, which is subsequently used in the utility network."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The bi-directional long short-term memory (LSTM) network is employed to process the raw action representations. Specifically, the candidate actions are first fed into a two-layer multilayer perceptron (MLP) with rectified linear unit (ReLU) activation, followed by a two-layer bidirectional LSTM (Huang et al., 2015) and finally another two-layer MLP to generate the action summary, which is then utilized in the subsequent utility network.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Bi-LSTM architecture processes the raw action representations of candidate actions in the following manner. First, the representations are fed into a 2-layer Multi-Layer Perceptron (MLP) with ReLU activation. The output of the MLP is then passed through a 2-layer bidirectional Long Short-Term Memory (LSTM) network, as proposed by Huang et al. (2015). Finally, the output of the LSTM is processed by another 2-layer MLP to generate the action-summary, which is subsequently used in the utility network."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The Bi-LSTM architecture processes the raw action representations of candidate actions as follows. Initially, these representations are fed into a 2-layer Multi-Layer Perceptron (MLP) with ReLU activation function. The output of the MLP is then passed through a 2-layer bidirectional Long Short-Term Memory (LSTM) network, as previously proposed by Huang et al. (2015). Finally, the output of the LSTM is processed by another 2-layer MLP to generate the action summary, which is subsequently utilized in the utility network."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Bi-LSTM architecture processes the raw action representations of candidate actions in the following manner. First, the representations are fed into a 2-layer Multi-Layer Perceptron (MLP) with ReLU activation. The output of the MLP is then passed through a 2-layer bidirectional Long Short-Term Memory (LSTM) network, as proposed by Huang et al. (2015). Finally, the output of the LSTM is processed by another 2-layer MLP to generate the action-summary, which is subsequently used in the utility network."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The bi-directional long short-term memory (LSTM) network is employed to process the raw action representations. Specifically, the candidate actions are first fed into a two-layer multilayer perceptron (MLP) with rectified linear unit (ReLU) activation, followed by a two-layer bidirectional LSTM (Huang et al., 2015) and finally another two-layer MLP to generate the action summary, which is then utilized in the subsequent utility network.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "instruction": "Update the last sentence and split it into two sentences to make it easier to understand", "revised_paragraph": "Revised paragraph: The raw action representations of candidate actions are passed on to a 2-layer MLP followed by ReLU, which serves as an initial processing step. The output of the MLP is then processed by a 2-layer bidirectional LSTM (Huang et al., 2015) to create a sequence of hidden states that capture the temporal dependencies between actions. Finally, the output of the LSTM is passed through another 2-layer MLP to generate the action-summary, which is used as input to the subsequent utility network.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "instruction": "Split this paragraph into smaller and more focused points.", "revised_paragraph": "Revised paragraph: \n\nThe Bi-LSTM network is employed to process the raw action representations. Specifically, the representations are first fed into a 2-layer MLP with ReLU activation. The output of the MLP is then processed by a 2-layer bidirectional LSTM (Huang et al., 2015) to capture the sequential dependencies in the action sequences. Finally, the output of the LSTM is fed into another 2-layer MLP to generate the action-summary, which serves as input to the subsequent utility network.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As shown in \u00a73.2, the disparity in conditional utilization rates indicates that the model is exploiting the connection between the target and only one input modality, neglecting cross-modal information. Although conditional utilization rate can be calculated after training, it is challenging to utilize it in real-time during the training process. To address this limitation, we introduce a proxy metric, termed conditional learning speed, which quantifies the relative learning speed between modalities during training."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As shown in \u00a73.2, the disparity in conditional utilization rates indicates that the model is exploiting the connection between the target and only one input modality, neglecting cross-modal information. Although conditional utilization rate can be calculated after training, it is challenging to utilize it in real-time during the training process. To address this limitation, we introduce a proxy metric, termed conditional learning speed, which quantifies the relative learning speed between modalities during training."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As shown in \u00a73.2, the disparity in conditional utilization rates indicates that the model is exploiting the connection between the target and only one input modality, neglecting cross-modal information. Although conditional utilization rate can be calculated after training, it is challenging to utilize it in real-time during the training process. To address this limitation, we introduce a proxy metric, termed conditional learning speed, which quantifies the relative learning speed between modalities during training."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As shown in \u00a73.2, the disparity in conditional utilization rates indicates that the model is exploiting the connection between the target and only one input modality, neglecting cross-modal information. Although conditional utilization rate can be calculated after training, it is challenging to utilize it in real-time during the training process. To address this limitation, we introduce a proxy metric, termed conditional learning speed, which quantifies the relative learning speed between modalities during training."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As shown in \u00a73.2, the disparity in conditional utilization rates indicates that the model is exploiting the connection between the target and only one input modality, neglecting cross-modal information. Although conditional utilization rate can be calculated after training, it is challenging to utilize it in real-time during the training process. To address this limitation, we introduce a proxy metric, termed conditional learning speed, which quantifies the relative learning speed between modalities during training."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As shown in \u00a73.2, the disparity in conditional utilization rates indicates that the model is exploiting the connection between the target and only one input modality, neglecting cross-modal information. Although conditional utilization rate can be calculated after training, it is challenging to utilize it in real-time during the training process. To address this limitation, we introduce a proxy metric, termed conditional learning speed, which quantifies the relative learning speed between modalities during training."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As shown in \u00a73.2, the disparity in conditional utilization rates indicates that the model is exploiting the connection between the target and only one input modality, neglecting cross-modal information. Although conditional utilization rate can be calculated after training, it is challenging to utilize it in real-time during the training process. To address this limitation, we introduce a proxy metric, termed conditional learning speed, which quantifies the relative learning speed between modalities during training."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: As shown in \u00a73.2, the disparity in conditional utilization rates indicates that the model is exploiting the connection between the target and only one input modality, neglecting cross-modal information. Although conditional utilization rate can be calculated after training, it is challenging to utilize it in real-time during the training process. To address this limitation, we introduce a proxy metric, termed conditional learning speed, which quantifies the relative learning speed between modalities during training."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "instruction": "Make expression concrete, add conjunction.", "revised_paragraph": "Revised paragraph: As demonstrated in \u00a73.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring cross-modal information. Moreover, conditional utilization rates can only be measured once training is complete, making it challenging to utilize them in real-time during the training process. Therefore, we derive a proxy metric, called conditional learning speed, which captures the relative learning speed between modalities during training.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "instruction": "Revise the wording of the middle sentence in this paragraph.", "revised_paragraph": "Revised paragraph: \"As demonstrated in \u00a73.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. Although conditional utilization rate can be measured after training, it is not feasible to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Despite the advancements in natural language processing (NLP) (Cherry et al., 2019), sentence embeddings often contain irrelevant information that can hinder the performance of language models on specific tasks. Fine-tuning these models with a large number of parameters on a small amount of target task data can be challenging, as it may lead to over-fitting. Moreover, collecting sufficient annotated data for large neural models to excel can be a costly and impractical solution for many real-world applications."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Despite the advancements in natural language processing (NLP) (Cherry et al., 2019), sentence embeddings often contain irrelevant information that can hinder the performance of language models on specific tasks. Fine-tuning these models with a large number of parameters on a small amount of target task data can be challenging, as it may lead to over-fitting. Moreover, collecting sufficient annotated data for large neural models to excel can be a costly and impractical solution for many real-world applications."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Despite the advancements in natural language processing (NLP) (Cherry et al., 2019), sentence embeddings often contain irrelevant information that can hinder the performance of language models on specific tasks. Fine-tuning these models with a large number of parameters on a small amount of target task data can be challenging, as it may lead to over-fitting. Moreover, collecting sufficient annotated data for large neural models to excel can be a costly and impractical solution for many real-world applications."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Despite the advancements in natural language processing (NLP) (Cherry et al., 2019), sentence embeddings often contain irrelevant information that can hinder the performance of language models on specific tasks. Fine-tuning these models with a large number of parameters on a small amount of target task data can be challenging, as it may lead to over-fitting. Moreover, collecting sufficient annotated data for large neural models to excel can be a costly and impractical solution for many real-world applications."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Despite the advancements in natural language processing (NLP) (Cherry et al., 2019), sentence embeddings often contain irrelevant information that can hinder the performance of language models on specific tasks. Fine-tuning these models with a large number of parameters on a small amount of target task data can be challenging, as it may lead to over-fitting. Moreover, collecting sufficient annotated data for large neural models to excel can be a costly and impractical solution for many real-world applications."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Despite the advancements in natural language processing (NLP) (Cherry et al., 2019), sentence embeddings often contain irrelevant information that can hinder the performance of language models on specific tasks. Fine-tuning these models with a large number of parameters on a small amount of target task data can be challenging, as it may lead to over-fitting. Moreover, collecting sufficient annotated data for large neural models to excel can be a costly and impractical solution for many real-world applications."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Despite the advancements in natural language processing (NLP) (Cherry et al., 2019), sentence embeddings often contain irrelevant information that can hinder the performance of language models on specific tasks. Fine-tuning these models with a large number of parameters on a small amount of target task data can be challenging, as it may lead to over-fitting. Moreover, collecting sufficient annotated data for large neural models to excel can be a costly and impractical solution for many real-world applications."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Despite the advancements in natural language processing (NLP) (Cherry et al., 2019), sentence embeddings often contain irrelevant information that can hinder the performance of language models on specific tasks. Fine-tuning these models with a large number of parameters on a small amount of target task data can be challenging, as it may lead to over-fitting. Moreover, collecting sufficient annotated data for large neural models to excel can be a costly and impractical solution for many real-world applications."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "instruction": "Improve the readablity of the text. Use more concise and straight-forward ideas.", "revised_paragraph": "Revised paragraph: \"Sentence embeddings generated by NLP (Cherry et al., 2019) often contain irrelevant information, making it challenging to identify relevant features when fine-tuning language models with many parameters on limited target task data. This can lead to over-fitting. In real-world applications, collecting sufficient annotated data to overcome this issue can be impractical and costly.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "usz0l2mwO.5ie3V0GP-.01", "instruction": "Rewrite this paragraph to better fit the academic writing style.", "revised_paragraph": "Revised paragraph: According to Cherry et al. (2019), sentence embeddings often contain a significant amount of irrelevant information that can hinder the performance of language models on target tasks. This is particularly challenging when fine-tuning models with a large number of parameters on limited target task data, as it can lead to over-fitting. Moreover, in many real-world applications, collecting sufficient annotated data to overcome this limitation can be a costly and time-consuming endeavor, making it essential to explore alternative solutions to optimize model performance.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"OOD detection is challenging because modern neural networks are typically trained only on in-distribution data, lacking explicit knowledge of unknowns. This results in decision boundaries that cover unknown data, as illustrated in Figure 1. Ideally, models should produce low uncertainty for in-distribution data and high uncertainty for out-of-distribution data. However, achieving this goal is difficult due to the lack of supervision signal for unknowns. This prompts the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?\""}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nOOD detection is particularly challenging due to the limitations of modern neural networks, which are typically optimized on in-distribution (ID) data only and lack explicit knowledge of unknowns during training. This can result in a decision boundary that is effective for ID tasks such as classification but undesirably covers out-of-distribution (OOD) data. Figure 1 illustrates this issue, showing a three-way softmax classifier trained on ID data consisting of three class-conditional Gaussians. The resulting classifier is overconfident for regions far from the ID data, as evident in the red shade in Figure 1(b). Directly employing such models can lead to an ill-fated decision boundary for OOD detection. Ideally, a model should learn a more compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere, as depicted in Figure 1(c). However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns. It is difficult to comprehensively anticipate unknown data in advance under a large space of OOD uncertainty, prompting the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nOOD detection is particularly challenging due to the limitations of modern neural networks, which are typically optimized on in-distribution (ID) data only and lack explicit knowledge of unknowns during training. This can result in a decision boundary that is effective for ID tasks such as classification but undesirably covers out-of-distribution (OOD) data. Figure 1 illustrates this issue, showing a three-way softmax classifier trained on ID data consisting of three class-conditional Gaussians. The resulting classifier is overconfident for regions far from the ID data, as evident in the red shade in Figure 1(b). Directly employing such models can lead to an ill-fated decision boundary for OOD detection. Ideally, a model should learn a more compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere, as depicted in Figure 1(c). However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns. It is difficult to comprehensively anticipate unknown data in advance under a large space of OOD uncertainty, prompting the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nOOD detection is particularly challenging due to the limitations of modern neural networks, which are typically optimized on in-distribution (ID) data only and lack explicit knowledge of unknowns during training. This can result in a decision boundary that is effective for ID tasks such as classification but undesirably covers out-of-distribution (OOD) data. Figure 1 illustrates this issue, showing a three-way softmax classifier trained on ID data consisting of three class-conditional Gaussians. The resulting classifier is overconfident for regions far from the ID data, as evident in the red shade in Figure 1(b). Directly employing such models can lead to an ill-fated decision boundary for OOD detection. Ideally, a model should learn a more compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere, as depicted in Figure 1(c). However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns. It is difficult to comprehensively anticipate unknown data in advance under a large space of OOD uncertainty, prompting the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nOOD detection is particularly challenging due to the limitations of modern neural networks, which are typically optimized on in-distribution (ID) data only and lack explicit knowledge of unknowns during training. This can result in a decision boundary that is effective for ID tasks such as classification but undesirably covers out-of-distribution (OOD) data. Figure 1 illustrates this issue, showing a three-way softmax classifier trained on ID data consisting of three class-conditional Gaussians. The resulting classifier is overconfident for regions far from the ID data, as evident in the red shade in Figure 1(b). Directly employing such models can lead to an ill-fated decision boundary for OOD detection. Ideally, a model should learn a more compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere, as depicted in Figure 1(c). However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns. It is difficult to comprehensively anticipate unknown data in advance under a large space of OOD uncertainty, prompting the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?"}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"OOD detection is challenging because modern neural networks are typically trained only on in-distribution data, lacking explicit knowledge of unknowns. This results in decision boundaries that cover unknown data, as illustrated in Figure 1. Ideally, models should produce low uncertainty for in-distribution data and high uncertainty for out-of-distribution data. However, achieving this goal is difficult due to the lack of supervision signal for unknowns. This prompts the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"OOD detection is challenging because modern neural networks are typically trained only on in-distribution data, lacking explicit knowledge of unknowns. This results in decision boundaries that cover unknown data, as illustrated in Figure 1. Ideally, models should produce low uncertainty for in-distribution data and high uncertainty for out-of-distribution data. However, achieving this goal is difficult due to the lack of supervision signal for unknowns. This prompts the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?\""}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"The detection of out-of-distribution (OOD) data is a challenging task due to the fact that modern neural networks are typically trained solely on in-distribution data, without explicit knowledge of unknowns. As a result, decision boundaries often cover unknown data, as depicted in Figure 1. Ideally, models should produce low uncertainty for in-distribution data and high uncertainty for out-of-distribution data. However, achieving this goal is difficult due to the lack of a supervision signal for unknowns. This raises the question of how to enable unknown-aware deep neural networks without requiring explicit knowledge of unknowns in advance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nOOD detection is particularly challenging due to the limitations of modern neural networks, which are typically optimized on in-distribution (ID) data only and lack explicit knowledge of unknowns during training. This can result in a decision boundary that is effective for ID tasks such as classification but undesirably covers out-of-distribution (OOD) data. Figure 1 illustrates this issue, showing a three-way softmax classifier trained on ID data consisting of three class-conditional Gaussians. The resulting classifier is overconfident for regions far from the ID data, as evident in the red shade in Figure 1(b). Directly employing such models can lead to an ill-fated decision boundary for OOD detection. Ideally, a model should learn a more compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere, as depicted in Figure 1(c). However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns. It is difficult to comprehensively anticipate unknown data in advance under a large space of OOD uncertainty, prompting the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nOOD detection is particularly challenging due to the limitations of modern neural networks, which are typically optimized on in-distribution (ID) data only and lack explicit knowledge of unknowns during training. This can result in a decision boundary that is effective for ID tasks such as classification but undesirably covers out-of-distribution (OOD) data. Figure 1 illustrates this issue, showing a three-way softmax classifier trained on ID data consisting of three class-conditional Gaussians. The resulting classifier is overconfident for regions far from the ID data, as evident in the red shade in Figure 1(b). Directly employing such models can lead to an ill-fated decision boundary for OOD detection. Ideally, a model should learn a more compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere, as depicted in Figure 1(c). However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns. It is difficult to comprehensively anticipate unknown data in advance under a large space of OOD uncertainty, prompting the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nOOD detection is particularly challenging due to the limitations of modern neural networks, which are typically optimized on in-distribution (ID) data only and lack explicit knowledge of unknowns during training. This can result in a decision boundary that is effective for ID tasks such as classification but undesirably covers out-of-distribution (OOD) data. Figure 1 illustrates this issue, showing a three-way softmax classifier trained on ID data consisting of three class-conditional Gaussians. The resulting classifier is overconfident for regions far from the ID data, as evident in the red shade in Figure 1(b). Directly employing such models can lead to an ill-fated decision boundary for OOD detection. Ideally, a model should learn a more compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere, as depicted in Figure 1(c). However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns. It is difficult to comprehensively anticipate unknown data in advance under a large space of OOD uncertainty, prompting the question: How can we enable unknown-aware deep neural networks without explicit knowledge of the unknowns in advance?"}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nOOD detection is challenging due to the limitations of modern neural networks, which are optimized on in-distribution data only and lack explicit knowledge of unknowns during training. This can result in a decision boundary that covers OOD data, leading to overconfidence for regions far from the ID data. Ideally, a model should learn a compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere. However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns, making it difficult to anticipate unknown data in advance."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "instruction": "Rewrite this paragraph to make it more concise and convincing.", "revised_paragraph": "Revised paragraph: \n\nOOD detection is challenging due to the fact that modern neural networks are typically trained on in-distribution (ID) data only, without explicit knowledge of unknowns. As a result, the decision boundary, effective for ID tasks like classification, can undesirably cover out-of-distribution (OOD) data. Figure 1 illustrates this issue, where a three-way softmax classifier is overconfident in regions far from ID data (red shade in Figure 1(b)). Ideally, a model should learn a compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere (Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns. This prompts the question: How can we enable unknown-aware deep neural networks without explicit knowledge of unknowns in advance?", "type_approach": "instruction-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.01", "instruction": "Rewrite this paragraph to make it more precise, clear and concise while fitting the academic style.", "revised_paragraph": "Revised paragraph: \n\nThe detection of out-of-distribution (OOD) data is a challenging task due to the fact that modern neural networks are typically optimized solely on in-distribution (ID) data during training, without explicit knowledge of unknowns. This results in a decision boundary that is effective for ID tasks, such as classification, but can undesirably cover OOD data. Figure 1 illustrates this issue, where a three-way softmax classifier is trained on ID data consisting of three class-conditional Gaussians. The resulting classifier exhibits overconfidence in regions distant from the ID data (Figure 1(b)). Directly employing such models can lead to poor OOD detection performance. Ideally, a model should learn a compact decision boundary with low uncertainty for ID data and high OOD uncertainty elsewhere (Figure 1(c)). However, achieving this goal is non-trivial due to the lack of supervision signal for unknowns. Anticipating unknown data in advance under a large space of OOD uncertainty is a daunting task. This prompts the question: How can we develop unknown-aware deep neural networks without explicit knowledge of unknowns in advance?", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Prescriptions are often accompanied by constraints related to drug dosage units, frequency, and indications. These constraints can arise within the same medication or between different medications. For instance, the prescription \"Take 600 mg of Ibuprofen three times a day as needed with food\" exemplifies three constraints: first, the specific dosage of 600mg must be taken at a given time; second, the maximum number of intakes per day is limited to three; and third, the medication must be taken with food. However, medications can be more complex than this. For example, consider the following prescription:\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Prescriptions are often accompanied by constraints related to drug dosage units, frequency, and indications. These constraints can arise within the same medication or between different medications. For instance, the prescription \"Take 600 mg of Ibuprofen three times a day as needed with food\" exemplifies three constraints: first, the specific dosage of 600mg must be taken at a given time; second, the maximum number of intakes per day is limited to three; and third, the medication must be taken with food. However, medications can be more complex than this. For example, consider the following prescription:\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Prescriptions are often accompanied by constraints related to drug dosage units, frequency, and indications. These constraints can arise within the same medication or between different medications. For instance, the prescription \"Take 600 mg of Ibuprofen three times a day as needed with food\" exemplifies three constraints: first, the specific dosage of 600mg must be taken at a given time; second, the maximum number of intakes per day is limited to three; and third, the medication must be taken with food. However, medications can be more complex than this. For example, consider the following prescription:\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Prescriptions are often accompanied by constraints related to drug dosage units, frequency, and indications. These constraints can arise within the same medication or between different medications. For instance, the prescription \"Take 600 mg of Ibuprofen three times a day as needed with food\" exemplifies three constraints: first, the specific dosage of 600mg must be taken at a given time; second, the maximum number of intakes per day is limited to three; and third, the medication must be taken with food. However, medications can be more complex than this. For example, consider the following prescription:\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Prescriptions are often accompanied by constraints related to drug dosage units, frequency, and indications. These constraints can arise within the same medication or between different medications. For instance, the prescription \"Take 600 mg of Ibuprofen three times a day as needed with food\" exemplifies three constraints: first, the specific dosage of 600mg must be taken at a given time; second, the maximum number of intakes per day is limited to three; and third, the medication must be taken with food. However, medications can be more complex than this. For example, consider the following prescription:\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Prescriptions are often accompanied by constraints related to drug dosage units, frequency, and indications. These constraints can arise within the same medication or between different medications. For instance, the prescription \"Take 600 mg of Ibuprofen three times a day as needed with food\" exemplifies three constraints: first, the specific dosage of 600mg must be taken at a given time; second, the maximum number of intakes per day is limited to three; and third, the medication must be taken with food. However, medications can be more complex than this. For example, consider the following prescription:\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Prescriptions are often accompanied by constraints related to drug dosage units, frequency, and indications. These constraints can arise within the same medication or between different medications. For instance, the prescription \"Take 600 mg of Ibuprofen three times a day as needed with food\" exemplifies three constraints: first, the specific dosage of 600mg must be taken at a given time; second, the maximum number of intakes per day is limited to three; and third, the medication must be taken with food. However, medications can be more complex than this. For example, consider the following prescription:\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Prescriptions are often accompanied by constraints related to drug dosage units, frequency, and indications. These constraints can arise within the same medication or between different medications. For instance, the prescription \"Take 600 mg of Ibuprofen three times a day as needed with food\" exemplifies three constraints: first, the specific dosage of 600mg must be taken at a given time; second, the maximum number of intakes per day is limited to three; and third, the medication must be taken with food. However, medications can be more complex than this. For example, consider the following prescription:\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "instruction": "Improve the English of the first sentence of this paragraph.", "revised_paragraph": "Revised paragraph: \"Pharmaceutical prescriptions are typically accompanied by constraints related to dosage units, frequency, and indications. These constraints can arise within a single medication or between different medications. For instance, a prescription such as \"Take 600 mg of Ibuprofen three times a day as needed with food\" exemplifies within-medication constraints, comprising three specific requirements: 1) a fixed dosage of 600mg, 2) a maximum of three intakes per day, and 3) co-administration with food. However, medications often exhibit greater complexity. Consider, for example, the following prescription:\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.08", "instruction": "Rephrase the two first sentences for better readability.", "revised_paragraph": "Revised paragraph: \"Medications come with a range of constraints, including specific dosage units, frequency, and indications. These constraints can be present within a single medication or between different medications. For instance, the prescription 'Take 600 mg of Ibuprofen three times a day as needed with food' exemplifies within-medication constraints, with three specific requirements: taking 600mg at a given time, limiting the number of intakes to three per day, and consuming the drug with food. However, medications often exhibit greater complexity.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segmentation. It assumes each segment has an independent normal distribution on a hypersphere and uses Spherical K-Means clustering (Banerjee et al., 2005) for segmentation and joint feature clustering. The model learns an embedding by maximizing the discrimination between segments and incorporates soft neighborhood assignment (Goldberger et al., 2005) to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segments an image. It assumes normal distributions on a hypersphere for each segment, with homogeneous representations within each. The model uses Spherical K-Means clustering to jointly learn feature clustering and segment an image. A maximum likelihood loss is formulated to maximize segment discrimination, and soft neighborhood assignment is incorporated to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segments an image. It assumes normal distributions on a hypersphere for each segment, with homogeneous representations within each. The model uses Spherical K-Means clustering to jointly learn feature clustering and segment an image. A maximum likelihood loss is formulated to maximize segment discrimination, and soft neighborhood assignment is incorporated to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segmentation. It assumes each segment has an independent normal distribution on a hypersphere and uses Spherical K-Means clustering (Banerjee et al., 2005) for segmentation and joint feature clustering. The model learns an embedding by maximizing the discrimination between segments and incorporates soft neighborhood assignment (Goldberger et al., 2005) to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segments an image. It assumes normal distributions on a hypersphere for each segment, with homogeneous representations within each. The model uses Spherical K-Means clustering to jointly learn feature clustering and segment an image. A maximum likelihood loss is formulated to maximize segment discrimination, and soft neighborhood assignment is incorporated to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segments an image. It assumes normal distributions on a hypersphere for each segment, with homogeneous representations within each. The model uses Spherical K-Means clustering to jointly learn feature clustering and segment an image. A maximum likelihood loss is formulated to maximize segment discrimination, and soft neighborhood assignment is incorporated to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segmentation. It assumes each segment has an independent normal distribution on a hypersphere and uses Spherical K-Means clustering (Banerjee et al., 2005) for segmentation and joint feature clustering. The model learns an embedding by maximizing the discrimination between segments and incorporates soft neighborhood assignment (Goldberger et al., 2005) to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates pixel-wise embeddings and over-segments images. It uses Spherical K-Means clustering (Banerjee et al., 2005) and soft neighborhood assignment (Goldberger et al., 2005) to group semantically similar segments and predict labels via K-Nearest Neighbor retrievals."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segments an image. It assumes normal distributions on a hypersphere for each segment, with homogeneous representations within each. The model uses Spherical K-Means clustering to jointly learn feature clustering and segment an image. A maximum likelihood loss is formulated to maximize segment discrimination, and soft neighborhood assignment is incorporated to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segmentation. It assumes each segment has an independent normal distribution on a hypersphere and uses Spherical K-Means clustering (Banerjee et al., 2005) for segmentation and joint feature clustering. The model learns an embedding by maximizing the discrimination between segments and incorporates soft neighborhood assignment (Goldberger et al., 2005) to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates pixel-wise embeddings and over-segments images. It uses Spherical K-Means clustering (Banerjee et al., 2005) and soft neighborhood assignment (Goldberger et al., 2005) to group semantically similar segments and predict labels via K-Nearest Neighbor retrievals."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segments an image. It assumes normal distributions on a hypersphere for each segment, with homogeneous representations within each. The model uses Spherical K-Means clustering to jointly learn feature clustering and segment an image. A maximum likelihood loss is formulated to maximize segment discrimination, and soft neighborhood assignment is incorporated to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "instruction": "Reduce the explanations in this paragraph and just give a high level explanation, to keep it concise.", "revised_paragraph": "Revised paragraph: SegSort is an end-to-end image segmentation model that generates a pixel-wise embedding and over-segments an image. It uses spherical K-Means clustering to learn discriminative features and assumes homogeneous representations within each segment. The model maximizes the discrimination between segments using a maximum likelihood loss and incorporates soft neighborhood assignment to group similar segments.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.13", "instruction": "Make the explanation of SegSort shorter.", "revised_paragraph": "Revised paragraph: SegSort (Hwang et al., 2019) is an end-to-end image segmentation model that generates pixel-wise embeddings and over-segments images. It assumes homogeneous representations within each segment and uses Spherical K-Means clustering to learn discriminative features. The model maximizes the discrimination between segments using a maximum likelihood loss and incorporates soft neighborhood assignment to group semantically similar segments. During inference, segment labels are predicted using K-Nearest Neighbor retrievals.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assess the performance impact of SDN in a more controlled environment, it was combined with a simpler VAE architecture compared to IAF-VAE. A non-hierarchical VAE is more suitable for representation learning due to its single stochastic vector and shorter training time, allowing for better control over the latent space. Specifically, the performance gains of using SDN were evaluated in terms of: (a) evidence lower bound (ELBO), which serves as a proxy for measuring the quality of approximating an image distribution; and (b) disentanglement of latent codes, as assessed by corresponding metrics, to examine the effects of the SDN decoder on the quality of learned latent representations."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the performance impact of SDN in a more controlled environment, it was paired with a non-hierarchical VAE, which is architecturally simpler than the IAF-VAE. The advantages of this simpler VAE include not only its reduced implementation complexity and shorter training time but also its suitability for representation learning, as it employs a single stochastic vector rather than a hierarchy of feature maps, thereby enabling better control over the latent space. The performance gains achieved through the use of SDN were evaluated in terms of: (a) the evidence lower bound (ELBO), which serves as a proxy for measuring the quality of an image distribution approximation; and (b) the disentanglement of latent codes based on corresponding metrics, to examine the effects of the SDN decoder on the quality of learned latent representations."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assess the performance impact of SDN in a more controlled environment, it was combined with a simpler VAE architecture compared to IAF-VAE. A non-hierarchical VAE is more suitable for representation learning due to its single stochastic vector and shorter training time, allowing for better control over the latent space. Specifically, the performance gains of using SDN were evaluated in terms of: (a) evidence lower bound (ELBO), which serves as a proxy for measuring the quality of approximating an image distribution; and (b) disentanglement of latent codes, as assessed by corresponding metrics, to examine the effects of the SDN decoder on the quality of learned latent representations."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the performance impact of SDN in a more controlled environment, it was paired with a non-hierarchical VAE, which is architecturally simpler than the IAF-VAE. The advantages of this simpler VAE include not only its reduced implementation complexity and shorter training time but also its suitability for representation learning, as it employs a single stochastic vector rather than a hierarchy of feature maps, thereby enabling better control over the latent space. The performance gains achieved through the use of SDN were evaluated in terms of: (a) the evidence lower bound (ELBO), which serves as a proxy for measuring the quality of an image distribution approximation; and (b) the disentanglement of latent codes based on corresponding metrics, to examine the effects of the SDN decoder on the quality of learned latent representations."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assess the performance impact of SDN in a more controlled environment, it was combined with a simpler VAE architecture compared to IAF-VAE. A non-hierarchical VAE is more suitable for representation learning due to its single stochastic vector and shorter training time, allowing for better control over the latent space. Specifically, the performance gains of using SDN were evaluated in terms of: (a) evidence lower bound (ELBO), which serves as a proxy for measuring the quality of approximating an image distribution; and (b) disentanglement of latent codes, as assessed by corresponding metrics, to examine the effects of the SDN decoder on the quality of learned latent representations."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To evaluate the performance impact of SDN in a more controlled setting, we combined it with a simpler VAE architecture compared to IAF-VAE. A non-hierarchical VAE is more suitable for representation learning due to its single stochastic vector and shorter training time, allowing for better control over the latent space. Specifically, we assessed the performance gains of using SDN in terms of two metrics: (a) the evidence lower bound (ELBO), which serves as a proxy for measuring the quality of approximating an image distribution; and (b) disentanglement of latent codes, as evaluated by corresponding metrics, to examine the effects of the SDN decoder on the quality of learned latent representations."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assess the performance impact of SDN in a more controlled environment, it was combined with a simpler VAE architecture compared to IAF-VAE. A non-hierarchical VAE is more suitable for representation learning due to its single stochastic vector and shorter training time, allowing for better control over the latent space. Specifically, the performance gains of using SDN were evaluated in terms of: (a) evidence lower bound (ELBO), which serves as a proxy for measuring the quality of approximating an image distribution; and (b) disentanglement of latent codes, as assessed by corresponding metrics, to examine the effects of the SDN decoder on the quality of learned latent representations."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the performance impact of SDN in a more controlled environment, it was paired with a non-hierarchical VAE, which is architecturally simpler than the IAF-VAE. The advantages of this simpler VAE include not only its reduced implementation complexity and shorter training time but also its suitability for representation learning, as it employs a single stochastic vector rather than a hierarchy of feature maps, thereby enabling better control over the latent space. The performance gains achieved through the use of SDN were evaluated in terms of: (a) the evidence lower bound (ELBO), which serves as a proxy for measuring the quality of an image distribution approximation; and (b) the disentanglement of latent codes based on corresponding metrics, to examine the effects of the SDN decoder on the quality of learned latent representations."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "instruction": "Make sentence precise.", "revised_paragraph": "Revised paragraph: To assess the performance impact of SDN in a more controlled environment, it was paired with a non-hierarchical VAE, which is simpler to implement and trains faster than IAF-VAE. This simpler architecture is better suited for representation learning, as it features a single stochastic vector rather than a hierarchy of feature maps, allowing for greater control over the latent space. The effectiveness of SDN was evaluated by examining its impact on: (a) the evidence lower bound (ELBO), a proxy for measuring the approximation of an image distribution; and (b) the disentanglement of latent codes, using corresponding metrics to assess the quality of learned representations and the effects of the SDN decoder.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "sIqSoZ9KiO.KLlOZMoJ9G.01", "instruction": "Rephrase the second sentence, mostly focusing on the second half.", "revised_paragraph": "Revised paragraph: \"To study its performance impact in a more constrained setting, SDN was paired with a non-hierarchical VAE, which offers a simpler architecture and shorter training time compared to IAF-VAE. This design choice enables better control over the latent space, as it involves a single stochastic vector rather than a hierarchy of feature maps, making it more suitable for representation learning. In particular, the gains in performance when using SDN were evaluated with respect to: (a) evidence lower bound (ELBO), as a proxy to measure how well an image distribution is approximated; (b) disentanglement of latent codes based on the corresponding metrics, to examine the effects of SDN decoder on the quality of learned latent representations.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: After the pruning process is complete, we physically remove the redundant filters from the model, resulting in a significantly smaller architecture. This is in line with common practice, where the pruned model is then fine-tuned to recover its performance, as previously suggested by Reed (1993)."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Upon completing the pruning process, we eliminate the redundant filters by physically removing them from the model, thereby yielding a compact model. Subsequently, we fine-tune the reduced model to recover its performance, consistent with the conventional approach in pruning (Reed, 1993)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: After the pruning process is complete, we physically remove the redundant filters from the model, resulting in a significantly smaller architecture. This is in line with common practice, where the pruned model is then fine-tuned to recover its performance, as previously suggested by Reed (1993)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Upon completing the pruning process, we eliminate the redundant filters by physically removing them from the model, thereby yielding a compact model. Subsequently, we fine-tune the reduced model to recover its performance, consistent with the conventional approach in pruning (Reed, 1993)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: After the pruning process is complete, we physically remove the redundant filters from the model, resulting in a significantly smaller architecture. This is in line with common practice, where the pruned model is then fine-tuned to recover its performance, as previously suggested by Reed (1993)."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: After the pruning process is finished, we physically remove the redundant filters from the model, leading to a significantly reduced architecture. This approach is consistent with conventional practice, where the pruned model is subsequently fine-tuned to recover its performance, as previously demonstrated by Reed (1993)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: After the pruning process is complete, we physically remove the redundant filters from the model, resulting in a significantly smaller architecture. This is in line with common practice, where the pruned model is then fine-tuned to recover its performance, as previously suggested by Reed (1993)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Upon completing the pruning process, we eliminate the redundant filters by physically removing them from the model, thereby yielding a compact model. Subsequently, we fine-tune the reduced model to recover its performance, consistent with the conventional approach in pruning (Reed, 1993)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "instruction": "Please rephrase my paragraph.", "revised_paragraph": "Revised paragraph: After pruning, we eliminate the redundant filters from the model, resulting in a compact architecture. This process is followed by fine-tuning the reduced model to recover its performance, a technique commonly employed in pruning (Reed, 1993).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.12", "instruction": "Revise this academic paragraph for readability.", "revised_paragraph": "Revised paragraph: After the pruning process is complete, we eliminate the redundant filters, literally removing them from the model, which leads to a smaller model. We then fine-tune the reduced model to recover its performance, following the conventional approach in pruning (Reed, 1993).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our approach handles rejected data points by employing a de-biased classifier to determine whether they should be added to the Pseudo-label dataset. If accepted, we apply the Pseudo-label mechanism, retraining on optimistic labels, to finalize the decision."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: When a data point is accepted by the biased classifier, it is incorporated into the dataset with its corresponding true label. Conversely, if a data point is rejected by the biased classifier, we employ our de-biased classifier to determine whether it should be included in the Pseudo-label dataset from PLOT. Subsequently, we apply the Pseudo-label mechanism from PLOT, which involves retraining on optimistically labeled data, to make a final decision on acceptance."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: When a data point is accepted by the biased classifier, it is incorporated into the dataset with its corresponding true label. Conversely, if a data point is rejected by the biased classifier, we employ our de-biased classifier to determine whether it should be included in the Pseudo-label dataset from PLOT. Subsequently, we apply the Pseudo-label mechanism from PLOT, which involves retraining on optimistically labeled data, to make a final decision on acceptance."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: When a data point is accepted by the biased classifier, it is incorporated into the dataset with its corresponding true label. Conversely, if a data point is rejected by the biased classifier, we employ our de-biased classifier to determine whether it should be included in the Pseudo-label dataset from PLOT. Subsequently, we apply the Pseudo-label mechanism from PLOT, which involves retraining on optimistically labeled data, to make a final decision on acceptance."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our approach handles rejected data points by employing a de-biased classifier to determine whether they should be added to the Pseudo-label dataset. If accepted, we apply the Pseudo-label mechanism, retraining on optimistic labels, to finalize the decision."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: When a data point is accepted by the biased classifier, it is incorporated into the dataset with its corresponding true label. Conversely, if a data point is rejected by the biased classifier, we employ our de-biased classifier to determine whether it should be included in the Pseudo-label dataset from PLOT. Subsequently, we apply the Pseudo-label mechanism from PLOT, which involves retraining on optimistically labeled data, to make a final decision on acceptance."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our approach handles rejected data points by employing a de-biased classifier to determine whether they should be added to the Pseudo-label dataset. If accepted, we apply the Pseudo-label mechanism, retraining on optimistic labels, to finalize the decision."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our approach addresses rejected data points by utilizing a debiased classifier to determine their suitability for inclusion in the Pseudo-label dataset. If deemed suitable, we employ the Pseudo-label mechanism, retraining the model on optimistically labelled data to finalize the classification decision."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: When a data point is accepted by the biased classifier, it is incorporated into the dataset with its corresponding true label. Conversely, if a data point is rejected by the biased classifier, we employ our de-biased classifier to determine whether it should be included in the Pseudo-label dataset from PLOT. Subsequently, we apply the Pseudo-label mechanism from PLOT, which involves retraining on optimistically labeled data, to make a final decision on acceptance."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: When a data point is accepted by the biased classifier, it is incorporated into the dataset with its corresponding true label. Conversely, if a data point is rejected by the biased classifier, we employ our de-biased classifier to determine whether it should be included in the Pseudo-label dataset from PLOT. Subsequently, we apply the Pseudo-label mechanism from PLOT, which involves retraining on optimistically labeled data, to make a final decision on acceptance."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our approach handles rejected data points by employing a de-biased classifier to determine whether they should be added to the Pseudo-label dataset. If accepted, we apply the Pseudo-label mechanism, retraining on optimistic labels, to finalize the decision."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our approach addresses rejected data points by utilizing a debiased classifier to determine their suitability for inclusion in the Pseudo-label dataset. If deemed suitable, we employ the Pseudo-label mechanism, retraining the model on optimistically labelled data to finalize the classification decision."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "instruction": "Rewrite the bullet points, making them more independent and preferring active over passive formulations", "revised_paragraph": "Revised paragraph: The biased classifier accepts data points and adds them to the dataset with their true labels. Conversely, when a data point is rejected by the biased classifier, our de-biased classifier determines whether it should be included in the Pseudo-label dataset from PLOT. We then apply the Pseudo-label mechanism from PLOT, retraining on optimistic labels, to make a final decision on acceptance.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "UlHNcByJV.W1RxpkrWx8.01", "instruction": "Shorten the last sentence. Make this paragraph more direct.", "revised_paragraph": "Revised paragraph: \"When a data point is accepted by the biased classifier, it is added to the dataset with its true label. If rejected, our de-biased classifier determines whether to include it in the Pseudo-label dataset. We then apply the Pseudo-label mechanism, retraining on optimistic labels, to finalize acceptance.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The SoftHebb layer features a simple normalization of activations and an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of a single 'hard' winner neuron. This allows us to prove formally that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler divergence from the input distribution through Bayesian inference. We experimentally validate its performance in recognizing MNIST handwritten digits and Fashion-MNIST fashion products, showing that it is more accurate than a hard-WTA model, minimizes the cross-entropy loss without labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, robustness to noisy data, and adversarial attacks.\""}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Importantly, the SoftHebb layer normalizes activations and includes an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of selecting a single \"hard\" winner neuron. This allows us to formally prove that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler (KL) divergence from the input distribution through Bayesian inference. We validate these theoretical results with small-scale experiments on MNIST and Fashion-MNIST, showing that SoftHebb is more accurate than a hard-WTA model, minimizes a loss function without access to labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, and robustness to noisy data and adversarial attacks."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The SoftHebb layer features a simple normalization of activations and an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of a single 'hard' winner neuron. This allows us to prove formally that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler divergence from the input distribution through Bayesian inference. We experimentally validate its performance in recognizing MNIST handwritten digits and Fashion-MNIST fashion products, showing that it is more accurate than a hard-WTA model, minimizes the cross-entropy loss without labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, robustness to noisy data, and adversarial attacks.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The SoftHebb layer features a simple normalization of activations and an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of a single 'hard' winner neuron. This allows us to prove formally that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler divergence from the input distribution through Bayesian inference. We experimentally validate its performance in recognizing MNIST handwritten digits and Fashion-MNIST fashion products, showing that it is more accurate than a hard-WTA model, minimizes the cross-entropy loss without labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, robustness to noisy data, and adversarial attacks.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Importantly, the SoftHebb layer normalizes activations and includes an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of selecting a single \"hard\" winner neuron. This allows us to formally prove that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler (KL) divergence from the input distribution through Bayesian inference. We validate these theoretical results with small-scale experiments on MNIST and Fashion-MNIST, showing that SoftHebb is more accurate than a hard-WTA model, minimizes a loss function without access to labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, and robustness to noisy data and adversarial attacks."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The SoftHebb layer features a simple normalization of activations and an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of a single 'hard' winner neuron. This allows us to prove formally that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler divergence from the input distribution through Bayesian inference. We experimentally validate its performance in recognizing MNIST handwritten digits and Fashion-MNIST fashion products, showing that it is more accurate than a hard-WTA model, minimizes the cross-entropy loss without labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, robustness to noisy data, and adversarial attacks.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The SoftHebb layer features a simple normalization of activations and an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of a single 'hard' winner neuron. This allows us to prove formally that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler divergence from the input distribution through Bayesian inference. We experimentally validate its performance in recognizing MNIST handwritten digits and Fashion-MNIST fashion products, showing that it is more accurate than a hard-WTA model, minimizes the cross-entropy loss without labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, robustness to noisy data, and adversarial attacks.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The SoftHebb layer features a soft winner-takes-all mechanism, producing a probabilistic output. We formally prove that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler divergence from the input distribution through Bayesian inference. Experimental results show that SoftHebb outperforms a hard-WTA model in accuracy and learning speed, and is robust to noisy data and adversarial attacks.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The SoftHebb layer features a simple normalization of activations and an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of a single 'hard' winner neuron. This allows us to prove formally that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler divergence from the input distribution through Bayesian inference. We experimentally validate its performance in recognizing MNIST handwritten digits and Fashion-MNIST fashion products, showing that it is more accurate than a hard-WTA model, minimizes the cross-entropy loss without labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, robustness to noisy data, and adversarial attacks.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The SoftHebb layer features a simple normalization of activations and an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of a single 'hard' winner neuron. This allows us to prove formally that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler divergence from the input distribution through Bayesian inference. We experimentally validate its performance in recognizing MNIST handwritten digits and Fashion-MNIST fashion products, showing that it is more accurate than a hard-WTA model, minimizes the cross-entropy loss without labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, robustness to noisy data, and adversarial attacks.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Importantly, the SoftHebb layer normalizes activations and includes an optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of selecting a single \"hard\" winner neuron. This allows us to formally prove that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler (KL) divergence from the input distribution through Bayesian inference. We validate these theoretical results with small-scale experiments on MNIST and Fashion-MNIST, showing that SoftHebb is more accurate than a hard-WTA model, minimizes a loss function without access to labels, and outperforms a supervised two-layer perceptron in learning speed, accuracy, and robustness to noisy data and adversarial attacks."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: The SoftHebb layer normalizes activations and includes a temperature-scaling mechanism, producing a soft winner-takes-all (WTA) model. This allows us to prove that SoftHebb is a generative mixture model that minimizes the KL divergence from the input distribution through Bayesian inference. Experimental results on MNIST and Fashion-MNIST demonstrate SoftHebb's advantages over hard-WTA and other models in accuracy, learning speed, and robustness to noisy data and adversarial attacks."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "instruction": "Make this paragraph shorter by removing details.", "revised_paragraph": "Revised paragraph: \"Our SoftHebb layer incorporates a simple normalization of activations and optional temperature-scaling mechanism, producing a soft winner-takes-all (WTA) instead of a single hard winner neuron. This enables us to prove formally that SoftHebb is a generative mixture model that minimizes its Kullback-Leibler divergence from the input distribution through Bayesian inference. We experimentally validate its accuracy and robustness on MNIST and Fashion-MNIST tasks, showing it outperforms a hard-WTA model and a supervised two-layer perceptron in terms of learning speed, accuracy, and robustness to noisy data and adversarial attacks.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.01", "instruction": "Summarize the middle of the paragraph to make it shorter and more concise. Remove unnecessary details.", "revised_paragraph": "Revised paragraph: \"The SoftHebb layer, equipped with normalization and temperature-scaling mechanisms, produces a soft winner-takes-all (WTA) output. This allows us to formally prove that it is a generative mixture model that minimizes the Kullback-Leibler divergence from the input distribution through Bayesian inference. We experimentally validate its performance on MNIST and Fashion-MNIST tasks, showing that it outperforms a hard-WTA model and a supervised two-layer perceptron in terms of learning speed, accuracy, robustness to noisy data, and resistance to projected gradient descent (PGD) attacks, without explicit defense. Additionally, the SoftHebb model exhibits inherent properties of deflecting adversarial attacks and generating object interpolations.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Jung et al. (2021) introduced a max-logit approach for detecting outliers in semantic segmentation. In contrast, Zhao et al. and Grcic et al. (2021) trained generative models to synthesize outliers in pixel space, which is not applicable to object detection. Their regularization terms, based on entropy maximization, differ from those used in Visual Object Segmentation (VOS)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Jung et al. (2021) introduced a max-logit approach for detecting outliers in semantic segmentation. In contrast, Zhao et al. and Grcic et al. (2021) trained generative models to synthesize outliers in pixel space, which is not applicable to object detection. Their regularization terms, based on entropy maximization, differ from those used in Visual Object Segmentation (VOS)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Jung et al. (2021) introduced a max-logit approach for detecting outliers in semantic segmentation. In contrast, Zhao et al. and Grcic et al. (2021) trained generative models to synthesize outliers in pixel space, which is not applicable to object detection. Their regularization terms, based on entropy maximization, differ from those used in Visual Object Segmentation (VOS)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Jung et al. (2021) introduced a max-logit approach for detecting outliers in semantic segmentation. In contrast, Zhao et al. and Grcic et al. (2021) trained generative models to synthesize outliers in pixel space, which is not applicable to object detection. Their regularization terms, based on entropy maximization, differ from those used in Visual Object Segmentation (VOS)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Jung et al. (2021) introduced a max-logit approach for detecting outliers in semantic segmentation. In contrast, Zhao et al. and Grcic et al. (2021) trained generative models to synthesize outliers in pixel space, which is not applicable to object detection. Their regularization terms, based on entropy maximization, differ from those used in Visual Object Segmentation (VOS)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Jung et al. (2021) introduced a max-logit approach for detecting outliers in semantic segmentation. In contrast, Zhao et al. and Grcic et al. (2021) trained generative models to synthesize outliers in pixel space, which is not applicable to object detection. Their regularization terms, based on entropy maximization, differ from those used in Visual Object Segmentation (VOS)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Jung et al. (2021) introduced a max-logit approach for detecting outliers in semantic segmentation. In contrast, Zhao et al. and Grcic et al. (2021) trained generative models to synthesize outliers in pixel space, which is not applicable to object detection. Their regularization terms, based on entropy maximization, differ from those used in Visual Object Segmentation (VOS)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Jung et al. (2021) introduced a max-logit approach for detecting outliers in semantic segmentation. In contrast, Zhao et al. and Grcic et al. (2021) trained generative models to synthesize outliers in pixel space, which is not applicable to object detection. Their regularization terms, based on entropy maximization, differ from those used in Visual Object Segmentation (VOS)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "instruction": "Shorten this paragraph.", "revised_paragraph": "Revised paragraph: Jung et al. (2021) proposed a standardized max-logit approach for detecting outliers in semantic segmentation, a post-hoc method. In contrast, Zhao et al. and Grcic et al. (2021) trained a generative model to synthesize outliers in pixel space, which is not applicable to object detection where both known and unknown objects coexist.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.03", "instruction": "Make the first sentence a lot shorter.", "revised_paragraph": "Revised paragraph: Jung et al. (2021) introduced a max-logit approach for detecting outliers in semantic segmentation. However, this post-hoc method is not suitable for object detection, where scenes contain both known and unknown objects. In contrast, Zhao et al. and Grcic et al. (2021) trained generative models to synthesize outliers, but this approach is limited by its reliance on entropy maximization, unlike VOS.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The pointing operation to the edge target leverages the cursor's natural stopping point at the screen's edge to complete the task without requiring precise control. However, the associated pushing-edge behavior increases the distance traveled by the mouse, leading to longer movement times. To quantify the efficiency of cursor movements, Yamanaka [25] introduced the Path Efficiency (PE) metric, which is calculated using Equation 7.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The pointing operation to an edge target leverages the cursor's tendency to stop at the screen's edge, allowing for completion without precise control. However, the pushing-edge behavior, where the cursor is pushed to the screen's edge, increases the distance traveled by the mouse, thereby prolonging movement time. Yamanaka [25] introduced the concept of Path Efficiency (PE) to quantify the efficiency of cursor movements, as described in Equation 7.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The pointing operation to an edge target leverages the cursor's tendency to stop at the screen's edge, allowing for completion without precise control. However, the pushing-edge behavior, where the cursor is pushed to the screen's edge, increases the distance traveled by the mouse, thereby prolonging movement time. Yamanaka [25] introduced the concept of Path Efficiency (PE) to quantify the efficiency of cursor movements, as described in Equation 7.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The pointing operation to an edge target leverages the cursor's tendency to stop at the screen's edge, allowing for completion without precise control. However, the pushing-edge behavior, where the cursor is pushed to the screen's edge, increases the distance traveled by the mouse, thereby prolonging movement time. Yamanaka [25] introduced the concept of Path Efficiency (PE) to quantify the efficiency of cursor movements, as described in Equation 7.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The pointing operation to the edge target leverages the cursor's natural stopping point at the screen's edge to complete the task without requiring precise control. However, the associated pushing-edge behavior increases the distance traveled by the mouse, leading to longer movement times. To quantify the efficiency of cursor movements, Yamanaka [25] introduced the Path Efficiency (PE) metric, which is calculated using Equation 7.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The pointing operation to an edge target leverages the cursor's tendency to stop at the screen's edge, allowing for completion without precise control. However, the pushing-edge behavior, where the cursor is pushed to the screen's edge, increases the distance traveled by the mouse, thereby prolonging movement time. Yamanaka [25] introduced the concept of Path Efficiency (PE) to quantify the efficiency of cursor movements, as described in Equation 7.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The pointing operation to the edge target leverages the cursor's natural stopping point at the screen's edge to complete the task without requiring precise control. However, the associated pushing-edge behavior increases the distance traveled by the mouse, leading to longer movement times. To quantify the efficiency of cursor movements, Yamanaka [25] introduced the Path Efficiency (PE) metric, which is calculated using Equation 7.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The pointing operation to the edge target leverages the cursor's natural stopping point at the screen's edge, eliminating the need for precise control. While this approach is effective, it is accompanied by an increased distance traveled by the mouse, resulting in longer movement times. To measure the efficiency of cursor movements, Yamanaka [25] proposed the Path Efficiency (PE) metric, which is calculated using Equation 7.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The pointing operation to an edge target leverages the cursor's tendency to stop at the screen's edge, allowing for completion without precise control. However, the pushing-edge behavior, where the cursor is pushed to the screen's edge, increases the distance traveled by the mouse, thereby prolonging movement time. Yamanaka [25] introduced the concept of Path Efficiency (PE) to quantify the efficiency of cursor movements, as described in Equation 7.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The pointing operation to an edge target leverages the cursor's tendency to stop at the screen's edge, allowing for completion without precise control. However, the pushing-edge behavior, where the cursor is pushed to the screen's edge, increases the distance traveled by the mouse, thereby prolonging movement time. Yamanaka [25] introduced the concept of Path Efficiency (PE) to quantify the efficiency of cursor movements, as described in Equation 7.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The pointing operation to the edge target leverages the cursor's natural stopping point at the screen's edge to complete the task without requiring precise control. However, the associated pushing-edge behavior increases the distance traveled by the mouse, leading to longer movement times. To quantify the efficiency of cursor movements, Yamanaka [25] introduced the Path Efficiency (PE) metric, which is calculated using Equation 7.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The pointing operation to the edge target leverages the cursor's natural stopping point at the screen's edge, eliminating the need for precise control. While this approach is effective, it is accompanied by an increased distance traveled by the mouse, resulting in longer movement times. To measure the efficiency of cursor movements, Yamanaka [25] proposed the Path Efficiency (PE) metric, which is calculated using Equation 7.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "instruction": "Change some words in this paragraph for the better ", "revised_paragraph": "Revised paragraph: \"The pointing operation to the edge target exploits the cursor's tendency to stop at the edge of the screen, allowing for successful completion without precise control. Nevertheless, the pushing-edge behavior, which involves moving the cursor to the edge of the screen, results in increased distance traveled and subsequently longer movement times. Yamanaka [25] introduced the concept of Path Efficiency (PE), a metric that quantifies the efficiency of cursor movements, as described in Equation 7.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "instruction": "Improve the linking between ideas to make the paragraph more precise and readable.", "revised_paragraph": "Revised paragraph: \"The pointing operation to the edge target leverages the cursor's tendency to stop at the edge of the screen, allowing for accurate completion without precise control. However, this pushing-edge behavior, where the cursor is pushed to the edge of the screen, has a counterintuitive effect: it increases the distance traveled by the mouse, subsequently prolonging movement time. This phenomenon is quantified by Yamanaka's definition of Path Efficiency (PE), which calculates the efficiency of cursor movements (Eq. 7), providing a valuable metric for understanding the complexities of cursor behavior.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The attention mechanism in our Entroformer models relationships between feature representations. We visualize the self-attention mechanism, focusing on specific points in the image, with rescaled attention maps for clarity. The visualizations in Figures 8 and 9 show how the Entroformer finds related context to support its distribution prediction, enabling it to capture richer dependencies and achieve better compression performance.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The attention mechanism in our Entroformer models relationships between feature representations. We visualize the self-attention mechanism, focusing on specific points in the image, with rescaled attention maps for clarity. The visualizations in Figures 8 and 9 show how the Entroformer finds related context to support its distribution prediction, enabling it to capture richer dependencies and achieve better compression performance.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The attention mechanism in our Entroformer models relationships between feature representations. We visualize the self-attention mechanism, focusing on specific points in the image, with rescaled attention maps for clarity. The visualizations in Figures 8 and 9 show how the Entroformer finds related context to support its distribution prediction, enabling it to capture richer dependencies and achieve better compression performance.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The attention mechanism in our Entroformer models relationships between feature representations. We visualize the self-attention mechanism, focusing on specific points in the image, with rescaled attention maps for clarity. The visualizations in Figures 8 and 9 show how the Entroformer finds related context to support its distribution prediction, enabling it to capture richer dependencies and achieve better compression performance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The attention mechanism in our Entroformer models relationships between feature representations. We visualize the self-attention mechanism, focusing on specific points in the image, with rescaled attention maps for clarity. The visualizations in Figures 8 and 9 show how the Entroformer finds related context to support its distribution prediction, enabling it to capture richer dependencies and achieve better compression performance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The attention mechanism in our Entroformer models relationships between feature representations. We visualize the self-attention mechanism, focusing on specific points in the image, with rescaled attention maps for clarity. The visualizations in Figures 8 and 9 show how the Entroformer finds related context to support its distribution prediction, enabling it to capture richer dependencies and achieve better compression performance.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The attention mechanism in our Entroformer models relationships between feature representations. We visualize the self-attention mechanism, focusing on specific points in the image, with rescaled attention maps for clarity. The visualizations in Figures 8 and 9 show how the Entroformer finds related context to support its distribution prediction, enabling it to capture richer dependencies and achieve better compression performance.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The attention mechanism in our Entroformer models relationships between feature representations. We visualize the self-attention mechanism, focusing on specific points in the image, with rescaled attention maps for clarity. The visualizations in Figures 8 and 9 show how the Entroformer finds related context to support its distribution prediction, enabling it to capture richer dependencies and achieve better compression performance.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "instruction": "Revise this paragraph to be more concise.", "revised_paragraph": "Revised paragraph: \"The attention mechanism in our Entroformer models relationships between feature representations. We visualize the self-attention mechanism in Figures 8 and 9, highlighting different points in the image. The attention maps are rescaled for clarity. The visualizations show how the Entroformer finds related context to support its distribution prediction, capturing richer dependencies and achieving better compression performance.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "zDDQ6YzcK8.rFbDzCD2Zq.00", "instruction": "This paragraph need to be shorter, do it by removing details but don\u2019t touch the first sentence.", "revised_paragraph": "Revised paragraph: \"Attention mechanism in transformer is the key component which models relations between feature representations. We visualize the self-attentions mechanism of our Entroformer, focusing on a few points in the image. The attention map is rescaled for a better view. Our visualizations show how the Entroformer captures richer dependencies of the latents and achieves better compression performance.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: On the other hand, neural network pruning is a well-established technique for reducing model complexity (Reed, 1993; Sze et al., 2017). To accelerate models, researchers primarily focus on filter pruning (also known as structured pruning) (Li et al., 2017) rather than weight-element pruning (also known as unstructured pruning) (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) may offer a promising solution to achieve a better balance between performance and complexity. However, filter pruning methods developed for classification tasks are not directly applicable to SR networks. This is because residual connections, which are commonly used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) with 32 residual blocks and RCAN (Zhang et al., 2018b) with nested residual blocks), are difficult to prune using structured pruning methods (Li et al., 2017)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: On the other hand, neural network pruning is a well-established technique for reducing model complexity (Reed, 1993; Sze et al., 2017). To accelerate models, researchers primarily focus on filter pruning (also known as structured pruning) (Li et al., 2017) rather than weight-element pruning (also known as unstructured pruning) (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) may offer a promising solution to achieve a better balance between performance and complexity. However, filter pruning methods developed for classification tasks are not directly applicable to SR networks. This is because residual connections, which are commonly used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) with 32 residual blocks and RCAN (Zhang et al., 2018b) with nested residual blocks), are difficult to prune using structured pruning methods (Li et al., 2017)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: On the other hand, neural network pruning is a well-established technique for reducing model complexity (Reed, 1993; Sze et al., 2017). To accelerate models, researchers primarily focus on filter pruning (also known as structured pruning) (Li et al., 2017) rather than weight-element pruning (also known as unstructured pruning) (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) may offer a promising solution to achieve a better balance between performance and complexity. However, filter pruning methods developed for classification tasks are not directly applicable to SR networks. This is because residual connections, which are commonly used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) with 32 residual blocks and RCAN (Zhang et al., 2018b) with nested residual blocks), are difficult to prune using structured pruning methods (Li et al., 2017)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: On the other hand, neural network pruning is a well-established technique for reducing model complexity (Reed, 1993; Sze et al., 2017). To accelerate models, researchers primarily focus on filter pruning (also known as structured pruning) (Li et al., 2017) rather than weight-element pruning (also known as unstructured pruning) (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) may offer a promising solution to achieve a better balance between performance and complexity. However, filter pruning methods developed for classification tasks are not directly applicable to SR networks. This is because residual connections, which are commonly used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) with 32 residual blocks and RCAN (Zhang et al., 2018b) with nested residual blocks), are difficult to prune using structured pruning methods (Li et al., 2017)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: On the other hand, neural network pruning is a well-established technique for reducing model complexity (Reed, 1993; Sze et al., 2017). To accelerate models, researchers primarily focus on filter pruning (also known as structured pruning) (Li et al., 2017) rather than weight-element pruning (also known as unstructured pruning) (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) may offer a promising solution to achieve a better balance between performance and complexity. However, filter pruning methods developed for classification tasks are not directly applicable to SR networks. This is because residual connections, which are commonly used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) with 32 residual blocks and RCAN (Zhang et al., 2018b) with nested residual blocks), are difficult to prune using structured pruning methods (Li et al., 2017)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: On the other hand, neural network pruning is a well-established technique for reducing model complexity (Reed, 1993; Sze et al., 2017). To accelerate models, researchers primarily focus on filter pruning (also known as structured pruning) (Li et al., 2017) rather than weight-element pruning (also known as unstructured pruning) (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) may offer a promising solution to achieve a better balance between performance and complexity. However, filter pruning methods developed for classification tasks are not directly applicable to SR networks. This is because residual connections, which are commonly used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) with 32 residual blocks and RCAN (Zhang et al., 2018b) with nested residual blocks), are difficult to prune using structured pruning methods (Li et al., 2017)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: On the other hand, neural network pruning is a well-established technique for reducing model complexity (Reed, 1993; Sze et al., 2017). To accelerate models, researchers primarily focus on filter pruning (also known as structured pruning) (Li et al., 2017) rather than weight-element pruning (also known as unstructured pruning) (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) may offer a promising solution to achieve a better balance between performance and complexity. However, filter pruning methods developed for classification tasks are not directly applicable to SR networks. This is because residual connections, which are commonly used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) with 32 residual blocks and RCAN (Zhang et al., 2018b) with nested residual blocks), are difficult to prune using structured pruning methods (Li et al., 2017)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: On the other hand, neural network pruning is a well-established technique for reducing model complexity (Reed, 1993; Sze et al., 2017). To accelerate models, researchers primarily focus on filter pruning (also known as structured pruning) (Li et al., 2017) rather than weight-element pruning (also known as unstructured pruning) (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) may offer a promising solution to achieve a better balance between performance and complexity. However, filter pruning methods developed for classification tasks are not directly applicable to SR networks. This is because residual connections, which are commonly used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) with 32 residual blocks and RCAN (Zhang et al., 2018b) with nested residual blocks), are difficult to prune using structured pruning methods (Li et al., 2017)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "instruction": "Improve the paragraph.", "revised_paragraph": "Revised paragraph: \"On the other hand, neural network pruning is a well-established technique for reducing model complexity, as demonstrated by Reed (1993) and Sze et al. (2017). Researchers have primarily focused on filter pruning (Li et al., 2017) for acceleration, rather than weight-element pruning (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) appears to be a promising approach to achieving a better performance-complexity trade-off. However, existing filter pruning methods in classification tasks are not directly applicable to SR networks. This is because residual connections, which are extensively used in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) and RCAN (Zhang et al., 2018b)), are challenging to prune in structured pruning methods (Li et al., 2017).\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.03", "instruction": "Rewrite the third sentence using more appropriate language.", "revised_paragraph": "Revised paragraph: On the other hand, neural network pruning is a well-established technique for reducing model complexity (Reed, 1993; Sze et al., 2017). Researchers have primarily focused on filter pruning (also known as structured pruning) (Li et al., 2017) as a means of acceleration, as opposed to weight-element pruning (also known as unstructured pruning) (Han et al., 2015; 2016b). Combining filter pruning with image super-resolution (SR) appears to be a promising approach to achieving a better performance-complexity trade-off. However, filter pruning methods developed for classification tasks are not directly applicable to SR networks. The primary obstacle is that residual connections are notoriously difficult to prune in structured pruning (Li et al., 2017), whereas they are extensively employed in state-of-the-art SR networks (e.g., EDSR (Lim et al., 2017) features 32 residual blocks, while RCAN (Zhang et al., 2018b) even incorporates nested residual blocks).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our method (Fig. 3) learns a pixel-wise embedding with a contrastive loss to segment an image. We define two disjoint sets - positive and negative segments (exemplars) with respect to each pixel. Our goal is to group the pixel with its positive segments while separating it from negative ones. We aim to decrease the distance between the pixel's latent feature and its positive segments, and increase the distance from its negative segments.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our method (Fig. 3) learns a pixel-wise embedding with a contrastive loss to segment an image. We define two disjoint sets - positive and negative segments (exemplars) with respect to each pixel. Our goal is to group the pixel with its positive segments while separating it from negative ones. We aim to decrease the distance between the pixel's latent feature and its positive segments, and increase the distance from its negative segments.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our method (Fig. 3) learns a pixel-wise embedding with a contrastive loss to segment an image. We define two disjoint sets - positive and negative segments (exemplars) with respect to each pixel. Our goal is to group the pixel with its positive segments while separating it from negative ones. We aim to decrease the distance between the pixel's latent feature and its positive segments, and increase the distance from its negative segments.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our method (Fig. 3) learns a pixel-wise embedding with a contrastive loss to segment an image. We define two disjoint sets - positive and negative segments (exemplars) with respect to each pixel. Our goal is to group the pixel with its positive segments while separating it from negative ones. We aim to decrease the distance between the pixel's latent feature and its positive segments, and increase the distance from its negative segments.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our method (Fig. 3) learns a pixel-wise embedding with a contrastive loss to segment an image. We define two disjoint sets - positive and negative segments (exemplars) with respect to each pixel. Our goal is to group the pixel with its positive segments while separating it from negative ones. We aim to decrease the distance between the pixel's latent feature and its positive segments, and increase the distance from its negative segments.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our method (Fig. 3) learns a pixel-wise embedding with a contrastive loss to segment an image. We define two disjoint sets - positive and negative segments (exemplars) with respect to each pixel. Our goal is to group the pixel with its positive segments while separating it from negative ones. We aim to decrease the distance between the pixel's latent feature and its positive segments, and increase the distance from its negative segments.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our method (Fig. 3) learns a pixel-wise embedding with a contrastive loss to segment an image. We define two disjoint sets - positive and negative segments (exemplars) with respect to each pixel. Our goal is to group the pixel with its positive segments while separating it from negative ones. We aim to decrease the distance between the pixel's latent feature and its positive segments, and increase the distance from its negative segments.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our method (Fig. 3) learns a pixel-wise embedding with a contrastive loss to segment an image. We define two disjoint sets - positive and negative segments (exemplars) with respect to each pixel. Our goal is to group the pixel with its positive segments while separating it from negative ones. We aim to decrease the distance between the pixel's latent feature and its positive segments, and increase the distance from its negative segments.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "instruction": "Make this paragraph heavily more concise in the explanations made.", "revised_paragraph": "Revised paragraph: Our method (Fig. 3) learns a pixel-wise embedding with a contrastive loss, grouping pixels with similar features and separating those with dissimilar features. We define two disjoint sets: positive and negative segments (exemplars) for each pixel, aiming to cluster the pixel with similar segments while separating it from dissimilar ones.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.04", "instruction": "Don't give to much details about the method of learning, just keep the main idea.", "revised_paragraph": "Revised paragraph: Metric learning develops a feature representation by grouping and separating image pixels. Our method segments images by learning a pixel-wise embedding with a contrastive loss between pixels and segments. We define positive and negative segments (exemplars) with respect to each pixel and aim to group it with positive segments while separating it from negative ones.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We introduce a theorem that provides a guideline for neural network architecture design in operator learning. The theorem suggests that a fully connected network is sufficient for large complexity training and verifies a sharp bound on the number of parameters for a universal activation function. Notably, this assumes a sufficient condition for the theorem's proof."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We now present the theorem, which provides a framework for designing neural network architectures for operator learning. The theorem stipulates that if the entire architecture can be replaced with a fully connected neural network, a high level of complexity is necessary for training. Moreover, it demonstrates that the lower bound for a universal activation function is a tight bound on the number of parameters. We highlight an assumption, which serves as a sufficient condition for proving the theorem.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We now present the theorem, which provides a framework for designing neural network architectures for operator learning. The theorem stipulates that if the entire architecture can be replaced with a fully connected neural network, a high level of complexity is necessary for training. Moreover, it demonstrates that the lower bound for a universal activation function is a tight bound on the number of parameters. We highlight an assumption, which serves as a sufficient condition for proving the theorem.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We introduce a theorem that provides a guideline for neural network architecture design in operator learning. The theorem suggests that a fully connected network is sufficient for large complexity training and verifies a sharp bound on the number of parameters for a universal activation function. Notably, this assumes a sufficient condition for the theorem's proof."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We now present the theorem, which provides a framework for designing neural network architectures for operator learning. The theorem stipulates that if the entire architecture can be replaced with a fully connected neural network, a high level of complexity is necessary for training. Moreover, it demonstrates that the lower bound for a universal activation function is a tight bound on the number of parameters. We highlight an assumption, which serves as a sufficient condition for proving the theorem.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We now present the theorem, which provides a framework for designing neural network architectures for operator learning. The theorem stipulates that if the entire architecture can be replaced with a fully connected neural network, a high level of complexity is necessary for training. Moreover, it demonstrates that the lower bound for a universal activation function is a tight bound on the number of parameters. We highlight an assumption, which serves as a sufficient condition for proving the theorem.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We introduce a theorem that provides a guideline for neural network architecture design in operator learning. The theorem suggests that a fully connected network is sufficient for large complexity training and verifies a sharp bound on the number of parameters for a universal activation function. Notably, this assumes a sufficient condition for the theorem's proof."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We present a theorem that offers a framework for designing neural network architectures in operator learning. The theorem demonstrates that a fully connected network is sufficient for large-complexity training and establishes a sharp bound on the number of parameters required for a universal activation function. Notably, this result assumes a sufficient condition for the theorem's proof, which is crucial for its validity."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We now present the theorem, which provides a framework for designing neural network architectures for operator learning. The theorem stipulates that if the entire architecture can be replaced with a fully connected neural network, a high level of complexity is necessary for training. Moreover, it demonstrates that the lower bound for a universal activation function is a tight bound on the number of parameters. We highlight an assumption, which serves as a sufficient condition for proving the theorem.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We introduce a theorem that provides a guideline for neural network architecture design in operator learning. The theorem suggests that a fully connected network is sufficient for large complexity training and verifies a sharp bound on the number of parameters for a universal activation function. Notably, this assumes a sufficient condition for the theorem's proof."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We present a theorem that offers a framework for designing neural network architectures in operator learning. The theorem demonstrates that a fully connected network is sufficient for large-complexity training and establishes a sharp bound on the number of parameters required for a universal activation function. Notably, this result assumes a sufficient condition for the theorem's proof, which is crucial for its validity."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We now present the theorem, which provides a framework for designing neural network architectures for operator learning. The theorem stipulates that if the entire architecture can be replaced with a fully connected neural network, a high level of complexity is necessary for training. Moreover, it demonstrates that the lower bound for a universal activation function is a tight bound on the number of parameters. We highlight an assumption, which serves as a sufficient condition for proving the theorem.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "instruction": "Remove redundant details. Use more precise words.", "revised_paragraph": "Revised paragraph: We introduce the theorem, which provides a framework for designing neural network architectures for operator learning. The theorem posits that if a fully connected neural network can replace the entire architecture, significant complexity is necessary for training. Additionally, it confirms that the lower bound for a universal activation function is a tight bound on the number of parameters. We note a sufficient condition for proving the theorem.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.01", "instruction": "Make it more precise when necessary.", "revised_paragraph": "Revised paragraph: We introduce the theorem, which provides a precise guideline for designing neural network architectures for operator learning. Specifically, it implies that if the entire architecture can be replaced with a fully connected neural network, a large number of parameters are required for training. Furthermore, the theorem establishes a sharp lower bound on the number of parameters for a universal activation function. Notably, this result is contingent upon a sufficient condition, which is assumed to hold for the theorem's proof.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, leveraging the tangential structure of the 2-Wasserstein space. Our method approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This approach allows for extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, demonstrating its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe have developed a projection method between sets of probability measures supported on R^d, leveraging the tangential structure of the 2-Wasserstein space. Our approach aims to approximate a target distribution, potentially multivariate, using a chosen set of control distributions. We provide an implementation that yields unique, interpretable weights in the context of regular probability measures. For general probability measures, we construct our projection by first creating a regular tangent space through the application of barycentric projection to optimal transport plans. The efficacy of our method is demonstrated through its application to evaluating the first- and second-order effects of Medicaid expansion in Montana, via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003; Abadie et al., 2010). Our approach is notable for its ability to accommodate general probability measures, and it can be extended to a continuum of measures, drawing on established consistency results for barycenters (e.g., Le Gouic & Loubes, 2017)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, leveraging the tangential structure of the 2-Wasserstein space. Our method approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This approach allows for extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, demonstrating its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, leveraging the tangential structure of the 2-Wasserstein space. Our method approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This approach allows for extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, demonstrating its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, leveraging the tangential structure of the 2-Wasserstein space. Our method approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This approach allows for extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, demonstrating its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe have developed a projection method between sets of probability measures supported on R^d, leveraging the tangential structure of the 2-Wasserstein space. Our approach aims to approximate a target distribution, potentially multivariate, using a chosen set of control distributions. We provide an implementation that yields unique, interpretable weights in the context of regular probability measures. For general probability measures, we construct our projection by first creating a regular tangent space through the application of barycentric projection to optimal transport plans. The efficacy of our method is demonstrated through its application to evaluating the first- and second-order effects of Medicaid expansion in Montana, via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003; Abadie et al., 2010). Our approach is notable for its ability to accommodate general probability measures, and it can be extended to a continuum of measures, drawing on established consistency results for barycenters (e.g., Le Gouic & Loubes, 2017)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, leveraging the tangential structure of the 2-Wasserstein space. Our method approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This approach allows for extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, demonstrating its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, capitalizing on the tangential structure of the 2-Wasserstein space. Our approach approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This methodology enables extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, showcasing its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, leveraging the tangential structure of the 2-Wasserstein space. Our method approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This approach allows for extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, demonstrating its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, leveraging the tangential structure of the 2-Wasserstein space. Our method approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This approach allows for extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, demonstrating its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, leveraging the tangential structure of the 2-Wasserstein space. Our method approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This approach allows for extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, demonstrating its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We have developed a projection method for sets of probability measures on Rd, capitalizing on the tangential structure of the 2-Wasserstein space. Our approach approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general measures, we construct a regular tangent space through barycentric projection of optimal transport plans. This methodology enables extrapolation beyond the convex hull of control units and can be extended to a continuum of measures, showcasing its efficiency in applications such as evaluating the effects of Medicaid expansion in Montana."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "instruction": "Please, make this paragraph mor concise, delete unnecessary details", "revised_paragraph": "Revised paragraph: We have developed a projection method for probability measures on Rd, leveraging the tangential structure of the 2-Wasserstein space. Our approach approximates a target distribution using a chosen set of control distributions, providing unique and interpretable weights for regular probability measures. For general probability measures, we first create a regular tangent space through barycentric projection of optimal transport plans. This method has been applied to evaluate the effects of Medicaid expansion in Montana, demonstrating its efficiency and necessity for general probability measures. The approach allows for extrapolation beyond the convex hull of control units, enabling tangential regression and extension to a continuum of measures.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "instruction": "Combine sentences 3 and 4 into a really short one keeping only the main idea. Improve the choice of wording.", "revised_paragraph": "Revised paragraph: We have developed a projection method between sets of probability measures supported on R d, which seeks to best approximate a target distribution using a chosen set of control distributions. Our method provides unique, interpretable weights and can be applied to general probability measures, including those that require extrapolation beyond the convex hull of the control units, and can be extended to a continuum of measures.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because most targets on graphical user interfaces (GUIs) are rectangular in shape, the height of the target (H) also influences the movement time [3, 8, 14, 20, 21, 27]. Accot and Zhai [1] developed a model for 2D pointing tasks that considers the impact of H, while Zhang et al. [28] suggested balancing the effects of both the width (W) and height (H) of the target, as described in Equation 2."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Because typical targets on graphical user interfaces are rectangular, the target height (H) also influences movement time [3, 8, 14, 20, 21, 27]. Accot and Zhai [1] developed a model for bivariate (2D) pointing tasks that incorporates H. Zhang et al. [28] suggested balancing the effects of width (W) and H, as described in Equation (2)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Because typical targets on graphical user interfaces are rectangular, the target height (H) also influences movement time [3, 8, 14, 20, 21, 27]. Accot and Zhai [1] developed a model for bivariate (2D) pointing tasks that incorporates H. Zhang et al. [28] suggested balancing the effects of width (W) and H, as described in Equation (2)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because most targets on graphical user interfaces (GUIs) are rectangular in shape, the height of the target (H) also influences the movement time [3, 8, 14, 20, 21, 27]. Accot and Zhai [1] developed a model for 2D pointing tasks that considers the impact of H, while Zhang et al. [28] suggested balancing the effects of both the width (W) and height (H) of the target, as described in Equation 2."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because most targets on graphical user interfaces (GUIs) are rectangular in shape, the height of the target (H) also influences the movement time [3, 8, 14, 20, 21, 27]. Accot and Zhai [1] developed a model for 2D pointing tasks that considers the impact of H, while Zhang et al. [28] suggested balancing the effects of both the width (W) and height (H) of the target, as described in Equation 2."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Because most graphical user interface (GUI) targets are rectangular in shape, the height of the target (H) also affects movement time [3, 8, 14, 20, 21, 27]. Accot and Zhai [1] have developed a model for 2D pointing tasks that takes into account the impact of H, while Zhang et al. [28] have suggested balancing the effects of both the width (W) and height (H) of the target, as described in Equation 2."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Because typical targets on graphical user interfaces are rectangular, the target height (H) also influences movement time [3, 8, 14, 20, 21, 27]. Accot and Zhai [1] developed a model for bivariate (2D) pointing tasks that incorporates H. Zhang et al. [28] suggested balancing the effects of width (W) and H, as described in Equation (2)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Because most targets on graphical user interfaces (GUIs) are rectangular in shape, the height of the target (H) also influences the movement time [3, 8, 14, 20, 21, 27]. Accot and Zhai [1] developed a model for 2D pointing tasks that considers the impact of H, while Zhang et al. [28] suggested balancing the effects of both the width (W) and height (H) of the target, as described in Equation 2."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "instruction": "Rewrite this paragraph and focus more on the first sentence", "revised_paragraph": "Revised paragraph: The importance of considering target height (H) in graphical user interfaces (GUIs) is underscored by the fact that typical targets are rectangular, which has a direct impact on movement time [3,8,14,20,21,27]. Accot and Zhai [1] developed a model for 2D pointing tasks that incorporates H, highlighting its significance in this context. Furthermore, Zhang et al. [28] proposed a strategy to balance the effects of both width (W) and H, as demonstrated in Equation 2.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.05", "instruction": "Improve this paragraph for clarity, mainly the first sentence.", "revised_paragraph": "Revised paragraph: Because the majority of targets on graphical user interfaces (GUIs) are rectangular in shape, the movement time is influenced not only by the target width (W) but also by the target height (H) [3,8,14,20,21,27]. Accot and Zhai [1] proposed a model for 2D pointing tasks that incorporates H, while Zhang et al. [28] suggested balancing the effects of W and H, as represented in Equation 2.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our main contributions can be summarized as follows: Firstly, we introduce a novel (\u03c3, \u03b4)-measure to quantify the effectiveness of data augmentation. Secondly, we establish a theoretical framework for contrastive self-supervised learning, which identifies alignment, divergence, and concentration as crucial factors influencing the generalization ability of models. Thirdly, we provide theoretical guarantees that both the InfoNCE loss and the cross-correlation loss satisfy the alignment and divergence criteria. Finally, our empirical results demonstrate a strong correlation between the concentration of the proposed augmented distance metric and downstream performance."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In summary, our contributions comprise a novel (\u03c3, \u03b4)-measure for quantifying data augmentation, a theoretical framework for contrastive self-supervised learning (SSL) that identifies alignment, divergence, and concentration as key factors influencing generalization ability, provable verification that both the InfoNCE loss and cross-correlation loss satisfy alignment and divergence criteria, and empirical evidence demonstrating a strong correlation between the concentration of the proposed augmented distance and downstream performance.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our main contributions can be summarized as follows: Firstly, we introduce a novel (\u03c3, \u03b4)-measure to quantify the effectiveness of data augmentation. Secondly, we establish a theoretical framework for contrastive self-supervised learning, which identifies alignment, divergence, and concentration as crucial factors influencing the generalization ability of models. Thirdly, we provide theoretical guarantees that both the InfoNCE loss and the cross-correlation loss satisfy the alignment and divergence criteria. Finally, our empirical results demonstrate a strong correlation between the concentration of the proposed augmented distance metric and downstream performance."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In summary, our contributions comprise a novel (\u03c3, \u03b4)-measure for quantifying data augmentation, a theoretical framework for contrastive self-supervised learning (SSL) that identifies alignment, divergence, and concentration as key factors influencing generalization ability, provable verification that both the InfoNCE loss and cross-correlation loss satisfy alignment and divergence criteria, and empirical evidence demonstrating a strong correlation between the concentration of the proposed augmented distance and downstream performance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our main contributions can be summarized as follows: Firstly, we introduce a novel (\u03c3, \u03b4)-measure to quantify the effectiveness of data augmentation. Secondly, we establish a theoretical framework for contrastive self-supervised learning, which identifies alignment, divergence, and concentration as crucial factors influencing the generalization ability of models. Thirdly, we provide theoretical guarantees that both the InfoNCE loss and the cross-correlation loss satisfy the alignment and divergence criteria. Finally, our empirical results demonstrate a strong correlation between the concentration of the proposed augmented distance metric and downstream performance."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our primary contributions can be succinctly summarized as follows: First, we introduce a novel (\u03c3, \u03b4)-measure to quantify the efficacy of data augmentation. Second, we establish a theoretical framework for contrastive self-supervised learning, which highlights alignment, divergence, and concentration as pivotal factors influencing the generalization ability of models. Thirdly, we provide theoretical assurances that both the InfoNCE loss and the cross-correlation loss satisfy the alignment and divergence criteria. Finally, our empirical results demonstrate a strong correlation between the concentration of the proposed augmented distance metric and downstream performance."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our main contributions can be summarized as follows: Firstly, we introduce a novel (\u03c3, \u03b4)-measure to quantify the effectiveness of data augmentation. Secondly, we establish a theoretical framework for contrastive self-supervised learning, which identifies alignment, divergence, and concentration as crucial factors influencing the generalization ability of models. Thirdly, we provide theoretical guarantees that both the InfoNCE loss and the cross-correlation loss satisfy the alignment and divergence criteria. Finally, our empirical results demonstrate a strong correlation between the concentration of the proposed augmented distance metric and downstream performance."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In summary, our contributions comprise a novel (\u03c3, \u03b4)-measure for quantifying data augmentation, a theoretical framework for contrastive self-supervised learning (SSL) that identifies alignment, divergence, and concentration as key factors influencing generalization ability, provable verification that both the InfoNCE loss and cross-correlation loss satisfy alignment and divergence criteria, and empirical evidence demonstrating a strong correlation between the concentration of the proposed augmented distance and downstream performance.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "instruction": "Make the sentence precise.", "revised_paragraph": "Revised paragraph: Our key contributions include proposing a novel (\u03c3, \u03b4)-measure to quantify data augmentation, developing a theoretical framework for contrastive self-supervised learning that identifies alignment, divergence, and concentration as essential factors of generalization ability, proving that both InfoNCE loss and cross-correlation loss satisfy alignment and divergence, and empirically demonstrating that concentration with respect to the proposed augmented distance is strongly correlated with downstream performance.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "instruction": "Improve english in this text.", "revised_paragraph": "Revised paragraph: \"In summary, our contributions are multifaceted: we introduce a novel (\u03c3, \u03b4)-measure to quantify data augmentation, propose a theoretical framework for contrastive self-supervised learning that highlights alignment, divergence, and concentration as crucial factors influencing generalization ability, provide provable guarantees that both the InfoNCE loss and cross-correlation loss satisfy alignment and divergence, and demonstrate empirically that concentration with respect to the proposed augmented distance is strongly correlated with downstream performance.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We introduce a novel concept of projection between sets of probability measures supported on Euclidean spaces. This definition is applicable to general probability measures with distinct supports and exhibits desirable computational and statistical properties. Moreover, it provides a unique solution to the projection problem under mild conditions and can replicate the geometric characteristics of the target measure, including its shape and support. To achieve this, we operate within the 2-Wasserstein space, which consists of all probability measures with finite second moments, equipped with the 2-Wasserstein distance."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: We introduce a novel notion of projection between sets of probability measures supported on Euclidean spaces, which is applicable to general probability measures with different supports and exhibits good computational and statistical properties. Under mild conditions, our definition provides a unique solution to the projection problem, allowing it to replicate the geometric properties of the target measure, such as its shape and support. To achieve this, we operate in the 2-Wasserstein space, which consists of all probability measures with finite second moments, equipped with the 2-Wasserstein distance."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We introduce a novel concept of projection between sets of probability measures supported on Euclidean spaces. This definition is applicable to general probability measures with distinct supports and exhibits desirable computational and statistical properties. Moreover, it provides a unique solution to the projection problem under mild conditions and can replicate the geometric characteristics of the target measure, including its shape and support. To achieve this, we operate within the 2-Wasserstein space, which consists of all probability measures with finite second moments, equipped with the 2-Wasserstein distance."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: We introduce a novel notion of projection between sets of probability measures supported on Euclidean spaces, which is applicable to general probability measures with different supports and exhibits good computational and statistical properties. Under mild conditions, our definition provides a unique solution to the projection problem, allowing it to replicate the geometric properties of the target measure, such as its shape and support. To achieve this, we operate in the 2-Wasserstein space, which consists of all probability measures with finite second moments, equipped with the 2-Wasserstein distance."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We introduce a novel concept of projection between sets of probability measures supported on Euclidean spaces. This definition is applicable to general probability measures with distinct supports and exhibits desirable computational and statistical properties. Moreover, it provides a unique solution to the projection problem under mild conditions and can replicate the geometric characteristics of the target measure, including its shape and support. To achieve this, we operate within the 2-Wasserstein space, which consists of all probability measures with finite second moments, equipped with the 2-Wasserstein distance."}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: We propose a novel concept of projection between sets of probability measures supported on Euclidean spaces, which is applicable to general probability measures with distinct supports and exhibits desirable computational and statistical properties. This definition provides a unique solution to the projection problem under mild conditions, and can replicate the geometric characteristics of the target measure, including its shape and support. Specifically, we operate within the 2-Wasserstein space, a set of all probability measures with finite second moments, equipped with the 2-Wasserstein distance."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We introduce a novel concept of projection between sets of probability measures supported on Euclidean spaces. This definition is applicable to general probability measures with distinct supports and exhibits desirable computational and statistical properties. Moreover, it provides a unique solution to the projection problem under mild conditions and can replicate the geometric characteristics of the target measure, including its shape and support. To achieve this, we operate within the 2-Wasserstein space, which consists of all probability measures with finite second moments, equipped with the 2-Wasserstein distance."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: We introduce a novel notion of projection between sets of probability measures supported on Euclidean spaces, which is applicable to general probability measures with different supports and exhibits good computational and statistical properties. Under mild conditions, our definition provides a unique solution to the projection problem, allowing it to replicate the geometric properties of the target measure, such as its shape and support. To achieve this, we operate in the 2-Wasserstein space, which consists of all probability measures with finite second moments, equipped with the 2-Wasserstein distance."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "instruction": "Please, make this paragraph easier to read.", "revised_paragraph": "Revised paragraph: We introduce a novel concept of projection between sets of probability measures supported on Euclidean spaces. Our definition is applicable to general probability measures with different supports and exhibits desirable computational and statistical properties. Moreover, it provides a unique solution to the projection problem under mild conditions, while also replicating the geometric properties of the target measure, such as its shape and support. To achieve this, we operate within the 2-Wasserstein space, which consists of all probability measures with finite second moments, equipped with the 2-Wasserstein distance.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.01", "instruction": "Rewrite and reorganise this paragraph to improve the english and be more convincing, let the last sentence as it is.", "revised_paragraph": "Revised paragraph: We propose a novel notion of projection between sets of probability measures supported on Euclidean spaces, which can be applied to general probability measures with distinct supports and exhibits excellent computational and statistical properties. Notably, this definition provides a unique solution to the projection problem under mild conditions and can accurately replicate the geometric properties of the target measure, including its shape and support. To achieve this, we operate within the 2-Wasserstein space, comprising all probability measures with finite second moments, equipped with the 2-Wasserstein distance.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: MLP-based architectures, such as MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021), have achieved promising results by utilizing matrix transposition, MLP, and skip connections. The concurrent work Res-MLP (Touvron et al., 2021a) also obtains impressive performance with residual MLP. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) further improve the performance by introducing Spatial Gating Unit and external attention, respectively."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: MLP-based architectures, such as MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021), have achieved promising results by utilizing matrix transposition, MLP, and skip connections. The concurrent work Res-MLP (Touvron et al., 2021a) also obtains impressive performance with residual MLP. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) further improve the performance by introducing Spatial Gating Unit and external attention, respectively."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: MLP-based architectures, such as MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021), have achieved promising results by utilizing matrix transposition, MLP, and skip connections. The concurrent work Res-MLP (Touvron et al., 2021a) also obtains impressive performance with residual MLP. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) further improve the performance by introducing Spatial Gating Unit and external attention, respectively."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: MLP-based architectures, such as MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021), have achieved promising results by utilizing matrix transposition, MLP, and skip connections. The concurrent work Res-MLP (Touvron et al., 2021a) also obtains impressive performance with residual MLP. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) further improve the performance by introducing Spatial Gating Unit and external attention, respectively."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: MLP-based architectures, such as MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021), have achieved promising results by utilizing matrix transposition, MLP, and skip connections. The concurrent work Res-MLP (Touvron et al., 2021a) also obtains impressive performance with residual MLP. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) further improve the performance by introducing Spatial Gating Unit and external attention, respectively."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: MLP-based architectures, such as MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021), have achieved promising results by utilizing matrix transposition, MLP, and skip connections. The concurrent work Res-MLP (Touvron et al., 2021a) also obtains impressive performance with residual MLP. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) further improve the performance by introducing Spatial Gating Unit and external attention, respectively."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: MLP-based architectures, such as MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021), have achieved promising results by utilizing matrix transposition, MLP, and skip connections. The concurrent work Res-MLP (Touvron et al., 2021a) also obtains impressive performance with residual MLP. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) further improve the performance by introducing Spatial Gating Unit and external attention, respectively."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: MLP-based architectures, such as MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021), have achieved promising results by utilizing matrix transposition, MLP, and skip connections. The concurrent work Res-MLP (Touvron et al., 2021a) also obtains impressive performance with residual MLP. gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) further improve the performance by introducing Spatial Gating Unit and external attention, respectively."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "instruction": "Revise this paragraph to be more concise.", "revised_paragraph": "Revised paragraph: \"The MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021) demonstrate the effectiveness of MLP-based architectures, achieving promising results through matrix transposition, MLP, skip connections, and normalization. The concurrent work Res-MLP (Touvron et al., 2021a) achieves impressive performance with residual MLP, while gMLP (Liu et al., 2021a) and EA (Guo et al., 2021) improve performance by introducing Spatial Gating Unit (SGU) and external attention, respectively.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.01", "instruction": "Make this paragraph shorter by deleting details.", "revised_paragraph": "Revised paragraph: MLP-based Architectures, such as MLP-Mixer (Tolstikhin et al., 2021) and FF (Melas-Kyriazi, 2021), have demonstrated promising results using matrix transposition and MLP to transmit information between spatial features. These architectures have achieved comparable performance with CNN-based and transformer-based architectures, with some variants introducing additional components to improve performance.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation reveals that black box optimizers rarely outperform Naive AutoML for 1-hour runtimes. Moreover, the \"Ex-def\" baseline is surprisingly strong in this timeframe. This finding contrasts with previous research (Thornton et al., 2013), which used a 30-hour timeout. Our results suggest that simple baselines are stronger than previously thought.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The outcome of our experimental evaluation was unexpected, as black box optimizers rarely outperformed Naive AutoML for runtimes of 1 hour. Notably, the \"Ex-def\" baseline itself performed remarkably well in this time frame. This finding does not contradict the results in Thornton et al. (2013), which used a 30-hour timeout. While this observation highlights the need for more comprehensive experiments with longer runtimes, it is already clear that simple baselines are stronger than previously thought."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation reveals that black box optimizers rarely outperform Naive AutoML for 1-hour runtimes. Moreover, the \"Ex-def\" baseline is surprisingly strong in this timeframe. This finding contrasts with previous research (Thornton et al., 2013), which used a 30-hour timeout. Our results suggest that simple baselines are stronger than previously thought.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation reveals that black box optimizers rarely outperform Naive AutoML for 1-hour runtimes. Moreover, the \"Ex-def\" baseline is surprisingly strong in this timeframe. This finding contrasts with previous research (Thornton et al., 2013), which used a 30-hour timeout. Our results suggest that simple baselines are stronger than previously thought.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The outcome of our experimental evaluation was unexpected, as black box optimizers rarely outperformed Naive AutoML for runtimes of 1 hour. Notably, the \"Ex-def\" baseline itself performed remarkably well in this time frame. This finding does not contradict the results in Thornton et al. (2013), which used a 30-hour timeout. While this observation highlights the need for more comprehensive experiments with longer runtimes, it is already clear that simple baselines are stronger than previously thought."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation reveals that black box optimizers rarely outperform Naive AutoML for 1-hour runtimes. Moreover, the \"Ex-def\" baseline is surprisingly strong in this timeframe. This finding contrasts with previous research (Thornton et al., 2013), which used a 30-hour timeout. Our results suggest that simple baselines are stronger than previously thought.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation reveals that black box optimizers rarely outperform Naive AutoML for 1-hour runtimes. Moreover, the \"Ex-def\" baseline is surprisingly strong in this timeframe. This finding contrasts with previous research (Thornton et al., 2013), which used a 30-hour timeout. Our results suggest that simple baselines are stronger than previously thought.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation shows that black box optimizers rarely outperform Naive AutoML within a 1-hour runtime constraint. Notably, the \"Ex-def\" baseline performs surprisingly well in this timeframe, which contrasts with previous research (Thornton et al., 2013) that used a 30-hour timeout. Our findings indicate that simple baselines may be stronger than previously thought.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation reveals that black box optimizers rarely outperform Naive AutoML for 1-hour runtimes. Moreover, the \"Ex-def\" baseline is surprisingly strong in this timeframe. This finding contrasts with previous research (Thornton et al., 2013), which used a 30-hour timeout. Our results suggest that simple baselines are stronger than previously thought.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation reveals that black box optimizers rarely outperform Naive AutoML for 1-hour runtimes. Moreover, the \"Ex-def\" baseline is surprisingly strong in this timeframe. This finding contrasts with previous research (Thornton et al., 2013), which used a 30-hour timeout. Our results suggest that simple baselines are stronger than previously thought.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation shows that black box optimizers rarely outperform Naive AutoML within a 1-hour runtime constraint. Notably, the \"Ex-def\" baseline performs surprisingly well in this timeframe, which contrasts with previous research (Thornton et al., 2013) that used a 30-hour timeout. Our findings indicate that simple baselines may be stronger than previously thought.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our experimental evaluation reveals that black box optimizers rarely outperform Naive AutoML for 1-hour runtimes. Moreover, the \"Ex-def\" baseline is surprisingly strong in this timeframe. This finding contrasts with previous research (Thornton et al., 2013), which used a 30-hour timeout. Our results suggest that simple baselines are stronger than previously thought.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "instruction": "Rewrite the last sentence, making it more concise.", "revised_paragraph": "Revised paragraph: \"The surprising result of our experimental evaluation is that, for 1h runtimes, black box optimizers rarely improve upon Naive AutoML. The \"Ex-def\" baseline is surprisingly strong in this timeframe, which is not a contradiction to Thornton et al.'s (2013) findings, as they used a 30-hour timeout. Our results suggest that simple baselines are stronger than previously thought, warranting more extensive experiments with longer runtimes.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.01", "instruction": "Make the last sentence more concise.", "revised_paragraph": "Revised paragraph: \"The surprising result of our experimental evaluation is that, for runtimes of 1h, black box optimizers rarely outperform Naive AutoML. The \"Ex-def\" baseline is surprisingly strong in this time frame, which is not a contradiction to Thornton et al. (2013), where a 30-hour timeout was used. This observation highlights the need for more exhaustive experiments with longer runtimes, but it is already clear that simple baselines are stronger than previously thought.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The diffusion distance is defined based on the intuition that two nodes are similar if they diffuse through the graph in a similar way, influencing other nodes in a similar manner (Fouss et al., 2012). In essence, two nodes are close if they belong to the same cluster with a consistent local structure."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The diffusion distance is defined based on the intuition that two nodes are similar if they diffuse through the graph in a similar way, influencing other nodes in a similar manner (Fouss et al., 2012). In essence, two nodes are close if they belong to the same cluster with a consistent local structure."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The diffusion distance is defined based on the intuition that two nodes are similar if they diffuse through the graph in a similar way, influencing other nodes in a similar manner (Fouss et al., 2012). In essence, two nodes are close if they belong to the same cluster with a consistent local structure."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The diffusion distance is defined based on the intuition that two nodes are similar if they diffuse through the graph in a similar way, influencing other nodes in a similar manner (Fouss et al., 2012). In essence, two nodes are close if they belong to the same cluster with a consistent local structure."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The diffusion distance is defined based on the intuition that two nodes are similar if they diffuse through the graph in a similar way, influencing other nodes in a similar manner (Fouss et al., 2012). In essence, two nodes are close if they belong to the same cluster with a consistent local structure."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The diffusion distance is defined based on the intuition that two nodes are similar if they diffuse through the graph in a similar way, influencing other nodes in a similar manner (Fouss et al., 2012). In essence, two nodes are close if they belong to the same cluster with a consistent local structure."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The diffusion distance is defined based on the intuition that two nodes are similar if they diffuse through the graph in a similar way, influencing other nodes in a similar manner (Fouss et al., 2012). In essence, two nodes are close if they belong to the same cluster with a consistent local structure."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The diffusion distance is defined based on the intuition that two nodes are similar if they diffuse through the graph in a similar way, influencing other nodes in a similar manner (Fouss et al., 2012). In essence, two nodes are close if they belong to the same cluster with a consistent local structure."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "instruction": "Remove the ideas which are not particularly essential for the overall paragraph.", "revised_paragraph": "Revised paragraph: \"Before we de\ufb01ne the diffusion distance, we introduce the intuition behind it: two nodes are considered similar when they diffuse in a similar way through the graph, and therefore when they in\ufb02uence the other nodes in a similar manner (Fouss et al., 2012). The diffusion distance at time K between nodes i and j is defined as...\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "l1D720s69O.vCKjjOP1ze.02", "instruction": "Delete the first part of the first sentence and adapt it in consequence.", "revised_paragraph": "Revised paragraph: Two nodes are considered similar when they diffuse in a similar way through the graph, and therefore when they influence the other nodes in a similar manner (Fouss et al., 2012). In other words, two nodes are close if they are in the same cluster which has a consistent local structure. The diffusion distance at time K between nodes i and j is defined as follows:", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To identify potential correspondences, we propose a straightforward approach: grouping validation samples into M equal-sized bins (referred to as validation-bins) and comparing the confidence levels with those of the training samples that fall within the same bins. Prior to this analysis, we clarify a few key notations of relevance.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To identify potential correspondences, we propose a straightforward approach: grouping validation samples into M equal-sized bins (referred to as validation-bins) and comparing the confidence levels with those of the training samples that fall within the same bins. Prior to this analysis, we clarify a few key notations of relevance.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To identify potential correspondences, we propose a straightforward approach: grouping validation samples into M equal-sized bins (referred to as validation-bins) and comparing the confidence levels with those of the training samples that fall within the same bins. Prior to this analysis, we clarify a few key notations of relevance.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To identify potential correspondences, we propose a straightforward approach: grouping validation samples into M equal-sized bins (referred to as validation-bins) and comparing the confidence levels with those of the training samples that fall within the same bins. Prior to this analysis, we clarify a few key notations of relevance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To identify potential correspondences, we propose a straightforward approach: grouping validation samples into M equal-sized bins (referred to as validation-bins) and comparing the confidence levels with those of the training samples that fall within the same bins. Prior to this analysis, we clarify a few key notations of relevance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To identify potential correspondences, we propose a straightforward approach: grouping validation samples into M equal-sized bins (referred to as validation-bins) and comparing the confidence levels with those of the training samples that fall within the same bins. Prior to this analysis, we clarify a few key notations of relevance.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To identify potential correspondences, we propose a straightforward approach: grouping validation samples into M equal-sized bins (referred to as validation-bins) and comparing the confidence levels with those of the training samples that fall within the same bins. Prior to this analysis, we clarify a few key notations of relevance.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To identify potential correspondences, we propose a straightforward approach: grouping validation samples into M equal-sized bins (referred to as validation-bins) and comparing the confidence levels with those of the training samples that fall within the same bins. Prior to this analysis, we clarify a few key notations of relevance.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "instruction": "Make the language of this paragraph more formal.", "revised_paragraph": "Revised paragraph: To facilitate the identification of potential correspondences, a straightforward approach is to partition the validation samples into M equal-sized bins, hereinafter referred to as validation-bins, and subsequently compare the confidence values with those obtained from the training samples that fall within the same bins. Prior to implementing this strategy, it is essential to establish a clear understanding of the relevant notations.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aFzc_2nNz.WIdHkazOg.01", "instruction": "Improve the writinng in the linking of the two last sentences to make it more formal.", "revised_paragraph": "Revised paragraph: One way to verify any potential correspondences is to group the validation samples into M equal-mass bins, referred to as validation-bins, and compare the confidence scores with those of the training samples that fall within the same validation-bins. Prior to conducting this analysis, it is essential to clarify a few notations of interest.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The NTK is defined using the gradient of the DNN output with respect to the weight parameter space, whereas the linear approximation lemma in this paper uses the gradient with respect to the input parameter space. Although NTK analysis is limited to gradient descent, our analysis can be applied to stochastic gradient descent."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The NTK is defined using the gradient of the DNN output with respect to the weight parameter space, whereas the linear approximation lemma in this paper uses the gradient with respect to the input parameter space. Although NTK analysis is limited to gradient descent, our analysis can be applied to stochastic gradient descent."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The NTK is defined using the gradient of the DNN output with respect to the weight parameter space, whereas the linear approximation lemma in this paper uses the gradient with respect to the input parameter space. Although NTK analysis is limited to gradient descent, our analysis can be applied to stochastic gradient descent."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The NTK is defined using the gradient of the DNN output with respect to the weight parameter space, whereas the linear approximation lemma in this paper uses the gradient with respect to the input parameter space. Although NTK analysis is limited to gradient descent, our analysis can be applied to stochastic gradient descent."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The NTK is defined using the gradient of the DNN output with respect to the weight parameter space, whereas the linear approximation lemma in this paper uses the gradient with respect to the input parameter space. Although NTK analysis is limited to gradient descent, our analysis can be applied to stochastic gradient descent."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The NTK is defined using the gradient of the DNN output with respect to the weight parameter space, whereas the linear approximation lemma in this paper uses the gradient with respect to the input parameter space. Although NTK analysis is limited to gradient descent, our analysis can be applied to stochastic gradient descent."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The NTK is defined using the gradient of the DNN output with respect to the weight parameter space, whereas the linear approximation lemma in this paper uses the gradient with respect to the input parameter space. Although NTK analysis is limited to gradient descent, our analysis can be applied to stochastic gradient descent."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The NTK is defined using the gradient of the DNN output with respect to the weight parameter space, whereas the linear approximation lemma in this paper uses the gradient with respect to the input parameter space. Although NTK analysis is limited to gradient descent, our analysis can be applied to stochastic gradient descent."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "instruction": "Please exclude the content that seems unnecessary.", "revised_paragraph": "Revised paragraph: The NTK is defined using the gradient of the DNN output with respect to the weight parameter space, whereas the linear approximation lemma in this paper uses the gradient with respect to the input parameter space, differing in the variables to be differentiated.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "S1CMuZFor.H1NchtnoS.01", "instruction": "Remove the second item of the list.", "revised_paragraph": "Revised paragraph: \"\u2022 The NTK is de\ufb01ned using the gradient of the DNN output with respect to weight parameter space. In contrast, the linear approximation Lemma in this paper is de\ufb01ned using the gradient of the DNN output with respect to input parameter space. This difference in variables to be differentiated is a key distinction between the two approaches. The random walk analysis indicates that over-parameterized ReLU DNNs interpolate almost linearly between the data points. For ReLU activation, since the NTK kernel mapping is not Lipschitz but 1 / 2 -H \u00a8 older, it is dif\ufb01cult to obtain such a result in the NTK analysis without a tradeoff between smoothness and approximation (Bietti & Mairal, 2019).\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We proposed a new inference algorithm for normalizing flow models, motivated by a theoretical hardness result for exact inference. We also presented a detailed empirical evaluation of our method, showcasing its effectiveness on various tasks and datasets. Our approach, leveraging pre-trained generators to create structured noise, is a useful and general method for solving new generative problems.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We proposed a new inference algorithm for normalizing flow models, motivated by a theoretical hardness result for exact inference. We also presented a detailed empirical evaluation of our method, showcasing its effectiveness on various tasks and datasets. Our approach, leveraging pre-trained generators to create structured noise, is a useful and general method for solving new generative problems.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We proposed a new inference algorithm for normalizing flow models, motivated by a theoretical hardness result for exact inference. We also presented a detailed empirical evaluation of our method, showcasing its effectiveness on various tasks and datasets. Our approach, leveraging pre-trained generators to create structured noise, is a useful and general method for solving new generative problems.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We proposed a new inference algorithm for normalizing flow models, motivated by a theoretical hardness result for exact inference. We also presented a detailed empirical evaluation of our method, showcasing its effectiveness on various tasks and datasets. Our approach, leveraging pre-trained generators to create structured noise, is a useful and general method for solving new generative problems.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We proposed a new inference algorithm for normalizing flow models, motivated by a theoretical hardness result for exact inference. We also presented a detailed empirical evaluation of our method, showcasing its effectiveness on various tasks and datasets. Our approach, leveraging pre-trained generators to create structured noise, is a useful and general method for solving new generative problems.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We proposed a new inference algorithm for normalizing flow models, motivated by a theoretical hardness result for exact inference. We also presented a detailed empirical evaluation of our method, showcasing its effectiveness on various tasks and datasets. Our approach, leveraging pre-trained generators to create structured noise, is a useful and general method for solving new generative problems.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We proposed a new inference algorithm for normalizing flow models, motivated by a theoretical hardness result for exact inference. We also presented a detailed empirical evaluation of our method, showcasing its effectiveness on various tasks and datasets. Our approach, leveraging pre-trained generators to create structured noise, is a useful and general method for solving new generative problems.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We proposed a new inference algorithm for normalizing flow models, motivated by a theoretical hardness result for exact inference. We also presented a detailed empirical evaluation of our method, showcasing its effectiveness on various tasks and datasets. Our approach, leveraging pre-trained generators to create structured noise, is a useful and general method for solving new generative problems.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "instruction": "Remove details which are unnecessary for the overall paragraph. Fix any spelling mistakes.", "revised_paragraph": "Revised paragraph: \"We proposed a new inference algorithm for distributions parametrized by normalizing flow models, motivated by a theoretical hardness result for exact inference. We also presented a detailed empirical evaluation of our method with both quantitative and qualitative results on a wide range of tasks and datasets. We believe that our approach is a useful and general method for leveraging pre-trained generators to solve new generative problems.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "jP_amc4U0A.Y2t7AFVo5Z.00", "instruction": "Correct and concise the two first sentences.", "revised_paragraph": "Revised paragraph: We introduce a novel inference algorithm for distributions parameterized by normalizing flow models, motivated by a theoretical hardness result for exact inference that is surprising given the invertibility of these models. Our algorithm is thoroughly evaluated through a combination of quantitative and qualitative results on a diverse range of tasks and datasets, demonstrating its effectiveness.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"A limitation of current AutoML performance assessments is the lack of'simple' baselines, such as imitating human data scientist steps or using default parametrized models. This makes it difficult to determine how AutoML tools improve upon ad-hoc techniques, as comparisons are only made between AutoML tools. Thornton et al. (2013) is an exception, using the Exhaustive-Default baseline, which takes the best default model in cross-validation. However, grid search is not a practical option.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Notably, the benchmarks used to evaluate the performance of AutoML tools are often limited to other AutoML tools, neglecting the consideration of'simple' baselines. A straightforward example of a baseline would be to mimic the steps a human data scientist would take, thereby providing a relevant point of comparison. The absence of such baselines hinders our understanding of how AutoML tools improve upon ad-hoc techniques, instead only allowing for relative comparisons among tools. To our knowledge, the only study that addresses this issue is that of Thornton et al. (2013), which introduces the Exhaustive-Default ('Ex-def') baseline, which involves selecting the default parametrized model that performs best in cross-validation. Additionally, they discuss grid search, although it is not a practical approach.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Notably, the benchmarks used to evaluate the performance of AutoML tools are often limited to other AutoML tools, neglecting the consideration of'simple' baselines. A straightforward example of a baseline would be to mimic the steps a human data scientist would take, thereby providing a relevant point of comparison. The absence of such baselines hinders our understanding of how AutoML tools improve upon ad-hoc techniques, instead only allowing for relative comparisons among tools. To our knowledge, the only study that addresses this issue is that of Thornton et al. (2013), which introduces the Exhaustive-Default ('Ex-def') baseline, which involves selecting the default parametrized model that performs best in cross-validation. Additionally, they discuss grid search, although it is not a practical approach.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Notably, the benchmarks used to evaluate the performance of AutoML tools are often limited to other AutoML tools, neglecting the consideration of'simple' baselines. A straightforward example of a baseline would be to mimic the steps a human data scientist would take, thereby providing a relevant point of comparison. The absence of such baselines hinders our understanding of how AutoML tools improve upon ad-hoc techniques, instead only allowing for relative comparisons among tools. To our knowledge, the only study that addresses this issue is that of Thornton et al. (2013), which introduces the Exhaustive-Default ('Ex-def') baseline, which involves selecting the default parametrized model that performs best in cross-validation. Additionally, they discuss grid search, although it is not a practical approach.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"A limitation of current AutoML performance assessments is the lack of'simple' baselines, such as imitating human data scientist steps or using default parametrized models. This makes it difficult to determine how AutoML tools improve upon ad-hoc techniques, as comparisons are only made between AutoML tools. Thornton et al. (2013) is an exception, using the Exhaustive-Default baseline, which takes the best default model in cross-validation. However, grid search is not a practical option.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Notably, the benchmarks used to evaluate the performance of AutoML tools are often limited to other AutoML tools, neglecting the consideration of'simple' baselines. A straightforward example of a baseline would be to mimic the steps a human data scientist would take, thereby providing a relevant point of comparison. The absence of such baselines hinders our understanding of how AutoML tools improve upon ad-hoc techniques, instead only allowing for relative comparisons among tools. To our knowledge, the only study that addresses this issue is that of Thornton et al. (2013), which introduces the Exhaustive-Default ('Ex-def') baseline, which involves selecting the default parametrized model that performs best in cross-validation. Additionally, they discuss grid search, although it is not a practical approach.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"A limitation of current AutoML performance assessments is the lack of'simple' baselines, such as imitating human data scientist steps or using default parametrized models. This makes it difficult to determine how AutoML tools improve upon ad-hoc techniques, as comparisons are only made between AutoML tools. Thornton et al. (2013) is an exception, using the Exhaustive-Default baseline, which takes the best default model in cross-validation. However, grid search is not a practical option.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"A limitation of current AutoML performance assessments is the absence of straightforward baselines, such as mimicking human data scientist workflows or utilizing default, parametrized models. This hinders the ability to determine the extent to which AutoML tools surpass ad-hoc techniques, as comparisons are typically limited to AutoML tools alone. Notably, Thornton et al. (2013) is an exception, employing the Exhaustive-Default baseline, which selects the best default model through cross-validation. However, grid search is not a practical option due to its computational demands.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Notably, the benchmarks used to evaluate the performance of AutoML tools are often limited to other AutoML tools, neglecting the consideration of'simple' baselines. A straightforward example of a baseline would be to mimic the steps a human data scientist would take, thereby providing a relevant point of comparison. The absence of such baselines hinders our understanding of how AutoML tools improve upon ad-hoc techniques, instead only allowing for relative comparisons among tools. To our knowledge, the only study that addresses this issue is that of Thornton et al. (2013), which introduces the Exhaustive-Default ('Ex-def') baseline, which involves selecting the default parametrized model that performs best in cross-validation. Additionally, they discuss grid search, although it is not a practical approach.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Notably, the benchmarks used to evaluate the performance of AutoML tools are often limited to other AutoML tools, neglecting the consideration of'simple' baselines. A straightforward example of a baseline would be to mimic the steps a human data scientist would take, thereby providing a relevant point of comparison. The absence of such baselines hinders our understanding of how AutoML tools improve upon ad-hoc techniques, instead only allowing for relative comparisons among tools. To our knowledge, the only study that addresses this issue is that of Thornton et al. (2013), which introduces the Exhaustive-Default ('Ex-def') baseline, which involves selecting the default parametrized model that performs best in cross-validation. Additionally, they discuss grid search, although it is not a practical approach.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"A limitation of current AutoML performance assessments is the lack of'simple' baselines, such as imitating human data scientist steps or using default parametrized models. This makes it difficult to determine how AutoML tools improve upon ad-hoc techniques, as comparisons are only made between AutoML tools. Thornton et al. (2013) is an exception, using the Exhaustive-Default baseline, which takes the best default model in cross-validation. However, grid search is not a practical option.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"A limitation of current AutoML performance assessments is the absence of straightforward baselines, such as mimicking human data scientist workflows or utilizing default, parametrized models. This hinders the ability to determine the extent to which AutoML tools surpass ad-hoc techniques, as comparisons are typically limited to AutoML tools alone. Notably, Thornton et al. (2013) is an exception, employing the Exhaustive-Default baseline, which selects the best default model through cross-validation. However, grid search is not a practical option due to its computational demands.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "instruction": "Edit some formulations to sound more neutral.", "revised_paragraph": "Revised paragraph: \"Notably, the baselines used to evaluate the performance of AutoML tools are often limited to other AutoML tools, without considering \"simple\" baselines that mimic the steps a human data scientist would take. Such a baseline could provide a more comprehensive understanding of how AutoML tools improve upon ad-hoc techniques. Currently, the literature lacks a diverse range of baselines, with Thornton et al. (2013) being an exception, who employed the Exhaustive-Default (\"Ex-def\") baseline, which involves selecting the default parametrized model that performs best in cross-validation. However, their discussion of a grid search is not practically applicable.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "instruction": "Make the beginning of the paragraph shorter.", "revised_paragraph": "Revised paragraph: The baselines used to evaluate AutoML tools are often limited to other AutoML tools, neglecting \"simple\" baselines that mimic human data scientists' steps. This oversight hinders our understanding of how AutoML tools improve upon ad-hoc techniques, as we only compare their performance relative to each other. Notably, Thornton et al. (2013) introduced the Exhaustive-Default (\"Ex-def\") baseline, which involves selecting the default, parametrized model that performs best in cross-validation. They also discussed grid search, although it is impractical in real-world scenarios.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we explore the practical instantiation of SafeNet. Prior to implementation, data owners must reach an agreement on two key aspects: the MPC framework used for secure training and prediction, and the parameters specified in Theorem 6 to ensure poisoning robustness. Specifically, the MPC framework is determined by selecting the total number of outsourced servers (N) participating in the MPC, the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm. Additionally, owners must agree on a filtering threshold (\u03c6) and the maximum number of poisoned owners (t) that can be tolerated. Once these parameters are established, the maximum allowed error probability of local models trained by honest owners, as outlined in Lemma 5, can be determined."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we explore the practical instantiation of SafeNet. Prior to implementation, data owners must reach an agreement on two key aspects: the MPC framework used for secure training and prediction, and the parameters specified in Theorem 6 to ensure poisoning robustness. Specifically, the MPC framework is determined by selecting the total number of outsourced servers (N) participating in the MPC, the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm. Additionally, owners must agree on a filtering threshold (\u03c6) and the maximum number of poisoned owners (t) that can be tolerated. Once these parameters are established, the maximum allowed error probability of local models trained by honest owners, as outlined in Lemma 5, can be determined."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we explore the practical instantiation of SafeNet. Prior to implementation, data owners must reach an agreement on two key aspects: the MPC framework used for secure training and prediction, and the parameters specified in Theorem 6 to ensure poisoning robustness. Specifically, the MPC framework is determined by selecting the total number of outsourced servers (N) participating in the MPC, the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm. Additionally, owners must agree on a filtering threshold (\u03c6) and the maximum number of poisoned owners (t) that can be tolerated. Once these parameters are established, the maximum allowed error probability of local models trained by honest owners, as outlined in Lemma 5, can be determined."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we explore the practical instantiation of SafeNet. Prior to implementation, data owners must reach an agreement on two key aspects: the MPC framework used for secure training and prediction, and the parameters specified in Theorem 6 to ensure poisoning robustness. Specifically, the MPC framework is determined by selecting the total number of outsourced servers (N) participating in the MPC, the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm. Additionally, owners must agree on a filtering threshold (\u03c6) and the maximum number of poisoned owners (t) that can be tolerated. Once these parameters are established, the maximum allowed error probability of local models trained by honest owners, as outlined in Lemma 5, can be determined."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we explore the practical instantiation of SafeNet. Prior to implementation, data owners must reach an agreement on two key aspects: the MPC framework used for secure training and prediction, and the parameters specified in Theorem 6 to ensure poisoning robustness. Specifically, the MPC framework is determined by selecting the total number of outsourced servers (N) participating in the MPC, the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm. Additionally, owners must agree on a filtering threshold (\u03c6) and the maximum number of poisoned owners (t) that can be tolerated. Once these parameters are established, the maximum allowed error probability of local models trained by honest owners, as outlined in Lemma 5, can be determined."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we explore the practical instantiation of SafeNet. Prior to implementation, data owners must reach an agreement on two key aspects: the MPC framework used for secure training and prediction, and the parameters specified in Theorem 6 to ensure poisoning robustness. Specifically, the MPC framework is determined by selecting the total number of outsourced servers (N) participating in the MPC, the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm. Additionally, owners must agree on a filtering threshold (\u03c6) and the maximum number of poisoned owners (t) that can be tolerated. Once these parameters are established, the maximum allowed error probability of local models trained by honest owners, as outlined in Lemma 5, can be determined."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we explore the practical instantiation of SafeNet. Prior to implementation, data owners must reach an agreement on two key aspects: the MPC framework used for secure training and prediction, and the parameters specified in Theorem 6 to ensure poisoning robustness. Specifically, the MPC framework is determined by selecting the total number of outsourced servers (N) participating in the MPC, the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm. Additionally, owners must agree on a filtering threshold (\u03c6) and the maximum number of poisoned owners (t) that can be tolerated. Once these parameters are established, the maximum allowed error probability of local models trained by honest owners, as outlined in Lemma 5, can be determined."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we explore the practical instantiation of SafeNet. Prior to implementation, data owners must reach an agreement on two key aspects: the MPC framework used for secure training and prediction, and the parameters specified in Theorem 6 to ensure poisoning robustness. Specifically, the MPC framework is determined by selecting the total number of outsourced servers (N) participating in the MPC, the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm. Additionally, owners must agree on a filtering threshold (\u03c6) and the maximum number of poisoned owners (t) that can be tolerated. Once these parameters are established, the maximum allowed error probability of local models trained by honest owners, as outlined in Lemma 5, can be determined."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "instruction": "Rewrite the middle sentence of this paragraph to make it clearer.", "revised_paragraph": "Revised paragraph: In this section, we discuss how SafeNet can be instantiated in practice. There are two crucial aspects that data owners need to agree upon before instantiating SafeNet: i) the MPC framework used for secure training and prediction, which involves choosing the total number of outsourced servers (N), the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm; and ii) the parameters in Theorem 6 to achieve poisoning robustness, including a filtering threshold (\u03d5) and the number of poisoned owners (t) that can be tolerated.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "txe2sPPkO.id6Xr1pUq.00", "instruction": "Rewrite the long sentence in the middle sentence to improve clarity.", "revised_paragraph": "Revised paragraph: In this section, we discuss how SafeNet can be instantiated in practice. There are two essential aspects that data owners must agree upon before instantiation: the choice of MPC framework for secure training and prediction, and the parameters required to achieve poisoning robustness, as outlined in Theorem 6. The MPC framework is determined by selecting the total number of outsourced servers (N), the number of corrupted servers (T), and the nature of the adversary (semihonest or malicious) in the SOC paradigm. Subsequently, the owners agree on a filtering threshold (\u03c6) and the maximum number of poisoned owners (t) that can be tolerated. Once these parameters are settled, the maximum allowed error probability of local models trained by honest owners can be determined using Lemma 5.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We propagate semantic labels from labeled data C to unlabeled data U by exploiting relationships between pixels and segments. Our label propagation is driven by grouping and separating data in a learned feature space. We describe each pixel-to-segment relationship for augmenting positive and negative segments using both labeled and unlabeled pixels."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We propagate semantic labels from labeled data C to unlabeled data U by exploiting relationships between pixels and segments. Our label propagation is driven by grouping and separating data in a learned feature space. We describe each pixel-to-segment relationship for augmenting positive and negative segments using both labeled and unlabeled pixels."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We propagate semantic labels from labeled data C to unlabeled data U by exploiting relationships between pixels and segments. Our label propagation is driven by grouping and separating data in a learned feature space. We describe each pixel-to-segment relationship for augmenting positive and negative segments using both labeled and unlabeled pixels."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We propagate semantic labels from labeled data C to unlabeled data U by exploiting relationships between pixels and segments. Our label propagation is driven by grouping and separating data in a learned feature space. We describe each pixel-to-segment relationship for augmenting positive and negative segments using both labeled and unlabeled pixels."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We propagate semantic labels from labeled data C to unlabeled data U by exploiting relationships between pixels and segments. Our label propagation is driven by grouping and separating data in a learned feature space. We describe each pixel-to-segment relationship for augmenting positive and negative segments using both labeled and unlabeled pixels."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We propagate semantic labels from labeled data C to unlabeled data U by exploiting relationships between pixels and segments. Our label propagation is driven by grouping and separating data in a learned feature space. We describe each pixel-to-segment relationship for augmenting positive and negative segments using both labeled and unlabeled pixels."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We propagate semantic labels from labeled data C to unlabeled data U by exploiting relationships between pixels and segments. Our label propagation is driven by grouping and separating data in a learned feature space. We describe each pixel-to-segment relationship for augmenting positive and negative segments using both labeled and unlabeled pixels."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We propagate semantic labels from labeled data C to unlabeled data U by exploiting relationships between pixels and segments. Our label propagation is driven by grouping and separating data in a learned feature space. We describe each pixel-to-segment relationship for augmenting positive and negative segments using both labeled and unlabeled pixels."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "instruction": "Make this paragraph considerably more concise. Remove any information that is not essential to this paragraph itself.", "revised_paragraph": "Revised paragraph: We propagate semantic labels from labeled data C to unlabeled data U by exploiting relationships between pixels and segments. Our label propagation is based on grouping and separating data in a learned feature space, driven by pixel-to-segment semantic relationships.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.07", "instruction": "Delete the third sentence. Concise the first and last one.", "revised_paragraph": "Revised paragraph: We consider propagating semantic labels from labeled data C to unlabeled data U, exploiting relationships between them. Our label propagation is driven by grouping and separating data in a learned feature space.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Since AlexNet won the ImageNet competition in 2012, CNN-based architectures have become popular for automatically extracting image features. The VGG network (Simonyan & Zisserman, 2015) and ResNet (He et al., 2016) further improved performance by using convolution and fully connected layers, and residual connections, respectively. These innovations have become essential components of network design, and subsequent architectures have built upon them, including transformer-based and MLP-based models. Notably, EfficientNet (Tan & Le, 2019; 2021) introduced neural architecture search to optimize CNN structure.\""}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"CNN-based architectures have gained popularity since AlexNet's success in the 2012 ImageNet competition. The VGG network, proposed in 2015, uses a series of convolution and fully connected layers to achieve outstanding performance in image classification. ResNet, introduced in 2016, utilizes residual connections to alleviate gradient vanishing and improve performance. The residual module has since become a crucial component in network design, appearing in transformer-based and MLP-based architectures. Notably, researchers have also explored improvements to the convolution operation, such as dilated and deformable convolutions, and more recently, introduced neural architecture search to CNNs with EfficientNet.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Since AlexNet won the ImageNet competition in 2012, CNN-based architectures have become popular for automatically extracting image features. The VGG network (Simonyan & Zisserman, 2015) and ResNet (He et al., 2016) further improved performance by using convolution and fully connected layers, and residual connections, respectively. These innovations have become essential components of network design, and subsequent architectures have built upon them, including transformer-based and MLP-based models. Notably, EfficientNet (Tan & Le, 2019; 2021) introduced neural architecture search to optimize CNN structure.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Since AlexNet won the ImageNet competition in 2012, CNN-based architectures have become popular for automatically extracting image features. The VGG network (Simonyan & Zisserman, 2015) and ResNet (He et al., 2016) further improved performance by using convolution and fully connected layers, and residual connections, respectively. These innovations have become essential components of network design, and subsequent architectures have built upon them, including transformer-based and MLP-based models. Notably, EfficientNet (Tan & Le, 2019; 2021) introduced neural architecture search to optimize CNN structure.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"CNN-based architectures have gained popularity since AlexNet's success in the 2012 ImageNet competition. The VGG network, proposed in 2015, uses a series of convolution and fully connected layers to achieve outstanding performance in image classification. ResNet, introduced in 2016, utilizes residual connections to alleviate gradient vanishing and improve performance. The residual module has since become a crucial component in network design, appearing in transformer-based and MLP-based architectures. Notably, researchers have also explored improvements to the convolution operation, such as dilated and deformable convolutions, and more recently, introduced neural architecture search to CNNs with EfficientNet.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Since AlexNet won the ImageNet competition in 2012, CNN-based architectures have become popular for automatically extracting image features. The VGG network (Simonyan & Zisserman, 2015) and ResNet (He et al., 2016) further improved performance by using convolution and fully connected layers, and residual connections, respectively. These innovations have become essential components of network design, and subsequent architectures have built upon them, including transformer-based and MLP-based models. Notably, EfficientNet (Tan & Le, 2019; 2021) introduced neural architecture search to optimize CNN structure.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Since AlexNet won the ImageNet competition in 2012, CNN-based architectures have become popular for automatically extracting image features. The VGG network (Simonyan & Zisserman, 2015) and ResNet (He et al., 2016) further improved performance by using convolution and fully connected layers, and residual connections, respectively. These innovations have become essential components of network design, and subsequent architectures have built upon them, including transformer-based and MLP-based models. Notably, EfficientNet (Tan & Le, 2019; 2021) introduced neural architecture search to optimize CNN structure.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Since AlexNet won the ImageNet competition in 2012, CNN-based architectures have gained popularity for automatically extracting image features. Innovations such as the VGG network (Simonyan & Zisserman, 2015) and ResNet (He et al., 2016) have become essential components of network design. Notably, EfficientNet (Tan & Le, 2019; 2021) introduced neural architecture search to optimize CNN structure.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Since AlexNet won the ImageNet competition in 2012, CNN-based architectures have become popular for automatically extracting image features. The VGG network (Simonyan & Zisserman, 2015) and ResNet (He et al., 2016) further improved performance by using convolution and fully connected layers, and residual connections, respectively. These innovations have become essential components of network design, and subsequent architectures have built upon them, including transformer-based and MLP-based models. Notably, EfficientNet (Tan & Le, 2019; 2021) introduced neural architecture search to optimize CNN structure.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Since AlexNet won the ImageNet competition in 2012, CNN-based architectures have become popular for automatically extracting image features. The VGG network (Simonyan & Zisserman, 2015) and ResNet (He et al., 2016) further improved performance by using convolution and fully connected layers, and residual connections, respectively. These innovations have become essential components of network design, and subsequent architectures have built upon them, including transformer-based and MLP-based models. Notably, EfficientNet (Tan & Le, 2019; 2021) introduced neural architecture search to optimize CNN structure.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"CNN-based architectures have gained popularity since AlexNet's success in the 2012 ImageNet competition. The VGG network, proposed in 2015, uses a series of convolution and fully connected layers to achieve outstanding performance in image classification. ResNet, introduced in 2016, utilizes residual connections to alleviate gradient vanishing and improve performance. The residual module has since become a crucial component in network design, appearing in transformer-based and MLP-based architectures. Notably, researchers have also explored improvements to the convolution operation, such as dilated and deformable convolutions, and more recently, introduced neural architecture search to CNNs with EfficientNet.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Since AlexNet's success in 2012, CNN-based architectures have gained popularity. Notable examples include VGG (2015), which uses convolution and fully connected layers, and ResNet (2016), which utilizes residual connections to alleviate gradient vanishing and improve performance. The residual module has since become a crucial component, appearing in various architectures, including transformer-based and MLP-based ones. Researchers have also explored improvements to the convolution operation and introduced neural architecture search with EfficientNet.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "instruction": "Make this paragraph more concise.", "revised_paragraph": "Revised paragraph: \"Since AlexNet's success in the 2012 ImageNet competition, CNN-based architectures have replaced hand-crafted features with automatic image feature extraction. VGG (2015) and ResNet (2016) further improved performance by using 3 \u00d7 3 convolution and residual connections, respectively. These innovations have become fundamental components in subsequent transformer-based and MLP-based architectures. Later, dilated and deformable convolutions (2016, 2017) enhanced the convolution operation, and EfficientNet (2019, 2021) introduced neural architecture search to optimize CNN structures.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "tOMAf1V5dI.SNeLZ71pb5.00", "instruction": "Remove the sentence about the residual module. Make the paragraph more concise.", "revised_paragraph": "Revised paragraph: \"CNN-based architectures have gained popularity since AlexNet (Krizhevsky et al., 2012) won the ImageNet competition. The VGG network (Simonyan & Zisserman, 2015) and ResNet (He et al., 2016) have achieved outstanding performance in image classification, with ResNet utilizing residual connections to alleviate gradient vanishing. Subsequent architectures, including transformer-based and MLP-based models, have employed residual connections. Further improvements have been made to convolution operations, such as dilated and deformable convolutions. Ef\ufb01cientNet (Tan & Le, 2019; 2021) introduced neural architecture search to find a suitable structure.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We introduce a novel, universally applicable method for weakly-supervised semantic segmentation, known as Semisupervised Pixel-wise Metric Learning. This approach enables the derivation of four fundamental types of relationships between pixels and segments, regardless of the level of annotation provided. Whether using coarse image tags and bounding boxes or sparse keypoints and scribbles, our method yields consistent and significant improvements over state-of-the-art results, particularly when using the sparsest keypoint supervision. Our experiments on PASCAL VOC and DensePose datasets demonstrate the effectiveness of our approach.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We introduce a novel, universally applicable method for weakly-supervised semantic segmentation, known as Semisupervised Pixel-wise Metric Learning. This approach enables the derivation of four fundamental types of relationships between pixels and segments, regardless of the level of annotation provided. Whether using coarse image tags and bounding boxes or sparse keypoints and scribbles, our method yields consistent and significant improvements over state-of-the-art results, particularly when using the sparsest keypoint supervision. Our experiments on PASCAL VOC and DensePose datasets demonstrate the effectiveness of our approach.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We introduce a novel, universally applicable method for weakly-supervised semantic segmentation, known as Semisupervised Pixel-wise Metric Learning. This approach enables the derivation of four fundamental types of relationships between pixels and segments, regardless of the level of annotation provided. Whether using coarse image tags and bounding boxes or sparse keypoints and scribbles, our method yields consistent and significant improvements over state-of-the-art results, particularly when using the sparsest keypoint supervision. Our experiments on PASCAL VOC and DensePose datasets demonstrate the effectiveness of our approach.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We introduce a novel, universally applicable method for weakly-supervised semantic segmentation, known as Semisupervised Pixel-wise Metric Learning. This approach enables the derivation of four fundamental types of relationships between pixels and segments, regardless of the level of annotation provided. Whether using coarse image tags and bounding boxes or sparse keypoints and scribbles, our method yields consistent and significant improvements over state-of-the-art results, particularly when using the sparsest keypoint supervision. Our experiments on PASCAL VOC and DensePose datasets demonstrate the effectiveness of our approach.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We introduce a novel, universally applicable method for weakly-supervised semantic segmentation, known as Semisupervised Pixel-wise Metric Learning. This approach enables the derivation of four fundamental types of relationships between pixels and segments, regardless of the level of annotation provided. Whether using coarse image tags and bounding boxes or sparse keypoints and scribbles, our method yields consistent and significant improvements over state-of-the-art results, particularly when using the sparsest keypoint supervision. Our experiments on PASCAL VOC and DensePose datasets demonstrate the effectiveness of our approach.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We introduce a novel, universally applicable method for weakly-supervised semantic segmentation, known as Semisupervised Pixel-wise Metric Learning. This approach enables the derivation of four fundamental types of relationships between pixels and segments, regardless of the level of annotation provided. Whether using coarse image tags and bounding boxes or sparse keypoints and scribbles, our method yields consistent and significant improvements over state-of-the-art results, particularly when using the sparsest keypoint supervision. Our experiments on PASCAL VOC and DensePose datasets demonstrate the effectiveness of our approach.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We introduce a novel, universally applicable method for weakly-supervised semantic segmentation, known as Semisupervised Pixel-wise Metric Learning. This approach enables the derivation of four fundamental types of relationships between pixels and segments, regardless of the level of annotation provided. Whether using coarse image tags and bounding boxes or sparse keypoints and scribbles, our method yields consistent and significant improvements over state-of-the-art results, particularly when using the sparsest keypoint supervision. Our experiments on PASCAL VOC and DensePose datasets demonstrate the effectiveness of our approach.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We introduce a novel, universally applicable method for weakly-supervised semantic segmentation, known as Semisupervised Pixel-wise Metric Learning. This approach enables the derivation of four fundamental types of relationships between pixels and segments, regardless of the level of annotation provided. Whether using coarse image tags and bounding boxes or sparse keypoints and scribbles, our method yields consistent and significant improvements over state-of-the-art results, particularly when using the sparsest keypoint supervision. Our experiments on PASCAL VOC and DensePose datasets demonstrate the effectiveness of our approach.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "instruction": "Rewrite this paragraph to improve readability and make contributions more evident.", "revised_paragraph": "Revised paragraph: \n\nThis paper presents a novel, universally applicable weakly-supervised semantic segmentation method, dubbed Semisupervised Pixel-wise Metric Learning. By leveraging four fundamental types of pixel-to-segment attraction and repulsion relationships, our approach can effectively utilize partial annotations, including coarse image tags and bounding boxes, as well as sparse keypoints and scribbles. Our experimental results on the PASCAL VOC and DensePose datasets demonstrate consistent and substantial improvements over the state-of-the-art (SOTA), with the sparsest keypoint supervision yielding the most notable gains.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.18", "instruction": "Improve the logical flow of ideas in this text.", "revised_paragraph": "Revised paragraph: We propose a novel universal weakly-supervised semantic segmentation method, Semisupervised Pixel-wise Metric Learning, which leverages four types of pixel-to-segment attraction and repulsion relationships. These relationships can be derived from various types of partial annotations, including coarse image tags and bounding boxes, or sparse keypoints and scribbles. Our approach achieves consistent and substantial gains over the state-of-the-art (SOTA) on both PASCAL VOC and DensePose, with the most significant improvements observed when using the sparsest keypoint supervision.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"A gap in the literature exists regarding a practical completeness threshold for cost-optimal planning problems with actions having 0-cost. This limitation hinders the application of SAT-based planning, as optimality can only be proved after solving the compilation for the entire state space, which can be impractically large. Some approaches, such as those by Robinson et al. and Leofante et al., attempt to circumvent this issue by adding an over-approximation to the encoding. While these methods prove optimality when the over-approximation is unsatisfiable, they still require computing compilations for multiple horizons and may need to solve exponentially large compilations unless a tighter completeness threshold is available.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nA notable gap in the literature appears to be a practical completeness threshold for cost-optimal planning problems that involve actions with zero cost. This limitation hinders the application of SAT-based planning to such problems, as the absence of a reasonable completeness threshold necessitates proving optimality by solving the compilation for a horizon equal to the number of states in the state space. Unfortunately, this approach is impractical for most problems, as the state space can be exponentially larger than the original problem size. Some approaches have attempted to circumvent the need for a tight completeness threshold by incorporating an over-approximation of the transition relation underlying the planning problem into the encoding, as proposed by Robinson et al. and Leofante et al. In these approaches, optimality is proved when the over-approximation is found to be unsatisfiable. However, these methods still require computing compilations for multiple horizons and are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available. This is because the over-approximation is a relaxation of the original problem, which can be solvable even if the concrete problem is not."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nA notable gap in the literature appears to be a practical completeness threshold for cost-optimal planning problems that involve actions with zero cost. This limitation hinders the application of SAT-based planning to such problems, as the absence of a reasonable completeness threshold necessitates proving optimality by solving the compilation for a horizon equal to the number of states in the state space. Unfortunately, this approach is impractical for most problems, as the state space can be exponentially larger than the original problem size. Some approaches have attempted to circumvent the need for a tight completeness threshold by incorporating an over-approximation of the transition relation underlying the planning problem into the encoding, as proposed by Robinson et al. and Leofante et al. In these approaches, optimality is proved when the over-approximation is found to be unsatisfiable. However, these methods still require computing compilations for multiple horizons and are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available. This is because the over-approximation is a relaxation of the original problem, which can be solvable even if the concrete problem is not."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nA notable gap in the literature appears to be a practical completeness threshold for cost-optimal planning problems that involve actions with zero cost. This limitation hinders the application of SAT-based planning to such problems, as the absence of a reasonable completeness threshold necessitates proving optimality by solving the compilation for a horizon equal to the number of states in the state space. Unfortunately, this approach is impractical for most problems, as the state space can be exponentially larger than the original problem size. Some approaches have attempted to circumvent the need for a tight completeness threshold by incorporating an over-approximation of the transition relation underlying the planning problem into the encoding, as proposed by Robinson et al. and Leofante et al. In these approaches, optimality is proved when the over-approximation is found to be unsatisfiable. However, these methods still require computing compilations for multiple horizons and are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available. This is because the over-approximation is a relaxation of the original problem, which can be solvable even if the concrete problem is not."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"A gap in the literature exists regarding a practical completeness threshold for cost-optimal planning problems with actions having 0-cost. This limitation hinders the application of SAT-based planning, as optimality can only be proved after solving the compilation for the entire state space, which can be impractically large. Some approaches, such as those by Robinson et al. and Leofante et al., attempt to circumvent this issue by adding an over-approximation to the encoding. While these methods prove optimality when the over-approximation is unsatisfiable, they still require computing compilations for multiple horizons and may need to solve exponentially large compilations unless a tighter completeness threshold is available.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nA notable gap in the literature appears to be a practical completeness threshold for cost-optimal planning problems that involve actions with zero cost. This limitation hinders the application of SAT-based planning to such problems, as the absence of a reasonable completeness threshold necessitates proving optimality by solving the compilation for a horizon equal to the number of states in the state space. Unfortunately, this approach is impractical for most problems, as the state space can be exponentially larger than the original problem size. Some approaches have attempted to circumvent the need for a tight completeness threshold by incorporating an over-approximation of the transition relation underlying the planning problem into the encoding, as proposed by Robinson et al. and Leofante et al. In these approaches, optimality is proved when the over-approximation is found to be unsatisfiable. However, these methods still require computing compilations for multiple horizons and are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available. This is because the over-approximation is a relaxation of the original problem, which can be solvable even if the concrete problem is not."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"A gap in the literature exists regarding a practical completeness threshold for cost-optimal planning problems with actions having 0-cost. This limitation hinders the application of SAT-based planning, as optimality can only be proved after solving the compilation for the entire state space, which can be impractically large. Some approaches, such as those by Robinson et al. and Leofante et al., attempt to circumvent this issue by adding an over-approximation to the encoding. While these methods prove optimality when the over-approximation is unsatisfiable, they still require computing compilations for multiple horizons and may need to solve exponentially large compilations unless a tighter completeness threshold is available.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"A notable gap in the literature pertains to the practical completeness threshold for cost-optimal planning problems involving actions with zero cost. This limitation hinders the application of SAT-based planning, as proving optimality necessitates solving the compilation for the entire state space, which can be impractically large. Some approaches, such as those proposed by Robinson et al. and Leofante et al., attempt to circumvent this issue by incorporating an over-approximation into the encoding. While these methods ensure optimality when the over-approximation is unsatisfiable, they still require computing compilations for multiple horizons and may necessitate solving exponentially large compilations unless a tighter completeness threshold is available.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nA notable gap in the literature appears to be a practical completeness threshold for cost-optimal planning problems that involve actions with zero cost. This limitation hinders the application of SAT-based planning to such problems, as the absence of a reasonable completeness threshold necessitates proving optimality by solving the compilation for a horizon equal to the number of states in the state space. Unfortunately, this approach is impractical for most problems, as the state space can be exponentially larger than the original problem size. Some approaches have attempted to circumvent the need for a tight completeness threshold by incorporating an over-approximation of the transition relation underlying the planning problem into the encoding, as proposed by Robinson et al. and Leofante et al. In these approaches, optimality is proved when the over-approximation is found to be unsatisfiable. However, these methods still require computing compilations for multiple horizons and are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available. This is because the over-approximation is a relaxation of the original problem, which can be solvable even if the concrete problem is not."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nA notable gap in the literature appears to be a practical completeness threshold for cost-optimal planning problems that involve actions with zero cost. This limitation hinders the application of SAT-based planning to such problems, as the absence of a reasonable completeness threshold necessitates proving optimality by solving the compilation for a horizon equal to the number of states in the state space. Unfortunately, this approach is impractical for most problems, as the state space can be exponentially larger than the original problem size. Some approaches have attempted to circumvent the need for a tight completeness threshold by incorporating an over-approximation of the transition relation underlying the planning problem into the encoding, as proposed by Robinson et al. and Leofante et al. In these approaches, optimality is proved when the over-approximation is found to be unsatisfiable. However, these methods still require computing compilations for multiple horizons and are susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available. This is because the over-approximation is a relaxation of the original problem, which can be solvable even if the concrete problem is not."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"A gap in the literature exists regarding a practical completeness threshold for cost-optimal planning problems with actions having 0-cost. This limitation hinders the application of SAT-based planning, as optimality can only be proved after solving the compilation for the entire state space, which can be impractically large. Some approaches, such as those by Robinson et al. and Leofante et al., attempt to circumvent this issue by adding an over-approximation to the encoding. While these methods prove optimality when the over-approximation is unsatisfiable, they still require computing compilations for multiple horizons and may need to solve exponentially large compilations unless a tighter completeness threshold is available.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"A notable gap in the literature pertains to the practical completeness threshold for cost-optimal planning problems involving actions with zero cost. This limitation hinders the application of SAT-based planning, as proving optimality necessitates solving the compilation for the entire state space, which can be impractically large. Some approaches, such as those proposed by Robinson et al. and Leofante et al., attempt to circumvent this issue by incorporating an over-approximation into the encoding. While these methods ensure optimality when the over-approximation is unsatisfiable, they still require computing compilations for multiple horizons and may necessitate solving exponentially large compilations unless a tighter completeness threshold is available.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "Revised paragraph: A notable gap in the literature pertains to the practical completeness threshold for cost-optimal planning problems featuring actions with zero cost. This limitation hinders the application of SAT-based planning to such problems, as the absence of a reasonable completeness threshold necessitates proving optimality by solving the compilation for a horizon equal to the number of states in the state space. However, this approach is impractical for most problems, as the size of the state space can grow exponentially with the size of the given problem. Notably, some approaches attempt to circumvent the need for a tight completeness threshold by incorporating an over-approximation of the transition relation underlying the planning problem into the encoding. In these approaches, optimality is demonstrated when the over-approximation is found to be unsatisfiable. Nonetheless, these methods still require computing compilations for multiple horizons and remain susceptible to having to solve compilations for an exponential horizon, unless a tighter completeness threshold is available, since the over-approximation is a relaxation of the original problem and may be solvable even if the concrete problem is not.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.00", "instruction": "Concise the last sentence of this text.", "revised_paragraph": "Revised paragraph: \"A gap in the literature is the lack of a practical completeness threshold for cost-optimal planning problems with 0-cost actions. This hinders the application of SAT-based planning, as optimality can only be proved after solving the compilation for a horizon equal to the state space, which can be exponentially larger than the problem size. Some approaches circumvent this issue by adding an over-approximation to the encoding, but they still require computing compilations for multiple horizons and may need to solve exponentially large compilations unless a tighter completeness threshold is available.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the implications of training a discriminator on empirical distributions, we consider a scenario where the reward is represented by an optimal discriminator, defined as r(s, a) = log E(s, a) D(s, a). Consequently, the objective function (9) is transformed into:"}], "type_approach": "separate-labels-union"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the implications of training a discriminator on empirical distributions, we consider a scenario where the reward is represented by an optimal discriminator, defined as r(s, a) = log E(s, a) D(s, a). Consequently, the objective function (9) is transformed into:"}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the implications of training a discriminator on empirical distributions, we consider a scenario where the reward is represented by an optimal discriminator, defined as r(s, a) = log E(s, a) D(s, a). Consequently, the objective function (9) is transformed into:"}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the implications of training a discriminator on empirical distributions, we consider a scenario where the reward is represented by an optimal discriminator, defined as r(s, a) = log E(s, a) D(s, a). Consequently, the objective function (9) is transformed into:"}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the implications of training a discriminator on empirical distributions, we consider a scenario where the reward is represented by an optimal discriminator, defined as r(s, a) = log E(s, a) D(s, a). Consequently, the objective function (9) is transformed into:"}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the implications of training a discriminator on empirical distributions, we consider a scenario where the reward is represented by an optimal discriminator, defined as r(s, a) = log E(s, a) D(s, a). Consequently, the objective function (9) is transformed into:"}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the implications of training a discriminator on empirical distributions, we consider a scenario where the reward is represented by an optimal discriminator, defined as r(s, a) = log E(s, a) D(s, a). Consequently, the objective function (9) is transformed into:"}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the implications of training a discriminator on empirical distributions, we consider a scenario where the reward is represented by an optimal discriminator, defined as r(s, a) = log E(s, a) D(s, a). Consequently, the objective function (9) is transformed into:"}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "instruction": "Be more specific when talking about the result.", "revised_paragraph": "Revised paragraph: To investigate the effects of training a discriminator on empirical distributions, we consider a scenario where the reward function is represented by an optimal discriminator, defined as r(s, a) = log E(s,a)D(s,a). This assumption enables us to reframe the objective function (9) as:", "type_approach": "instruction-annot_1"}
{"id_paragraph": "uTur5gpEC.TOWMu718N.00", "instruction": "Improve this text to fit a more academic style.", "revised_paragraph": "Revised paragraph: To investigate the outcome of training a discriminator on empirical distributions, we consider a scenario in which the reward function is represented by an optimal discriminator, denoted as r(s, a) = log E(s,a)D(s,a). Consequently, the objective function (9) takes on the form:", "type_approach": "instruction-annot_2"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our work is related to previous studies on the importance of noise in stochastic gradient descent (SGD), which have explored the benefits of adding noise to aid optimization of very deep networks (Neelakantan et al., 2015). Our analysis derives the impact of gradient noise on the SGD stationary distribution and provides a theoretical understanding of the Cyclic Learning Rate (CLR) schedule (Smith, 2015). We show that CLR's benefits can be attributed to the noise it induces, equivalent to mixing in Monte Carlo Markov Chain (MCMC) methods."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Our work is related to previous studies on the importance of noise in stochastic gradient descent (SGD) and its impact on optimization. The idea of a learning rate schedule was inspired by the need to anneal noise (Bottou, 1998). Our analysis provides a theoretical understanding of the gradient noise's impact on the SGD stationary distribution, offering insights into the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). We show that CLR's benefits can be attributed to the noise it induces, which is equivalent to mixing in Monte Carlo Markov Chain (MCMC) methods."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our work is also connected to previous research on the significance of noise in stochastic gradient descent (SGD), which has been extensively explored. The primary motivation behind introducing a learning rate schedule is to anneal noise, as suggested by Bottou (1998). Empirical evidence from Neelakantan et al. (2015) demonstrates that adding noise can facilitate the optimization of very deep networks. Our analysis enables us to derive the impact of gradient noise on the stationary distribution of SGD. Furthermore, our work provides theoretical insights into the recently proposed Cyclic Learning Rate (CLR) schedule, which has been shown to achieve good optimization and generalization performances (Smith, 2015). While CLR schedules are grounded in empirical observation, we show that they can be replaced with an equivalent batch size schedule, suggesting that the benefits of CLR relate to the noise it induces and can be viewed as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing, as observed by Graham and Storkey (2017)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our work is also connected to previous research on the significance of noise in stochastic gradient descent (SGD), which has been extensively explored. The primary motivation behind introducing a learning rate schedule is to anneal noise, as suggested by Bottou (1998). Empirical evidence from Neelakantan et al. (2015) demonstrates that adding noise can facilitate the optimization of very deep networks. Our analysis enables us to derive the impact of gradient noise on the stationary distribution of SGD. Furthermore, our work provides theoretical insights into the recently proposed Cyclic Learning Rate (CLR) schedule, which has been shown to achieve good optimization and generalization performances (Smith, 2015). While CLR schedules are grounded in empirical observation, we show that they can be replaced with an equivalent batch size schedule, suggesting that the benefits of CLR relate to the noise it induces and can be viewed as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing, as observed by Graham and Storkey (2017)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our work is related to previous studies on the importance of noise in stochastic gradient descent (SGD), which have explored the benefits of adding noise to aid optimization of very deep networks (Neelakantan et al., 2015). Our analysis derives the impact of gradient noise on the SGD stationary distribution and provides a theoretical understanding of the Cyclic Learning Rate (CLR) schedule (Smith, 2015). We show that CLR's benefits can be attributed to the noise it induces, equivalent to mixing in Monte Carlo Markov Chain (MCMC) methods."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our work is also connected to previous research on the significance of noise in stochastic gradient descent (SGD), which has been extensively explored. The primary motivation behind introducing a learning rate schedule is to anneal noise, as suggested by Bottou (1998). Empirical evidence from Neelakantan et al. (2015) demonstrates that adding noise can facilitate the optimization of very deep networks. Our analysis enables us to derive the impact of gradient noise on the stationary distribution of SGD. Furthermore, our work provides theoretical insights into the recently proposed Cyclic Learning Rate (CLR) schedule, which has been shown to achieve good optimization and generalization performances (Smith, 2015). While CLR schedules are grounded in empirical observation, we show that they can be replaced with an equivalent batch size schedule, suggesting that the benefits of CLR relate to the noise it induces and can be viewed as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing, as observed by Graham and Storkey (2017)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our work is related to previous studies on the importance of noise in stochastic gradient descent (SGD) and its impact on optimization. The idea of a learning rate schedule was inspired by the need to anneal noise (Bottou, 1998). Our analysis provides a theoretical understanding of the gradient noise's impact on the SGD stationary distribution, offering insights into the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). We show that CLR's benefits can be attributed to the noise it induces, which is equivalent to mixing in Monte Carlo Markov Chain (MCMC) methods."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our work is also connected to previous research on the significance of noise in stochastic gradient descent (SGD), which has been extensively explored. The primary motivation behind introducing a learning rate schedule is to anneal noise, as suggested by Bottou (1998). Empirical evidence from Neelakantan et al. (2015) demonstrates that adding noise can facilitate the optimization of very deep networks. Our analysis enables us to derive the impact of gradient noise on the stationary distribution of SGD. Furthermore, our work provides theoretical insights into the recently proposed Cyclic Learning Rate (CLR) schedule, which has been shown to achieve good optimization and generalization performances (Smith, 2015). While CLR schedules are grounded in empirical observation, we show that they can be replaced with an equivalent batch size schedule, suggesting that the benefits of CLR relate to the noise it induces and can be viewed as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing, as observed by Graham and Storkey (2017)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our work is related to previous studies on the importance of noise in stochastic gradient descent (SGD), which have explored the benefits of adding noise to aid optimization of very deep networks (Neelakantan et al., 2015). Our analysis derives the impact of gradient noise on the SGD stationary distribution and provides a theoretical understanding of the Cyclic Learning Rate (CLR) schedule (Smith, 2015). We show that CLR's benefits can be attributed to the noise it induces, equivalent to mixing in Monte Carlo Markov Chain (MCMC) methods."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our work builds upon previous studies highlighting the benefits of adding noise to stochastic gradient descent (SGD) for optimizing deep networks (Neelakantan et al., 2015). We analyze the impact of gradient noise on the SGD stationary distribution and provide a theoretical understanding of the Cyclic Learning Rate (CLR) schedule's benefits, which can be attributed to the noise it induces, similar to Monte Carlo Markov Chain (MCMC) methods (Smith, 2015)."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our research draws upon previous investigations that have demonstrated the advantages of incorporating noise into stochastic gradient descent (SGD) for optimizing deep neural networks (Neelakantan et al., 2015). This study examines the influence of gradient noise on the stationary distribution of SGD and provides a theoretical framework for understanding the benefits of the Cyclic Learning Rate (CLR) schedule, which can be attributed to the noise it introduces, akin to Monte Carlo Markov Chain (MCMC) methods (Smith, 2015)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our work is also connected to previous research on the significance of noise in stochastic gradient descent (SGD), which has been extensively explored. The primary motivation behind introducing a learning rate schedule is to anneal noise, as suggested by Bottou (1998). Empirical evidence from Neelakantan et al. (2015) demonstrates that adding noise can facilitate the optimization of very deep networks. Our analysis enables us to derive the impact of gradient noise on the stationary distribution of SGD. Furthermore, our work provides theoretical insights into the recently proposed Cyclic Learning Rate (CLR) schedule, which has been shown to achieve good optimization and generalization performances (Smith, 2015). While CLR schedules are grounded in empirical observation, we show that they can be replaced with an equivalent batch size schedule, suggesting that the benefits of CLR relate to the noise it induces and can be viewed as mixing in Monte Carlo Markov Chain (MCMC) methods. In the MCMC setting, annealing processes enable better mixing, as observed by Graham and Storkey (2017)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our work is related to previous studies on the importance of noise in stochastic gradient descent (SGD), which have explored the benefits of adding noise to aid optimization of very deep networks (Neelakantan et al., 2015). Our analysis derives the impact of gradient noise on the SGD stationary distribution and provides a theoretical understanding of the Cyclic Learning Rate (CLR) schedule (Smith, 2015). We show that CLR's benefits can be attributed to the noise it induces, equivalent to mixing in Monte Carlo Markov Chain (MCMC) methods."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our research builds upon previous studies that have highlighted the significance of noise in stochastic gradient descent (SGD), particularly in the context of optimizing very deep neural networks (Neelakantan et al., 2015). This study extends the existing body of work by analytically investigating the effects of gradient noise on the stationary distribution of SGD and providing a theoretical framework for understanding the Cyclic Learning Rate (CLR) schedule (Smith, 2015). Notably, our findings suggest that the benefits of CLR can be attributed to the noise it introduces, which is analogous to the mixing process employed in Monte Carlo Markov Chain (MCMC) methods."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our work is related to previous studies on the importance of noise in stochastic gradient descent (SGD) and its impact on optimization. The idea of a learning rate schedule was inspired by the need to anneal noise (Bottou, 1998). Our analysis provides a theoretical understanding of the gradient noise's impact on the SGD stationary distribution, offering insights into the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). We show that CLR's benefits can be attributed to the noise it induces, which is equivalent to mixing in Monte Carlo Markov Chain (MCMC) methods."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our research builds upon previous studies highlighting the significance of noise in stochastic gradient descent (SGD) and its influence on optimization. The concept of a learning rate schedule was motivated by the need to anneal noise, as suggested by Bottou (1998). Our analysis provides a theoretical framework for understanding the impact of gradient noise on the stationary distribution of SGD, offering insights into the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). Notably, we demonstrate that CLR's benefits can be attributed to the noise it induces, which is analogous to the mixing process in Monte Carlo Markov Chain (MCMC) methods."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "instruction": "Remove unnecessary content in the last sentence.", "revised_paragraph": "Revised paragraph: Our work is also related to other research on the importance of noise in stochastic gradient descent (SGDs), which has been previously explored. The main inspiration for having a learning rate schedule is to anneal noise (Bottou, 1998). Neelakantan et al. (2015) empirically found that adding noise can aid optimization of very deep networks. Our analysis allows us to derive the impact of gradient noise in the SGD stationary distribution. We also provide intuition for explaining the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015), which demonstrates good optimization and generalization performances.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.01", "instruction": "Make the last sentence shorter, only keep the main idea. Slightly concise this paragraph and improve the english.", "revised_paragraph": "Revised paragraph: Our work is related to previous studies on the importance of noise in stochastic gradient descent (SGD). The main inspiration for our learning rate schedule is to anneal noise, as proposed by Bottou (1998). Adding noise has been empirically shown to aid optimization of deep networks (Neelakantan et al., 2015). Our analysis derives the impact of gradient noise on the SGD stationary distribution and provides insight into the recently proposed Cyclic Learning Rate (CLR) schedule (Smith, 2015). We show that CLR's benefits can be attributed to the noise it induces, which can be viewed as mixing in Monte Carlo Markov Chain methods, similar to annealing processes that enable better mixing (Graham & Storkey, 2017).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Four participants consistently reported using the edges to navigate the interface, regardless of the condition (Figure 5(iv)). Notably, they were hindered by the cursor's concealment by the notch, which led to a loss of cursor visibility. In response, all participants attempted to locate the cursor by rapidly moving the mouse, as they sought to regain visual feedback."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Four participants consistently reported using the edges to navigate the interface, regardless of the condition (Figure 5(iv)). Notably, they were hindered by the cursor's concealment by the notch, which led to a loss of cursor visibility. In response, all participants attempted to locate the cursor by rapidly moving the mouse, as they sought to regain visual feedback."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Four participants consistently reported using the edges to navigate the interface, regardless of the condition (Figure 5(iv)). Notably, they were hindered by the cursor's concealment by the notch, which led to a loss of cursor visibility. In response, all participants attempted to locate the cursor by rapidly moving the mouse, as they sought to regain visual feedback."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Four participants consistently reported using the edges to navigate the interface, regardless of the condition (Figure 5(iv)). Notably, they were hindered by the cursor's concealment by the notch, which led to a loss of cursor visibility. In response, all participants attempted to locate the cursor by rapidly moving the mouse, as they sought to regain visual feedback."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Four participants consistently reported using the edges to navigate the interface, regardless of the condition (Figure 5(iv)). Notably, they were hindered by the cursor's concealment by the notch, which led to a loss of cursor visibility. In response, all participants attempted to locate the cursor by rapidly moving the mouse, as they sought to regain visual feedback."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Four participants consistently reported using the edges to navigate the interface, regardless of the condition (Figure 5(iv)). Notably, they were hindered by the cursor's concealment by the notch, which led to a loss of cursor visibility. In response, all participants attempted to locate the cursor by rapidly moving the mouse, as they sought to regain visual feedback."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Four participants consistently reported using the edges to navigate the interface, regardless of the condition (Figure 5(iv)). Notably, they were hindered by the cursor's concealment by the notch, which led to a loss of cursor visibility. In response, all participants attempted to locate the cursor by rapidly moving the mouse, as they sought to regain visual feedback."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Four participants consistently reported using the edges to navigate the interface, regardless of the condition (Figure 5(iv)). Notably, they were hindered by the cursor's concealment by the notch, which led to a loss of cursor visibility. In response, all participants attempted to locate the cursor by rapidly moving the mouse, as they sought to regain visual feedback."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "instruction": "Restructure the last two sentences in this paragraph", "revised_paragraph": "Revised paragraph: Four participants reported intentionally using edges (Figure 5 (iv)) in all conditions. Despite this, they were hindered by the cursor being hidden by the notch, which caused them to lose sight of the cursor. In response, all participants attempted to locate the cursor by moving the mouse with increased vigor.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.15", "instruction": "Revise this paragraph to make it more clear and concise.", "revised_paragraph": "Revised paragraph: Four participants consistently reported using the edges to navigate in all conditions, as shown in Figure 5 (iv). However, this approach was compromised when the cursor was obscured by the notch, leading to disorientation. In response, all participants attempted to reacquire the cursor by moving the mouse with increased vigor.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Ethier et al. [58], a prescription is composed of six essential building blocks that define the administration modalities for a given drug: drug prescription item, drug administration specification, drug course specification, drug dosage specification, drug dose administration specification, and drug dispensing specification. Kumar et al. [59] condense these building blocks into superscription, inscription, subscription, and signature, while Fox [60] categorizes them as drug name, drug dose, drug dose units, drug dose frequency, duration, and indication. We adopt Fox's [60] classification, which is simpler and more direct, as it is similar to other studies (e.g., [14, 31])."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: The prescription of a given drug is composed of six building blocks, as identified by Ethier et al. [58], which define the modalities of administration: drug prescription item, drug administration specification, drug course specification, drug dosage specification, drug dose administration specification, and drug dispensing specification. These blocks can be categorized in different ways, with Kumar et al. [59] proposing superscription, inscription, subscription, and signature, while Fox [60] uses drug name, drug dose, drug dose units, drug dose frequency, duration, and indication. We adopt Fox's classification [60] due to its simplicity and directness, in line with other researchers (e.g., [14,31])."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: The prescription of a given drug is composed of six building blocks, as identified by Ethier et al. [58], which define the modalities of administration: drug prescription item, drug administration specification, drug course specification, drug dosage specification, drug dose administration specification, and drug dispensing specification. These blocks can be categorized in different ways, with Kumar et al. [59] proposing superscription, inscription, subscription, and signature, while Fox [60] uses drug name, drug dose, drug dose units, drug dose frequency, duration, and indication. We adopt Fox's classification [60] due to its simplicity and directness, in line with other researchers (e.g., [14,31])."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Ethier et al. [58], a prescription is composed of six essential building blocks that define the administration modalities for a given drug: drug prescription item, drug administration specification, drug course specification, drug dosage specification, drug dose administration specification, and drug dispensing specification. Kumar et al. [59] condense these building blocks into superscription, inscription, subscription, and signature, while Fox [60] categorizes them as drug name, drug dose, drug dose units, drug dose frequency, duration, and indication. We adopt Fox's [60] classification, which is simpler and more direct, as it is similar to other studies (e.g., [14, 31])."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Ethier et al. [58], a prescription is composed of six essential building blocks that define the administration modalities for a given drug: drug prescription item, drug administration specification, drug course specification, drug dosage specification, drug dose administration specification, and drug dispensing specification. Kumar et al. [59] condense these building blocks into superscription, inscription, subscription, and signature, while Fox [60] categorizes them as drug name, drug dose, drug dose units, drug dose frequency, duration, and indication. We adopt Fox's [60] classification, which is simpler and more direct, as it is similar to other studies (e.g., [14, 31])."}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: The prescription of a drug is defined by several essential components, which vary across different studies. Ethier et al. [58] identify six building blocks, including drug prescription item, administration specification, course specification, dosage specification, dose administration specification, and dispensing specification. Kumar et al. [59] and Fox [60] propose alternative categorizations, with Fox's [60] classification being the most straightforward and widely adopted. This classification, which includes drug name, dose, dose units, frequency, duration, and indication, is similar to that used in other studies (e.g., [14, 31])."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: The prescription of a given drug is composed of six building blocks, as identified by Ethier et al. [58], which define the modalities of administration: drug prescription item, drug administration specification, drug course specification, drug dosage specification, drug dose administration specification, and drug dispensing specification. These blocks can be categorized in different ways, with Kumar et al. [59] proposing superscription, inscription, subscription, and signature, while Fox [60] uses drug name, drug dose, drug dose units, drug dose frequency, duration, and indication. We adopt Fox's classification [60] due to its simplicity and directness, in line with other researchers (e.g., [14,31])."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: According to Ethier et al. [58], a prescription is composed of six essential building blocks that define the administration modalities for a given drug: drug prescription item, drug administration specification, drug course specification, drug dosage specification, drug dose administration specification, and drug dispensing specification. Kumar et al. [59] condense these building blocks into superscription, inscription, subscription, and signature, while Fox [60] categorizes them as drug name, drug dose, drug dose units, drug dose frequency, duration, and indication. We adopt Fox's [60] classification, which is simpler and more direct, as it is similar to other studies (e.g., [14, 31])."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "instruction": "Rewrite the opening sentences of the paragraph to make them more explicit and clear.", "revised_paragraph": "Revised paragraph: The prescription process involves a set of six building blocks, as identified by Ethier et al. [58], which define the modalities of administration for a given drug. These building blocks include the drug prescription item, drug administration specification, drug course specification, drug dosage specification, drug dose administration specification, and drug dispensing specification. Kumar et al. [59] have also summarized these building blocks into four categories: superscription, inscription, subscription, and signature. Fox [60] further categorizes these building blocks into drug name, drug dose, drug dose units, drug dose frequency, duration, and indication. We adopt Fox's [60] classification due to its simplicity and directness, as well as its widespread adoption by others in the field (e.g. [14,31]).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.05", "instruction": "Replace the listing by normal text to better incorporate de six building blocks into the paragraph.", "revised_paragraph": "Revised paragraph: According to Ethier et al. [58], a prescription is composed of six building blocks that define the modalities of administration for a given drug. These blocks include the drug prescription item, specifying actions related to one or several drugs; drug administration specification, which specifies the drug product; drug course specification, which details duration, initiation, and termination; drug dosage specification, which specifies the dosage of a drug; drug dose administration specification, which provides administration instructions; and drug dispensing specification, which specifies the dispensing of a drug product. Kumar et al. [59] summarize these blocks as superscription, inscription, subscription, and signature, while Fox [60] categorizes them as drug name, drug dose, drug dose units, drug dose frequency, duration, and indication. We adopt Fox's classification [60] due to its simplicity and directness, as advocated by others [14, 31].", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our results demonstrate good alignment with image boundaries and visual similarity to fully-supervised methods, as shown in Fig. The addition of different relationships for regularization also yields significant improvements, as seen in Fig. 7. Further details and ablation studies can be found in the Appendix.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Visual quality comparison and ablation study. As illustrated in Fig., our results exhibit a high degree of alignment with image boundaries and demonstrate a visually comparable performance to that of fully-supervised counterparts. Fig. 7 further highlights the substantial improvement achieved by incorporating diverse relationships for additional regularization. For a more detailed analysis and comprehensive ablation studies, please refer to the Appendix.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our results demonstrate good alignment with image boundaries and visual similarity to fully-supervised methods, as shown in Fig. The addition of different relationships for regularization also yields significant improvements, as seen in Fig. 7. Further details and ablation studies can be found in the Appendix.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our results demonstrate good alignment with image boundaries and visual similarity to fully-supervised methods, as shown in Fig. The addition of different relationships for regularization also yields significant improvements, as seen in Fig. 7. Further details and ablation studies can be found in the Appendix.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Visual quality comparison and ablation study. As illustrated in Fig., our results exhibit a high degree of alignment with image boundaries and demonstrate a visually comparable performance to that of fully-supervised counterparts. Fig. 7 further highlights the substantial improvement achieved by incorporating diverse relationships for additional regularization. For a more detailed analysis and comprehensive ablation studies, please refer to the Appendix.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our results demonstrate good alignment with image boundaries and visual similarity to fully-supervised methods, as shown in Fig. The addition of different relationships for regularization also yields significant improvements, as seen in Fig. 7. Further details and ablation studies can be found in the Appendix.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our results demonstrate good alignment with image boundaries and visual similarity to fully-supervised methods, as shown in Fig. The addition of different relationships for regularization also yields significant improvements, as seen in Fig. 7. Further details and ablation studies can be found in the Appendix.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Our results exhibit a strong alignment with image boundaries and visual similarity to those obtained with fully-supervised methods, as illustrated in Fig. Furthermore, the incorporation of diverse relationships for regularization leads to substantial improvements, as evident in Fig. 7. Additional details and ablation studies are provided in the Appendix.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our results demonstrate good alignment with image boundaries and visual similarity to fully-supervised methods, as shown in Fig. The addition of different relationships for regularization also yields significant improvements, as seen in Fig. 7. Further details and ablation studies can be found in the Appendix.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our results demonstrate good alignment with image boundaries and visual similarity to fully-supervised methods, as shown in Fig. The addition of different relationships for regularization also yields significant improvements, as seen in Fig. 7. Further details and ablation studies can be found in the Appendix.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Visual quality comparison and ablation study. As illustrated in Fig., our results exhibit a high degree of alignment with image boundaries and demonstrate a visually comparable performance to that of fully-supervised counterparts. Fig. 7 further highlights the substantial improvement achieved by incorporating diverse relationships for additional regularization. For a more detailed analysis and comprehensive ablation studies, please refer to the Appendix.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our results (Fig.) show high alignment with image boundaries and comparable visual performance to fully-supervised methods. Fig. 7 illustrates the improvement from incorporating diverse relationships. For further analysis and ablation studies, see the Appendix.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "instruction": "Edit this paragraph to be more concise.", "revised_paragraph": "Revised paragraph: \"Our results visually align with image boundaries and closely approach those of fully-supervised methods, as shown in Fig.. The addition of different relationships for regularization further improves our results, as demonstrated in Fig. 7. For more details and ablation studies, please refer to the Appendix.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.17", "instruction": "Improve the english of this paragraph and make it slightly shorter.", "revised_paragraph": "Revised paragraph: \"Our results demonstrate a strong visual quality, aligning well with image boundaries and closely matching those of fully-supervised methods. Fig. 7 illustrates the significant improvement achieved by incorporating additional relationships for regularization. For further details and ablation studies, please refer to the Appendix.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Twelve students from a different participant group, distinct from Experiment 1, participated in this study. The average age was 22.3 years (standard deviation = 1.67), with all participants possessing proficiency in mouse operation and predominantly using their dominant right hand.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Twelve students from a different participant group, distinct from Experiment 1, participated in this study. The average age was 22.3 years (standard deviation = 1.67), with all participants possessing proficiency in mouse operation and predominantly using their dominant right hand.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Twelve students from a different participant group, distinct from Experiment 1, participated in this study. The average age was 22.3 years (standard deviation = 1.67), with all participants possessing proficiency in mouse operation and predominantly using their dominant right hand.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Twelve students from a different participant group, distinct from Experiment 1, participated in this study. The average age was 22.3 years (standard deviation = 1.67), with all participants possessing proficiency in mouse operation and predominantly using their dominant right hand.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Twelve students from a different participant group, distinct from Experiment 1, participated in this study. The average age was 22.3 years (standard deviation = 1.67), with all participants possessing proficiency in mouse operation and predominantly using their dominant right hand.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Twelve students from a different participant group, distinct from Experiment 1, participated in this study. The average age was 22.3 years (standard deviation = 1.67), with all participants possessing proficiency in mouse operation and predominantly using their dominant right hand.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Twelve students from a different participant group, distinct from Experiment 1, participated in this study. The average age was 22.3 years (standard deviation = 1.67), with all participants possessing proficiency in mouse operation and predominantly using their dominant right hand.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Twelve students from a different participant group, distinct from Experiment 1, participated in this study. The average age was 22.3 years (standard deviation = 1.67), with all participants possessing proficiency in mouse operation and predominantly using their dominant right hand.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "instruction": "Rephrase the paragraph", "revised_paragraph": "Revised paragraph: Twelve participants from a distinct group, separate from Experiment 1, took part in this study. The average age of the participants was 22.3 years (standard deviation = 1.67), with all individuals possessing proficiency in mouse operation and utilizing their dominant right hand.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.19", "instruction": "Revise this text to make it more clear.", "revised_paragraph": "Revised paragraph: Twelve participants from a separate group, distinct from those in Experiment 1, took part in this study. The average age of these participants was 22.3 years, with a standard deviation of 1.67 years. All participants were proficient in operating a computer mouse and were right-handed, using their dominant right hand.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, since neural network estimators primarily employ stochastic gradient methods to update parameters, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, since neural network estimators primarily employ stochastic gradient methods to update parameters, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, since neural network estimators primarily employ stochastic gradient methods to update parameters, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, since neural network estimators primarily employ stochastic gradient methods to update parameters, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, since neural network estimators primarily employ stochastic gradient methods to update parameters, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, since neural network estimators primarily employ stochastic gradient methods to update parameters, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, since neural network estimators primarily employ stochastic gradient methods to update parameters, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, since neural network estimators primarily employ stochastic gradient methods to update parameters, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "instruction": "check the wordings but keep the original content as much as possible", "revised_paragraph": "Revised paragraph: However, as neural network estimators primarily update parameters using stochastic gradient methods, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.08", "instruction": "Improve the language to make it more formal.", "revised_paragraph": "Revised paragraph: However, since neural network estimators primarily employ stochastic gradient methods to update parameters, only a limited subset of the representation's distribution is accessible within each iteration. Consequently, a common approach (Liuyi et al., 2018) is to calculate the group discrepancy at the level of a stochastic mini-batch.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses have been proposed, including DENT, PNI, and TRS. These methods optimize the model during test-time, inject noise during training, and ensemble multiple models to reduce attack transferability. While they were originally designed for gradient-based attacks, they also provide some protection against SQAs. However, as shown in Table 3, they are not comparable to AAA-linear in real cases regarding accuracy, calibration, and defense performance."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses have been proposed, including DENT [19], which optimizes the model in test-time, PNI [51], which injects noise during training, and TRS [60], which ensembles three models with low attack transferability. While these defenses provide some protection against SQAs, they are not comparable to AAA-linear in real cases regarding accuracy, calibration, and defense performance (Table 3). We also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN, but AAA remains the best defense."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Besides adversarial training (AT) and robust neural networks (RND), various other defense mechanisms have been proposed, and it would be intriguing to examine their performance. DENT [19] optimizes the model during test-time, attempting to learn the adversarial example (AE) distribution. PNI [51] injects noise during training, rendering the learned weights less susceptible to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. Originally designed to counter gradient-based attacks, they also provide some protection against sophisticated query attacks (SQAs). As shown in Table 3, however, they are not comparable to AAA-linear in real-world scenarios regarding accuracy, calibration, and defense performance. We also evaluate a strong SQA QueryNet, which leverages three architecture-alterable models to steal the deep neural network (DNN). Due to its reliance on large-scale testing samples, QueryNet significantly compromises DNNs, but AAA remains the most effective defense mechanism in protecting the model."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses have been proposed, including DENT, PNI, and TRS. These methods optimize the model during test-time, inject noise during training, and ensemble multiple models to reduce attack transferability. While they were originally designed for gradient-based attacks, they also provide some protection against SQAs. However, as shown in Table 3, they are not comparable to AAA-linear in real cases regarding accuracy, calibration, and defense performance."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Besides adversarial training (AT) and robust neural networks (RND), various other defense mechanisms have been proposed, and it would be intriguing to examine their performance. DENT [19] optimizes the model during test-time, attempting to learn the adversarial example (AE) distribution. PNI [51] injects noise during training, rendering the learned weights less susceptible to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. Originally designed to counter gradient-based attacks, they also provide some protection against sophisticated query attacks (SQAs). As shown in Table 3, however, they are not comparable to AAA-linear in real-world scenarios regarding accuracy, calibration, and defense performance. We also evaluate a strong SQA QueryNet, which leverages three architecture-alterable models to steal the deep neural network (DNN). Due to its reliance on large-scale testing samples, QueryNet significantly compromises DNNs, but AAA remains the most effective defense mechanism in protecting the model."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses have been proposed, including DENT [19], which optimizes the model in test-time, PNI [51], which injects noise during training, and TRS [60], which ensembles three models with low attack transferability. While these defenses provide some protection against SQAs, they are not comparable to AAA-linear in real cases regarding accuracy, calibration, and defense performance (Table 3). We also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN, but AAA remains the best defense."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses have been proposed, including DENT, PNI, and TRS. These methods optimize the model during test-time, inject noise during training, and ensemble multiple models to reduce attack transferability. While they were originally designed for gradient-based attacks, they also provide some protection against SQAs. However, as shown in Table 3, they are not comparable to AAA-linear in real cases regarding accuracy, calibration, and defense performance."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses include DENT, PNI, and TRS, which optimize models during test-time, inject noise during training, and ensemble multiple models to reduce attack transferability. While originally designed for gradient-based attacks, they also provide some protection against SQAs. However, as shown in Table 3, they fall short of AAA-linear in real-world scenarios regarding accuracy, calibration, and defense performance."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses that optimize models during test-time, inject noise during training, and ensemble multiple models to reduce attack transferability include DENT, PNI, and TRS. Although originally designed to counter gradient-based attacks, these defenses also offer some protection against Squared-Signal Attacks (SQAs). However, as demonstrated in Table 3, they fall short of AAA-linear in real-world scenarios, compromising on accuracy, calibration, and defense performance."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses have been proposed, including DENT, PNI, and TRS. These methods optimize the model during test-time, inject noise during training, and ensemble multiple models to reduce attack transferability. While they were originally designed for gradient-based attacks, they also provide some protection against SQAs. However, as shown in Table 3, they are not comparable to AAA-linear in real cases regarding accuracy, calibration, and defense performance."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses have been proposed, including DENT, PNI, and TRS. These methods leverage various techniques to improve robustness, such as optimizing models during test-time, injecting noise during training, and ensembling multiple models to reduce attack transferability. Although originally designed to counter gradient-based attacks, they also provide some protection against Squared Gradient Attacks (SQAs). However, as illustrated in Table 3, these methods fall short of AAA-linear in real-world scenarios, compromising on accuracy, calibration, and defense performance."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses have been proposed, including DENT [19], which optimizes the model in test-time, PNI [51], which injects noise during training, and TRS [60], which ensembles three models with low attack transferability. While these defenses provide some protection against SQAs, they are not comparable to AAA-linear in real cases regarding accuracy, calibration, and defense performance (Table 3). We also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN, but AAA remains the best defense."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "instruction": "Remove unnecessary details.", "revised_paragraph": "Revised paragraph: Besides AT and RND, other defenses have been proposed, including DENT, PNI, and TRS. These defenses aim to optimize the model in test-time, inject noise during training, and ensemble multiple models to reduce attack transferability. However, as shown in Table 3, they are not comparable to AAA-linear in real cases regarding accuracy, calibration, and defense performance. We also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN, and find that AAA is still the defense that protects the model best.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "VRrAfKMSF8.g8rfar4U7.00", "instruction": "Delete unnecessary details, mostly in the two first sentences.", "revised_paragraph": "Revised paragraph: PNI [51] injects noise during training, making the learned weights less sensitive to input perturbations. TRS [60] ensembles three models with low attack transferability between each other. As displayed in Table 3, however, these defenses are not comparable to AAA-linear in real cases regarding the accuracy, calibration, and defense performance. Here, we also test a strong SQA QueryNet, which uses three architecture-alterable models to steal the DNN. Despite its utilization of large-scale testing samples, AAA is still the defense that protects the model best.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Snuba uses a set of weak learner primitives, such as decision stumps and k-nearest neighbors, to generate candidate rules, which are then synthesized and pruned to produce final rules for labeling. ReGAL builds upon this framework by enabling iterative communication between downstream classifiers and rule selectors, allowing each component to improve the other. This unique approach enables ReGAL to offer the benefits of model-generated labeling functions, while also incorporating the nuanced insights of human annotator input."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Snuba uses a set of weak learner primitives, such as decision stumps and k-nearest neighbors, to generate candidate rules, which are then synthesized and pruned to produce final rules for labeling. ReGAL builds upon this framework by enabling iterative communication between downstream classifiers and rule selectors, allowing each component to improve the other. This unique approach enables ReGAL to offer the benefits of model-generated labeling functions, while also incorporating the nuanced insights of human annotator input."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Snuba uses a set of weak learner primitives, such as decision stumps and k-nearest neighbors, to generate candidate rules, which are then synthesized and pruned to produce final rules for labeling. ReGAL builds upon this framework by enabling iterative communication between downstream classifiers and rule selectors, allowing each component to improve the other. This unique approach enables ReGAL to offer the benefits of model-generated labeling functions, while also incorporating the nuanced insights of human annotator input."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Snuba uses a set of weak learner primitives, such as decision stumps and k-nearest neighbors, to generate candidate rules, which are then synthesized and pruned to produce final rules for labeling. ReGAL builds upon this framework by enabling iterative communication between downstream classifiers and rule selectors, allowing each component to improve the other. This unique approach enables ReGAL to offer the benefits of model-generated labeling functions, while also incorporating the nuanced insights of human annotator input."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Snuba uses a set of weak learner primitives, such as decision stumps and k-nearest neighbors, to generate candidate rules, which are then synthesized and pruned to produce final rules for labeling. ReGAL builds upon this framework by enabling iterative communication between downstream classifiers and rule selectors, allowing each component to improve the other. This unique approach enables ReGAL to offer the benefits of model-generated labeling functions, while also incorporating the nuanced insights of human annotator input."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Snuba uses a set of weak learner primitives, such as decision stumps and k-nearest neighbors, to generate candidate rules, which are then synthesized and pruned to produce final rules for labeling. ReGAL builds upon this framework by enabling iterative communication between downstream classifiers and rule selectors, allowing each component to improve the other. This unique approach enables ReGAL to offer the benefits of model-generated labeling functions, while also incorporating the nuanced insights of human annotator input."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Snuba uses a set of weak learner primitives, such as decision stumps and k-nearest neighbors, to generate candidate rules, which are then synthesized and pruned to produce final rules for labeling. ReGAL builds upon this framework by enabling iterative communication between downstream classifiers and rule selectors, allowing each component to improve the other. This unique approach enables ReGAL to offer the benefits of model-generated labeling functions, while also incorporating the nuanced insights of human annotator input."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Snuba uses a set of weak learner primitives, such as decision stumps and k-nearest neighbors, to generate candidate rules, which are then synthesized and pruned to produce final rules for labeling. ReGAL builds upon this framework by enabling iterative communication between downstream classifiers and rule selectors, allowing each component to improve the other. This unique approach enables ReGAL to offer the benefits of model-generated labeling functions, while also incorporating the nuanced insights of human annotator input."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "instruction": "Rephrase the last sentence.", "revised_paragraph": "Revised paragraph: \"Snuba generates candidate rules by combining weak learner primitives, such as decision stumps and k-nearest neighbors, and then refines this set to produce final rules for labeling. ReGAL builds upon this framework, enabling iterative communication between downstream classifiers and rule selectors to enhance each other's performance. This innovative approach allows ReGAL to leverage the benefits of model-generated labels while incorporating the nuanced insights of human annotator input.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "IoTyuVEanE.Et-c0vQfeb.01", "instruction": "Rewrite the last sentence to better convey the idea.", "revised_paragraph": "Revised paragraph: \"Snuba [14] generates candidate rules using a collection of weak learner primitives (e.g. decision stumps, k-nearest neighbors) and then synthesizes and prunes this set of rules to generate final rules for labeling. ReGAL builds upon this framework by enabling iterative communication between downstream classifiers and rule selectors, allowing each component to refine the other and leverage their respective strengths. This unique combination enables ReGAL to offer the efficiency of model-generated labeling functions while also incorporating the nuanced insights provided by human annotators.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Many models exhibit high |d util| when trained on two distinct modalities, confirming that the standard multi-modal learning process encourages reliance on one modality and ignores the other, consistent with our hypothesis. This greedy behavior is observed across all tasks, regardless of network architecture or task.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Many models exhibit high |d util| when trained on two distinct modalities, confirming that the standard multi-modal learning process encourages reliance on one modality and ignores the other, consistent with our hypothesis. This greedy behavior is observed across all tasks, regardless of network architecture or task.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Many models exhibit high |d util| when trained on two distinct modalities, confirming that the standard multi-modal learning process encourages reliance on one modality and ignores the other, consistent with our hypothesis. This greedy behavior is observed across all tasks, regardless of network architecture or task.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Many models exhibit high |d util| when trained on two distinct modalities, confirming that the standard multi-modal learning process encourages reliance on one modality and ignores the other, consistent with our hypothesis. This greedy behavior is observed across all tasks, regardless of network architecture or task.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Many models exhibit high |d util| when trained on two distinct modalities, confirming that the standard multi-modal learning process encourages reliance on one modality and ignores the other, consistent with our hypothesis. This greedy behavior is observed across all tasks, regardless of network architecture or task.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Many models exhibit high |d util| when trained on two distinct modalities, confirming that the standard multi-modal learning process encourages reliance on one modality and ignores the other, consistent with our hypothesis. This greedy behavior is observed across all tasks, regardless of network architecture or task.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Many models exhibit high |d util| when trained on two distinct modalities, confirming that the standard multi-modal learning process encourages reliance on one modality and ignores the other, consistent with our hypothesis. This greedy behavior is observed across all tasks, regardless of network architecture or task.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Many models exhibit high |d util| when trained on two distinct modalities, confirming that the standard multi-modal learning process encourages reliance on one modality and ignores the other, consistent with our hypothesis. This greedy behavior is observed across all tasks, regardless of network architecture or task.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "instruction": "Remove the second part of the first sentence", "revised_paragraph": "Revised paragraph: First, many models have high | d util |, especially when trained to use two distinct modalities. This confirms that the standard multi-modal learning process encourages the model to rely on one modality and ignore the other one, which is consistent with our hypothesis.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.16", "instruction": "Exclude unnecessary details.", "revised_paragraph": "Revised paragraph: \"Many models exhibit high |d util| when trained on two distinct modalities, suggesting that the standard multi-modal learning process prioritizes one modality over the other, consistent with our hypothesis. This observation holds across all tasks, regardless of network architectures.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Mahapatra and Rajan (2020) introduced Exact Pareto Optimal (EPO), a multi-objective optimization method that converges to a desired ray in loss space. The EPO method searches for an exact Pareto optimal solution, which is defined as a solution that is both Pareto optimal and lies on the intersection of the Pareto front and the preference vector r. To achieve this, EPO balances two goals: finding a descent direction and reaching the desired ray. Specifically, EPO searches for a point within the convex hull of the gradients, which includes descent directions (D\u00e9sid\u00e9ri, 2012), that has the maximum angle with a vector d_bal, which pulls the point towards the desired ray. By combining gradient descent and controlled ascent, EPO is capable of reaching an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Mahapatra and Rajan (2020) introduced Exact Pareto Optimal (EPO), a multi-objective optimization method capable of converging to a desired ray in loss space. Given a preference ray r, EPO searches for an exact Pareto optimal solution, which satisfies two criteria: (i) Pareto optimality, and (ii) intersection with the Pareto front and the preference vector r. The EPO method strikes a balance between two goals: identifying a descent direction and converging to the desired ray. Specifically, EPO seeks a point within the convex hull of gradients, known to include descent directions (D\u00e9sid\u00e9ri, 2012), that maximizes the angle with a vector d_bal, which pulls the point towards the desired ray. By combining gradient descent and controlled ascent, EPO is able to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Mahapatra and Rajan (2020) introduced Exact Pareto Optimal (EPO), a multi-objective optimization method capable of converging to a desired ray in loss space. Given a preference ray r, EPO searches for an exact Pareto optimal solution, which satisfies two criteria: (i) Pareto optimality, and (ii) intersection with the Pareto front and the preference vector r. The EPO method strikes a balance between two goals: identifying a descent direction and converging to the desired ray. Specifically, EPO seeks a point within the convex hull of gradients, known to include descent directions (D\u00e9sid\u00e9ri, 2012), that maximizes the angle with a vector d_bal, which pulls the point towards the desired ray. By combining gradient descent and controlled ascent, EPO is able to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Mahapatra and Rajan (2020) introduced Exact Pareto Optimal (EPO), a multi-objective optimization method that converges to a desired ray in loss space. The EPO method searches for an exact Pareto optimal solution, which is defined as a solution that is both Pareto optimal and lies on the intersection of the Pareto front and the preference vector r. To achieve this, EPO balances two goals: finding a descent direction and reaching the desired ray. Specifically, EPO searches for a point within the convex hull of the gradients, which includes descent directions (D\u00e9sid\u00e9ri, 2012), that has the maximum angle with a vector d_bal, which pulls the point towards the desired ray. By combining gradient descent and controlled ascent, EPO is capable of reaching an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Mahapatra and Rajan (2020) introduced Exact Pareto Optimal (EPO), a multi-objective optimization method that converges to a desired ray in loss space. The EPO method searches for an exact Pareto optimal solution, which is defined as a solution that is both Pareto optimal and lies on the intersection of the Pareto front and the preference vector r. To achieve this, EPO balances two goals: finding a descent direction and reaching the desired ray. Specifically, EPO searches for a point within the convex hull of the gradients, which includes descent directions (D\u00e9sid\u00e9ri, 2012), that has the maximum angle with a vector d_bal, which pulls the point towards the desired ray. By combining gradient descent and controlled ascent, EPO is capable of reaching an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Mahapatra and Rajan (2020) proposed Exact Pareto Optimal (EPO), a multi-objective optimization method that converges to a desired ray in loss space by seeking an exact Pareto optimal solution. This solution is defined as a point that is both Pareto optimal and lies at the intersection of the Pareto front and the preference vector r. To achieve this, EPO balances two key goals: finding a descent direction and reaching the desired ray. Specifically, EPO searches for a point within the convex hull of the gradients, which includes descent directions (D\u00e9sid\u00e9ri, 2012), that maximizes the angle with a vector d_bal, which guides the point towards the desired ray. By combining gradient descent and controlled ascent, EPO is capable of reaching an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Mahapatra and Rajan (2020) introduced Exact Pareto Optimal (EPO), a multi-objective optimization method capable of converging to a desired ray in loss space. Given a preference ray r, EPO searches for an exact Pareto optimal solution, which satisfies two criteria: (i) Pareto optimality, and (ii) intersection with the Pareto front and the preference vector r. The EPO method strikes a balance between two goals: identifying a descent direction and converging to the desired ray. Specifically, EPO seeks a point within the convex hull of gradients, known to include descent directions (D\u00e9sid\u00e9ri, 2012), that maximizes the angle with a vector d_bal, which pulls the point towards the desired ray. By combining gradient descent and controlled ascent, EPO is able to reach an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Mahapatra and Rajan (2020) introduced Exact Pareto Optimal (EPO), a multi-objective optimization method that converges to a desired ray in loss space. The EPO method searches for an exact Pareto optimal solution, which is defined as a solution that is both Pareto optimal and lies on the intersection of the Pareto front and the preference vector r. To achieve this, EPO balances two goals: finding a descent direction and reaching the desired ray. Specifically, EPO searches for a point within the convex hull of the gradients, which includes descent directions (D\u00e9sid\u00e9ri, 2012), that has the maximum angle with a vector d_bal, which pulls the point towards the desired ray. By combining gradient descent and controlled ascent, EPO is capable of reaching an exact Pareto optimal solution if one exists, or the closest Pareto optimal solution."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "instruction": "Exclude unnecessary ideas.", "revised_paragraph": "Revised paragraph: Mahapatra & Rajan (2020) introduced Exact Pareto Optimal (EPO), a multi-objective optimization method that converges to a desired ray in loss space. Given a preference ray r, EPO searches for an exact Pareto optimal solution, which lies at the intersection of the Pareto front and the preference vector r. The EPO method balances two goals: finding a descent direction and reaching the desired ray. It achieves this by searching for a point in the convex hull of gradients, which includes descent directions, that has the maximum angle with a vector d bal, which pulls the point towards the desired ray.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "ssjKKm0b5y.3wi5X8wrM_.00", "instruction": "Rewrite the first half of this paragraph to make it clearer and easier to read.", "revised_paragraph": "Revised paragraph: Mahapatra and Rajan (2020) introduced Exact Pareto Optimal (EPO), a multi-objective optimization method that can converge to a specific ray in loss space. Given a preference ray, r, EPO searches for an exact Pareto optimal solution, which is characterized by two properties: (i) Pareto optimality, and (ii) lying at the intersection of the Pareto front and the preference vector, r. The EPO method aims to balance two objectives: finding a descent direction and reaching the desired ray.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Alternative methods use the returns of the behavior policy as a signal for policy learning, as seen in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods can be limited by imperfect behavior policies and limited data. To balance imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which combines the Bellman expectation operator and optimality operator through a new expectile operator.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"An alternative approach uses the returns of the behavior policy as a signal for policy learning, as demonstrated in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). By leveraging these returns, the learning procedure is confined to the dataset's support. However, the behavior policy may be imperfect and insufficient to guide policy learning. Conversely, learning optimal values solely within the dataset can lead to overly optimistic value estimates due to limited data and off-policy issues. To strike a balance between imitation learning and optimal value learning, we introduce Expectile V-learning (EVL), which is founded on a novel expectile operator that seamlessly interpolates between the Bellman expectation operator and the optimality operator.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Alternative methods use the returns of the behavior policy as a signal for policy learning, as seen in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods can be limited by imperfect behavior policies and limited data. To balance imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which combines the Bellman expectation operator and optimality operator through a new expectile operator.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Alternative methods use the returns of the behavior policy as a signal for policy learning, as seen in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods can be limited by imperfect behavior policies and limited data. To balance imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which combines the Bellman expectation operator and optimality operator through a new expectile operator.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"An alternative approach uses the returns of the behavior policy as a signal for policy learning, as demonstrated in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). By leveraging these returns, the learning procedure is confined to the dataset's support. However, the behavior policy may be imperfect and insufficient to guide policy learning. Conversely, learning optimal values solely within the dataset can lead to overly optimistic value estimates due to limited data and off-policy issues. To strike a balance between imitation learning and optimal value learning, we introduce Expectile V-learning (EVL), which is founded on a novel expectile operator that seamlessly interpolates between the Bellman expectation operator and the optimality operator.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Alternative methods use the returns of the behavior policy as a signal for policy learning, as seen in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods can be limited by imperfect behavior policies and limited data. To balance imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which combines the Bellman expectation operator and optimality operator through a new expectile operator.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Alternative methods use the returns of the behavior policy as a signal for policy learning, as seen in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods can be limited by imperfect behavior policies and limited data. To balance imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which combines the Bellman expectation operator and optimality operator through a new expectile operator.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Alternative methods leverage the returns of behavior policies as a signal for policy learning, as exemplified in the works of Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods are often constrained by imperfect behavior policies and limited data. To reconcile imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which integrates the Bellman expectation operator and optimality operator through a novel expectile operator.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Alternative methods use the returns of the behavior policy as a signal for policy learning, as seen in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods can be limited by imperfect behavior policies and limited data. To balance imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which combines the Bellman expectation operator and optimality operator through a new expectile operator.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Alternative methods use the returns of the behavior policy as a signal for policy learning, as seen in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods can be limited by imperfect behavior policies and limited data. To balance imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which combines the Bellman expectation operator and optimality operator through a new expectile operator.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Alternative methods leverage the returns of behavior policies as a signal for policy learning, as exemplified in the works of Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods are often constrained by imperfect behavior policies and limited data. To reconcile imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which integrates the Bellman expectation operator and optimality operator through a novel expectile operator.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Alternative methods use the returns of the behavior policy as a signal for policy learning, as seen in Wang et al. (2018), Peng et al. (2019), and Chen et al. (2020). However, these methods can be limited by imperfect behavior policies and limited data. To balance imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which combines the Bellman expectation operator and optimality operator through a new expectile operator.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "instruction": "Remove a redundant sentence. Correct citation format.", "revised_paragraph": "Revised paragraph: \"Another line of methods uses the returns of the behavior policy as the signal for policy learning, as adopted in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). This approach keeps the whole learning procedure within the dataset\u2019s support, but may be imperfect and insufficient to guide policy learning. To achieve a trade-off between imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which is based on a new expectile operator that smoothly interpolates between the Bellman expectation operator and optimality operator.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "fDUdAYCQqZy.0cNiGAHFml.00", "instruction": "Make it shorter by removing what is not essential.", "revised_paragraph": "Revised paragraph: Another line of methods uses the returns of the behavior policy as a signal for policy learning, as seen in (Wang et al., 2018; Peng et al., 2019; Chen et al., 2020). However, these methods may be limited by imperfect behavior policies and limited data. To balance imitation learning and optimal value learning, we propose Expectile V-learning (EVL), which combines the Bellman expectation operator and optimality operator using a new expectile operator.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In our previous study (Chakraborti et al., 2017), we addressed inconsistencies by distinguishing between model differences and discrepancies between human and robot models when generating explanations. This approach enables humans to adjust their mental models to align with the robot's behavior, which is expected to make sense within the updated model that reflects the human's expectations. This decision-making process, where an agent reconciles model differences, has been previously described (Chakraborti et al., 2017; Zhang et al., 2017)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In our previous study (Chakraborti et al., 2017), we addressed inconsistencies by distinguishing between model differences and discrepancies between human and robot models when generating explanations. This approach enables humans to adjust their mental models to align with the robot's behavior, which is expected to make sense within the updated model that reflects the human's expectations. This decision-making process, where an agent reconciles model differences, has been previously described (Chakraborti et al., 2017; Zhang et al., 2017)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In our previous study (Chakraborti et al., 2017), we addressed inconsistencies by distinguishing between model differences and discrepancies between human and robot models when generating explanations. This approach enables humans to adjust their mental models to align with the robot's behavior, which is expected to make sense within the updated model that reflects the human's expectations. This decision-making process, where an agent reconciles model differences, has been previously described (Chakraborti et al., 2017; Zhang et al., 2017)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In our previous study (Chakraborti et al., 2017), we addressed inconsistencies by distinguishing between model differences and discrepancies between human and robot models when generating explanations. This approach enables humans to adjust their mental models to align with the robot's behavior, which is expected to make sense within the updated model that reflects the human's expectations. This decision-making process, where an agent reconciles model differences, has been previously described (Chakraborti et al., 2017; Zhang et al., 2017)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In our previous study (Chakraborti et al., 2017), we addressed inconsistencies by distinguishing between model differences and discrepancies between human and robot models when generating explanations. This approach enables humans to adjust their mental models to align with the robot's behavior, which is expected to make sense within the updated model that reflects the human's expectations. This decision-making process, where an agent reconciles model differences, has been previously described (Chakraborti et al., 2017; Zhang et al., 2017)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In our previous study (Chakraborti et al., 2017), we addressed inconsistencies by distinguishing between model differences and discrepancies between human and robot models when generating explanations. This approach enables humans to adjust their mental models to align with the robot's behavior, which is expected to make sense within the updated model that reflects the human's expectations. This decision-making process, where an agent reconciles model differences, has been previously described (Chakraborti et al., 2017; Zhang et al., 2017)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In our previous study (Chakraborti et al., 2017), we addressed inconsistencies by distinguishing between model differences and discrepancies between human and robot models when generating explanations. This approach enables humans to adjust their mental models to align with the robot's behavior, which is expected to make sense within the updated model that reflects the human's expectations. This decision-making process, where an agent reconciles model differences, has been previously described (Chakraborti et al., 2017; Zhang et al., 2017)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In our previous study (Chakraborti et al., 2017), we addressed inconsistencies by distinguishing between model differences and discrepancies between human and robot models when generating explanations. This approach enables humans to adjust their mental models to align with the robot's behavior, which is expected to make sense within the updated model that reflects the human's expectations. This decision-making process, where an agent reconciles model differences, has been previously described (Chakraborti et al., 2017; Zhang et al., 2017)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "instruction": "Revise the opening of this paragraph to make it more compelling.", "revised_paragraph": "Revised paragraph: \"In our pioneering work (Chakraborti et al. 2017), we tackled the long-standing challenge of inconsistencies in human-robot collaboration by introducing the concept of model reconciliation. This novel approach recognizes that humans and robots possess fundamentally different models of the world, leading to discrepancies in their understanding of each other's behavior. By acknowledging these model differences, we enable agents to generate explanations that bridge the gap between human and robotic perspectives, ultimately fostering a deeper understanding of each other's intentions and actions. The model reconciliation process, which we introduced in our earlier work (Chakraborti et al. 2017; Zhang et al. 2017), has since been widely recognized as a crucial step towards more effective human-robot collaboration.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "instruction": "Rewrite the first sentence to make it more convincing.", "revised_paragraph": "Revised paragraph: In our pioneering study (Chakraborti et al. 2017), we pioneered the concept of encapsulating inconsistencies as model differences, and demonstrated the significance of considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot\u2019s behavior would make sense in the updated model, which captures the human\u2019s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To evaluate the plausibility of KG-augmented models' explanations, we conducted a user study using both the original KG and the RLRR perturbed KG. We selected 30 questions from the CSQA and OBQA test sets that were correctly answered by MHGRN and retrieved the top-scoring paths for each answer choice via MHGRN's path decoder attention. Three human subjects then rated each path for readability and usability, with ratings aggregated through majority voting. Readability was measured as whether the path makes sense, while usability referred to its relevance to the given question-answer pair, both on a scale of 0 to 1. The Fleiss' \u03ba value of 0.1891 indicates slight agreement among raters. For illustration, we provide examples of explanation paths and their consensus ratings."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To assess the plausibility of KG-augmented models' explanations, we conducted a human evaluation study using both the original KG and RLRR perturbed KG. We selected 30 questions from the CSQA and OBQA test sets that were correctly answered by MHGRN and retrieved the top-scoring paths for each answer choice via MHGRN's path decoder attention. Three human subjects then rated each path for readability and usability, with ratings aggregated using majority voting. Readability (Read) refers to the path's coherence, while usability (Use) assesses its relevance to the question-answer pair. Ratings were scored on a [0, 1] scale. Inter-rater agreement was moderate, with a Fleiss' \u03ba of 0.1891. To illustrate the evaluation process, we provide examples of explanation paths and their consensus ratings.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To assess the plausibility of KG-augmented models' explanations, we conducted a human evaluation study using both the original KG and RLRR perturbed KG. We selected 30 questions from the CSQA and OBQA test sets that were correctly answered by MHGRN and retrieved the top-scoring paths for each answer choice via MHGRN's path decoder attention. Three human subjects then rated each path for readability and usability, with ratings aggregated using majority voting. Readability (Read) refers to the path's coherence, while usability (Use) assesses its relevance to the question-answer pair. Ratings were scored on a [0, 1] scale. Inter-rater agreement was moderate, with a Fleiss' \u03ba of 0.1891. To illustrate the evaluation process, we provide examples of explanation paths and their consensus ratings.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To evaluate the plausibility of KG-augmented models' explanations, we conducted a user study using both the original KG and the RLRR perturbed KG. We selected 30 questions from the CSQA and OBQA test sets that were correctly answered by MHGRN and retrieved the top-scoring paths for each answer choice via MHGRN's path decoder attention. Three human subjects then rated each path for readability and usability, with ratings aggregated through majority voting. Readability was measured as whether the path makes sense, while usability referred to its relevance to the given question-answer pair, both on a scale of 0 to 1. The Fleiss' \u03ba value of 0.1891 indicates slight agreement among raters. For illustration, we provide examples of explanation paths and their consensus ratings."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To evaluate the plausibility of KG-augmented models' explanations, we conducted a user study using both the original KG and the RLRR perturbed KG. We selected 30 questions from the CSQA and OBQA test sets that were correctly answered by MHGRN and retrieved the top-scoring paths for each answer choice via MHGRN's path decoder attention. Three human subjects then rated each path for readability and usability, with ratings aggregated through majority voting. Readability was measured as whether the path makes sense, while usability referred to its relevance to the given question-answer pair, both on a scale of 0 to 1. The Fleiss' \u03ba value of 0.1891 indicates slight agreement among raters. For illustration, we provide examples of explanation paths and their consensus ratings."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To assess the plausibility of explanations provided by KG-augmented models, we conducted a user study using both the original knowledge graph (KG) and a perturbed KG generated by the RLRR algorithm. We selected 30 questions from the CSQA and OBQA test sets that were correctly answered by the MHGRN model and retrieved the top-scoring paths for each answer choice using the model's path decoder attention mechanism. Three human subjects then evaluated each path for readability and usability, with ratings aggregated through majority voting. Readability was measured as the extent to which the path makes sense, while usability referred to its relevance to the given question-answer pair, both on a scale of 0 to 1. The Fleiss' \u03ba value of 0.1891 indicates a moderate level of agreement among raters. To illustrate the types of explanation paths and their consensus ratings, we provide several examples."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To assess the plausibility of KG-augmented models' explanations, we conducted a human evaluation study using both the original KG and RLRR perturbed KG. We selected 30 questions from the CSQA and OBQA test sets that were correctly answered by MHGRN and retrieved the top-scoring paths for each answer choice via MHGRN's path decoder attention. Three human subjects then rated each path for readability and usability, with ratings aggregated using majority voting. Readability (Read) refers to the path's coherence, while usability (Use) assesses its relevance to the question-answer pair. Ratings were scored on a [0, 1] scale. Inter-rater agreement was moderate, with a Fleiss' \u03ba of 0.1891. To illustrate the evaluation process, we provide examples of explanation paths and their consensus ratings.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To evaluate the plausibility of KG-augmented models' explanations, we conducted a user study using both the original KG and the RLRR perturbed KG. We selected 30 questions from the CSQA and OBQA test sets that were correctly answered by MHGRN and retrieved the top-scoring paths for each answer choice via MHGRN's path decoder attention. Three human subjects then rated each path for readability and usability, with ratings aggregated through majority voting. Readability was measured as whether the path makes sense, while usability referred to its relevance to the given question-answer pair, both on a scale of 0 to 1. The Fleiss' \u03ba value of 0.1891 indicates slight agreement among raters. For illustration, we provide examples of explanation paths and their consensus ratings."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "instruction": "Review the following paragraph, only when necesarry make modificatons to make it easier to read", "revised_paragraph": "Revised paragraph: Human Evaluation of KG Explanations: We conduct a user study to assess the ability of KG-augmented models to provide plausible explanations, using both the original KG and RLRR perturbed KG. We sampled 30 questions from the CSQA and OBQA test sets that were correctly answered by MHGRN. For each question, we retrieved the top-scoring path for each answer choice via MHGRN's path decoder attention. Three human subjects then rated each path for readability and usability, with ratings aggregated via majority voting. Readability (Read) refers to whether the path makes sense, while usability (Use) assesses whether the path is relevant to the given question-answer pair, both measured on a [0, 1] scale. Our results show a Fleiss' \u03ba of 0.1891, indicating slight agreement between raters. To illustrate, we provide examples of explanation paths and their consensus ratings.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "ZcvguGK9Q.dBwWtd12-n.00", "instruction": "Better balance the length of the first and second sentences.", "revised_paragraph": "Revised paragraph: \"We conduct a user study to measure the ability of KG-augmented models to provide plausible explanations, using both the original KG and RLRR perturbed KG. We sample 30 questions from the CSQA and OBQA test sets, which were correctly answered by MHGRN, and retrieve the top-scoring paths for each answer choice via MHGRN's path decoder attention. Human subjects then rate each path for readability and usability, with ratings aggregated via majority voting. Specifically, readability assesses whether the path makes sense, while usability evaluates whether the path is relevant to the given question-answer pair, both measured on a [0, 1] scale. We report a Fleiss' \u03ba of 0.1891, indicating slight agreement between raters. Examples of explanation paths and their consensus ratings are provided to illustrate our findings.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"This paper derives new generalization bounds for convolutional networks, accounting for the effect of initial weights and number of parameters. Unlike previous analyses, our bounds are size-free, meaning they are independent of input size and hidden feature map dimensions.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"This paper derives new generalization bounds for convolutional networks, accounting for the effect of initial weights and number of parameters. Unlike previous analyses, our bounds are size-free, meaning they are independent of input size and hidden feature map dimensions.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"This paper derives new generalization bounds for convolutional networks, accounting for the effect of initial weights and number of parameters. Unlike previous analyses, our bounds are size-free, meaning they are independent of input size and hidden feature map dimensions.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"This paper derives new generalization bounds for convolutional networks, accounting for the effect of initial weights and number of parameters. Unlike previous analyses, our bounds are size-free, meaning they are independent of input size and hidden feature map dimensions.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"This paper derives new generalization bounds for convolutional networks, accounting for the effect of initial weights and number of parameters. Unlike previous analyses, our bounds are size-free, meaning they are independent of input size and hidden feature map dimensions.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"This paper derives new generalization bounds for convolutional networks, accounting for the effect of initial weights and number of parameters. Unlike previous analyses, our bounds are size-free, meaning they are independent of input size and hidden feature map dimensions.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"This paper derives new generalization bounds for convolutional networks, accounting for the effect of initial weights and number of parameters. Unlike previous analyses, our bounds are size-free, meaning they are independent of input size and hidden feature map dimensions.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"This paper derives new generalization bounds for convolutional networks, accounting for the effect of initial weights and number of parameters. Unlike previous analyses, our bounds are size-free, meaning they are independent of input size and hidden feature map dimensions.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "instruction": "Make the ideas more concise.", "revised_paragraph": "Revised paragraph: \"This paper establishes novel generalization bounds for convolutional networks, considering the effect in question. Our bounds, similar to those for fully connected networks, rely on the distance from initial weights and the number of parameters. Notably, they are'size-free', unaffected by the input's pixel count or hidden feature map dimensions.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "B1SkMaDvr.W2MCLgZGr.00", "instruction": "Remove unnecessary details.", "revised_paragraph": "Revised paragraph: \"Our paper establishes new generalization bounds for convolutional networks that consider this effect. Like earlier analyses for fully connected networks, our bounds rely on the distance from the initial weights and the number of parameters. Notably, our bounds are size-free, meaning they are independent of the input size or hidden feature map dimensions.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have achieved promising results with moderate model sizes, but their extension to larger networks has been impractical or neglected. In contrast, model compression techniques such as neural architecture search and knowledge distillation typically require significant computational resources. Network pruning, on the other hand, is a cost-effective and efficient method that can be applied to SR networks. However, filter pruning for residual blocks is known to be challenging. To address these issues, we propose a novel structure-regularized pruning (SRP) technique that imposes regularization on the pruned structure to align the locations of pruned filters across different layers. Specifically, for layers connected by the same residual, we select filters with the same indices as unimportant filters and employ L2 regularization to drive the weights towards zero, allowing the network to adapt to the absence of these filters without significant performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network (SRPN-L) and a very deep one (SRPN). We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating superior performance gains over recent methods in both quantitative and visual evaluations."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have achieved promising results with moderate model sizes, but their extension to larger networks has been impractical or neglected. In contrast, model compression techniques such as neural architecture search and knowledge distillation typically require significant computational resources. Network pruning, on the other hand, is a cost-effective and efficient method that can be applied to SR networks. However, filter pruning for residual blocks is known to be challenging. To address these issues, we propose a novel structure-regularized pruning (SRP) technique that imposes regularization on the pruned structure to align the locations of pruned filters across different layers. Specifically, for layers connected by the same residual, we select filters with the same indices as unimportant filters and employ L2 regularization to drive the weights towards zero, allowing the network to adapt to the absence of these filters without significant performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network (SRPN-L) and a very deep one (SRPN). We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating superior performance gains over recent methods in both quantitative and visual evaluations."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have achieved promising results with moderate model sizes, but their extension to larger networks has been impractical or neglected. In contrast, model compression techniques such as neural architecture search and knowledge distillation typically require significant computational resources. Network pruning, on the other hand, is a cost-effective and efficient method that can be applied to SR networks. However, filter pruning for residual blocks is known to be challenging. To address these issues, we propose a novel structure-regularized pruning (SRP) technique that imposes regularization on the pruned structure to align the locations of pruned filters across different layers. Specifically, for layers connected by the same residual, we select filters with the same indices as unimportant filters and employ L2 regularization to drive the weights towards zero, allowing the network to adapt to the absence of these filters without significant performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network (SRPN-L) and a very deep one (SRPN). We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating superior performance gains over recent methods in both quantitative and visual evaluations."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have achieved promising results with moderate model sizes, but their extension to larger networks has been impractical or neglected. In contrast, model compression techniques such as neural architecture search and knowledge distillation typically require significant computational resources. Network pruning, on the other hand, is a cost-effective and efficient method that can be applied to SR networks. However, filter pruning for residual blocks is known to be challenging. To address these issues, we propose a novel structure-regularized pruning (SRP) technique that imposes regularization on the pruned structure to align the locations of pruned filters across different layers. Specifically, for layers connected by the same residual, we select filters with the same indices as unimportant filters and employ L2 regularization to drive the weights towards zero, allowing the network to adapt to the absence of these filters without significant performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network (SRPN-L) and a very deep one (SRPN). We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating superior performance gains over recent methods in both quantitative and visual evaluations."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have achieved promising results with moderate model sizes, but their extension to larger networks has been impractical or neglected. In contrast, model compression techniques such as neural architecture search and knowledge distillation typically require significant computational resources. Network pruning, on the other hand, is a cost-effective and efficient method that can be applied to SR networks. However, filter pruning for residual blocks is known to be challenging. To address these issues, we propose a novel structure-regularized pruning (SRP) technique that imposes regularization on the pruned structure to align the locations of pruned filters across different layers. Specifically, for layers connected by the same residual, we select filters with the same indices as unimportant filters and employ L2 regularization to drive the weights towards zero, allowing the network to adapt to the absence of these filters without significant performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network (SRPN-L) and a very deep one (SRPN). We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating superior performance gains over recent methods in both quantitative and visual evaluations."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have achieved promising results with moderate model sizes, but their extension to larger networks has been impractical or neglected. In contrast, model compression techniques such as neural architecture search and knowledge distillation typically require significant computational resources. Network pruning, on the other hand, is a cost-effective and efficient method that can be applied to SR networks. However, filter pruning for residual blocks is known to be challenging. To address these issues, we propose a novel structure-regularized pruning (SRP) technique that imposes regularization on the pruned structure to align the locations of pruned filters across different layers. Specifically, for layers connected by the same residual, we select filters with the same indices as unimportant filters and employ L2 regularization to drive the weights towards zero, allowing the network to adapt to the absence of these filters without significant performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network (SRPN-L) and a very deep one (SRPN). We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating superior performance gains over recent methods in both quantitative and visual evaluations."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have achieved promising results with moderate model sizes, but their extension to larger networks has been impractical or neglected. In contrast, model compression techniques such as neural architecture search and knowledge distillation typically require significant computational resources. Network pruning, on the other hand, is a cost-effective and efficient method that can be applied to SR networks. However, filter pruning for residual blocks is known to be challenging. To address these issues, we propose a novel structure-regularized pruning (SRP) technique that imposes regularization on the pruned structure to align the locations of pruned filters across different layers. Specifically, for layers connected by the same residual, we select filters with the same indices as unimportant filters and employ L2 regularization to drive the weights towards zero, allowing the network to adapt to the absence of these filters without significant performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network (SRPN-L) and a very deep one (SRPN). We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating superior performance gains over recent methods in both quantitative and visual evaluations."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have achieved promising results with moderate model sizes, but their extension to larger networks has been impractical or neglected. In contrast, model compression techniques such as neural architecture search and knowledge distillation typically require significant computational resources. Network pruning, on the other hand, is a cost-effective and efficient method that can be applied to SR networks. However, filter pruning for residual blocks is known to be challenging. To address these issues, we propose a novel structure-regularized pruning (SRP) technique that imposes regularization on the pruned structure to align the locations of pruned filters across different layers. Specifically, for layers connected by the same residual, we select filters with the same indices as unimportant filters and employ L2 regularization to drive the weights towards zero, allowing the network to adapt to the absence of these filters without significant performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network (SRPN-L) and a very deep one (SRPN). We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating superior performance gains over recent methods in both quantitative and visual evaluations."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "instruction": "Replace all occurrences of SRPN-L with SRPN-Lite. Improve the english of this paragraph.", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have achieved promising results with moderate model sizes. However, they are often impractical or neglected when attempting to scale up to larger networks. In contrast, model compression techniques, such as neural architecture search and knowledge distillation, typically require significant computational resources. Network pruning, on the other hand, is a cost-effective and efficient model compression technique. Nevertheless, applying pruning directly to SR networks can be challenging, particularly when pruning filters in residual blocks, which is a well-known tricky task. To address these limitations, we propose structure-regularized pruning (SRP), which introduces regularization on the pruned structure to ensure that the locations of pruned filters are aligned across different layers. Specifically, for layers connected by the same residual, we identify filters of the same indices as unimportant and employ L2 regularization to drive the weights towards zero, allowing the network to adapt and maintain minimal performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network, SRPN-Lite, and a very deep one, SRPN. We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating superior performance gains over recent methods both quantitatively and visually.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.00", "instruction": "Replace SRPN-L by SPRN-Lite. Make the first and last sentence more fitting to the academic style.", "revised_paragraph": "Revised paragraph: Lightweight image super-resolution (SR) networks have garnered significant attention in recent years due to their ability to achieve promising results with moderate model size. However, extending these networks to larger models remains a challenge. At the same time, model compression techniques, such as neural architecture search and knowledge distillation, often require considerable computational resources. In contrast, network pruning is a cost-effective and efficient model compression technique. However, its application to SR networks is hindered by the difficulty of filter pruning for residual blocks. To address these limitations, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to ensure the alignment of pruned filters across different layers. Specifically, for layers connected by the same residual, we select filters with the same indices as unimportant filters. To transfer the expressive power in unimportant filters to the rest of the network, we employ L2 regularization to drive the weights towards zero, minimizing performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network, SPRN-Lite, and a very deep one, SPRN. We conduct extensive comparisons with both lightweight and larger image SR networks, demonstrating that SPRN-Lite and SPRN achieve superior performance gains over recent methods quantitatively and visually.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The literature on post hoc explanations is plagued by a lack of common goals among methods, leading to fragmentation and confusion. For instance, some methods focus on function approximation, while others use game theoretic concepts or aim for clean visualizations. This diversity of goals hinders a unified understanding of post hoc explainability and makes it difficult to choose the most suitable method.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"A pervasive issue in the literature on post hoc explanations is the absence of a shared, foundational objective among methodologies. For instance, some approaches are guided by function approximation, while others draw on game-theoretic concepts such as Shapley-Aumann values, and some are driven by the need for visually appealing results. This fragmentation of goals not only hinders the development of a coherent conceptual framework for post hoc explainability but also creates a practical challenge, as it is unclear which method to employ in a given situation.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The literature on post hoc explanations is plagued by a lack of common goals among methods, leading to fragmentation and confusion. For instance, some methods focus on function approximation, while others use game theoretic concepts or aim for clean visualizations. This diversity of goals hinders a unified understanding of post hoc explainability and makes it difficult to choose the most suitable method.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The literature on post hoc explanations is plagued by a lack of common goals among methods, leading to fragmentation and confusion. For instance, some methods focus on function approximation, while others use game theoretic concepts or aim for clean visualizations. This diversity of goals hinders a unified understanding of post hoc explainability and makes it difficult to choose the most suitable method.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The literature on post hoc explanations is plagued by a lack of common goals among methods, leading to fragmentation and confusion. For instance, some methods focus on function approximation, while others use game theoretic concepts or aim for clean visualizations. This diversity of goals hinders a unified understanding of post hoc explainability and makes it difficult to choose the most suitable method.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"A pervasive issue in the literature on post hoc explanations is the absence of a shared, foundational objective among methodologies. For instance, some approaches are guided by function approximation, while others draw on game-theoretic concepts such as Shapley-Aumann values, and some are driven by the need for visually appealing results. This fragmentation of goals not only hinders the development of a coherent conceptual framework for post hoc explainability but also creates a practical challenge, as it is unclear which method to employ in a given situation.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The literature on post hoc explanations is plagued by a lack of common goals among methods, leading to fragmentation and confusion. For instance, some methods focus on function approximation, while others use game theoretic concepts or aim for clean visualizations. This diversity of goals hinders a unified understanding of post hoc explainability and makes it difficult to choose the most suitable method.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The existing literature on post hoc explanations is characterized by a lack of consensus on objectives, resulting in fragmentation and confusion. For example, some approaches prioritize function approximation, while others employ game-theoretic concepts or strive for clear visualizations. This diversity of goals hinders the development of a unified understanding of post hoc explainability, making it challenging to select the most suitable method.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The literature on post hoc explanations is plagued by a lack of common goals among methods, leading to fragmentation and confusion. For instance, some methods focus on function approximation, while others use game theoretic concepts or aim for clean visualizations. This diversity of goals hinders a unified understanding of post hoc explainability and makes it difficult to choose the most suitable method.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The literature on post hoc explanations is plagued by a lack of common goals among methods, leading to fragmentation and confusion. For instance, some methods focus on function approximation, while others use game theoretic concepts or aim for clean visualizations. This diversity of goals hinders a unified understanding of post hoc explainability and makes it difficult to choose the most suitable method.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The literature on post hoc explanations is plagued by a lack of common goals among methods, leading to fragmentation and confusion. For instance, some methods focus on function approximation, while others use game theoretic concepts or aim for clean visualizations. This diversity of goals hinders a unified understanding of post hoc explainability and makes it difficult to choose the most suitable method.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The existing literature on post hoc explanations is characterized by a lack of consensus on objectives, resulting in fragmentation and confusion. For example, some approaches prioritize function approximation, while others employ game-theoretic concepts or strive for clear visualizations. This diversity of goals hinders the development of a unified understanding of post hoc explainability, making it challenging to select the most suitable method.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "instruction": "Make as concise as possible the paragraph, removing any ideas that are not essential. Use a clearer word choice.", "revised_paragraph": "Revised paragraph: The literature on post hoc explanations lacks a unified foundation, as methods are driven by diverse goals. Some aim to approximate functions, others use game theory, and some are ad hoc, prioritizing visualization. This fragmentation hinders a coherent understanding of post hoc explainability and creates a practical challenge in selecting the most suitable method.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "instruction": "Concise this paragraph while improving the academic english.", "revised_paragraph": "Revised paragraph: A significant issue in the literature on post hoc explanations is the absence of a unified objective among methods, leading to methodological fragmentation. While some approaches focus on function approximation, others rely on game-theoretic concepts, such as Shapley-Aumann values, or are driven by the need for visually appealing results. This lack of coherence not only hinders a comprehensive understanding of post hoc explainability but also presents a practical challenge, as it is unclear which method to employ in a given context.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can effectively convey suggested actions. Specifically, end-of-line arrows can be used to indicate that medication entries that are too close together should be spaced apart, or vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"When resolving conflicts, arrows are a effective means of communicating suggested conflict resolution actions. End-of-line arrows can be used to indicate that medication entries scheduled too close together should be spaced apart, and vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed and non-prescription medication purchased over-the-counter. These design decisions are informed by everyday activities that users are familiar with, making the system more intuitive and user-friendly.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can effectively convey suggested actions. Specifically, end-of-line arrows can be used to indicate that medication entries that are too close together should be spaced apart, or vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can effectively convey suggested actions. Specifically, end-of-line arrows can be used to indicate that medication entries that are too close together should be spaced apart, or vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can effectively convey suggested actions. Specifically, end-of-line arrows can be used to indicate that medication entries that are too close together should be spaced apart, or vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"When resolving conflicts, arrows are a effective means of communicating suggested conflict resolution actions. End-of-line arrows can be used to indicate that medication entries scheduled too close together should be spaced apart, and vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed and non-prescription medication purchased over-the-counter. These design decisions are informed by everyday activities that users are familiar with, making the system more intuitive and user-friendly.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can effectively convey suggested actions. Specifically, end-of-line arrows can be used to indicate that medication entries that are too close together should be spaced apart, or vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can be used to suggest actions effectively. Specifically, end-of-line arrows can be employed to indicate that medication entries that are too close together should be spaced apart, or vice versa. Furthermore, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to, drawing on their existing knowledge and experience."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can effectively convey suggested actions. Specifically, end-of-line arrows can be used to indicate that medication entries that are too close together should be spaced apart, or vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can effectively convey suggested actions. Specifically, end-of-line arrows can be used to indicate that medication entries that are too close together should be spaced apart, or vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can effectively convey suggested actions. Specifically, end-of-line arrows can be used to indicate that medication entries that are too close together should be spaced apart, or vice versa. Additionally, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows can be used to suggest actions effectively. Specifically, end-of-line arrows can be employed to indicate that medication entries that are too close together should be spaced apart, or vice versa. Furthermore, the calendar should support the indication of optional entries, such as prescription medication that should be taken as needed or non-prescription medication that is purchased over the counter. These design decisions are informed by familiar everyday activities that users are accustomed to, drawing on their existing knowledge and experience."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "instruction": "Clarify the wording in this paragraph.", "revised_paragraph": "Revised paragraph: When resolving conflicts, arrows are a useful tool for communicating suggested conflict resolution actions. Specifically, end-of-line arrows can be employed to indicate that medication entries scheduled too close together should be spaced apart, and vice versa. Additionally, the calendar should support the indication of optional entries, which is particularly relevant for medication that is taken as needed, such as prescription medication, or is purchased over-the-counter, like non-prescription medication. These design decisions are informed by everyday activities that users are familiar with.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "instruction": "Reword my sentence about entries.", "revised_paragraph": "Revised paragraph: When resolving conflicts, end-of-line arrows can be used to convey suggested action plans. Specifically, arrows can indicate that medication entries that are too close together should be separated, and vice versa. Additionally, the calendar should accommodate the option to mark specific entries as non-mandatory, such as prescription medication taken as needed or over-the-counter medication. These design decisions are informed by familiar everyday activities that users can relate to.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Future work includes improving upper bounds on the pseudo-dimension by restricting heuristic functions to specific classes, as discussed in Section 2. This is particularly important for path-finding instances with many vertices, where learned heuristics can be applied using GBFS/A*. We demonstrate the feasibility of this approach in Appendix D, achieving polylog(n) upper bounds by designing instance-specific heuristic functions with fewer tunable parameters than n.\""}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Another future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to specific classes. This direction is particularly important when applying GBFS/A* with learned heuristics to path-finding instances with many vertices."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Future work includes improving upper bounds on the pseudo-dimension by restricting heuristic functions to specific classes, as discussed in Section 2. This is particularly important for path-finding instances with many vertices, where learned heuristics can be applied using GBFS/A*. We demonstrate the feasibility of this approach in Appendix D, achieving polylog(n) upper bounds by designing instance-specific heuristic functions with fewer tunable parameters than n.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Another future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to specific classes. This direction is particularly important when applying GBFS/A* with learned heuristics to path-finding instances with many vertices."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Future work includes improving upper bounds on the pseudo-dimension by restricting heuristic functions to specific classes, as discussed in Section 2. This is particularly important for path-finding instances with many vertices, where learned heuristics can be applied using GBFS/A*. We demonstrate the feasibility of this approach in Appendix D, achieving polylog(n) upper bounds by designing instance-specific heuristic functions with fewer tunable parameters than n.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Future work involves improving upper bounds on the pseudo-dimension by restricting heuristic functions to specific classes, which is crucial for path-finding instances with many vertices. We demonstrate the feasibility of this approach in Appendix D, achieving polylog(n) upper bounds.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Future work includes improving upper bounds on the pseudo-dimension by restricting heuristic functions to specific classes, as discussed in Section 2. This is particularly important for path-finding instances with many vertices, where learned heuristics can be applied using GBFS/A*. We demonstrate the feasibility of this approach in Appendix D, achieving polylog(n) upper bounds by designing instance-specific heuristic functions with fewer tunable parameters than n.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Another future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to specific classes. This direction is particularly important when applying GBFS/A* with learned heuristics to path-finding instances with many vertices."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "instruction": "Make this paragraph shorter by eliminating details about further work.", "revised_paragraph": "Revised paragraph: \"Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to specific classes, as discussed in Section 2. This direction is particularly relevant for path-finding instances with many vertices, where GBFS/A* with learned heuristics may be effective.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "instruction": "Delete the sentence about further study and the reference to section 2.", "revised_paragraph": "Revised paragraph: Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes. In Appendix D, we present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The assumption in backdoor-based model watermarking that the trigger matches hidden backdoors in the suspicious model may not hold, as the backdoor can be changed during the stealing process. We verify this limitation.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The assumption in backdoor-based model watermarking that the trigger matches hidden backdoors in the suspicious model may not hold, as the backdoor can be changed during the stealing process. We verify this limitation.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The assumption in backdoor-based model watermarking that the trigger matches hidden backdoors in the suspicious model may not hold, as the backdoor can be changed during the stealing process. We verify this limitation.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The assumption in backdoor-based model watermarking that the trigger matches hidden backdoors in the suspicious model may not hold, as the backdoor can be changed during the stealing process. We verify this limitation.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The assumption in backdoor-based model watermarking that the trigger matches hidden backdoors in the suspicious model may not hold, as the backdoor can be changed during the stealing process. We verify this limitation.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The assumption in backdoor-based model watermarking that the trigger matches hidden backdoors in the suspicious model may not hold, as the backdoor can be changed during the stealing process. We verify this limitation.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The assumption in backdoor-based model watermarking that the trigger matches hidden backdoors in the suspicious model may not hold, as the backdoor can be changed during the stealing process. We verify this limitation.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The assumption in backdoor-based model watermarking that the trigger matches hidden backdoors in the suspicious model may not hold, as the backdoor can be changed during the stealing process. We verify this limitation.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "instruction": "Remove information on why the assumption might not hold.", "revised_paragraph": "Revised paragraph: \"Backdoor-based model watermarking relies on the assumption that the trigger matches hidden backdoors contained in the suspicious model.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "dD-sDO1KaC.N7AsVzdCxV.00", "instruction": "Make the second sentence much shorter, only keep the main idea.", "revised_paragraph": "Revised paragraph: \"Backdoor-based model watermarking relied on an assumption that the trigger matches hidden backdoors contained in the suspicious model. However, this assumption may not hold.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: This paper investigates the generalization performance of gradient-based meta learning with overparameterized models, focusing on linear models with limited data from all tasks. We show that when data heterogeneity is relatively small, certain covariance matrices lead to benign overfitting, enabling good generalization in new data and tasks. Our theory also suggests that overfitting is more likely in metalearning than ERM, especially with high data heterogeneity. While our analysis is limited to linear regression, it can be extended to nonlinear cases via random features and neural tangent kernels in future work."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This paper investigates the generalization performance of gradient-based meta learning with an overparameterized model. To facilitate a precise analysis, we focus on linear models where the total number of data points from all tasks is smaller than the dimension of the model's parameter space. Our results show that when data heterogeneity across tasks is relatively low, per-task data covariance matrices with specific properties lead to benign overfitting for gradient-based meta learning with the minimum-norm solution. This explains why overparameterized meta learning models can generalize well in new data and tasks. Moreover, our theory suggests that overfitting is more likely to occur in metalearning than in ERM, particularly when data heterogeneity across tasks is relatively high. One limitation of this work is that the analysis is limited to the meta-linear regression case. While this analysis can capture practical scenarios where a feature extractor is reused from pre-trained models and only the parameters in the last linear layer are meta-trained, it is also promising to extend our analysis to nonlinear cases via random features and neural tangent kernels in future work."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nThis paper investigates the generalization performance of gradient-based meta learning with an overparameterized model. To facilitate a precise analysis, we concentrate on linear models, where the total number of data points from all tasks is smaller than the dimension of the model's parameter space. We demonstrate that when data heterogeneity across tasks is relatively small, per-task data covariance matrices with specific properties lead to benign overfitting for gradient-based meta learning with the minimum-norm solution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory reveals that overfitting is more likely to occur in metalearning than in ERM, particularly when data heterogeneity across tasks is relatively high. A limitation of this work is that the analysis is limited to the meta-linear regression case. While this analysis can capture practical scenarios where we reuse a feature extractor from pre-trained models and only meta-train the parameters in the last linear layer, it is also promising to extend our analysis to nonlinear cases via random features and neural tangent kernels in future work."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: This paper investigates the generalization performance of gradient-based meta learning with overparameterized models, focusing on linear models with limited data from all tasks. We show that when data heterogeneity is relatively small, certain covariance matrices lead to benign overfitting, enabling good generalization in new data and tasks. Our theory also suggests that overfitting is more likely in metalearning than ERM, especially with high data heterogeneity. While our analysis is limited to linear regression, it can be extended to nonlinear cases via random features and neural tangent kernels in future work."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nThis paper investigates the generalization performance of gradient-based meta learning with an overparameterized model. To facilitate a precise analysis, we concentrate on linear models, where the total number of data points from all tasks is smaller than the dimension of the model's parameter space. We demonstrate that when data heterogeneity across tasks is relatively small, per-task data covariance matrices with specific properties lead to benign overfitting for gradient-based meta learning with the minimum-norm solution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory reveals that overfitting is more likely to occur in metalearning than in ERM, particularly when data heterogeneity across tasks is relatively high. A limitation of this work is that the analysis is limited to the meta-linear regression case. While this analysis can capture practical scenarios where we reuse a feature extractor from pre-trained models and only meta-train the parameters in the last linear layer, it is also promising to extend our analysis to nonlinear cases via random features and neural tangent kernels in future work."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This paper investigates the generalization performance of gradient-based meta learning with an overparameterized model. To facilitate a precise analysis, we focus on linear models where the total number of data points from all tasks is smaller than the dimension of the model's parameter space. Our results show that when data heterogeneity across tasks is relatively low, per-task data covariance matrices with specific properties lead to benign overfitting for gradient-based meta learning with the minimum-norm solution. This explains why overparameterized meta learning models can generalize well in new data and tasks. Moreover, our theory suggests that overfitting is more likely to occur in metalearning than in ERM, particularly when data heterogeneity across tasks is relatively high. One limitation of this work is that the analysis is limited to the meta-linear regression case. While this analysis can capture practical scenarios where a feature extractor is reused from pre-trained models and only the parameters in the last linear layer are meta-trained, it is also promising to extend our analysis to nonlinear cases via random features and neural tangent kernels in future work."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: This paper investigates the generalization performance of gradient-based meta learning with overparameterized models, focusing on linear models with limited data from all tasks. We show that when data heterogeneity is relatively small, certain covariance matrices lead to benign overfitting, enabling good generalization in new data and tasks. Our theory also suggests that overfitting is more likely in metalearning than ERM, especially with high data heterogeneity. While our analysis is limited to linear regression, it can be extended to nonlinear cases via random features and neural tangent kernels in future work."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This paper explores the generalization capabilities of gradient-based meta learning with overparameterized models, with a specific focus on linear models and limited data from multiple tasks. Our results demonstrate that when data heterogeneity is relatively low, certain covariance matrices lead to benign overfitting, allowing for good generalization in new data and tasks. Moreover, our theory suggests that overfitting is more likely to occur in metalearning compared to ERM, particularly when data heterogeneity is high. Although our analysis is currently limited to linear regression, we propose that this framework can be extended to nonlinear cases through the use of random features and neural tangent kernels in future research."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: This paper investigates the generalization capabilities of gradient-based meta learning with overparameterized models, with a particular focus on linear models and limited data from multiple tasks. Our findings show that when data heterogeneity is relatively low, specific covariance matrices can lead to benign overfitting, enabling good generalization in new data and tasks. Furthermore, our theoretical framework suggests that overfitting is more likely to occur in metalearning compared to ERM, particularly when data heterogeneity is high. Although our analysis is currently limited to linear regression, we propose that this framework can be extended to nonlinear cases through the use of random features and neural tangent kernels in future research."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: This paper investigates the generalization performance of gradient-based meta learning with overparameterized models, focusing on linear models with limited data from all tasks. We show that when data heterogeneity is relatively small, certain covariance matrices lead to benign overfitting, enabling good generalization in new data and tasks. Our theory also suggests that overfitting is more likely in metalearning than ERM, especially with high data heterogeneity. While our analysis is limited to linear regression, it can be extended to nonlinear cases via random features and neural tangent kernels in future work."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: This paper explores the generalization capabilities of gradient-based meta learning with overparameterized models, specifically examining linear models with limited data from all tasks. We demonstrate that when data heterogeneity is relatively low, certain covariance matrices give rise to benign overfitting, enabling good generalization on new data and tasks. Our theory further suggests that overfitting is more likely in metalearning compared to ERM, particularly when data heterogeneity is high. Although our analysis is currently limited to linear regression, we propose that it can be extended to nonlinear cases via random features and neural tangent kernels in future research."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: This paper investigates the generalization performance of gradient-based meta learning with an overparameterized model. To facilitate a precise analysis, we focus on linear models where the total number of data points from all tasks is smaller than the dimension of the model's parameter space. Our results show that when data heterogeneity across tasks is relatively low, per-task data covariance matrices with specific properties lead to benign overfitting for gradient-based meta learning with the minimum-norm solution. This explains why overparameterized meta learning models can generalize well in new data and tasks. Moreover, our theory suggests that overfitting is more likely to occur in metalearning than in ERM, particularly when data heterogeneity across tasks is relatively high. One limitation of this work is that the analysis is limited to the meta-linear regression case. While this analysis can capture practical scenarios where a feature extractor is reused from pre-trained models and only the parameters in the last linear layer are meta-trained, it is also promising to extend our analysis to nonlinear cases via random features and neural tangent kernels in future work."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "instruction": "Exclude unnecessary reasoning, correct the typos.", "revised_paragraph": "Revised paragraph: This paper investigates the generalization performance of gradient-based meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We show that when data heterogeneity across tasks is relatively small, per-task data covariance matrices with certain properties lead to benign overfitting for gradient-based meta learning with the minimum-norm solution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Moreover, our theory suggests that overfitting is more likely to occur in metalearning than in ERM, especially when data heterogeneity across tasks is relatively high. A limitation of this work is that the analysis focuses on linear regression, although this can capture practical cases where we reuse a feature extractor from pre-trained models and only meta-train the parameters in the last linear layer. Future work may extend our analysis to nonlinear cases via random features and neural tangent kernels.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.03", "instruction": "Improve the english of this paragraph, particularly the last part. Replace all mentions of \"gradient-based meta learning\" with \"nested meta learning\".", "revised_paragraph": "Revised paragraph: This paper investigates the generalization performance of nested meta learning with an overparameterized model. For a precise analysis, we focus on linear models where the total number of data from all tasks is smaller than the dimension of the model parameter. We demonstrate that when the data heterogeneity across tasks is relatively small, the per-task data covariance matrices with certain properties lead to benign overfitting for nested meta learning with the minimum-norm solution. This explains why overparameterized meta learning models can generalize well in new data and new tasks. Furthermore, our theory shows that overfitting is more likely to occur in metalearning than in ERM, especially when the data heterogeneity across tasks is relatively high. A limitation of this work is that the analysis is limited to the meta-linear regression case. While this analysis can capture practical scenarios where we reuse the feature extractor from pre-trained models and only meta-train the parameters in the last linear layer, it is also promising to extend our analysis to nonlinear cases via means of random features and neural tangent kernels in future work.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We formulate a feature matching problem, similar to inverse reinforcement learning and imitation of control, to learn driving and risk management preferences from a demonstrator's behavior. We design features that capture these preferences and learn risk metric parameters and weights to combine feature values. This yields a cost model, which, when optimized, generates driving behaviors similar to the demonstrator. Our approach improves upon existing methods by incorporating a risk measure, enabling better matching of drivers in risky situations, while still generalizing to new scenarios.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Problem 1 is a feature matching problem, similar to those encountered in inverse reinforcement learning (IRL) [10] and inverse optimal control (IOC) [11] formulations. We design a set of features, including a risk feature, to capture the driving and risk management preferences of the demonstrator. From the demonstration data, we learn the parameters of the risk metric and the weights that combine the feature values, resulting in a cost model. By solving for a trajectory that optimizes this cost model, we generate driving behaviors that are similar to those of the demonstrator, as defined by our features and risk models. Unlike existing IOC approaches, which assume the probability distribution is exponential [11], our approach incorporates a risk measure, enabling better matching of drivers in risky situations. While our approach does not exactly replicate the demonstrator's behavior, it captures the driving style and allows for generalization to new, risky scenarios."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Problem 1 is a feature matching problem, similar to those encountered in inverse reinforcement learning (IRL) [10] and inverse optimal control (IOC) [11] formulations. We design a set of features, including a risk feature, to capture the driving and risk management preferences of the demonstrator. From the demonstration data, we learn the parameters of the risk metric and the weights that combine the feature values, resulting in a cost model. By solving for a trajectory that optimizes this cost model, we generate driving behaviors that are similar to those of the demonstrator, as defined by our features and risk models. Unlike existing IOC approaches, which assume the probability distribution is exponential [11], our approach incorporates a risk measure, enabling better matching of drivers in risky situations. While our approach does not exactly replicate the demonstrator's behavior, it captures the driving style and allows for generalization to new, risky scenarios."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Problem 1 is a feature matching problem, similar to those encountered in inverse reinforcement learning (IRL) [10] and inverse optimal control (IOC) [11] formulations. We design a set of features, including a risk feature, to capture the driving and risk management preferences of the demonstrator. From the demonstration data, we learn the parameters of the risk metric and the weights that combine the feature values, resulting in a cost model. By solving for a trajectory that optimizes this cost model, we generate driving behaviors that are similar to those of the demonstrator, as defined by our features and risk models. Unlike existing IOC approaches, which assume the probability distribution is exponential [11], our approach incorporates a risk measure, enabling better matching of drivers in risky situations. While our approach does not exactly replicate the demonstrator's behavior, it captures the driving style and allows for generalization to new, risky scenarios."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Problem 1 is a feature matching problem, similar to those encountered in inverse reinforcement learning (IRL) [10] and inverse optimal control (IOC) [11] formulations. We design a set of features, including a risk feature, to capture the driving and risk management preferences of the demonstrator. From the demonstration data, we learn the parameters of the risk metric and the weights that combine the feature values, resulting in a cost model. By solving for a trajectory that optimizes this cost model, we generate driving behaviors that are similar to those of the demonstrator, as defined by our features and risk models. Unlike existing IOC approaches, which assume the probability distribution is exponential [11], our approach incorporates a risk measure, enabling better matching of drivers in risky situations. While our approach does not exactly replicate the demonstrator's behavior, it captures the driving style and allows for generalization to new, risky scenarios."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We formulate a feature matching problem, similar to inverse reinforcement learning and imitation of control, to learn driving and risk management preferences from a demonstrator's behavior. We design features that capture these preferences and learn risk metric parameters and weights to combine feature values. This yields a cost model, which, when optimized, generates driving behaviors similar to the demonstrator. Our approach improves upon existing methods by incorporating a risk measure, enabling better matching of drivers in risky situations, while still generalizing to new scenarios.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We formulate a feature matching problem, similar to inverse reinforcement learning and imitation of control, to learn driving and risk management preferences from a demonstrator's behavior. We design features that capture these preferences and learn risk metric parameters and weights to combine feature values. This yields a cost model, which, when optimized, generates driving behaviors similar to the demonstrator. Our approach improves upon existing methods by incorporating a risk measure, enabling better matching of drivers in risky situations, while still generalizing to new scenarios.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"We employ a feature matching framework, analogous to inverse reinforcement learning and imitation of control, to learn a demonstrator's driving and risk management preferences from their behavior. We engineer features that capture these preferences and estimate risk metric parameters and weights to combine feature values. This yields a cost model that, when optimized, produces driving behaviors that closely resemble those of the demonstrator. Our approach surpasses existing methods by incorporating a risk measure, thereby enabling more accurate matching of drivers in high-risk situations, while still generalizing to novel scenarios.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Problem 1 is a feature matching problem, similar to those encountered in inverse reinforcement learning (IRL) [10] and inverse optimal control (IOC) [11] formulations. We design a set of features, including a risk feature, to capture the driving and risk management preferences of the demonstrator. From the demonstration data, we learn the parameters of the risk metric and the weights that combine the feature values, resulting in a cost model. By solving for a trajectory that optimizes this cost model, we generate driving behaviors that are similar to those of the demonstrator, as defined by our features and risk models. Unlike existing IOC approaches, which assume the probability distribution is exponential [11], our approach incorporates a risk measure, enabling better matching of drivers in risky situations. While our approach does not exactly replicate the demonstrator's behavior, it captures the driving style and allows for generalization to new, risky scenarios."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Problem 1 is a feature matching problem, similar to those encountered in inverse reinforcement learning (IRL) [10] and inverse optimal control (IOC) [11] formulations. We design a set of features, including a risk feature, to capture the driving and risk management preferences of the demonstrator. From the demonstration data, we learn the parameters of the risk metric and the weights that combine the feature values, resulting in a cost model. By solving for a trajectory that optimizes this cost model, we generate driving behaviors that are similar to those of the demonstrator, as defined by our features and risk models. Unlike existing IOC approaches, which assume the probability distribution is exponential [11], our approach incorporates a risk measure, enabling better matching of drivers in risky situations. While our approach does not exactly replicate the demonstrator's behavior, it captures the driving style and allows for generalization to new, risky scenarios."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Problem 1 is a feature matching problem, similar to those encountered in inverse reinforcement learning (IRL) [10] and inverse optimal control (IOC) [11] formulations. We design a set of features, including a risk feature, to capture the driving and risk management preferences of the demonstrator. From the demonstration data, we learn the parameters of the risk metric and the weights that combine the feature values, resulting in a cost model. By solving for a trajectory that optimizes this cost model, we generate driving behaviors that are similar to those of the demonstrator, as defined by our features and risk models. Unlike existing IOC approaches, which assume the probability distribution is exponential [11], our approach incorporates a risk measure, enabling better matching of drivers in risky situations. While our approach does not exactly replicate the demonstrator's behavior, it captures the driving style and allows for generalization to new, risky scenarios."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Problem 1 is a feature matching problem, similar to inverse reinforcement learning (IRL) and inverse optimal control (IOC) formulations. We design features, including a risk feature, to capture the demonstrator's driving and risk management preferences. From demonstration data, we learn a cost model that optimizes driving behaviors similar to the demonstrator's, while incorporating a risk measure to better match drivers in risky situations."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "instruction": "Please, paraphrase this paragraph.", "revised_paragraph": "Revised paragraph: \n\nThe first problem we address is a feature matching issue, akin to those encountered in inverse reinforcement learning (IRL) and inverse optimal control (IOC) formulations. We develop a set of features, including a risk feature, to capture the driving and risk management preferences of the demonstrator. By analyzing the demonstration data, we learn the parameters of the risk metric and the weights that combine feature values, yielding a cost model. By optimizing this cost model, we generate driving behaviors that closely resemble those of the demonstrator, as defined by our feature set and risk models. In contrast to existing IOC approaches, which assume an exponential distribution for the probability P \u03b8, our approach incorporates a risk measure, enabling more accurate matching of drivers in high-risk situations. While our method does not perfectly replicate the demonstrator's behavior, it effectively captures their driving style and enables generalization to novel, high-risk scenarios.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.01", "instruction": "This paragraph is confusing, rewrite the second and the two last sentence for clarity. Smooth out the liking between sentences.", "revised_paragraph": "Revised paragraph: \n\nProblem 1 can be formulated as a feature matching problem, similar to inverse reinforcement learning (IRL) and inverse optimal control (IOC) formulations. We design a set of features, including a risk feature, to capture the driving and risk management preferences of the demonstrator. From the demonstration data, we learn the risk metric parameters and weights that combine feature values, resulting in a cost model that reflects the demonstrator's preferences. By solving for a trajectory that optimizes this cost model, we generate driving behaviors that closely match those of the demonstrator. Unlike existing IOC approaches, which assume an exponential distribution for the probability P\u03b8, our approach incorporates a risk measure, enabling us to better match drivers in risky situations. While our approach does not exactly mimic the demonstrator, it captures the driving style and allows for generalization to new, risky scenarios.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Fig 2 shows the proportion of outliers selected by uncertainty sampling for different datasets and models. Each bar represents the average of three runs, with 10% random data points injected from another dataset in each run. The dataset has the greatest impact, with newsgroup showing the highest proportion of outliers (80% on average)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Fig 2 shows the proportion of outliers selected by uncertainty sampling for different datasets and models. Each bar represents the average of three runs, with 10% random data points injected from another dataset in each run. The dataset has the greatest impact, with newsgroup showing the highest proportion of outliers (80% on average)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Fig 2 shows the proportion of outliers selected by uncertainty sampling for different datasets and models. Each bar represents the average of three runs, with 10% random data points injected from another dataset in each run. The dataset has the greatest impact, with newsgroup showing the highest proportion of outliers (80% on average)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Fig 2 shows the proportion of outliers selected by uncertainty sampling for different datasets and models. Each bar represents the average of three runs, with 10% random data points injected from another dataset in each run. The dataset has the greatest impact, with newsgroup showing the highest proportion of outliers (80% on average)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Fig 2 shows the proportion of outliers selected by uncertainty sampling for different datasets and models. Each bar represents the average of three runs, with 10% random data points injected from another dataset in each run. The dataset has the greatest impact, with newsgroup showing the highest proportion of outliers (80% on average)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Fig 2 shows the proportion of outliers selected by uncertainty sampling for different datasets and models. Each bar represents the average of three runs, with 10% random data points injected from another dataset in each run. The dataset has the greatest impact, with newsgroup showing the highest proportion of outliers (80% on average)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Fig 2 shows the proportion of outliers selected by uncertainty sampling for different datasets and models. Each bar represents the average of three runs, with 10% random data points injected from another dataset in each run. The dataset has the greatest impact, with newsgroup showing the highest proportion of outliers (80% on average)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Fig 2 shows the proportion of outliers selected by uncertainty sampling for different datasets and models. Each bar represents the average of three runs, with 10% random data points injected from another dataset in each run. The dataset has the greatest impact, with newsgroup showing the highest proportion of outliers (80% on average)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "instruction": "Shorten this paragraph by removing details about the figure.", "revised_paragraph": "Revised paragraph: Fig 2 plots the proportion of outliers selected by uncertainty sampling for different datasets and models.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "kBsx5htyKn.qV5njV8W5.03", "instruction": "Remove unnecessary details to make this paragraph shorter.", "revised_paragraph": "Revised paragraph: Fig 2 plots the proportion of outliers selected by uncertainty sampling for different datasets and models. Each bar represents the average of three runs, with 10% random data points injected from another dataset in each run. The dataset has the biggest influence, with newsgroup showing the highest proportion of outliers (80% on average).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We refer to the standard training steps, where we perform forward and backward passes, as regular steps. To accelerate learning from individual input modalities, we introduce re-balancing steps, which involve forcing the model to update only one of the unimodal branches at a time. A detailed explanation of the re-balancing step can be found in Appendix A."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We refer to the standard training steps, where we perform forward and backward passes, as regular steps. To accelerate learning from individual input modalities, we introduce re-balancing steps, which involve forcing the model to update only one of the unimodal branches at a time. A detailed explanation of the re-balancing step can be found in Appendix A."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We refer to the standard training steps, where we perform forward and backward passes, as regular steps. To accelerate learning from individual input modalities, we introduce re-balancing steps, which involve forcing the model to update only one of the unimodal branches at a time. A detailed explanation of the re-balancing step can be found in Appendix A."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We refer to the standard training steps, where we perform forward and backward passes, as regular steps. To accelerate learning from individual input modalities, we introduce re-balancing steps, which involve forcing the model to update only one of the unimodal branches at a time. A detailed explanation of the re-balancing step can be found in Appendix A."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We refer to the standard training steps, where we perform forward and backward passes, as regular steps. To accelerate learning from individual input modalities, we introduce re-balancing steps, which involve forcing the model to update only one of the unimodal branches at a time. A detailed explanation of the re-balancing step can be found in Appendix A."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We refer to the standard training steps, where we perform forward and backward passes, as regular steps. To accelerate learning from individual input modalities, we introduce re-balancing steps, which involve forcing the model to update only one of the unimodal branches at a time. A detailed explanation of the re-balancing step can be found in Appendix A."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We refer to the standard training steps, where we perform forward and backward passes, as regular steps. To accelerate learning from individual input modalities, we introduce re-balancing steps, which involve forcing the model to update only one of the unimodal branches at a time. A detailed explanation of the re-balancing step can be found in Appendix A."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We refer to the standard training steps, where we perform forward and backward passes, as regular steps. To accelerate learning from individual input modalities, we introduce re-balancing steps, which involve forcing the model to update only one of the unimodal branches at a time. A detailed explanation of the re-balancing step can be found in Appendix A."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "instruction": "Improve the English of this paragraph", "revised_paragraph": "Revised paragraph: We denote the typical training steps where we execute forward and backward passes as regular steps. To expedite learning from specific input modalities, we introduce re-balancing steps, which compel the model to update only one of the unimodal branches at a time. A detailed explanation of the re-balancing step is provided in Appendix A.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.10", "instruction": "Rewrite  ", "revised_paragraph": "Revised paragraph: In this study, we distinguish between two types of training steps. Regular steps involve standard forward and backward passes, whereas re-balancing steps are introduced to accelerate learning from individual input modalities. During re-balancing steps, the model is forced to update only one of the unimodal branches, allowing for a more focused learning process. A detailed explanation of the re-balancing step can be found in Appendix A.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Meta-EGN significantly outperforms EGN and RUN-CSP across five datasets, both before and after fine-tuning. Compared to traditional CO solvers, Meta-EGN narrows the gap with Gurobi9.5 on small graphs, outperforming it on RB graphs for the MC problem and on RB500 for the MVC problem.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Meta-EGN significantly outperforms EGN and RUN-CSP across five datasets, both before and after fine-tuning. Compared to traditional CO solvers, Meta-EGN narrows the gap with Gurobi9.5 on small graphs, outperforming it on RB graphs for the MC problem and on RB500 for the MVC problem.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Meta-EGN significantly outperforms EGN and RUN-CSP across five datasets, both before and after fine-tuning. Compared to traditional CO solvers, Meta-EGN narrows the gap with Gurobi9.5 on small graphs, outperforming it on RB graphs for the MC problem and on RB500 for the MVC problem.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Meta-EGN significantly outperforms EGN and RUN-CSP across five datasets, both before and after fine-tuning. Compared to traditional CO solvers, Meta-EGN narrows the gap with Gurobi9.5 on small graphs, outperforming it on RB graphs for the MC problem and on RB500 for the MVC problem.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Meta-EGN significantly outperforms EGN and RUN-CSP across five datasets, both before and after fine-tuning. Compared to traditional CO solvers, Meta-EGN narrows the gap with Gurobi9.5 on small graphs, outperforming it on RB graphs for the MC problem and on RB500 for the MVC problem.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Meta-EGN significantly outperforms EGN and RUN-CSP across five datasets, both before and after fine-tuning. Compared to traditional CO solvers, Meta-EGN narrows the gap with Gurobi9.5 on small graphs, outperforming it on RB graphs for the MC problem and on RB500 for the MVC problem.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Meta-EGN significantly outperforms EGN and RUN-CSP across five datasets, both before and after fine-tuning. Compared to traditional CO solvers, Meta-EGN narrows the gap with Gurobi9.5 on small graphs, outperforming it on RB graphs for the MC problem and on RB500 for the MVC problem.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Meta-EGN significantly outperforms EGN and RUN-CSP across five datasets, both before and after fine-tuning. Compared to traditional CO solvers, Meta-EGN narrows the gap with Gurobi9.5 on small graphs, outperforming it on RB graphs for the MC problem and on RB500 for the MVC problem.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "instruction": "Fuse the last two sentences for conciseness.", "revised_paragraph": "Revised paragraph: \"Meta-EGN significantly outperforms EGN and RUN-CSP, both before and after fine-tuning, across the five datasets and in both the MC and MVC problems. Moreover, it narrows the gap with traditional CO solvers, such as Gurobi9.5, on real small graphs, outperforming it for the RB graphs' MC problem and RB500's MVC problem.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "X50LVGSli.jqJzurpUu.02", "instruction": "Merge the two last sentences to make it shorter.", "revised_paragraph": "Revised paragraph: \"In both problems and across the five datasets, Meta-EGN significantly outperforms EGN and RUN-CSP, both before and after the fine-tuning step. Notably, Meta-EGN narrows the gap with traditional CO solvers, outperforming Gurobi9.5 on small graphs and achieving better results for both MC and MVC problems, with the latter outperforming Gurobi9.5 on RB500.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The \u03b8 matrix, where higher values indicate higher sampling probabilities, parameterizes the probabilistic distribution of discrete solutions. By using a compact, continuous, and differentiable space, we leverage gradient-based optimization, avoiding costly MDP-based construction and MCMC-based sampling. Instead, we employ autoregressive factorization for faster sampling from the auxiliary distribution, eliminating the need for MCMC-based optimization.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Here, a higher valued \u03b8i,j indicates a higher probability for the edge from node i to node j to be sampled. Notably, we employ a matrix \u03b8 \u2208 \u211d^(n \u00d7 n) to parameterize the probabilistic distribution of n discrete feasible solutions. The compact, continuous, and differentiable nature of \u03b8 enables us to leverage gradient-based optimization without the costly construction of feasible solutions, a bottleneck in scaling up representative DRL solvers to date. In other words, we no longer require costly MCMC-based sampling for optimizing our model, thanks to the chain-rule decomposition. Instead, we utilize autoregressive factorization for sampling from the auxiliary distribution, which is faster than sampling with MCMC from the distribution defined by the energy function."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Here, we parameterize the probabilistic distribution of n discrete feasible solutions using a matrix \u03b8 \u2208 R n \u00d7 n. The compact, continuous, and differentiable space of \u03b8 enables gradient-based optimization, bypassing the need for costly MDP-based construction of feasible solutions and MCMC-based sampling. Instead, we employ autoregressive factorization for sampling from the auxiliary distribution, which is faster than MCMC-based sampling from the energy function-defined distribution."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The \u03b8 matrix, where higher values indicate higher sampling probabilities, parameterizes the probabilistic distribution of discrete solutions. By using a compact, continuous, and differentiable space, we leverage gradient-based optimization, avoiding costly MDP-based construction and MCMC-based sampling. Instead, we employ autoregressive factorization for faster sampling from the auxiliary distribution, eliminating the need for MCMC-based optimization.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Here, we parameterize the probabilistic distribution of n discrete feasible solutions using a matrix \u03b8 \u2208 R n \u00d7 n. The compact, continuous, and differentiable space of \u03b8 enables gradient-based optimization, bypassing the need for costly MDP-based construction of feasible solutions and MCMC-based sampling. Instead, we employ autoregressive factorization for sampling from the auxiliary distribution, which is faster than MCMC-based sampling from the energy function-defined distribution."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Here, a higher valued \u03b8i,j indicates a higher probability for the edge from node i to node j to be sampled. Notably, we employ a matrix \u03b8 \u2208 \u211d^(n \u00d7 n) to parameterize the probabilistic distribution of n discrete feasible solutions. The compact, continuous, and differentiable nature of \u03b8 enables us to leverage gradient-based optimization without the costly construction of feasible solutions, a bottleneck in scaling up representative DRL solvers to date. In other words, we no longer require costly MCMC-based sampling for optimizing our model, thanks to the chain-rule decomposition. Instead, we utilize autoregressive factorization for sampling from the auxiliary distribution, which is faster than sampling with MCMC from the distribution defined by the energy function."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The \u03b8 matrix, where higher values indicate higher sampling probabilities, parameterizes the probabilistic distribution of discrete solutions. By using a compact, continuous, and differentiable space, we leverage gradient-based optimization, avoiding costly MDP-based construction and MCMC-based sampling. Instead, we employ autoregressive factorization for faster sampling from the auxiliary distribution, eliminating the need for MCMC-based optimization.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The \u03b8 matrix, which assigns higher values to solutions with greater sampling probabilities, parameterizes the probabilistic distribution of discrete solutions. By leveraging a compact, continuous, and differentiable space, we can utilize gradient-based optimization, thereby circumventing the computationally expensive processes of MDP-based construction and MCMC-based sampling. In contrast, we utilize autoregressive factorization to facilitate faster sampling from the auxiliary distribution, eliminating the need for MCMC-based optimization and thereby enhancing computational efficiency.\""}, {"depth": 3, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"The \u03b8 matrix parameterizes the probabilistic distribution of discrete solutions, assigning higher values to solutions with greater sampling probabilities. We utilize a compact, continuous, and differentiable space to leverage gradient-based optimization, enhancing computational efficiency by avoiding computationally expensive processes.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The \u03b8 matrix, where higher values indicate higher sampling probabilities, parameterizes the probabilistic distribution of discrete solutions. By using a compact, continuous, and differentiable space, we leverage gradient-based optimization, avoiding costly MDP-based construction and MCMC-based sampling. Instead, we employ autoregressive factorization for faster sampling from the auxiliary distribution, eliminating the need for MCMC-based optimization.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Here, we parameterize the probabilistic distribution of n discrete feasible solutions using a matrix \u03b8 \u2208 R n \u00d7 n. The compact, continuous, and differentiable space of \u03b8 enables gradient-based optimization, bypassing the need for costly MDP-based construction of feasible solutions and MCMC-based sampling. Instead, we employ autoregressive factorization for sampling from the auxiliary distribution, which is faster than MCMC-based sampling from the energy function-defined distribution."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Here, we parameterize the probabilistic distribution of n discrete feasible solutions using a matrix \u03b8 \u2208 Rn \u00d7 n. The compact, continuous, and differentiable space of \u03b8 enables gradient-based optimization, thereby circumventing the need for computationally expensive MDP-based construction of feasible solutions and MCMC-based sampling. Instead, we employ autoregressive factorization for sampling from the auxiliary distribution, which is significantly faster than MCMC-based sampling from the energy function-defined distribution."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "instruction": "Make this paragraph more concise.", "revised_paragraph": "Revised paragraph: \"We parameterize the probabilistic distribution of n! discrete feasible solutions using a compact, continuous, and differentiable matrix \u03b8 \u2208 Rn\u00d7n. This allows us to leverage gradient-based optimization, bypassing the bottleneck of costly MDP-based construction of feasible solutions and MCMC-based sampling. Instead, we employ autoregressive factorization for sampling from the auxiliary distribution, which is faster and more efficient.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "9ALnOEcGN_.4eEIRZ-dm.02", "instruction": "Delete the second sentence. Improve the english in the first sentence.", "revised_paragraph": "Revised paragraph: Here, the higher valued \u03b8 i,j represents the probability of sampling the edge from node i to node j. The compact, continuous, and differentiable space of \u03b8 enables gradient-based optimization without the need for costly MDP-based construction of feasible solutions, a bottleneck for scaling up in representative DRL solvers.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention in modern clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial. Non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in significant financial burdens."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: A prescription is a fundamental medical intervention widely used in contemporary clinical settings. It is a recommendation from a healthcare provider to a patient, outlining specific actions such as taking medication, following a diet, or engaging in physical exercises. When a patient agrees to a prescription with their healthcare provider, they are expected to adhere to the recommended treatment plan. The extent to which a patient follows their prescription as agreed upon is known as adherence. Unfortunately, non-adherence to prescriptions is a significant issue in healthcare, with adherence rates averaging 50% and accounting for 33-69% of hospital re-admissions, resulting in billions of dollars in annual costs."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention in modern clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial. Non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in significant financial burdens."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention in modern clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial. Non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in significant financial burdens."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention in modern clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial. Non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in significant financial burdens."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: A prescription is a fundamental medical intervention widely used in contemporary clinical settings. It is a recommendation from a healthcare provider to a patient, outlining specific actions such as taking medication, following a diet, or engaging in physical exercises. When a patient agrees to a prescription with their healthcare provider, they are expected to adhere to the recommended treatment plan. The extent to which a patient follows their prescription as agreed upon is known as adherence. Unfortunately, non-adherence to prescriptions is a significant issue in healthcare, with adherence rates averaging 50% and accounting for 33-69% of hospital re-admissions, resulting in billions of dollars in annual costs."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention in modern clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial. Non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in significant financial burdens."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: A prescription is a standard medical intervention in contemporary clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial for achieving optimal health outcomes. Unfortunately, non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in substantial financial burdens."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention in modern clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial. Non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in significant financial burdens."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention in modern clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial. Non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in significant financial burdens."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention in modern clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial. Non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in significant financial burdens."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: A prescription is a standard medical intervention in contemporary clinical settings, typically issued by a healthcare provider to a patient. It outlines specific actions, such as taking medications or following a diet, and adherence to the prescription is crucial for achieving optimal health outcomes. Unfortunately, non-adherence is a significant problem, with average rates of 50% and contributing to 33-69% of hospital re-admissions, resulting in substantial financial burdens."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "instruction": "Revise this paragraph to be more concise.", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention in modern clinical settings, recommended by a healthcare provider to a patient. It outlines actions such as medication use, dietary changes, or exercise regimens. When agreed upon, patients are expected to follow the prescription. Adherence, or the extent to which patients follow the agreed-upon plan, is crucial, as non-adherence is a significant healthcare problem, with average adherence rates of 50% and estimated annual costs of billions of dollars due to hospital re-admissions.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.00", "instruction": "Merge the two first sentences in one shorter one. Improve the sentence defining adherence to make it clearer.", "revised_paragraph": "Revised paragraph: A prescription is a common medical intervention that recommends specific actions, such as taking medications, following a diet, or exercising, to patients by healthcare providers [1,2]. When a patient agrees to follow a prescription, adherence is expected, which refers to the extent to which the patient's actions correspond to the agreed-upon recommendation [2]. Non-adherence to prescriptions is a significant problem in healthcare, with average adherence rates of 50% and a significant impact on hospital re-admissions and healthcare costs, resulting in billions of dollars per year [2,4,5,6].", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints has been explored in several studies [24, 20, 16, 6, 22]. For instance, [24] proposed an online mirrored descent algorithm achieving O(p?Tq) regret and O(pT3/4q) violation, which was later generalized by [6, 16]. [20] presented an online gradient descent algorithm based on the drift-plus-penalty method, achieving O(p?Tq) regret and O(p?Tq) violation. While these works improved upon earlier results, it remains unclear whether O(pT3/4q) violation can be reduced with adversarial constraints without Slater's condition."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints has been explored in the literature [24, 20, 16, 6, 22]. The authors in [24] developed an online algorithm achieving O(p?T)q regret and O(pT)q violation, which was later generalized in [6, 16] to achieve the same regret and violation bounds. [20] presented an online gradient descent algorithm based on the drift-plus-penalty method, achieving O(p?T)q regret and O(p?T)q violation with Slater's condition. The key improvement in these works is the Lyapunov drift technique, which provides a refined bound on virtual queues and achieves a smaller soft constraint violation. It remains open whether O(pT)q violation can be reduced with adversarial constraints while keeping O(p?T)q regret without Slater's condition."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints has been explored in several studies [24, 20, 16, 6, 22]. For instance, [24] proposed an online mirrored descent algorithm achieving O(p?Tq) regret and O(pT3/4q) violation, which was later generalized by [6, 16]. [20] presented an online gradient descent algorithm based on the drift-plus-penalty method, achieving O(p?Tq) regret and O(p?Tq) violation. While these works improved upon earlier results, it remains unclear whether O(pT3/4q) violation can be reduced with adversarial constraints without Slater's condition."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints has been explored in the literature [24, 20, 16, 6, 22]. The authors in [24] developed an online algorithm achieving O(p?T)q regret and O(pT)q violation, which was later generalized in [6, 16] to achieve the same regret and violation bounds. [20] presented an online gradient descent algorithm based on the drift-plus-penalty method, achieving O(p?T)q regret and O(p?T)q violation with Slater's condition. The key improvement in these works is the Lyapunov drift technique, which provides a refined bound on virtual queues and achieves a smaller soft constraint violation. It remains open whether O(pT)q violation can be reduced with adversarial constraints while keeping O(p?T)q regret without Slater's condition."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints has been explored in several studies [24, 20, 16, 6, 22]. For instance, [24] proposed an online mirrored descent algorithm achieving O(p?Tq) regret and O(pT3/4q) violation, which was later generalized by [6, 16]. [20] presented an online gradient descent algorithm based on the drift-plus-penalty method, achieving O(p?Tq) regret and O(p?Tq) violation. While these works improved upon earlier results, it remains unclear whether O(pT3/4q) violation can be reduced with adversarial constraints without Slater's condition."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints has been explored in several studies [24, 20, 16, 6, 22]. For instance, [24] proposed an online mirrored descent algorithm achieving O(p?Tq) regret and O(pT3/4q) violation, which was later generalized by [6, 16]. However, it remains unclear whether O(pT3/4q) violation can be reduced with adversarial constraints without Slater's condition."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints has been explored in several studies [24, 20, 16, 6, 22]. For instance, [24] proposed an online mirrored descent algorithm achieving O(p?Tq) regret and O(pT3/4q) violation, which was later generalized by [6, 16]. [20] presented an online gradient descent algorithm based on the drift-plus-penalty method, achieving O(p?Tq) regret and O(p?Tq) violation. While these works improved upon earlier results, it remains unclear whether O(pT3/4q) violation can be reduced with adversarial constraints without Slater's condition."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints has been explored in the literature [24, 20, 16, 6, 22]. The authors in [24] developed an online algorithm achieving O(p?T)q regret and O(pT)q violation, which was later generalized in [6, 16] to achieve the same regret and violation bounds. [20] presented an online gradient descent algorithm based on the drift-plus-penalty method, achieving O(p?T)q regret and O(p?T)q violation with Slater's condition. The key improvement in these works is the Lyapunov drift technique, which provides a refined bound on virtual queues and achieves a smaller soft constraint violation. It remains open whether O(pT)q violation can be reduced with adversarial constraints while keeping O(p?T)q regret without Slater's condition."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "instruction": "Remove the second last sentence", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints: Adversarial constraints are more dif\ufb01cult to satisfy but have been considered in the literature [24, 20, 16, 6, 22]. For COCO-Soft with adversarial constraints, the authors in [24] developed an online mirrored descent type algorithm that achieves O p? T q regret and O p T 3 { 4 q violation. Later, [6, 16] generalized the baseline in [24] and still achieve O p? T q regret and O p T 3 { 4 q violation. With Slater\u2019s condition, [20] presents an online gradient descent algorithm based on the drift-plus-penalty method [19], which achieves O p? T q regret and O p? T q violation and [22] extended it to an online optimization with sub-modular losses.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MnewiFDvHZ.iAYttXl-uH.01", "instruction": "Remove unnecessary sentence from this paragraph to make it shorter.", "revised_paragraph": "Revised paragraph: COCO-Soft with adversarial constraints have been explored in the literature [24, 20, 16, 6, 22]. The authors in [24] developed an online mirrored descent type algorithm achieving O p? T q regret and O p T 3 { 4 q violation. This was later generalized in [6, 16] and extended to online optimization with sub-modular losses in [22]. The key improvement is the Lyapunov drift technique, which provides a refined bound on virtual queues with Slater\u2019s condition, achieving a smaller soft constraint violation.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we qualitatively analyze the performance of our agent in three different environments. Figure 6 shows that in CREATE, the agent's attention mechanism in AGILE's GAT initially considers multiple tools, including trampoline, which is selected at time step t = 1. This suggests that the agent checks for the presence of spring before selecting trampoline, allowing it to be placed before or after the trampoline. In Grid World, we visualize the attention mechanism of the summarizer in the Summary-GAT ablation. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before making an irreversible decision to enter the pink lava. This highlights the agent's ability to consider alternative actions based on its knowledge of available skills. In contrast, the Utility Policy always follows a safe but suboptimal path, unaware of the available dig-skills before entering the lava. Finally, in RecSim, we observe that the agent maximizes the CPR score by selecting 5 out of 6 items from the same primary category, whereas the Utility Policy struggles to determine the most common category and maximize CPR."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we qualitatively analyze the performance of our agent in three different environments. Figure 6 shows that in CREATE, the agent's attention mechanism in AGILE's GAT initially considers multiple tools, including trampoline, which is selected at time step t = 1. This suggests that the agent checks for the presence of spring before selecting trampoline, allowing it to be placed before or after the trampoline. In Grid World, we visualize the attention mechanism of the summarizer in the Summary-GAT ablation. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before making an irreversible decision to enter the pink lava. This highlights the agent's ability to consider alternative actions based on its knowledge of available skills. In contrast, the Utility Policy always follows a safe but suboptimal path, unaware of the available dig-skills before entering the lava. Finally, in RecSim, we observe that the agent maximizes the CPR score by selecting 5 out of 6 items from the same primary category, whereas the Utility Policy struggles to determine the most common category and maximize CPR."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we qualitatively analyze the performance of our agent in three different environments. Figure 6 shows that in CREATE, the agent's attention mechanism in AGILE's GAT initially considers multiple tools, including trampoline, which is selected at time step t = 1. This suggests that the agent checks for the presence of spring before selecting trampoline, allowing it to be placed before or after the trampoline. In Grid World, we visualize the attention mechanism of the summarizer in the Summary-GAT ablation. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before making an irreversible decision to enter the pink lava. This highlights the agent's ability to consider alternative actions based on its knowledge of available skills. In contrast, the Utility Policy always follows a safe but suboptimal path, unaware of the available dig-skills before entering the lava. Finally, in RecSim, we observe that the agent maximizes the CPR score by selecting 5 out of 6 items from the same primary category, whereas the Utility Policy struggles to determine the most common category and maximize CPR."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we qualitatively analyze the performance of our agent in three different environments. Figure 6 shows that in CREATE, the agent's attention mechanism in AGILE's GAT initially considers multiple tools, including trampoline, which is selected at time step t = 1. This suggests that the agent checks for the presence of spring before selecting trampoline, allowing it to be placed before or after the trampoline. In Grid World, we visualize the attention mechanism of the summarizer in the Summary-GAT ablation. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before making an irreversible decision to enter the pink lava. This highlights the agent's ability to consider alternative actions based on its knowledge of available skills. In contrast, the Utility Policy always follows a safe but suboptimal path, unaware of the available dig-skills before entering the lava. Finally, in RecSim, we observe that the agent maximizes the CPR score by selecting 5 out of 6 items from the same primary category, whereas the Utility Policy struggles to determine the most common category and maximize CPR."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we qualitatively analyze the performance of our agent in three different environments. Figure 6 shows that in CREATE, the agent's attention mechanism in AGILE's GAT initially considers multiple tools, including trampoline, which is selected at time step t = 1. This suggests that the agent checks for the presence of spring before selecting trampoline, allowing it to be placed before or after the trampoline. In Grid World, we visualize the attention mechanism of the summarizer in the Summary-GAT ablation. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before making an irreversible decision to enter the pink lava. This highlights the agent's ability to consider alternative actions based on its knowledge of available skills. In contrast, the Utility Policy always follows a safe but suboptimal path, unaware of the available dig-skills before entering the lava. Finally, in RecSim, we observe that the agent maximizes the CPR score by selecting 5 out of 6 items from the same primary category, whereas the Utility Policy struggles to determine the most common category and maximize CPR."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we qualitatively analyze the performance of our agent in three different environments. Figure 6 shows that in CREATE, the agent's attention mechanism in AGILE's GAT initially considers multiple tools, including trampoline, which is selected at time step t = 1. This suggests that the agent checks for the presence of spring before selecting trampoline, allowing it to be placed before or after the trampoline. In Grid World, we visualize the attention mechanism of the summarizer in the Summary-GAT ablation. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before making an irreversible decision to enter the pink lava. This highlights the agent's ability to consider alternative actions based on its knowledge of available skills. In contrast, the Utility Policy always follows a safe but suboptimal path, unaware of the available dig-skills before entering the lava. Finally, in RecSim, we observe that the agent maximizes the CPR score by selecting 5 out of 6 items from the same primary category, whereas the Utility Policy struggles to determine the most common category and maximize CPR."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we qualitatively analyze the performance of our agent in three different environments. Figure 6 shows that in CREATE, the agent's attention mechanism in AGILE's GAT initially considers multiple tools, including trampoline, which is selected at time step t = 1. This suggests that the agent checks for the presence of spring before selecting trampoline, allowing it to be placed before or after the trampoline. In Grid World, we visualize the attention mechanism of the summarizer in the Summary-GAT ablation. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before making an irreversible decision to enter the pink lava. This highlights the agent's ability to consider alternative actions based on its knowledge of available skills. In contrast, the Utility Policy always follows a safe but suboptimal path, unaware of the available dig-skills before entering the lava. Finally, in RecSim, we observe that the agent maximizes the CPR score by selecting 5 out of 6 items from the same primary category, whereas the Utility Policy struggles to determine the most common category and maximize CPR."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this section, we qualitatively analyze the performance of our agent in three different environments. Figure 6 shows that in CREATE, the agent's attention mechanism in AGILE's GAT initially considers multiple tools, including trampoline, which is selected at time step t = 1. This suggests that the agent checks for the presence of spring before selecting trampoline, allowing it to be placed before or after the trampoline. In Grid World, we visualize the attention mechanism of the summarizer in the Summary-GAT ablation. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before making an irreversible decision to enter the pink lava. This highlights the agent's ability to consider alternative actions based on its knowledge of available skills. In contrast, the Utility Policy always follows a safe but suboptimal path, unaware of the available dig-skills before entering the lava. Finally, in RecSim, we observe that the agent maximizes the CPR score by selecting 5 out of 6 items from the same primary category, whereas the Utility Policy struggles to determine the most common category and maximize CPR."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "instruction": "Make this paragraph better. Rewrite a sentece about the Grid World", "revised_paragraph": "Revised paragraph: In this section, we qualitatively analyze the agent's performance in three environments: CREATE, Grid World, and RecSim. In CREATE, at t = 0, the AGILE's GAT attends to various tools, including the trampoline, which is selected with strong attention at t = 1. This highlights the agent's ability to consider the presence of other tools before making a decision. In Grid World, we visualize the Summary-GAT ablation to demonstrate how the summarizer utilizes attention. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before entering the pink lava, whereas the Utility Policy follows a safe but suboptimal path due to its lack of knowledge about dig-skills. In RecSim, the agent successfully maximizes the CPR score by selecting items from the same primary category, whereas the Utility Policy is unable to determine the most common category and consequently performs poorly.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.16", "instruction": "Improve the clarity in this paragraph.", "revised_paragraph": "Revised paragraph: \n\nIn Figure 6, we provide a qualitative analysis of agent performance. In CREATE, the attention mechanism of AGILE's GAT (Figure 6(a)) initially considers multiple tools, including the trampoline, which is subsequently selected with strong attention at time t = 1. This suggests that the agent checks for the presence of spring before selecting the trampoline, allowing it to be placed before or after the trampoline. In Grid World, the Summary-GAT ablation (Figure 6(b)) demonstrates how the summarizer utilizes attention. When both dig-lava skills are available, the agent attends to the Dig-Pink skill with high weight before entering the pink lava, avoiding an irreversible decision. In contrast, the Utility Policy always follows the safe suboptimal path, unaware of the dig-skills before entering the lava. In RecSim, the agent maximizes the CPR score by selecting 5 out of 6 items from the same primary category, whereas the Utility Policy is unable to determine the most common category and poorly maximizes CPR.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: However, as illustrated in Figure 2(a), the treatment selection bias alters the distribution of covariates across groups, which can lead to overfitting of each group's specific properties by \u03d51 and \u03d50. As a result, these models cannot effectively generalize to the broader population, and the estimated treatment effect \u02c6\u03c4 would be biased."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, as illustrated in Figure 2 (a), the treatment selection bias induces significant differences in the distributions of covariates across groups. Consequently, the parameters \u03d5 1 and \u03d5 0 would be overly fitted to the specific characteristics of their respective groups, thereby compromising their ability to generalize to the broader population. As a result, the estimated treatment effect \u02c6 \u03c4 would be subject to bias.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: However, as illustrated in Figure 2(a), the treatment selection bias alters the distribution of covariates across groups, which can lead to overfitting of each group's specific properties by \u03d51 and \u03d50. As a result, these models cannot effectively generalize to the broader population, and the estimated treatment effect \u02c6\u03c4 would be biased."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, as illustrated in Figure 2 (a), the treatment selection bias induces significant differences in the distributions of covariates across groups. Consequently, the parameters \u03d5 1 and \u03d5 0 would be overly fitted to the specific characteristics of their respective groups, thereby compromising their ability to generalize to the broader population. As a result, the estimated treatment effect \u02c6 \u03c4 would be subject to bias.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: However, as illustrated in Figure 2(a), the treatment selection bias alters the distribution of covariates across groups, which can lead to overfitting of each group's specific properties by \u03d51 and \u03d50. As a result, these models cannot effectively generalize to the broader population, and the estimated treatment effect \u02c6\u03c4 would be biased."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: However, as Figure 2(a) illustrates, the treatment selection bias introduces a distributional shift in covariates across groups, which can lead to overfitting of each group's unique characteristics by \u03d51 and \u03d50. Consequently, these models struggle to generalize to the broader population, resulting in a biased estimate of the treatment effect, \u02c6\u03c4."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: However, as illustrated in Figure 2(a), the treatment selection bias alters the distribution of covariates across groups, which can lead to overfitting of each group's specific properties by \u03d51 and \u03d50. As a result, these models cannot effectively generalize to the broader population, and the estimated treatment effect \u02c6\u03c4 would be biased."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"However, as illustrated in Figure 2 (a), the treatment selection bias induces significant differences in the distributions of covariates across groups. Consequently, the parameters \u03d5 1 and \u03d5 0 would be overly fitted to the specific characteristics of their respective groups, thereby compromising their ability to generalize to the broader population. As a result, the estimated treatment effect \u02c6 \u03c4 would be subject to bias.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "instruction": "Improve the english of this paragraph.", "revised_paragraph": "Revised paragraph: \"As illustrated in Figure 2 (a), the treatment selection bias leads to a disparity in covariate distributions across groups. Consequently, the parameters \u03d5 1 and \u03d5 0 may overfit the specific characteristics of each group, rendering them ineffective in generalizing to the broader population. As a result, the estimated treatment effect \u02c6 \u03c4 would be subject to bias.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.03", "instruction": "Edit the paragraph to make it more formal and precise.", "revised_paragraph": "Revised paragraph: \"As illustrated in Figure 2 (a), the treatment selection bias leads to a disparity in the distribution of covariates across groups. Consequently, the parameters \u03d5 1 and \u03d5 0 are likely to overfit the specific characteristics of their respective groups, thereby compromising their ability to generalize to the broader population. As a result, the estimated treatment effect \u02c6 \u03c4 would be susceptible to bias.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This section demonstrates that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, including those found in value-based RL. Capacity loss is particularly pronounced in sparse prediction tasks, where many target values are zero. We present a special case of the target-fitting capacity measure, which is efficient to compute and measures the ability to linearly disentangle states. Our findings show that agents with greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite, while those suffering from representation collapse fail to make any learning progress."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"This section demonstrates that neural networks deteriorate in their ability to quickly adapt to new targets when trained on sequential prediction tasks, including those in value-based RL. Capacity loss is particularly pronounced in sparse prediction tasks, where many target values are zero. To investigate the impact of extreme capacity loss, we introduce a computationally efficient target-fitting capacity measure that assesses the representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity according to this metric perform better in challenging Atari environments, while those suffering from representation collapse fail to learn.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nIn this section, we demonstrate that neural networks progressively lose their ability to quickly adapt to new targets when trained on sequential prediction tasks, including those commonly found in value-based reinforcement learning (RL). Notably, capacity loss is most pronounced in sparse prediction tasks, where many target values are zero. To further investigate the impact of extreme capacity loss on performance, we introduce a novel target-fitting capacity measure that is computationally efficient and provides an intuitive understanding of the representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite, where agents struggle to match human-level performance, whereas those suffering from representation collapse fail to make any progress at all."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nIn this section, we demonstrate that neural networks progressively lose their ability to quickly adapt to new targets when trained on sequential prediction tasks, including those commonly found in value-based reinforcement learning (RL). Notably, capacity loss is most pronounced in sparse prediction tasks, where many target values are zero. To further investigate the impact of extreme capacity loss on performance, we introduce a novel target-fitting capacity measure that is computationally efficient and provides an intuitive understanding of the representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite, where agents struggle to match human-level performance, whereas those suffering from representation collapse fail to make any progress at all."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nIn this section, we demonstrate that neural networks progressively lose their ability to quickly adapt to new targets when trained on sequential prediction tasks, including those commonly found in value-based reinforcement learning (RL). Notably, capacity loss is most pronounced in sparse prediction tasks, where many target values are zero. To further investigate the impact of extreme capacity loss on performance, we introduce a novel target-fitting capacity measure that is computationally efficient and provides an intuitive understanding of the representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite, where agents struggle to match human-level performance, whereas those suffering from representation collapse fail to make any progress at all."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This section demonstrates that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, including those found in value-based RL. Capacity loss is particularly pronounced in sparse prediction tasks, where many target values are zero. We present a special case of the target-fitting capacity measure, which is efficient to compute and measures the ability to linearly disentangle states. Our findings show that agents with greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite, while those suffering from representation collapse fail to make any learning progress."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"This section demonstrates that neural networks deteriorate in their ability to quickly adapt to new targets when trained on sequential prediction tasks, including those in value-based RL. Capacity loss is particularly pronounced in sparse prediction tasks, where many target values are zero. To investigate the impact of extreme capacity loss, we introduce a computationally efficient target-fitting capacity measure that assesses the representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity according to this metric perform better in challenging Atari environments, while those suffering from representation collapse fail to learn.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nIn this section, we demonstrate that neural networks progressively lose their ability to quickly adapt to new targets when trained on sequential prediction tasks, including those commonly found in value-based reinforcement learning (RL). Notably, capacity loss is most pronounced in sparse prediction tasks, where many target values are zero. To further investigate the impact of extreme capacity loss on performance, we introduce a novel target-fitting capacity measure that is computationally efficient and provides an intuitive understanding of the representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite, where agents struggle to match human-level performance, whereas those suffering from representation collapse fail to make any progress at all."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: This section demonstrates that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, including those found in value-based RL. Capacity loss is particularly pronounced in sparse prediction tasks, where many target values are zero. We present a special case of the target-fitting capacity measure, which is efficient to compute and measures the ability to linearly disentangle states. Our findings show that agents with greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite, while those suffering from representation collapse fail to make any learning progress."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: This section shows that neural networks' ability to quickly adapt to new targets degrades over time in sequential prediction tasks, including value-based RL. Capacity loss is more severe in sparse tasks where many target values are zero. We introduce a novel metric that efficiently measures an agent's ability to linearly disentangle states, and find that agents with higher capacity achieve better performance in challenging Atari environments, while those with representation collapse fail to learn."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: This section demonstrates that the ability of neural networks to rapidly adapt to new targets deteriorates over time in sequential prediction tasks, including value-based reinforcement learning (RL). Notably, capacity loss is more pronounced in sparse tasks, where many target values are zero. We propose a novel metric that effectively assesses an agent's capacity to linearly disentangle states, and find that agents with higher capacity exhibit superior performance in challenging Atari environments, whereas those experiencing representation collapse are unable to learn."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nIn this section, we demonstrate that neural networks progressively lose their ability to quickly adapt to new targets when trained on sequential prediction tasks, including those commonly found in value-based reinforcement learning (RL). Notably, capacity loss is most pronounced in sparse prediction tasks, where many target values are zero. To further investigate the impact of extreme capacity loss on performance, we introduce a novel target-fitting capacity measure that is computationally efficient and provides an intuitive understanding of the representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite, where agents struggle to match human-level performance, whereas those suffering from representation collapse fail to make any progress at all."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nIn this section, we demonstrate that neural networks progressively lose their ability to quickly adapt to new targets when trained on sequential prediction tasks, including those commonly found in value-based reinforcement learning (RL). Notably, capacity loss is most pronounced in sparse prediction tasks, where many target values are zero. To further investigate the impact of extreme capacity loss on performance, we introduce a novel target-fitting capacity measure that is computationally efficient and provides an intuitive understanding of the representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite, where agents struggle to match human-level performance, whereas those suffering from representation collapse fail to make any progress at all."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \n\nThis section shows that neural networks increasingly struggle to adapt to new targets when trained on sequential prediction tasks, including those found in value-based reinforcement learning. Capacity loss is most severe in sparse prediction tasks, where many target values are zero. We introduce a novel capacity measure to investigate the impact of extreme capacity loss on performance. Our results suggest that agents with greater capacity tend to perform better in challenging environments, while those with representation collapse fail to make progress."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"This section demonstrates that neural networks deteriorate in their ability to quickly adapt to new targets when trained on sequential prediction tasks, including those in value-based RL. Capacity loss is particularly pronounced in sparse prediction tasks, where many target values are zero. To investigate the impact of extreme capacity loss, we introduce a computationally efficient target-fitting capacity measure that assesses the representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity according to this metric perform better in challenging Atari environments, while those suffering from representation collapse fail to learn.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"This section reveals that neural networks exhibit a decline in their capacity to rapidly adapt to novel targets when trained on sequential prediction tasks, including those in value-based reinforcement learning. Notably, this capacity loss is most pronounced in sparse prediction tasks, where many target values are zero. To investigate the impact of extreme capacity loss, we introduce a computationally efficient target-fitting capacity measure that assesses the representation's ability to linearly disentangle states. Our results indicate that agents with greater capacity according to this metric outperform in challenging Atari environments, whereas those suffering from representation collapse struggle to learn.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "instruction": "Rewrite the first sentence. Remove the example to make it shorter.", "revised_paragraph": "Revised paragraph: In this section, we demonstrate that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, including those found in value-based RL. Capacity loss is particularly pronounced in sparse prediction tasks, where many target values are zero. We present a special case of the target-fitting capacity measure, which is efficient to compute and measures the ability of the representation to linearly disentangle states.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "instruction": "Revise the first sentence in a more academic style. Remove unnecessary details.", "revised_paragraph": "Revised paragraph: This section examines the performance of neural networks in sequential prediction tasks, where the agent must adapt to changing regression problems over time. We demonstrate that capacity loss is a significant issue in these tasks, particularly in sparse prediction scenarios where many target values are zero. To investigate the impact of extreme capacity loss on performance, we introduce a novel target-fitting capacity measure that can be efficiently computed and provides an intuitive understanding of the representation's ability to disentangle states linearly. Our results show that agents with greater capacity according to this metric achieve better performance in challenging environments from the Atari suite, while those suffering from representation collapse fail to make any learning progress.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In a comprehensive comparison with all previous methods, our proposed SRPN-L outperforms them on all datasets, regardless of scaling factors. Unlike other methods that have carefully designed their networks, we build upon the existing EDSR baseline (Lim et al., 2017) and prune it to a significantly smaller network, thereby demonstrating the effectiveness of our proposed SRP approach.\""}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L outperforms all previous methods on all datasets, regardless of scaling factors. In contrast to careful network designs employed by most compared methods, we commence with the existing EDSR baseline (Lim et al., 2017) and prune it to a significantly smaller network, thereby demonstrating the effectiveness of our proposed SRP approach."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L outperforms all previous methods on all datasets, regardless of scaling factors. In contrast to careful network designs employed by most compared methods, we commence with the existing EDSR baseline (Lim et al., 2017) and prune it to a significantly smaller network, thereby demonstrating the effectiveness of our proposed SRP approach."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In a comprehensive comparison with all previous methods, our proposed SRPN-L outperforms them on all datasets, regardless of scaling factors. Unlike other methods that have carefully designed their networks, we build upon the existing EDSR baseline (Lim et al., 2017) and prune it to a significantly smaller network, thereby demonstrating the effectiveness of our proposed SRP approach.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In a comprehensive comparison with all previous methods, our proposed SRPN-L outperforms them on all datasets, regardless of scaling factors. Unlike other methods that have carefully designed their networks, we build upon the existing EDSR baseline (Lim et al., 2017) and prune it to a significantly smaller network, thereby demonstrating the effectiveness of our proposed SRP approach.\""}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L outperforms all previous methods on all datasets, regardless of scaling factors, in a comprehensive comparison. Building upon the existing EDSR baseline (Lim et al., 2017), we prune it to a significantly smaller network, thereby demonstrating the effectiveness of our proposed SRP approach."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Our proposed SRPN-L outperforms all previous methods on all datasets, regardless of scaling factors. In contrast to careful network designs employed by most compared methods, we commence with the existing EDSR baseline (Lim et al., 2017) and prune it to a significantly smaller network, thereby demonstrating the effectiveness of our proposed SRP approach."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In a comprehensive comparison with all previous methods, our proposed SRPN-L outperforms them on all datasets, regardless of scaling factors. Unlike other methods that have carefully designed their networks, we build upon the existing EDSR baseline (Lim et al., 2017) and prune it to a significantly smaller network, thereby demonstrating the effectiveness of our proposed SRP approach.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "instruction": "Rewrite the following paragraph, make it more formal.", "revised_paragraph": "Revised paragraph: In a comprehensive comparison with existing methods, our proposed SRPN-L demonstrates superior performance across all datasets and scaling factors. Unlike previous approaches that have focused on meticulous network design, our method commences with the established EDSR baseline (Lim et al., 2017) and subsequently prunes it to a significantly smaller network, thereby highlighting the efficacy of our proposed SRP approach.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.19", "instruction": "Improve the writing and change SRPN-L to SRPN-Lite", "revised_paragraph": "Revised paragraph: \"Notably, our SRPN-Lite outperforms all previous methods across all datasets and scaling factors. In contrast to the careful network designs employed by most compared methods, we adopt a more efficient approach by starting with the existing EDSR baseline (Lim et al., 2017) and pruning it to a much smaller network, thereby demonstrating the effectiveness of our proposed SRP.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The SDE model, as depicted in Figures 2c-d, demonstrates that the time-variant drift function significantly reduces prediction error, suggesting that the model learns the underlying dynamics of a golf swing motion more effectively. Furthermore, the error consistently decreases as the number of inducing points (M) increases, with the minimum error achieved at M = 80."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The SDE model, as depicted in Figures 2c-d, demonstrates that the time-variant drift function significantly reduces prediction error, suggesting that the model learns the underlying dynamics of a golf swing motion more effectively. Furthermore, the error consistently decreases as the number of inducing points (M) increases, with the minimum error achieved at M = 80."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The SDE model, as depicted in Figures 2c-d, demonstrates that the time-variant drift function significantly reduces prediction error, suggesting that the model learns the underlying dynamics of a golf swing motion more effectively. Furthermore, the error consistently decreases as the number of inducing points (M) increases, with the minimum error achieved at M = 80."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The SDE model, as depicted in Figures 2c-d, demonstrates that the time-variant drift function significantly reduces prediction error, suggesting that the model learns the underlying dynamics of a golf swing motion more effectively. Furthermore, the error consistently decreases as the number of inducing points (M) increases, with the minimum error achieved at M = 80."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The SDE model, as depicted in Figures 2c-d, demonstrates that the time-variant drift function significantly reduces prediction error, suggesting that the model learns the underlying dynamics of a golf swing motion more effectively. Furthermore, the error consistently decreases as the number of inducing points (M) increases, with the minimum error achieved at M = 80."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The SDE model, as depicted in Figures 2c-d, demonstrates that the time-variant drift function significantly reduces prediction error, suggesting that the model learns the underlying dynamics of a golf swing motion more effectively. Furthermore, the error consistently decreases as the number of inducing points (M) increases, with the minimum error achieved at M = 80."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The SDE model, as depicted in Figures 2c-d, demonstrates that the time-variant drift function significantly reduces prediction error, suggesting that the model learns the underlying dynamics of a golf swing motion more effectively. Furthermore, the error consistently decreases as the number of inducing points (M) increases, with the minimum error achieved at M = 80."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The SDE model, as depicted in Figures 2c-d, demonstrates that the time-variant drift function significantly reduces prediction error, suggesting that the model learns the underlying dynamics of a golf swing motion more effectively. Furthermore, the error consistently decreases as the number of inducing points (M) increases, with the minimum error achieved at M = 80."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "instruction": "Rephrase the sentence related to Figures 2c-d.", "revised_paragraph": "Revised paragraph: The performance of the SDE model is visualized in Figures 2c-d, which demonstrate that incorporating a time-variant drift function significantly reduces prediction error, suggesting that the model better captures the underlying dynamics of a golf swing motion. Furthermore, the error consistently decreases as the number of inducing points M increases, reaching a minimum at M = 80.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "HkW3nTM6X.S1d278zJ4.00", "instruction": "Rephrase the first long sentence to better fit the academic style.", "revised_paragraph": "Revised paragraph: The SDE model demonstrates improved performance when incorporating a time-variant drift function, as evident in Figures 2c-d, which show a reduction in prediction error. Notably, the error decreases consistently as the number of inducing points M increases, reaching a minimum at M = 80.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In contrast, random convolution can lead to a growing challenge by introducing an increasing number of factors on a single background. Consequently, generalization rates rapidly decline after augmentation is interrupted when training with a single background, as the learning direction is not conducive to generalizing across various backgrounds. In contrast, training can be facilitated when the difficulties posed by augmentation are addressed, as evident in Figure 2(b) and Figure 2(c). Furthermore, in deep RL, neural networks can maintain regularization when augmentation effectively supports the training process.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In contrast, random convolution can lead to a growing challenge by introducing an increasing number of factors on a single background. Consequently, generalization rates rapidly decline after augmentation is interrupted when training with a single background, as the learning direction is not conducive to generalizing across various backgrounds. In contrast, training can be facilitated when the difficulties posed by augmentation are addressed, as evident in Figure 2(b) and Figure 2(c). Furthermore, in deep RL, neural networks can maintain regularization when augmentation effectively supports the training process.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In contrast, random convolution can lead to a growing challenge by introducing an increasing number of factors on a single background. Consequently, generalization rates rapidly decline after augmentation is interrupted when training with a single background, as the learning direction is not conducive to generalizing across various backgrounds. In contrast, training can be facilitated when the difficulties posed by augmentation are addressed, as evident in Figure 2(b) and Figure 2(c). Furthermore, in deep RL, neural networks can maintain regularization when augmentation effectively supports the training process.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In contrast, random convolution can lead to a growing challenge by introducing an increasing number of factors on a single background. Consequently, generalization rates rapidly decline after augmentation is interrupted when training with a single background, as the learning direction is not conducive to generalizing across various backgrounds. In contrast, training can be facilitated when the difficulties posed by augmentation are addressed, as evident in Figure 2(b) and Figure 2(c). Furthermore, in deep RL, neural networks can maintain regularization when augmentation effectively supports the training process.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In contrast, random convolution can lead to a growing challenge by introducing an increasing number of factors on a single background. Consequently, generalization rates rapidly decline after augmentation is interrupted when training with a single background, as the learning direction is not conducive to generalizing across various backgrounds. In contrast, training can be facilitated when the difficulties posed by augmentation are addressed, as evident in Figure 2(b) and Figure 2(c). Furthermore, in deep RL, neural networks can maintain regularization when augmentation effectively supports the training process.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In contrast, random convolution can lead to a growing challenge by introducing an increasing number of factors on a single background. Consequently, generalization rates rapidly decline after augmentation is interrupted when training with a single background, as the learning direction is not conducive to generalizing across various backgrounds. In contrast, training can be facilitated when the difficulties posed by augmentation are addressed, as evident in Figure 2(b) and Figure 2(c). Furthermore, in deep RL, neural networks can maintain regularization when augmentation effectively supports the training process.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In contrast, random convolution can lead to a growing challenge by introducing an increasing number of factors on a single background. Consequently, generalization rates rapidly decline after augmentation is interrupted when training with a single background, as the learning direction is not conducive to generalizing across various backgrounds. In contrast, training can be facilitated when the difficulties posed by augmentation are addressed, as evident in Figure 2(b) and Figure 2(c). Furthermore, in deep RL, neural networks can maintain regularization when augmentation effectively supports the training process.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In contrast, random convolution can lead to a growing challenge by introducing an increasing number of factors on a single background. Consequently, generalization rates rapidly decline after augmentation is interrupted when training with a single background, as the learning direction is not conducive to generalizing across various backgrounds. In contrast, training can be facilitated when the difficulties posed by augmentation are addressed, as evident in Figure 2(b) and Figure 2(c). Furthermore, in deep RL, neural networks can maintain regularization when augmentation effectively supports the training process.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "instruction": "Add missing spaces.", "revised_paragraph": "Revised paragraph: \"On the contrary, random convolution can induce a growing difficulty by increasing the number of factors on a single background. Therefore, the generalization rapidly decreases after augmentation, interrupted when training with a single background because the learning direction towards generalization about various backgrounds is not helpful for training. On the other hand, the training can be helped when their difficulty is solved by augmentation, such as Figure 2(b) and Figure 2(c). Thus, in deep RL, neural networks maintain regularization when augmentation helps the training.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "Byyb66j52G.hR5KKRfhQm.13", "instruction": "Improve the english in the paragraph, make it slightly more formal.", "revised_paragraph": "Revised paragraph: In contrast, random convolution can lead to a growing complexity issue as the number of factors on a single background increases. Consequently, generalization rapidly deteriorates after augmentation is interrupted during training with a single background, as the learning direction towards generalization across various backgrounds is not conducive to training. However, the training process can be facilitated when the complexity issue is addressed through augmentation, as evident in Figure 2(b) and Figure 2(c). Ultimately, in deep reinforcement learning, neural networks can maintain regularization when augmentation assists the training process.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with representative model compression techniques for image SR, including neural architecture search and knowledge distillation based methods. We provide quantitative results in Tab. 4, showing that our SRPN-L achieves the best performance with the least parameters and computations. In contrast to these methods, our SRP pruning method does not require searching multiple architectures or training a teacher network, making it more efficient."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with prominent model compression techniques for image super-resolution (SR). Specifically, we compare our approach with neural architecture search-based methods (Chu et al., 2019b;a) and knowledge distillation-based methods (Lee et al., 2020). The results are presented in Table 4, which demonstrates that our SRPN-L achieves the best performance with the fewest parameters and computational requirements. In contrast to other methods, our SRP pruning approach eliminates the need for extensive architecture searches or training a teacher network, thereby reducing computational costs. These comparisons highlight the potential of our SRP method for efficient image SR, and further discussions and comparisons with related works (e.g., DCP (Zhuang et al., 2018), DHP (Li et al., 2020)) are provided in the appendix."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with prominent model compression techniques for image super-resolution (SR). Specifically, we compare our approach with neural architecture search-based methods (Chu et al., 2019b;a) and knowledge distillation-based methods (Lee et al., 2020). The results are presented in Table 4, which demonstrates that our SRPN-L achieves the best performance with the fewest parameters and computational requirements. In contrast to other methods, our SRP pruning approach eliminates the need for extensive architecture searches or training a teacher network, thereby reducing computational costs. These comparisons highlight the potential of our SRP method for efficient image SR, and further discussions and comparisons with related works (e.g., DCP (Zhuang et al., 2018), DHP (Li et al., 2020)) are provided in the appendix."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with prominent model compression techniques for image super-resolution (SR). Specifically, we compare our approach with neural architecture search-based methods (Chu et al., 2019b;a) and knowledge distillation-based methods (Lee et al., 2020). The results are presented in Table 4, which demonstrates that our SRPN-L achieves the best performance with the fewest parameters and computational requirements. In contrast to other methods, our SRP pruning approach eliminates the need for extensive architecture searches or training a teacher network, thereby reducing computational costs. These comparisons highlight the potential of our SRP method for efficient image SR, and further discussions and comparisons with related works (e.g., DCP (Zhuang et al., 2018), DHP (Li et al., 2020)) are provided in the appendix."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with prominent model compression techniques for image super-resolution (SR). Specifically, we compare our approach with neural architecture search-based methods (Chu et al., 2019b;a) and knowledge distillation-based methods (Lee et al., 2020). The results are presented in Table 4, which demonstrates that our SRPN-L achieves the best performance with the fewest parameters and computational requirements. In contrast to other methods, our SRP pruning approach eliminates the need for extensive architecture searches or training a teacher network, thereby reducing computational costs. These comparisons highlight the potential of our SRP method for efficient image SR, and further discussions and comparisons with related works (e.g., DCP (Zhuang et al., 2018), DHP (Li et al., 2020)) are provided in the appendix."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with representative model compression techniques for image SR, including neural architecture search and knowledge distillation based methods. We provide quantitative results in Tab. 4, showing that our SRPN-L achieves the best performance with the least parameters and computations. In contrast to these methods, our SRP pruning method does not require searching multiple architectures or training a teacher network, making it more efficient."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with representative model compression techniques for image SR, including neural architecture search and knowledge distillation based methods. We provide quantitative results in Tab. 4, showing that our SRPN-L achieves the best performance with the least parameters and computations. In contrast to these methods, our SRP pruning method does not require searching multiple architectures or training a teacher network, making it more efficient."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with leading model compression techniques for image super-resolution (SR), including neural architecture search and knowledge distillation-based methods. As presented in Table 4, our SRPN-L outperforms these methods in terms of both performance and efficiency, requiring the least parameters and computations. Unlike these methods, our SRP pruning approach does not necessitate searching multiple architectures or training a teacher network, making it a more efficient solution."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with prominent model compression techniques for image super-resolution (SR). Specifically, we compare our approach with neural architecture search-based methods (Chu et al., 2019b;a) and knowledge distillation-based methods (Lee et al., 2020). The results are presented in Table 4, which demonstrates that our SRPN-L achieves the best performance with the fewest parameters and computational requirements. In contrast to other methods, our SRP pruning approach eliminates the need for extensive architecture searches or training a teacher network, thereby reducing computational costs. These comparisons highlight the potential of our SRP method for efficient image SR, and further discussions and comparisons with related works (e.g., DCP (Zhuang et al., 2018), DHP (Li et al., 2020)) are provided in the appendix."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with prominent model compression techniques for image super-resolution (SR). Specifically, we compare our approach with neural architecture search-based methods (Chu et al., 2019b;a) and knowledge distillation-based methods (Lee et al., 2020). The results are presented in Table 4, which demonstrates that our SRPN-L achieves the best performance with the fewest parameters and computational requirements. In contrast to other methods, our SRP pruning approach eliminates the need for extensive architecture searches or training a teacher network, thereby reducing computational costs. These comparisons highlight the potential of our SRP method for efficient image SR, and further discussions and comparisons with related works (e.g., DCP (Zhuang et al., 2018), DHP (Li et al., 2020)) are provided in the appendix."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with prominent model compression techniques for image super-resolution (SR). Specifically, we compare our approach with neural architecture search-based methods (Chu et al., 2019b;a) and knowledge distillation-based methods (Lee et al., 2020). The results are presented in Table 4, which demonstrates that our SRPN-L achieves the best performance with the fewest parameters and computational requirements. In contrast to other methods, our SRP pruning approach eliminates the need for extensive architecture searches or training a teacher network, thereby reducing computational costs. These comparisons highlight the potential of our SRP method for efficient image SR, and further discussions and comparisons with related works (e.g., DCP (Zhuang et al., 2018), DHP (Li et al., 2020)) are provided in the appendix."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with prominent model compression techniques for image super-resolution (SR). We compare our approach with neural architecture search-based methods (Chu et al., 2019b;a) and knowledge distillation-based methods (Lee et al., 2020). As shown in Table 4, our SRPN-L achieves the best performance with the fewest parameters and computational requirements. Our approach eliminates the need for extensive architecture searches or training a teacher network, reducing computational costs."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "instruction": "Please, rewrite this paragraph, make it easier to read", "revised_paragraph": "Revised paragraph: \n\nTo evaluate the effectiveness of our network pruning method, we compare it with other prominent model compression techniques for image super-resolution (SR). Specifically, we contrast our approach with neural architecture search-based methods (Chu et al., 2019b;a) and knowledge distillation-based methods (Lee et al., 2020). The results are presented in Table 4, which demonstrates that our SRPN-L achieves the best performance while minimizing the number of parameters and multiply-accumulates. In contrast to these methods, our SRP pruning approach does not require extensive architecture searches or the training of a teacher network, thereby reducing computational overhead. Our comparisons highlight the potential of our SRP method for efficient image SR. Further discussions and comparisons with related works, such as DCP (Zhuang et al., 2018) and DHP (Li et al., 2020), are provided in the appendix.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.22", "instruction": "Write in a more passive style and remove the last sentence", "revised_paragraph": "Revised paragraph: Our network pruning method is compared with representative model compression techniques for image SR. Specifically, it is compared with neural architecture search based methods (Chu et al., 2019b;a) and knowledge distillation (KD) based methods (Lee et al., 2020). Quantitative results are provided in Tab. 4. SRPN-L obtains the best performance with the least parameter number and Mult-Adds. The SRP pruning method does not require searching lots of architectures or training a teacher network, which consumes extra computation resources.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The discrete variational autoencoder (DVAE) (Rolfe, 2016) consists of an encoder and decoder. In our study, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete 20-dimensional latent space and the decoder reconstructs the images.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The discrete variational autoencoder (DVAE) (Rolfe, 2016) consists of an encoder and decoder. In our study, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete 20-dimensional latent space and the decoder reconstructs the images.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The discrete variational autoencoder (DVAE) (Rolfe, 2016) consists of an encoder and decoder. In our study, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete 20-dimensional latent space and the decoder reconstructs the images.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The discrete variational autoencoder (DVAE) (Rolfe, 2016) consists of an encoder and decoder. In our study, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete 20-dimensional latent space and the decoder reconstructs the images.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The discrete variational autoencoder (DVAE) (Rolfe, 2016) consists of an encoder and decoder. In our study, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete 20-dimensional latent space and the decoder reconstructs the images.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The discrete variational autoencoder (DVAE) (Rolfe, 2016) consists of an encoder and decoder. In our study, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete 20-dimensional latent space and the decoder reconstructs the images.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The discrete variational autoencoder (DVAE) (Rolfe, 2016) consists of an encoder and decoder. In our study, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete 20-dimensional latent space and the decoder reconstructs the images.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The discrete variational autoencoder (DVAE) (Rolfe, 2016) consists of an encoder and decoder. In our study, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete 20-dimensional latent space and the decoder reconstructs the images.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "instruction": "Make this paragraph more concise by introducing acronyms earlier.", "revised_paragraph": "Revised paragraph: \"In this study, we utilize a Discrete Variational Auto-Encoder (DVAE) (Rolfe, 2016), where the encoder and decoder are represented by the network layers before and after the sampling solver, respectively. Specifically, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete distribution of k-hot binary vectors of length 20 in the latent space, and the decoder reconstructs the original image.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "xV0XmrSMtk.sYfR73R9z.02", "instruction": "Introduce the acronym DVAE earlier to avoid repeating it.", "revised_paragraph": "Revised paragraph: We employ a Discrete Variational Auto-Encoder (DVAE), a type of neural network that consists of layers before the sampling solver representing the encoder and those after representing the decoder (Rolfe, 2016). In our experiment, we train a DVAE on the MNIST dataset, where the encoder maps input images to a discrete distribution of k-hot binary vectors of length 20 in the latent space, and the decoder reconstructs the original image.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Discussion. This study demonstrates that ID-calibrated ensembles, a straightforward approach that calibrates a reliable and robust model solely on in-distribution data and then aggregates the results, can effectively eliminate the trade-off between in-distribution and out-of-distribution accuracy on a broad range of natural shifts. We anticipate that this finding will contribute to the increased adoption and deployment of robustness interventions in various applications.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Discussion. This study demonstrates that ID-calibrated ensembles, a straightforward approach that calibrates a reliable and robust model solely on in-distribution data and then aggregates the results, can effectively eliminate the trade-off between in-distribution and out-of-distribution accuracy on a broad range of natural shifts. We anticipate that this finding will contribute to the increased adoption and deployment of robustness interventions in various applications.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Discussion. This study demonstrates that ID-calibrated ensembles, a straightforward approach that calibrates a reliable and robust model solely on in-distribution data and then aggregates the results, can effectively eliminate the trade-off between in-distribution and out-of-distribution accuracy on a broad range of natural shifts. We anticipate that this finding will contribute to the increased adoption and deployment of robustness interventions in various applications.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Discussion. This study demonstrates that ID-calibrated ensembles, a straightforward approach that calibrates a reliable and robust model solely on in-distribution data and then aggregates the results, can effectively eliminate the trade-off between in-distribution and out-of-distribution accuracy on a broad range of natural shifts. We anticipate that this finding will contribute to the increased adoption and deployment of robustness interventions in various applications.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Discussion. This study demonstrates that ID-calibrated ensembles, a straightforward approach that calibrates a reliable and robust model solely on in-distribution data and then aggregates the results, can effectively eliminate the trade-off between in-distribution and out-of-distribution accuracy on a broad range of natural shifts. We anticipate that this finding will contribute to the increased adoption and deployment of robustness interventions in various applications.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Discussion. This study demonstrates that ID-calibrated ensembles, a straightforward approach that calibrates a reliable and robust model solely on in-distribution data and then aggregates the results, can effectively eliminate the trade-off between in-distribution and out-of-distribution accuracy on a broad range of natural shifts. We anticipate that this finding will contribute to the increased adoption and deployment of robustness interventions in various applications.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Discussion. This study demonstrates that ID-calibrated ensembles, a straightforward approach that calibrates a reliable and robust model solely on in-distribution data and then aggregates the results, can effectively eliminate the trade-off between in-distribution and out-of-distribution accuracy on a broad range of natural shifts. We anticipate that this finding will contribute to the increased adoption and deployment of robustness interventions in various applications.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Discussion. This study demonstrates that ID-calibrated ensembles, a straightforward approach that calibrates a reliable and robust model solely on in-distribution data and then aggregates the results, can effectively eliminate the trade-off between in-distribution and out-of-distribution accuracy on a broad range of natural shifts. We anticipate that this finding will contribute to the increased adoption and deployment of robustness interventions in various applications.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "instruction": "Rename this section to a more approapiate title.", "revised_paragraph": "Revised paragraph: \"Conclusion: Breaking the Tradeoff between ID and OOD Accuracy - ID-Calibrated Ensembles as a Solution\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "W6V9WgTOwm.kXnvpTSqMp.00", "instruction": "Rename the section \"Conclusion and Future Work\"", "revised_paragraph": "Revised paragraph: Discussion. This paper demonstrates that ID-calibrated ensembles, a straightforward approach of calibrating a standard and robust model solely on ID data and then combining them, can effectively eliminate the trade-off between in-distribution and out-of-distribution accuracy across a broad spectrum of natural shifts. We anticipate that this finding will contribute to the increased adoption and deployment of robustness interventions.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: To investigate the statistical significance of the relationship between entropy estimated by the RDE and experimental \u2206\u2206G values, we conducted linear regression analysis using the RDE-Linear model (Eq. 9). The model includes 7 coefficients and 1 bias term. We merged two coefficients due to identical entropy estimates for the receptor. The regression results are presented in Table 3, including coefficients, bias, and P-values."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To establish a statistically significant relationship between the entropy estimated by the RDE and the experimental \u2206\u2206G values, we employed linear regression analysis using the RDE-Linear model defined in Eq. 9. This model consists of 7 coefficients and 1 bias term, including wbound WL, wbound WR, wunbnd WL, wbound ML, wbound MR, wunbnd ML, and (wunbnd MR - wunbnd WR), as well as b. Notably, wunbnd MR and wunbnd WR are combined, as the receptor is not mutated, resulting in identical entropy estimates. For simplicity, we denote this merged coefficient as wunbnd R. The results of the linear regression analysis on the SKEMPI2 dataset are presented in Table 3, including the regression coefficients, bias, and P-values."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nTo establish a statistically significant relationship between the entropy estimated by the RDE model and the experimental \u0394\u0394G values, we employ linear regression analysis using the RDE-Linear model defined in Equation 9. This model comprises seven coefficients and one bias term: w_bound_W_L, w_bound_W_R, w_unbnd_W_L, w_bound_M_L, w_bound_M_R, w_unbnd_M_L, and (w_unbnd_M_R - w_unbnd_W_R), as well as the bias term b. Since the receptor is not mutated, the entropy estimates from the model are identical for w_unbnd_M_R and w_unbnd_W_R, and we denote the merged coefficient as w_unbnd_R for brevity. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: To investigate the statistical significance of the relationship between entropy estimated by the RDE and experimental \u2206\u2206G values, we conducted linear regression analysis using the RDE-Linear model (Eq. 9). The model includes 7 coefficients and 1 bias term. We merged two coefficients due to identical entropy estimates for the receptor. The regression results are presented in Table 3, including coefficients, bias, and P-values."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To establish a statistically significant relationship between the entropy estimated by the RDE and the experimental \u2206\u2206G values, we employed linear regression analysis using the RDE-Linear model defined in Eq. 9. This model consists of 7 coefficients and 1 bias term, including wbound WL, wbound WR, wunbnd WL, wbound ML, wbound MR, wunbnd ML, and (wunbnd MR - wunbnd WR), as well as b. Notably, wunbnd MR and wunbnd WR are combined, as the receptor is not mutated, resulting in identical entropy estimates. For simplicity, we denote this merged coefficient as wunbnd R. The results of the linear regression analysis on the SKEMPI2 dataset are presented in Table 3, including the regression coefficients, bias, and P-values."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: To investigate the statistical significance of the relationship between entropy estimated by the RDE and experimental \u2206\u2206G values, we conducted linear regression analysis using the RDE-Linear model (Eq. 9). The model includes 7 coefficients and 1 bias term. We merged two coefficients due to identical entropy estimates for the receptor. The regression results are presented in Table 3, including coefficients, bias, and P-values."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: To investigate the statistical significance of the relationship between entropy estimated by the RDE and experimental \u2206\u2206G values, we conducted linear regression analysis using the RDE-Linear model (Eq. 9). The model includes 7 coefficients and 1 bias term. We merged two coefficients due to identical entropy estimates for the receptor. The regression results are presented in Table 3, including coefficients, bias, and P-values."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nTo establish a statistically significant relationship between the entropy estimated by the RDE model and the experimental \u0394\u0394G values, we employ linear regression analysis using the RDE-Linear model defined in Equation 9. This model comprises seven coefficients and one bias term: w_bound_W_L, w_bound_W_R, w_unbnd_W_L, w_bound_M_L, w_bound_M_R, w_unbnd_M_L, and (w_unbnd_M_R - w_unbnd_W_R), as well as the bias term b. Since the receptor is not mutated, the entropy estimates from the model are identical for w_unbnd_M_R and w_unbnd_W_R, and we denote the merged coefficient as w_unbnd_R for brevity. We perform linear regression on the SKEMPI2 dataset and present the regression coefficients, bias, and P-values in Table 3."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: To investigate the statistical significance of the relationship between entropy estimated by the RDE and experimental \u2206\u2206G values, we conducted linear regression analysis using the RDE-Linear model (Eq. 9). The model includes 7 coefficients and 1 bias term. We merged two coefficients due to identical entropy estimates for the receptor. The regression results are presented in Table 3, including coefficients, bias, and P-values."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To examine the statistical significance of the relationship between entropy estimated by the RDE and experimental \u0394G values, we employed linear regression analysis using the RDE-Linear model (Equation 9). This model consists of 7 coefficients and 1 bias term, with two coefficients merged due to identical entropy estimates for the receptor. The regression results are summarized in Table 3, which presents the coefficients, bias, and P-values."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To investigate the statistical significance of the relationship between the entropy estimated by the RDE method and the experimental \u0394G values, we performed a linear regression analysis using the RDE-Linear model (Equation 9). This model comprises 7 coefficients and 1 bias term, with two coefficients combined due to identical entropy estimates for the receptor. The regression results are summarized in Table 3, which presents the coefficients, bias, and corresponding P-values."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: To investigate the statistical significance of the relationship between entropy estimated by the RDE and experimental \u2206\u2206G values, we conducted linear regression analysis using the RDE-Linear model (Eq. 9). The model includes 7 coefficients and 1 bias term. We merged two coefficients due to identical entropy estimates for the receptor. The regression results are presented in Table 3, including coefficients, bias, and P-values."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To establish a statistically significant relationship between the entropy estimated by the RDE and the experimental \u2206\u2206G values, we employed linear regression analysis using the RDE-Linear model defined in Eq. 9. This model consists of 7 coefficients and 1 bias term, including wbound WL, wbound WR, wunbnd WL, wbound ML, wbound MR, wunbnd ML, and (wunbnd MR - wunbnd WR), as well as b. Notably, wunbnd MR and wunbnd WR are combined, as the receptor is not mutated, resulting in identical entropy estimates. For simplicity, we denote this merged coefficient as wunbnd R. The results of the linear regression analysis on the SKEMPI2 dataset are presented in Table 3, including the regression coefficients, bias, and P-values."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: To establish a statistically significant relationship between RDE-estimated entropy and experimental \u2206\u2206G values, we applied linear regression analysis using the RDE-Linear model defined in Eq. 9. The model includes 7 coefficients and 1 bias term, with wunbnd R combining the receptor's entropy estimates. The results, presented in Table 3, show regression coefficients, bias, and P-values for the SKEMPI2 dataset."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: To investigate the statistical significance of the relationship between entropy estimated by the RDE and experimental \u2206\u2206G values, we conducted linear regression analysis using the RDE-Linear model (Eq. 9). The model includes 7 coefficients and 1 bias term. We merged two coefficients due to identical entropy estimates for the receptor. The regression results are presented in Table 3, including coefficients, bias, and P-values."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To examine the statistical significance of the relationship between the entropy estimated by the residual dipolar coupling (RDE) and the experimental changes in Gibbs free energy (\u2206\u2206G) values, we performed a linear regression analysis using the RDE-linear model (Equation 9). This model comprises 7 coefficients and 1 bias term. Notably, we combined two coefficients due to identical entropy estimates for the receptor. The regression results are presented in Table 3, which includes the estimated coefficients, bias, and corresponding P-values."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "instruction": "Simplify the explanation of the merged w unbnd M R and w unbnd W R.", "revised_paragraph": "Revised paragraph: Statistical significance was evaluated by conducting linear regression analysis using the RDE-Linear model defined in Eq.9. The model consisted of 7 coefficients and 1 bias: w bound W L, w bound W R, w unbnd W L, w bound M L, w bound M R, w unbnd M L, and b. Notably, w unbnd M R and w unbnd W R were merged, as the receptor was not mutated, resulting in identical entropy estimates. This merged coefficient is denoted as w unbnd R. The linear regression analysis was performed on the SKEMPI2 dataset, and the resulting regression coefficients, bias, and P-values are presented in Table 3.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.23", "instruction": "Concise the penultimate sentence. Improve the English in this paragraph.", "revised_paragraph": "Revised paragraph: Statistical significance is demonstrated by conducting linear regression analysis using the RDE-Linear model (Eq. 9) to show a statistically significant relationship between the entropy estimated by the RDE and experimental \u2206\u2206G values. The model contains 7 coefficients and 1 bias: wboundWL, wboundWR, wunbndWL, wboundML, wboundMR, wunbndML, (wunbndMR - wunbndWR), and b. Notably, wunbndMR and wunbndWR are merged, as the receptor is not mutated, resulting in identical entropy estimates. We denote the merged coefficient as wunbndR. Table 3 presents the regression coefficients, bias, and P-values obtained from analyzing the SKEMPI2 dataset.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. Although it does not outperform most of the baselines across the entire SKEMPI2 dataset, we observe a significant improvement when considering only single-point mutations (Table 6 in the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics derived from estimated rotamer density alone can accurately predict \u2206\u2206G, providing a foundation for the development of more accurate models, such as RDE-Network.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. Although it does not outperform most of the baselines across the entire SKEMPI2 dataset, we observe a significant improvement when considering only single-point mutations (Table 6 in the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics derived from estimated rotamer density alone can accurately predict \u2206\u2206G, providing a foundation for the development of more accurate models, such as RDE-Network.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. Although it does not outperform most of the baselines across the entire SKEMPI2 dataset, we observe a significant improvement when considering only single-point mutations (Table 6 in the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics derived from estimated rotamer density alone can accurately predict \u2206\u2206G, providing a foundation for the development of more accurate models, such as RDE-Network.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. Although it does not outperform most of the baselines across the entire SKEMPI2 dataset, we observe a significant improvement when considering only single-point mutations (Table 6 in the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics derived from estimated rotamer density alone can accurately predict \u2206\u2206G, providing a foundation for the development of more accurate models, such as RDE-Network.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. Although it does not outperform most of the baselines across the entire SKEMPI2 dataset, we observe a significant improvement when considering only single-point mutations (Table 6 in the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics derived from estimated rotamer density alone can accurately predict \u2206\u2206G, providing a foundation for the development of more accurate models, such as RDE-Network.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. Although it does not outperform most of the baselines across the entire SKEMPI2 dataset, we observe a significant improvement when considering only single-point mutations (Table 6 in the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics derived from estimated rotamer density alone can accurately predict \u2206\u2206G, providing a foundation for the development of more accurate models, such as RDE-Network.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. Although it does not outperform most of the baselines across the entire SKEMPI2 dataset, we observe a significant improvement when considering only single-point mutations (Table 6 in the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics derived from estimated rotamer density alone can accurately predict \u2206\u2206G, providing a foundation for the development of more accurate models, such as RDE-Network.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. Although it does not outperform most of the baselines across the entire SKEMPI2 dataset, we observe a significant improvement when considering only single-point mutations (Table 6 in the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics derived from estimated rotamer density alone can accurately predict \u2206\u2206G, providing a foundation for the development of more accurate models, such as RDE-Network.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "instruction": "Make this paragraph more clear.", "revised_paragraph": "Revised paragraph: RDE-Linear exhibits performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Although it does not surpass most baselines across the entire SKEMPI2 dataset, our analysis reveals that its performance is significantly better when considering only single-point mutations (as shown in Table 6 of the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates the potential of using simple statistics from estimated rotamer density to predict \u2206\u2206G, providing a foundation for the development of more accurate models, such as RDE-Network.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "instruction": "Improve the English in this paragraph.", "revised_paragraph": "Revised paragraph: \"RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. While it does not outperform most baselines across the entire SKEMPI2 dataset, its performance is significantly better when considering single-point mutations only (Table 6 in the appendix). This may be attributed to the limitations of simple linear models in capturing the non-linear relationships that dominate multi-point mutations. Nonetheless, RDE-Linear demonstrates the potential of using simple statistics from estimated rotamer density to predict \u2206\u2206G, providing a foundation for the more accurate RDE-Network.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Reweighting methods, such as the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994), aim to obtain globally balanced distributions by weighting individuals with balanced scores. Alternative methods, proposed by Imai & Ratkovic (2014) and Fong et al. (2018), calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) have further improved these methods by considering non-confounding factors in covariates. However, these approaches are often plagued by high variance and are vulnerable to non-overlapped units, which can limit their effectiveness."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Reweighting methods, such as those based on the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994), aim to obtain globally balanced distributions by weighting individuals with balanced scores. Alternative approaches, proposed by Imai & Ratkovic (2014) and Fong et al. (2018), involve calculating the balancing score via an optimization problem. Building upon these methods, Kuang et al. (2017b) and Kuang et al. (2017a) have further incorporated non-confounding factors in covariates. However, these methods are prone to high variance and vulnerable to non-overlapped units, which can limit their effectiveness.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Reweighting methods, such as the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994), aim to obtain globally balanced distributions by weighting individuals with balanced scores. Alternative methods, proposed by Imai & Ratkovic (2014) and Fong et al. (2018), calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) have further improved these methods by considering non-confounding factors in covariates. However, these approaches are often plagued by high variance and are vulnerable to non-overlapped units, which can limit their effectiveness."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Reweighting methods, such as those based on the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994), aim to obtain globally balanced distributions by weighting individuals with balanced scores. Alternative approaches, proposed by Imai & Ratkovic (2014) and Fong et al. (2018), involve calculating the balancing score via an optimization problem. Building upon these methods, Kuang et al. (2017b) and Kuang et al. (2017a) have further incorporated non-confounding factors in covariates. However, these methods are prone to high variance and vulnerable to non-overlapped units, which can limit their effectiveness.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Reweighting methods, such as the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994), aim to obtain globally balanced distributions by weighting individuals with balanced scores. Alternative methods, proposed by Imai & Ratkovic (2014) and Fong et al. (2018), calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) have further improved these methods by considering non-confounding factors in covariates. However, these approaches are often plagued by high variance and are vulnerable to non-overlapped units, which can limit their effectiveness."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Reweighting methods, such as the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994), aim to achieve globally balanced distributions by assigning weights to individuals based on their propensity scores. Alternative methods, proposed by Imai & Ratkovic (2014) and Fong et al. (2018), calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) have improved these methods by incorporating non-confounding factors into the covariates. However, these approaches are often hindered by high variance and are susceptible to non-overlapping units, which can restrict their effectiveness."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Reweighting methods, such as the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994), aim to obtain globally balanced distributions by weighting individuals with balanced scores. Alternative methods, proposed by Imai & Ratkovic (2014) and Fong et al. (2018), calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) have further improved these methods by considering non-confounding factors in covariates. However, these approaches are often plagued by high variance and are vulnerable to non-overlapped units, which can limit their effectiveness."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Reweighting methods, such as those based on the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994), aim to obtain globally balanced distributions by weighting individuals with balanced scores. Alternative approaches, proposed by Imai & Ratkovic (2014) and Fong et al. (2018), involve calculating the balancing score via an optimization problem. Building upon these methods, Kuang et al. (2017b) and Kuang et al. (2017a) have further incorporated non-confounding factors in covariates. However, these methods are prone to high variance and vulnerable to non-overlapped units, which can limit their effectiveness.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "instruction": "Use formal words in the last sentence.", "revised_paragraph": "Revised paragraph: \"Reweighting methods weight individuals with balanced scores to obtain globally balanced distributions, represented by the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994). Imai & Ratkovic (2014) and Fong et al. (2018) propose to calculate the balancing score via an optimization problem. Kuang et al. (2017b) and Kuang et al. (2017a) further consider the non-confounding factors in covariates. Nevertheless, these methods are beset by high variance and are susceptible to non-overlapped units, rendering them inadequate for precise analysis.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.18", "instruction": "Reorder the last sentence arguments. Make this paragraph a bit more precise.", "revised_paragraph": "Revised paragraph: \"Reweighting methods, such as the inverse propensity score (IPS) approach (Rosenbaum & Rubin, 1983a) and its doubly robust variant (Robins et al., 1994), weight individuals with balanced scores to obtain globally balanced distributions. Alternative methods, proposed by Imai & Ratkovic (2014) and Fong et al. (2018), calculate the balancing score via an optimization problem. Additionally, Kuang et al. (2017b) and Kuang et al. (2017a) consider non-confounding factors in covariates. However, these methods are susceptible to high variance and non-overlapped units, which can compromise their effectiveness.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The simplest way to guarantee m n = m n +1 and a non-zero acceptance probability is to set the time step h = 0. However, this approach renders the sampler ineffective. Alternatively, taking the limit h \u2192 0 allows the Euler-Maruyama scheme to closely approximate the true SDE trajectory. Nevertheless, according to Theorem 1, the acceptance probability remains zero for any h > 0, making it impossible to monitor the discretisation error using this metric. Consequently, the Euler-Maruyama scheme fails to satisfy detailed balance. It is essential to note that these findings apply to any choice of stochastic gradients \u2207 \u03b8 U ( \u03b8 n ) and do not consider stochastic gradients, which will be examined separately."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To ensure that the acceptance probability remains nonzero, it is necessary to set m n = m n +1. However, setting the time step h = 0 renders the sampler ineffective. Alternatively, taking the limit h \u2192 0 allows the Euler-Maruyama scheme to closely approximate the true SDE trajectory. Nevertheless, according to Theorem 1, the acceptance probability remains zero for any h > 0. Consequently, it is impossible to utilize the acceptance probability to monitor the discretization error, and the Euler-Maruyama scheme fails to satisfy detailed balance. It is essential to note that this result holds regardless of the choice of stochastic gradient \u2207 \u03b8 U ( \u03b8 n ) and has not been influenced by the consideration of stochastic gradients.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The simplest way to guarantee m n = m n +1 and a non-zero acceptance probability is to set the time step h = 0. However, this approach renders the sampler ineffective. Alternatively, taking the limit h \u2192 0 allows the Euler-Maruyama scheme to closely approximate the true SDE trajectory. Nevertheless, according to Theorem 1, the acceptance probability remains zero for any h > 0, making it impossible to monitor the discretisation error using this metric. Consequently, the Euler-Maruyama scheme fails to satisfy detailed balance. It is essential to note that these findings apply to any choice of stochastic gradients \u2207 \u03b8 U ( \u03b8 n ) and do not consider stochastic gradients, which will be examined separately."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To ensure that the acceptance probability remains nonzero, it is necessary to set m n = m n +1. However, setting the time step h = 0 renders the sampler ineffective. Alternatively, taking the limit h \u2192 0 allows the Euler-Maruyama scheme to closely approximate the true SDE trajectory. Nevertheless, according to Theorem 1, the acceptance probability remains zero for any h > 0. Consequently, it is impossible to utilize the acceptance probability to monitor the discretization error, and the Euler-Maruyama scheme fails to satisfy detailed balance. It is essential to note that this result holds regardless of the choice of stochastic gradient \u2207 \u03b8 U ( \u03b8 n ) and has not been influenced by the consideration of stochastic gradients.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The simplest way to guarantee m n = m n +1 and a non-zero acceptance probability is to set the time step h = 0. However, this approach renders the sampler ineffective. Alternatively, taking the limit h \u2192 0 allows the Euler-Maruyama scheme to closely approximate the true SDE trajectory. Nevertheless, according to Theorem 1, the acceptance probability remains zero for any h > 0, making it impossible to monitor the discretisation error using this metric. Consequently, the Euler-Maruyama scheme fails to satisfy detailed balance. It is essential to note that these findings apply to any choice of stochastic gradients \u2207 \u03b8 U ( \u03b8 n ) and do not consider stochastic gradients, which will be examined separately."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The simplest approach to ensure m n = m n +1 and a non-zero acceptance probability is to set the time step h = 0, but this renders the sampler ineffective. Alternatively, taking the limit h \u2192 0 enables the Euler-Maruyama scheme to closely approximate the true stochastic differential equation (SDE) trajectory. However, according to Theorem 1, the acceptance probability remains zero for any h > 0, precluding the use of this metric to monitor the discretisation error. Consequently, the Euler-Maruyama scheme fails to satisfy detailed balance. Notably, these findings apply to any choice of stochastic gradients \u2207 \u03b8 U ( \u03b8 n ) and do not consider stochastic gradients, which will be examined separately."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The simplest way to guarantee m n = m n +1 and a non-zero acceptance probability is to set the time step h = 0. However, this approach renders the sampler ineffective. Alternatively, taking the limit h \u2192 0 allows the Euler-Maruyama scheme to closely approximate the true SDE trajectory. Nevertheless, according to Theorem 1, the acceptance probability remains zero for any h > 0, making it impossible to monitor the discretisation error using this metric. Consequently, the Euler-Maruyama scheme fails to satisfy detailed balance. It is essential to note that these findings apply to any choice of stochastic gradients \u2207 \u03b8 U ( \u03b8 n ) and do not consider stochastic gradients, which will be examined separately."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To ensure that the acceptance probability remains nonzero, it is necessary to set m n = m n +1. However, setting the time step h = 0 renders the sampler ineffective. Alternatively, taking the limit h \u2192 0 allows the Euler-Maruyama scheme to closely approximate the true SDE trajectory. Nevertheless, according to Theorem 1, the acceptance probability remains zero for any h > 0. Consequently, it is impossible to utilize the acceptance probability to monitor the discretization error, and the Euler-Maruyama scheme fails to satisfy detailed balance. It is essential to note that this result holds regardless of the choice of stochastic gradient \u2207 \u03b8 U ( \u03b8 n ) and has not been influenced by the consideration of stochastic gradients.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "instruction": "Make the last sentence logical.", "revised_paragraph": "Revised paragraph: The easiest way to ensure mn = mn+1, such that the acceptance probability remains nonzero, is to set the time step h = 0. However, this approach renders the sampler useless. Alternatively, taking the limit h \u2192 0, the Euler-Maruyama scheme can be shown to converge to the true SDE trajectory. However, as per Theorem 1, the acceptance probability remains zero for any h > 0, making it impossible to use the acceptance probability to monitor the discretization error. Consequently, the Euler-Maruyama scheme cannot satisfy detailed balance. Notably, this result holds regardless of the choice of stochastic gradients, \u2207\u03b8U(\u03b8n), which will be explored in subsequent sections.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "instruction": "Make the last sentence more formal and academic.", "revised_paragraph": "Revised paragraph: The easiest way to ensure mn = mn+1, such that the acceptance probability remains nonzero, is to set the time step h = 0. However, this approach renders the sampler ineffective. Alternatively, taking the limit h \u2192 0, the Euler-Maruyama scheme converges to the true SDE trajectory. Nevertheless, according to Theorem 1, the acceptance probability remains zero for any h > 0. Consequently, it is impossible to utilize the acceptance probability to monitor the discretization error. The Euler-Maruyama scheme cannot satisfy detailed balance. It is worth noting that this result is valid for any choice of \u2207\u03b8U(\u03b8n) and has not been extended to consider stochastic gradients.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding method. We train the baseline SimCLR [7] and our method on STL-10 and CIFAR-10 datasets, using \u21132,1-norm and nuclear-norm regularization. We fine-tune a linear softmax and record the test accuracy. Our method learns embeddings in a fixed low-dimensional space (256, 512), whereas the baseline method uses high-dimensional spaces (2048, 3072, 4096) and a fixed low-dimensional space."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this subsection, we conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding approach. We train the baseline SimCLR [7] and two implementations of CLLR, employing \u21132,1-norm-based regularization and nuclear-norm-based regularization, on the STL-10 and CIFAR-10 datasets. All models are trained for 100 and 400 epochs with the same batch size and learning rate, and their test accuracy is recorded by fine-tuning a linear softmax. The baseline method learns contrastive embeddings in both high-dimensional (2048, 3072, and 4096 dimensions) and fixed low-dimensional (256 and 512 dimensions) spaces, as well as in the unconstrained setting (\u03b1 = 0). In contrast, our method learns embeddings in a low-dimensional space, where we utilize a regularizer to maintain non-zero columns in the projection matrix L."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding method. We train the baseline SimCLR [7] and our method on STL-10 and CIFAR-10 datasets, using \u21132,1-norm and nuclear-norm regularization. We fine-tune a linear softmax and record the test accuracy. Our method learns embeddings in a fixed low-dimensional space (256, 512), whereas the baseline method uses high-dimensional spaces (2048, 3072, 4096) and a fixed low-dimensional space."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this subsection, we conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding approach. We train the baseline SimCLR [7] and two implementations of CLLR, employing \u21132,1-norm-based regularization and nuclear-norm-based regularization, on the STL-10 and CIFAR-10 datasets. All models are trained for 100 and 400 epochs with the same batch size and learning rate, and their test accuracy is recorded by fine-tuning a linear softmax. The baseline method learns contrastive embeddings in both high-dimensional (2048, 3072, and 4096 dimensions) and fixed low-dimensional (256 and 512 dimensions) spaces, as well as in the unconstrained setting (\u03b1 = 0). In contrast, our method learns embeddings in a low-dimensional space, where we utilize a regularizer to maintain non-zero columns in the projection matrix L."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding method. We train the baseline SimCLR [7] and our method on STL-10 and CIFAR-10 datasets, using \u21132,1-norm and nuclear-norm regularization. We fine-tune a linear softmax and record the test accuracy. Our method learns embeddings in a fixed low-dimensional space (256, 512), whereas the baseline method uses high-dimensional spaces (2048, 3072, 4096) and a fixed low-dimensional space."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this subsection, we conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding approach. We train the baseline SimCLR [7] and two implementations of CLLR, employing \u21132,1-norm-based regularization and nuclear-norm-based regularization, on the STL-10 and CIFAR-10 datasets. All models are trained for 100 and 400 epochs with the same batch size and learning rate, and their test accuracy is recorded by fine-tuning a linear softmax. The baseline method learns contrastive embeddings in both high-dimensional (2048, 3072, and 4096 dimensions) and fixed low-dimensional (256 and 512 dimensions) spaces, as well as in the unconstrained setting (\u03b1 = 0). In contrast, our method learns embeddings in a low-dimensional space, where we utilize a regularizer to maintain non-zero columns in the projection matrix L."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding method. We train the baseline SimCLR [7] and our method on STL-10 and CIFAR-10 datasets, using \u21132,1-norm and nuclear-norm regularization. We fine-tune a linear softmax and record the test accuracy. Our method learns embeddings in a fixed low-dimensional space (256, 512), whereas the baseline method uses high-dimensional spaces (2048, 3072, 4096) and a fixed low-dimensional space."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: In this subsection, we conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding approach. We train the baseline SimCLR [7] and two implementations of CLLR, employing \u21132,1-norm-based regularization and nuclear-norm-based regularization, on the STL-10 and CIFAR-10 datasets. All models are trained for 100 and 400 epochs with the same batch size and learning rate, and their test accuracy is recorded by fine-tuning a linear softmax. The baseline method learns contrastive embeddings in both high-dimensional (2048, 3072, and 4096 dimensions) and fixed low-dimensional (256 and 512 dimensions) spaces, as well as in the unconstrained setting (\u03b1 = 0). In contrast, our method learns embeddings in a low-dimensional space, where we utilize a regularizer to maintain non-zero columns in the projection matrix L."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding method. We train the baseline SimCLR [7] and our method on STL-10 and CIFAR-10 datasets, using \u21132,1-norm and nuclear-norm regularization. We fine-tune a linear softmax and record the test accuracy. Our method learns embeddings in a fixed low-dimensional space (256, 512), whereas the baseline method uses high-dimensional spaces (2048, 3072, 4096) and a fixed low-dimensional space."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conduct an ablation study to showcase the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding approach. We train our method and the baseline SimCLR [7] on the STL-10 and CIFAR-10 datasets, employing \u21132,1-norm and nuclear-norm regularization. We then fine-tune a linear softmax classifier and record the test accuracy. Notably, our method learns embeddings in a fixed low-dimensional space of 256 or 512 dimensions, whereas the baseline method utilises high-dimensional spaces of 2048, 3072, or 4096 dimensions, as well as a fixed low-dimensional space."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding method. We train the baseline SimCLR [7] and our method on STL-10 and CIFAR-10 datasets, using \u21132,1-norm and nuclear-norm regularization. We fine-tune a linear softmax and record the test accuracy. Our method learns embeddings in a fixed low-dimensional space (256, 512), whereas the baseline method uses high-dimensional spaces (2048, 3072, 4096) and a fixed low-dimensional space."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conduct an ablation study to showcase the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding approach. We train our method and the baseline SimCLR [7] on the STL-10 and CIFAR-10 datasets, employing \u21132,1-norm and nuclear-norm regularization. We then fine-tune a linear softmax classifier and record the test accuracy. Notably, our method learns embeddings in a fixed low-dimensional space of 256 or 512 dimensions, whereas the baseline method utilises high-dimensional spaces of 2048, 3072, or 4096 dimensions, as well as a fixed low-dimensional space."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding method. We train the baseline SimCLR [7] and our method on STL-10 and CIFAR-10 datasets, using \u21132,1-norm and nuclear-norm regularization. We fine-tune a linear softmax and record the test accuracy. Our method learns embeddings in a fixed low-dimensional space (256, 512), whereas the baseline method uses high-dimensional spaces (2048, 3072, 4096) and a fixed low-dimensional space."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conduct an ablation study to showcase the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding approach. We train our method and the baseline SimCLR [7] on the STL-10 and CIFAR-10 datasets, employing \u21132,1-norm and nuclear-norm regularization. We then fine-tune a linear softmax classifier and record the test accuracy. Notably, our method learns embeddings in a fixed low-dimensional space of 256 or 512 dimensions, whereas the baseline method utilises high-dimensional spaces of 2048, 3072, or 4096 dimensions, as well as a fixed low-dimensional space."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding method. We train the baseline SimCLR [7] and our method on STL-10 and CIFAR-10 datasets, using \u21132,1-norm and nuclear-norm regularization. We fine-tune a linear softmax and record the test accuracy. Our method learns embeddings in a fixed low-dimensional space (256, 512), whereas the baseline method uses high-dimensional spaces (2048, 3072, 4096) and a fixed low-dimensional space."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conduct an ablation study to showcase the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding approach. We train our method and the baseline SimCLR [7] on the STL-10 and CIFAR-10 datasets, employing \u21132,1-norm and nuclear-norm regularization. We then fine-tune a linear softmax classifier and record the test accuracy. Notably, our method learns embeddings in a fixed low-dimensional space of 256 or 512 dimensions, whereas the baseline method utilises high-dimensional spaces of 2048, 3072, or 4096 dimensions, as well as a fixed low-dimensional space."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "instruction": "Remove details about the baseline results and improve the readability.", "revised_paragraph": "Revised paragraph: This subsection presents an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over traditional contrastive embedding methods. We compare our method with SimCLR [7] on STL-10 and CIFAR-10 datasets, using two implementations of CLLR with different regularization techniques. All models are trained with the same batch size and learning rate, and test accuracy is recorded after fine-tuning with a linear softmax. Our method learns embeddings in a low-dimensional space, whereas traditional methods operate in high-dimensional spaces (2048, 3072, and 4096) or fixed low-dimensional spaces (256 and 512). We also include results without regularization (\u03b1 = 0) for comparison.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "I-N2JgVIgy.BNpWofyXgi.00", "instruction": "Remove sentences that are unnecessary here. Simplify this text a bit.", "revised_paragraph": "Revised paragraph: We conduct an ablation study to demonstrate the superiority of our low-dimensional contrastive embedding method over the traditional contrastive embedding method, using the STL-10 and CIFAR-10 datasets. We train the baseline SimCLR and two implementations of CLLR with 100 and 400 epochs, and record the test accuracy after fine-tuning with a linear softmax. We compare the baseline method's performance in both high-dimensional (2048, 3072, 4096) and low-dimensional (256, 512) spaces, as well as without regularization (\u03b1 = 0). Our method learns embeddings in a fixed low-dimensional space, using a regularizer to maintain non-zero columns in the projection matrix L.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Lemma 1 ensures that CPD kernels in Corollary 1 can be made PD by adding large enough constants, such as c - ||x - x'||p for sufficiently large c. Although c's value is not explicitly constructed, the shift-invariant property of Softmax normalization allows us to treat it as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). If needed, c's value can be computed using a geometric sequence search."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Lemma 1 ensures that CPD kernels in Corollary 1 can be made PD by adding large enough constants, such as c - ||x - x'||p for sufficiently large c. Although c's value is not explicitly constructed, the shift-invariant property of Softmax normalization allows us to treat it as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). If needed, c's value can be computed using a geometric sequence search."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Lemma 1 ensures that CPD kernels in Corollary 1 can be made PD by adding large enough constants, such as c - ||x - x'||p for sufficiently large c. Although c's value is not explicitly constructed, the shift-invariant property of Softmax normalization allows us to treat it as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). If needed, c's value can be computed using a geometric sequence search."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Lemma 1 ensures that CPD kernels in Corollary 1 can be made PD by adding large enough constants, such as c - ||x - x'||p for sufficiently large c. Although c's value is not explicitly constructed, the shift-invariant property of Softmax normalization allows us to treat it as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). If needed, c's value can be computed using a geometric sequence search."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Lemma 1 ensures that CPD kernels in Corollary 1 can be made PD by adding large enough constants, such as c - ||x - x'||p for sufficiently large c. Although c's value is not explicitly constructed, the shift-invariant property of Softmax normalization allows us to treat it as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). If needed, c's value can be computed using a geometric sequence search."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Lemma 1 ensures that CPD kernels in Corollary 1 can be made PD by adding large enough constants, such as c - ||x - x'||p for sufficiently large c. Although c's value is not explicitly constructed, the shift-invariant property of Softmax normalization allows us to treat it as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). If needed, c's value can be computed using a geometric sequence search."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Lemma 1 ensures that CPD kernels in Corollary 1 can be made PD by adding large enough constants, such as c - ||x - x'||p for sufficiently large c. Although c's value is not explicitly constructed, the shift-invariant property of Softmax normalization allows us to treat it as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). If needed, c's value can be computed using a geometric sequence search."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Lemma 1 ensures that CPD kernels in Corollary 1 can be made PD by adding large enough constants, such as c - ||x - x'||p for sufficiently large c. Although c's value is not explicitly constructed, the shift-invariant property of Softmax normalization allows us to treat it as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). If needed, c's value can be computed using a geometric sequence search."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "instruction": "Rewrite some formulations, giving preference to shorter ones.", "revised_paragraph": "Revised paragraph: Lemma 1 ensures that CPD kernels in Corollary 1 can be made PD by adding large constants, such as c - \u2225x - x'\u2225p for a sufficiently large c. Although Lemma 1 does not provide an explicit construction for c, the shift-invariant Softmax normalization allows us to treat c as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). We can then perform a geometric sequence search on a set of test points {xi}Ni=1 to find a suitable c that satisfies c + \u02dck(xi, xj) \u2ab0 0. In this work, we do not require the value of c, but it can be computed if needed, for instance, to derive the feature map of c + \u02dck.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "uJRtLYIOIq.e9xxGlB_c.00", "instruction": "Shorten this paragraph a bit while keeping all the informations.", "revised_paragraph": "Revised paragraph: \"Lemma 1 implies that CPD kernels in Corollary 1 can be made PD by adding large enough constants, such as c - ||x - x'||p for a sufficiently large c. Although Lemma 1 does not provide an explicit construction of c, the shift-invariant property of Softmax normalization allows us to treat c as an under-determined constant in our positional embedding design (Eq. (1) in Section 4). If needed, we can compute a suitable value of c using a geometric sequence search, but in this work, we do not require its exact value.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: There is a substantial body of literature on benchmarking studies that focus on node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016, 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018, 2019; Aynulin, 2019a,b; Courtain et al., 2020; Leleux et al., 2020). Despite the abundance of experimental results, theoretical results remain elusive. A notable exception is the work by Luxburg et al. (2010), which provides a theoretical treatment of Commute Time on large graphs and proposes a substantiated amendment to address the issue. The paper illustrates the challenges involved in such proofs. Furthermore, there is still a lack of comprehensive empirical understanding of what effects need to be proven. Our empirical study has two key advantages over previous works. Firstly, we consider a vast array of graph measures, providing a complete picture for the first time. Secondly, unlike studies that conclude with a global leaderboard, we aim to identify the leading measures for each set of LFR parameters."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: There is a substantial body of literature on benchmarking studies that focus on node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016, 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018, 2019; Aynulin, 2019a,b; Courtain et al., 2020; Leleux et al., 2020). Despite the abundance of experimental results, theoretical results remain elusive. A notable exception is the work by Luxburg et al. (2010), which provides a theoretical treatment of Commute Time on large graphs and proposes a substantiated amendment to address the issue. The paper illustrates the challenges involved in such proofs. Furthermore, there is still a lack of comprehensive empirical understanding of what effects need to be proven. Our empirical study has two key advantages over previous works. Firstly, we consider a vast array of graph measures, providing a complete picture for the first time. Secondly, unlike studies that conclude with a global leaderboard, we aim to identify the leading measures for each set of LFR parameters."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: There is a substantial body of literature on benchmarking studies that focus on node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016, 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018, 2019; Aynulin, 2019a,b; Courtain et al., 2020; Leleux et al., 2020). Despite the abundance of experimental results, theoretical results remain elusive. A notable exception is the work by Luxburg et al. (2010), which provides a theoretical treatment of Commute Time on large graphs and proposes a substantiated amendment to address the issue. The paper illustrates the challenges involved in such proofs. Furthermore, there is still a lack of comprehensive empirical understanding of what effects need to be proven. Our empirical study has two key advantages over previous works. Firstly, we consider a vast array of graph measures, providing a complete picture for the first time. Secondly, unlike studies that conclude with a global leaderboard, we aim to identify the leading measures for each set of LFR parameters."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: There is a substantial body of literature on benchmarking studies that focus on node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016, 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018, 2019; Aynulin, 2019a,b; Courtain et al., 2020; Leleux et al., 2020). Despite the abundance of experimental results, theoretical results remain elusive. A notable exception is the work by Luxburg et al. (2010), which provides a theoretical treatment of Commute Time on large graphs and proposes a substantiated amendment to address the issue. The paper illustrates the challenges involved in such proofs. Furthermore, there is still a lack of comprehensive empirical understanding of what effects need to be proven. Our empirical study has two key advantages over previous works. Firstly, we consider a vast array of graph measures, providing a complete picture for the first time. Secondly, unlike studies that conclude with a global leaderboard, we aim to identify the leading measures for each set of LFR parameters."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: There is a substantial body of literature on benchmarking studies that focus on node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016, 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018, 2019; Aynulin, 2019a,b; Courtain et al., 2020; Leleux et al., 2020). Despite the abundance of experimental results, theoretical results remain elusive. A notable exception is the work by Luxburg et al. (2010), which provides a theoretical treatment of Commute Time on large graphs and proposes a substantiated amendment to address the issue. The paper illustrates the challenges involved in such proofs. Furthermore, there is still a lack of comprehensive empirical understanding of what effects need to be proven. Our empirical study has two key advantages over previous works. Firstly, we consider a vast array of graph measures, providing a complete picture for the first time. Secondly, unlike studies that conclude with a global leaderboard, we aim to identify the leading measures for each set of LFR parameters."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: There is a substantial body of literature on benchmarking studies that focus on node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016, 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018, 2019; Aynulin, 2019a,b; Courtain et al., 2020; Leleux et al., 2020). Despite the abundance of experimental results, theoretical results remain elusive. A notable exception is the work by Luxburg et al. (2010), which provides a theoretical treatment of Commute Time on large graphs and proposes a substantiated amendment to address the issue. The paper illustrates the challenges involved in such proofs. Furthermore, there is still a lack of comprehensive empirical understanding of what effects need to be proven. Our empirical study has two key advantages over previous works. Firstly, we consider a vast array of graph measures, providing a complete picture for the first time. Secondly, unlike studies that conclude with a global leaderboard, we aim to identify the leading measures for each set of LFR parameters."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: There is a substantial body of literature on benchmarking studies that focus on node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016, 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018, 2019; Aynulin, 2019a,b; Courtain et al., 2020; Leleux et al., 2020). Despite the abundance of experimental results, theoretical results remain elusive. A notable exception is the work by Luxburg et al. (2010), which provides a theoretical treatment of Commute Time on large graphs and proposes a substantiated amendment to address the issue. The paper illustrates the challenges involved in such proofs. Furthermore, there is still a lack of comprehensive empirical understanding of what effects need to be proven. Our empirical study has two key advantages over previous works. Firstly, we consider a vast array of graph measures, providing a complete picture for the first time. Secondly, unlike studies that conclude with a global leaderboard, we aim to identify the leading measures for each set of LFR parameters."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: There is a substantial body of literature on benchmarking studies that focus on node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016, 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018, 2019; Aynulin, 2019a,b; Courtain et al., 2020; Leleux et al., 2020). Despite the abundance of experimental results, theoretical results remain elusive. A notable exception is the work by Luxburg et al. (2010), which provides a theoretical treatment of Commute Time on large graphs and proposes a substantiated amendment to address the issue. The paper illustrates the challenges involved in such proofs. Furthermore, there is still a lack of comprehensive empirical understanding of what effects need to be proven. Our empirical study has two key advantages over previous works. Firstly, we consider a vast array of graph measures, providing a complete picture for the first time. Secondly, unlike studies that conclude with a global leaderboard, we aim to identify the leading measures for each set of LFR parameters."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "instruction": "Improve the writing of this text", "revised_paragraph": "Revised paragraph: \n\nNumerous benchmarking studies have investigated node classification and clustering on both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020). Despite the wealth of experimental results, theoretical understanding remains elusive. One notable exception is the work by Luxburg et al. (2010), which provides a theoretical framework for Commute Time on large graphs and proposes a substantiated correction to address the issue. The study highlights the complexity of such proofs, underscoring the need for further research. Moreover, a comprehensive empirical understanding of what effects need to be proven is still lacking. Our empirical work offers two key advantages over previous studies. Firstly, we consider a vast array of graph measures, providing a complete picture for the first time. Secondly, unlike studies that conclude with a global leaderboard, we aim to identify the leading measures for each set of LFR parameters, offering a more nuanced understanding of their performance.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MZYBK_Wp2X.HVFitLjAId.00", "instruction": "Use accurate and scientific words.", "revised_paragraph": "Revised paragraph: There is a substantial body of literature on benchmarking studies that investigate node classification and clustering for both generated graphs and datasets (Fouss et al., 2012; Sommer et al., 2016; 2017; Avrachenkov et al., 2017; Ivashkin & Chebotarev, 2016; Guex et al., 2018; 2019; Aynulin, 2019a;b; Courtain et al., 2020; Leleux et al., 2020). Notwithstanding the plethora of experimental results, theoretical advancements remain elusive. A notable exception is the work by Luxburg et al. (2010), which provides a theoretical framework for addressing the Commute Time problem on large graphs, proposing a substantiated amendment to rectify the issue. The paper underscores the complexity of such proofs, while also highlighting the lack of a comprehensive empirical understanding of the effects that need to be demonstrated. Our empirical study offers two distinct advantages over previous works. Firstly, we consider a broad range of graph measures, providing a holistic perspective for the first time. Secondly, unlike studies that conclude with a global leaderboard, we focus on identifying the leading measures for each set of LFR parameters.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions and sample conformations to predict binding free energy changes (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods, on the other hand, rely on feature engineering, using descriptors to fit a model that predicts the effect of mutations on binding free energy (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited by the need for human knowledge and the increasing number of available protein structures."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions, sampling conformations to predict changes in binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods use feature engineering, fitting models with descriptors summarizing protein properties to predict binding free energy changes (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy due to time-consuming sampling, and rely heavily on human knowledge, limiting their pace of improvement with increasing protein structures."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions and sample conformations to predict binding free energy changes (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods, on the other hand, rely on feature engineering, using descriptors to fit a model that predicts the effect of mutations on binding free energy (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited by the need for human knowledge and the increasing number of available protein structures."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions and sample conformations to predict binding free energy changes (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods, on the other hand, rely on feature engineering, using descriptors to fit a model that predicts the effect of mutations on binding free energy (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited by the need for human knowledge and the increasing number of available protein structures."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions, sampling conformations to predict changes in binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods use feature engineering, fitting models with descriptors summarizing protein properties to predict binding free energy changes (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy due to time-consuming sampling, and rely heavily on human knowledge, limiting their pace of improvement with increasing protein structures."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions and sample conformations to predict binding free energy changes (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods, on the other hand, rely on feature engineering, using descriptors to fit a model that predicts the effect of mutations on binding free energy (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited by the need for human knowledge and the increasing number of available protein structures."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions and sample conformations to predict binding free energy changes (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods, on the other hand, rely on feature engineering, using descriptors to fit a model that predicts the effect of mutations on binding free energy (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited by the need for human knowledge and the increasing number of available protein structures."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions to predict binding free energy changes, while statistical methods rely on feature engineering to fit a model. These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions and sample conformations to predict binding free energy changes (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods, on the other hand, rely on feature engineering, using descriptors to fit a model that predicts the effect of mutations on binding free energy (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited by the need for human knowledge and the increasing number of available protein structures."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions and sample conformations to predict binding free energy changes (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods, on the other hand, rely on feature engineering, using descriptors to fit a model that predicts the effect of mutations on binding free energy (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited by the need for human knowledge and the increasing number of available protein structures."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions to predict binding free energy changes, while statistical methods rely on feature engineering to fit a model. These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly classified into biophysical and statistical methods. Biophysical methods model inter-atomic interactions using energy functions and sample conformations to predict binding free energy changes (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). Statistical methods, on the other hand, rely on feature engineering, using descriptors to fit a model that predicts the effect of mutations on binding free energy (Geng et al., 2019a; Zhang et al., 2020). These traditional methods often face a trade-off between speed and accuracy, and their improvement is limited by the need for human knowledge and the increasing number of available protein structures."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "instruction": "Summarize this:", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the impact of mutations on protein binding can be broadly categorized into biophysical and statistical methods. Biophysical methods employ energy functions to model inter-atomic interactions, sampling conformations of the mutated protein complex to predict changes in binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017). In contrast, statistical methods rely on feature engineering, using descriptors to summarize protein properties and fit a statistical model that predicts the effect of mutations on binding free energy (Geng et al., 2019a; Zhang et al., 2020). However, traditional methods often struggle with the trade-off between speed and accuracy due to time-consuming sampling processes, and their reliance on human knowledge limits their ability to adapt to the rapidly growing number of available protein structures.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.06", "instruction": "Make this paragraph shorter.", "revised_paragraph": "Revised paragraph: Traditional approaches to predicting the effect of mutation on protein binding can be broadly categorized into biophysical and statistical methods. Biophysical methods model inter-atomic interactions and sample conformations to predict binding free energy changes, while statistical methods use feature engineering to fit a model that predicts binding free energy effects (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Steinbrecher et al., 2017; Geng et al., 2019a; Zhang et al., 2020). However, these methods often face a trade-off between speed and accuracy due to time-consuming sampling processes and reliance on human knowledge.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Given the desirability of the avoid-strategy in Experiment 2, a potential modification to consider is changing the notch to an area where the cursor cannot enter. Experiment 3 was similar to Experiment 2, with the key difference being the notch's relocation to an area inaccessible to the cursor. The apparatus, participants, task, and measurements remained unchanged from Experiment 2."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Given the desirability of the avoid-strategy in Experiment 2, a potential modification to consider is changing the notch to an area where the cursor cannot enter. Experiment 3 was similar to Experiment 2, with the key difference being the notch's relocation to an area inaccessible to the cursor. The apparatus, participants, task, and measurements remained unchanged from Experiment 2."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Given the desirability of the avoid-strategy in Experiment 2, a potential modification to consider is changing the notch to an area where the cursor cannot enter. Experiment 3 was similar to Experiment 2, with the key difference being the notch's relocation to an area inaccessible to the cursor. The apparatus, participants, task, and measurements remained unchanged from Experiment 2."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Given the desirability of the avoid-strategy in Experiment 2, a potential modification to consider is changing the notch to an area where the cursor cannot enter. Experiment 3 was similar to Experiment 2, with the key difference being the notch's relocation to an area inaccessible to the cursor. The apparatus, participants, task, and measurements remained unchanged from Experiment 2."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Given the desirability of the avoid-strategy in Experiment 2, a potential modification to consider is changing the notch to an area where the cursor cannot enter. Experiment 3 was similar to Experiment 2, with the key difference being the notch's relocation to an area inaccessible to the cursor. The apparatus, participants, task, and measurements remained unchanged from Experiment 2."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Given the desirability of the avoid-strategy in Experiment 2, a potential modification to consider is changing the notch to an area where the cursor cannot enter. Experiment 3 was similar to Experiment 2, with the key difference being the notch's relocation to an area inaccessible to the cursor. The apparatus, participants, task, and measurements remained unchanged from Experiment 2."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Given the desirability of the avoid-strategy in Experiment 2, a potential modification to consider is changing the notch to an area where the cursor cannot enter. Experiment 3 was similar to Experiment 2, with the key difference being the notch's relocation to an area inaccessible to the cursor. The apparatus, participants, task, and measurements remained unchanged from Experiment 2."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Given the desirability of the avoid-strategy in Experiment 2, a potential modification to consider is changing the notch to an area where the cursor cannot enter. Experiment 3 was similar to Experiment 2, with the key difference being the notch's relocation to an area inaccessible to the cursor. The apparatus, participants, task, and measurements remained unchanged from Experiment 2."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "instruction": "Switch the two parts of the first sentence", "revised_paragraph": "Revised paragraph: Changing the notch to an area where the cursor cannot enter can be considered because avoid-strategy was shown to be desirable in experiment 2. Experiment 3 was almost the same as experiment 2, with the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were identical to those used in experiment 2.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "instruction": "Reorder the first sentence.", "revised_paragraph": "Revised paragraph: Experiment 3 was almost the same experiment as experiment 2, with the notch changed to an area where the cursor cannot enter. Because avoid-strategy was shown to be desirable in experiment 2, this modification can be considered. The apparatuses, participants, task, and measurements were the same as in experiment 2.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Figure 13(b) presents the performance results for both training and testing actions. The AGILE-Tuned, With pre-summarizer, and No twin-GAT models exhibit similar performance, outperforming the No target-q-change model. Notably, the comparison between AGILE-Tuned and No target-q-change highlights the importance of considering intermediate lists in decision-making, as the cascaded network requires referencing the q-value of the next position in the same list, rather than a list from a future time-step, when computing target q-values."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Figure 13(b) presents the performance results for both training and testing actions. The AGILE-Tuned, With pre-summarizer, and No twin-GAT models exhibit similar performance, outperforming the No target-q-change model. Notably, the comparison between AGILE-Tuned and No target-q-change highlights the importance of considering intermediate lists in decision-making, as the cascaded network requires referencing the q-value of the next position in the same list, rather than a list from a future time-step, when computing target q-values."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Figure 13(b) presents the performance results for both training and testing actions. The AGILE-Tuned, With pre-summarizer, and No twin-GAT models exhibit similar performance, outperforming the No target-q-change model. Notably, the comparison between AGILE-Tuned and No target-q-change highlights the importance of considering intermediate lists in decision-making, as the cascaded network requires referencing the q-value of the next position in the same list, rather than a list from a future time-step, when computing target q-values."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Figure 13(b) presents the performance results for both training and testing actions. The AGILE-Tuned, With pre-summarizer, and No twin-GAT models exhibit similar performance, outperforming the No target-q-change model. Notably, the comparison between AGILE-Tuned and No target-q-change highlights the importance of considering intermediate lists in decision-making, as the cascaded network requires referencing the q-value of the next position in the same list, rather than a list from a future time-step, when computing target q-values."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Figure 13(b) presents the performance results for both training and testing actions. The AGILE-Tuned, With pre-summarizer, and No twin-GAT models exhibit similar performance, outperforming the No target-q-change model. Notably, the comparison between AGILE-Tuned and No target-q-change highlights the importance of considering intermediate lists in decision-making, as the cascaded network requires referencing the q-value of the next position in the same list, rather than a list from a future time-step, when computing target q-values."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Figure 13(b) presents the performance results for both training and testing actions. The AGILE-Tuned, With pre-summarizer, and No twin-GAT models exhibit similar performance, outperforming the No target-q-change model. Notably, the comparison between AGILE-Tuned and No target-q-change highlights the importance of considering intermediate lists in decision-making, as the cascaded network requires referencing the q-value of the next position in the same list, rather than a list from a future time-step, when computing target q-values."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Figure 13(b) presents the performance results for both training and testing actions. The AGILE-Tuned, With pre-summarizer, and No twin-GAT models exhibit similar performance, outperforming the No target-q-change model. Notably, the comparison between AGILE-Tuned and No target-q-change highlights the importance of considering intermediate lists in decision-making, as the cascaded network requires referencing the q-value of the next position in the same list, rather than a list from a future time-step, when computing target q-values."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Figure 13(b) presents the performance results for both training and testing actions. The AGILE-Tuned, With pre-summarizer, and No twin-GAT models exhibit similar performance, outperforming the No target-q-change model. Notably, the comparison between AGILE-Tuned and No target-q-change highlights the importance of considering intermediate lists in decision-making, as the cascaded network requires referencing the q-value of the next position in the same list, rather than a list from a future time-step, when computing target q-values."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "instruction": "Rewrite the last sentence, splitting it into two to make it easier to understand", "revised_paragraph": "Revised paragraph: Figure 13(b) shows the result on both train and test actions. AGILE-Tuned, With pre-summrizer, and No twin-GAT exhibited similar performance, which was better than No target-q-change. The latter's inferior performance highlights the importance of considering intermediate lists in decision-making, whereas the cascaded network in AGILE-Tuned also incorporates the q-value of the next position in the same list, rather than referring to a list from a future time-step, when computing target q-values.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.20", "instruction": "Simplify heavily the explanations in this paragraph keeping the main points.", "revised_paragraph": "Revised paragraph: Figure 13(b) compares the performance of different models on both training and testing actions. AGILE-Tuned, With pre-summarizer, and No twin-GAT performed similarly and outperformed No target-q-change. The results suggest that the cascaded network benefits from considering intermediate lists in decision-making, as the agent needs to refer to future q-values in the same list rather than switching to another list.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 fixed the starting position, whereas Experiment 2 varied it as a condition. The starting area was a rectangle, initiated by a single click."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 featured a fixed starting position for each trial, whereas in Experiment 2, the starting position was varied as a condition. The starting area was a rectangle, and trials commenced by simply clicking within the designated area once. Notably, all other aspects of the task remained identical to those in Experiment 1, except for the aforementioned modification."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 fixed the starting position, whereas Experiment 2 varied it as a condition. The starting area was a rectangle, initiated by a single click."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 fixed the starting position, whereas Experiment 2 varied it as a condition. The starting area was a rectangle, initiated by a single click."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 featured a fixed starting position for each trial, whereas in Experiment 2, the starting position was varied as a condition. The starting area was a rectangle, and trials commenced by simply clicking within the designated area once. Notably, all other aspects of the task remained identical to those in Experiment 1, except for the aforementioned modification."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 fixed the starting position, whereas Experiment 2 varied it as a condition. The starting area was a rectangle, initiated by a single click."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 fixed the starting position, whereas Experiment 2 varied it as a condition. The starting area was a rectangle, initiated by a single click."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic, which is presented below. In Experiment 1, the starting position was fixed, whereas in Experiment 2, it was varied as a condition. Specifically, the starting area was a rectangle that was initiated by a single click."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 fixed the starting position, whereas Experiment 2 varied it as a condition. The starting area was a rectangle, initiated by a single click."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 fixed the starting position, whereas Experiment 2 varied it as a condition. The starting area was a rectangle, initiated by a single click."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic, which is presented below. In Experiment 1, the starting position was fixed, whereas in Experiment 2, it was varied as a condition. Specifically, the starting area was a rectangle that was initiated by a single click."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 6 illustrates the task schematic. Experiment 1 fixed the starting position, whereas Experiment 2 varied it as a condition. The starting area was a rectangle, initiated by a single click."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "instruction": "Make the second sentence more concise", "revised_paragraph": "Revised paragraph: \"Figure 6 shows a schematic of the task. In experiment 1, the starting position was strictly set, whereas in experiment 2, it was not set as a condition. The task was identical except for the starting area, which was a rectangle, and the trials began by clicking once. The only difference between the two experiments was the introduction of a new starting condition.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "instruction": "Make sentence 2 shorter.", "revised_paragraph": "Revised paragraph: \"Figure 6 shows a schematic of the task. In experiment 1, the starting position was strictly set, whereas in experiment 2, it was not set as a condition. The starting area was a rectangle, and trials began by clicking once. Except for this change, the task was identical to experiment 1.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 3 illustrates how to apply Eq. 6 to compute CTCR for each camera, with a breakdown of the equation provided below. In essence, CTCR is incentivized by the Shapley Value, which requires optimizing not only the overall formation but also every possible sub-formation. In an active HPE task, a camera agent's highest CTCR is achieved when its current position and view are optimal for both the current formation and any potential sub-formation."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 3 illustrates the process of plugging numerical values into Equation (6) to calculate the CTCR for each of the three cameras. A detailed breakdown of Equation (6) is provided below. For clarity, we also offer an intuitive explanation of Equation (6). The CTCR is motivated by the Shapley Value, which encourages the overall optimality to consider the optimality of every possible sub-formation. In the context of an active HPE task, a camera agent can achieve the highest possible CTCR by ensuring that its current position and view are optimal with respect to both its current formation and any potential sub-formations."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 3 illustrates how to apply Eq. 6 to compute CTCR for each camera, with a breakdown of the equation provided below. In essence, CTCR is incentivized by the Shapley Value, which requires optimizing not only the overall formation but also every possible sub-formation. In an active HPE task, a camera agent's highest CTCR is achieved when its current position and view are optimal for both the current formation and any potential sub-formation."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 3 illustrates the process of plugging numerical values into Equation (6) to calculate the CTCR for each of the three cameras. A detailed breakdown of Equation (6) is provided below. For clarity, we also offer an intuitive explanation of Equation (6). The CTCR is motivated by the Shapley Value, which encourages the overall optimality to consider the optimality of every possible sub-formation. In the context of an active HPE task, a camera agent can achieve the highest possible CTCR by ensuring that its current position and view are optimal with respect to both its current formation and any potential sub-formations."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 3 illustrates how to apply Eq. 6 to compute CTCR for each camera, with a breakdown of the equation provided below. In essence, CTCR is incentivized by the Shapley Value, which requires optimizing not only the overall formation but also every possible sub-formation. In an active HPE task, a camera agent's highest CTCR is achieved when its current position and view are optimal for both the current formation and any potential sub-formation."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 3 illustrates the process of plugging numerical values into Equation (6) to calculate the CTCR for each of the three cameras. A detailed breakdown of Equation (6) is provided below. For clarity, we also offer an intuitive explanation of Equation (6). The CTCR is motivated by the Shapley Value, which encourages the overall optimality to consider the optimality of every possible sub-formation. In the context of an active HPE task, a camera agent can achieve the highest possible CTCR by ensuring that its current position and view are optimal with respect to both its current formation and any potential sub-formations."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 3 illustrates how to apply Eq. 6 to compute CTCR for each camera, with a breakdown of the equation provided below. In essence, CTCR is incentivized by the Shapley Value, which requires optimizing not only the overall formation but also every possible sub-formation. In an active HPE task, a camera agent's highest CTCR is achieved when its current position and view are optimal for both the current formation and any potential sub-formation."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 3 illustrates the process of plugging numerical values into Equation (6) to calculate the CTCR for each of the three cameras. A detailed breakdown of Equation (6) is provided below. For clarity, we also offer an intuitive explanation of Equation (6). The CTCR is motivated by the Shapley Value, which encourages the overall optimality to consider the optimality of every possible sub-formation. In the context of an active HPE task, a camera agent can achieve the highest possible CTCR by ensuring that its current position and view are optimal with respect to both its current formation and any potential sub-formations."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 3 illustrates how to apply Eq. 6 to compute CTCR for each camera, with a breakdown of the equation provided below. In essence, CTCR is incentivized by the Shapley Value, which requires optimizing not only the overall formation but also every possible sub-formation. In an active HPE task, a camera agent's highest CTCR is achieved when its current position and view are optimal for both the current formation and any potential sub-formation."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 3 demonstrates the application of Equation 6 to compute Camera Task Completion Rate (CTCR) for each camera, with a detailed breakdown of the equation presented below. Essentially, CTCR is motivated by the Shapley Value, which necessitates optimizing not only the overall formation but also every possible sub-formation. In an active Hierarchical Pursuit and Evasion (HPE) task, a camera agent's maximum CTCR is attained when its current position and view are optimal for both the current formation and any potential sub-formation."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 3 illustrates how to apply Eq. 6 to compute CTCR for each camera, with a breakdown of the equation provided below. In essence, CTCR is incentivized by the Shapley Value, which requires optimizing not only the overall formation but also every possible sub-formation. In an active HPE task, a camera agent's highest CTCR is achieved when its current position and view are optimal for both the current formation and any potential sub-formation."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 3 demonstrates the application of Equation 6 to compute Camera Task Completion Rate (CTCR) for each camera, with a detailed breakdown of the equation presented below. Essentially, CTCR is motivated by the Shapley Value, which necessitates optimizing not only the overall formation but also every possible sub-formation. In an active Hierarchical Pursuit and Evasion (HPE) task, a camera agent's maximum CTCR is attained when its current position and view are optimal for both the current formation and any potential sub-formation."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 3 illustrates how to apply Eq. 6 to compute CTCR for each camera, with a breakdown of the equation provided below. In essence, CTCR is incentivized by the Shapley Value, which requires optimizing not only the overall formation but also every possible sub-formation. In an active HPE task, a camera agent's highest CTCR is achieved when its current position and view are optimal for both the current formation and any potential sub-formation."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 3 demonstrates the application of Equation 6 to compute Camera Task Completion Rate (CTCR) for each camera, with a detailed breakdown of the equation presented below. Essentially, CTCR is motivated by the Shapley Value, which necessitates optimizing not only the overall formation but also every possible sub-formation. In an active Hierarchical Pursuit and Evasion (HPE) task, a camera agent's maximum CTCR is attained when its current position and view are optimal for both the current formation and any potential sub-formation."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Figure 3 illustrates how to apply Eq. 6 to compute CTCR for each camera, with a breakdown of the equation provided below. In essence, CTCR is incentivized by the Shapley Value, which requires optimizing not only the overall formation but also every possible sub-formation. In an active HPE task, a camera agent's highest CTCR is achieved when its current position and view are optimal for both the current formation and any potential sub-formation."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Figure 3 demonstrates the application of Equation 6 to compute Camera Task Completion Rate (CTCR) for each camera, with a detailed breakdown of the equation presented below. Essentially, CTCR is motivated by the Shapley Value, which necessitates optimizing not only the overall formation but also every possible sub-formation. In an active Hierarchical Pursuit and Evasion (HPE) task, a camera agent's maximum CTCR is attained when its current position and view are optimal for both the current formation and any potential sub-formation."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "instruction": "Remove the second setence and make the paragraph more concise", "revised_paragraph": "Revised paragraph: Figure 3 illustrates the computation of CTCR for each camera using Eq. 6. The CTCR is incentivized by the Shapley Value, ensuring overall optimality considers the optimality of every possible sub-formation, including the current formation and any sub-formation.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "instruction": "Remove unnecessary information, use concicse expression.", "revised_paragraph": "Revised paragraph: Figure 3 illustrates the computation of CTCR for each camera using Eq. 6, with a breakdown provided below. The CTCR is incentivized by the Shapley Value, which ensures that overall optimality is aligned with the optimality of each possible sub-formation. For a camera agent to maximize CTCR in an active HPE task, its position and view must be optimal for both its current formation and any potential sub-formation.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our approach differs from recent causal inference methods based on optimal transport, which are limited by high variance (Dunipace, 2021) or designed for multi-phase data (Torous et al., 2021). Our work shares similarities with Li et al. (2022) and Uri et al. (2017), but focuses on applying optimal transport to augment CFR, addressing MSE and UCE issues that remain unmitigated in the literature."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIt is essential to highlight the distinctions between our approach and emerging causal inference methods based on optimal transport. While Dunipace (2021) improved the IPS method using a propensity score estimator grounded in optimal transport, its application is limited by the high variance issue. In contrast, Torous et al. (2021) employed the push forward operator to enhance change-in-change models, but these are designed for multi-phase data, which is not available in our study. Li et al. (2022) shares similar settings with our research, focusing on variable decomposition in latent space, similar to Uri et al. (2017) in terms of alignment technology. Our contribution lies in exploring the role and flexibility of optimal transport in augmenting CFR, thereby addressing the MSE and UCE issues that have long been overlooked in the literature, including recent studies published this year."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"It is essential to highlight the distinctions between our approach and emerging causal inference methods based on optimal transport. While Dunipace (2021) improves the IPS method by incorporating a propensity score estimator grounded in optimal transport, this approach is hindered by the high variance issue previously discussed. Torous et al. (2021) employs the push forward operator to enhance change-in-change models, but these models are designed for multi-phase data, which is not applicable to our case. Li et al. (2022) shares similar settings with our study, focusing on variable decomposition in latent space, a concept identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport in augmenting CFR, thereby mitigating the MSE and UCE issues that have long been overlooked in the literature, as recent as this year.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIt is essential to highlight the distinctions between our approach and emerging causal inference methods based on optimal transport. While Dunipace (2021) improved the IPS method using a propensity score estimator grounded in optimal transport, its application is limited by the high variance issue. In contrast, Torous et al. (2021) employed the push forward operator to enhance change-in-change models, but these are designed for multi-phase data, which is not available in our study. Li et al. (2022) shares similar settings with our research, focusing on variable decomposition in latent space, similar to Uri et al. (2017) in terms of alignment technology. Our contribution lies in exploring the role and flexibility of optimal transport in augmenting CFR, thereby addressing the MSE and UCE issues that have long been overlooked in the literature, including recent studies published this year."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"It is essential to highlight the distinctions between our approach and emerging causal inference methods based on optimal transport. While Dunipace (2021) improves the IPS method by incorporating a propensity score estimator grounded in optimal transport, this approach is hindered by the high variance issue previously discussed. Torous et al. (2021) employs the push forward operator to enhance change-in-change models, but these models are designed for multi-phase data, which is not applicable to our case. Li et al. (2022) shares similar settings with our study, focusing on variable decomposition in latent space, a concept identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport in augmenting CFR, thereby mitigating the MSE and UCE issues that have long been overlooked in the literature, as recent as this year.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Our approach differs from recent causal inference methods based on optimal transport, which are limited by high variance (Dunipace, 2021) or designed for multi-phase data (Torous et al., 2021). Our work shares similarities with Li et al. (2022) and Uri et al. (2017), but focuses on applying optimal transport to augment CFR, addressing MSE and UCE issues that remain unmitigated in the literature."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our approach differs from recent causal inference methods based on optimal transport, which are limited by high variance (Dunipace, 2021) or designed for multi-phase data (Torous et al., 2021). Our work shares similarities with Li et al. (2022) and Uri et al. (2017), but focuses on applying optimal transport to augment CFR, addressing MSE and UCE issues that remain unmitigated in the literature."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our approach diverges from recent causal inference methods grounded in optimal transport, which are hampered by high variance (Dunipace, 2021) or are tailored for multi-phase data (Torous et al., 2021). In contrast, our work draws parallels with Li et al. (2022) and Uri et al. (2017), but uniquely focuses on leveraging optimal transport to enhance CFR, thereby addressing the outstanding issues of MSE and UCE that persist in the literature."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our approach differs from recent causal inference methods based on optimal transport, which are limited by high variance (Dunipace, 2021) and are typically designed for multi-phase data (Torous et al., 2021). In contrast, our work builds upon the ideas of Li et al. (2022) and Uri et al. (2017), but innovatively applies optimal transport to improve Conditional Finite Rate (CFR), thereby addressing the long-standing issues of Mean Squared Error (MSE) and Unconditional Coverage Error (UCE) that persist in the literature."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIt is essential to highlight the distinctions between our approach and emerging causal inference methods based on optimal transport. While Dunipace (2021) improved the IPS method using a propensity score estimator grounded in optimal transport, its application is limited by the high variance issue. In contrast, Torous et al. (2021) employed the push forward operator to enhance change-in-change models, but these are designed for multi-phase data, which is not available in our study. Li et al. (2022) shares similar settings with our research, focusing on variable decomposition in latent space, similar to Uri et al. (2017) in terms of alignment technology. Our contribution lies in exploring the role and flexibility of optimal transport in augmenting CFR, thereby addressing the MSE and UCE issues that have long been overlooked in the literature, including recent studies published this year."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"It is essential to highlight the distinctions between our approach and emerging causal inference methods based on optimal transport. While Dunipace (2021) improves the IPS method by incorporating a propensity score estimator grounded in optimal transport, this approach is hindered by the high variance issue previously discussed. Torous et al. (2021) employs the push forward operator to enhance change-in-change models, but these models are designed for multi-phase data, which is not applicable to our case. Li et al. (2022) shares similar settings with our study, focusing on variable decomposition in latent space, a concept identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport in augmenting CFR, thereby mitigating the MSE and UCE issues that have long been overlooked in the literature, as recent as this year.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our approach differs from emerging causal inference methods based on optimal transport. While some studies, such as Dunipace (2021) and Torous et al. (2021), address specific limitations, they are not directly applicable to our case. Our contribution lies in investigating the role and flexibility of optimal transport in augmenting CFR, thereby mitigating the MSE and UCE issues that have long been overlooked in the literature, as recent as this year.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "instruction": "Revise this paragraph for better clarity.", "revised_paragraph": "Revised paragraph: It is essential to highlight the distinctiveness of our approach from emerging causal inference methods based on optimal transport. While Dunipace (2021) improved the IPS method by incorporating a propensity score estimator based on optimal transport, this approach is hindered by the high variance issue mentioned earlier. Torous et al. (2021) employed the push forward operator to enhance change-in-change models, but their method is tailored for multi-phase data, which is not applicable to our case. Li et al. (2022) shares similarities with our study, focusing on variable decomposition in latent space, similar to Uri et al. (2017) in terms of alignment technology. Our unique contribution lies in exploring the role and flexibility of optimal transport in augmenting CFR, thereby addressing the long-standing issues of MSE and UCE that have persisted in the literature, including recent works.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "instruction": "Make this paragraph more simple to read and concise phrases that are to long when possible.", "revised_paragraph": "Revised paragraph: Our approach differs from recent causal inference methods based on optimal transport. Dunipace (2021) improved the IPS method using optimal transport, but was limited by high variance. Torous et al. (2021) used a push forward operator to enhance change-in-change models, but these are designed for multi-phase data, which is not available in our case. Li et al. (2022) shares similar settings, focusing on variable decomposition in latent space, similar to Uri et al. (2017). Our contribution is investigating the role and flexibility of optimal transport in augmenting CFR, addressing MSE and UCE issues that have been overlooked in recent literature.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch, which can hinder movement. To avoid this issue, users can either avoid the notch or move the cursor carefully around it, but this may increase the movement time. Our study aimed to evaluate the impact of the notch on mouse cursor movement. In Experiment 1, we found that the notch significantly increased pointing movement time in specific situations. Experiment 2 demonstrated that avoiding the notch altogether is more effective than attempting to navigate around it in the current notch design. In Experiment 3, we showed that modifying the notch to an area where the cursor cannot enter can greatly improve pointing speed and accuracy when the target is adjacent to the notch. In fact, the outer edge of the notch can effectively stop the cursor, resulting in faster and more accurate target-pointing. Overall, our findings suggest that the notch should be designed to prevent cursor entry."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nAlthough the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely obscured by the notch. This obstruction can lead to increased movement times, particularly when attempting to avoid or carefully navigate around the notch. In this study, we conducted a series of experiments to assess the impact of the notch on mouse cursor movement. Experiment 1 demonstrated that the notch significantly increased pointing movement times in specific situations. Experiment 2 revealed that it is more efficient to avoid the notch than to enter it, given the current notch design. Experiment 3 showed that modifying the notch to a region where the cursor cannot enter can significantly improve target-pointing speed and accuracy, particularly when the target is adjacent to the notch. Consequently, the outer edge of the notch serves as a barrier, allowing for faster and more accurate target-pointing. Our findings suggest that the notch should be designed to prevent cursor entry to enhance overall user experience."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nAlthough the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely obscured by the notch. This obstruction can lead to increased movement times, particularly when attempting to avoid or carefully navigate around the notch. In this study, we conducted a series of experiments to assess the impact of the notch on mouse cursor movement. Experiment 1 demonstrated that the notch significantly increased pointing movement times in specific situations. Experiment 2 revealed that it is more efficient to avoid the notch than to enter it, given the current notch design. Experiment 3 showed that modifying the notch to a region where the cursor cannot enter can significantly improve target-pointing speed and accuracy, particularly when the target is adjacent to the notch. Consequently, the outer edge of the notch serves as a barrier, allowing for faster and more accurate target-pointing. Our findings suggest that the notch should be designed to prevent cursor entry to enhance overall user experience."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch, which can hinder movement. To avoid this issue, users can either avoid the notch or move the cursor carefully around it, but this may increase the movement time. Our study aimed to evaluate the impact of the notch on mouse cursor movement. In Experiment 1, we found that the notch significantly increased pointing movement time in specific situations. Experiment 2 demonstrated that avoiding the notch altogether is more effective than attempting to navigate around it in the current notch design. In Experiment 3, we showed that modifying the notch to an area where the cursor cannot enter can greatly improve pointing speed and accuracy when the target is adjacent to the notch. In fact, the outer edge of the notch can effectively stop the cursor, resulting in faster and more accurate target-pointing. Overall, our findings suggest that the notch should be designed to prevent cursor entry."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch, which can hinder movement. To avoid this issue, users can either avoid the notch or move the cursor carefully around it, but this may increase the movement time. Our study aimed to evaluate the impact of the notch on mouse cursor movement. In Experiment 1, we found that the notch significantly increased pointing movement time in specific situations. Experiment 2 demonstrated that avoiding the notch altogether is more effective than attempting to navigate around it in the current notch design. In Experiment 3, we showed that modifying the notch to an area where the cursor cannot enter can greatly improve pointing speed and accuracy when the target is adjacent to the notch. In fact, the outer edge of the notch can effectively stop the cursor, resulting in faster and more accurate target-pointing. Overall, our findings suggest that the notch should be designed to prevent cursor entry."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, its visibility is partially or entirely obstructed, potentially hindering movement. To circumvent this issue, users can either deliberately avoid the notch or navigate around it with caution, although this may prolong movement time. Our study aimed to investigate the impact of the notch on mouse cursor movement. Experiment 1 revealed that the notch significantly increased pointing movement time in specific situations. Experiment 2 demonstrated that completely avoiding the notch is more effective than attempting to navigate around it in the current design. In Experiment 3, we showed that modifying the notch to prevent cursor entry can greatly enhance pointing speed and accuracy when the target is adjacent to the notch. Moreover, the outer edge of the notch can effectively halt the cursor, resulting in faster and more accurate target-pointing. Overall, our findings suggest that the notch should be designed to prevent cursor entry, thereby improving user experience."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nAlthough the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely obscured by the notch. This obstruction can lead to increased movement times, particularly when attempting to avoid or carefully navigate around the notch. In this study, we conducted a series of experiments to assess the impact of the notch on mouse cursor movement. Experiment 1 demonstrated that the notch significantly increased pointing movement times in specific situations. Experiment 2 revealed that it is more efficient to avoid the notch than to enter it, given the current notch design. Experiment 3 showed that modifying the notch to a region where the cursor cannot enter can significantly improve target-pointing speed and accuracy, particularly when the target is adjacent to the notch. Consequently, the outer edge of the notch serves as a barrier, allowing for faster and more accurate target-pointing. Our findings suggest that the notch should be designed to prevent cursor entry to enhance overall user experience."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Although the mouse cursor can enter the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely hidden by the notch, which can hinder movement. To avoid this issue, users can either avoid the notch or move the cursor carefully around it, but this may increase the movement time. Our study aimed to evaluate the impact of the notch on mouse cursor movement. In Experiment 1, we found that the notch significantly increased pointing movement time in specific situations. Experiment 2 demonstrated that avoiding the notch altogether is more effective than attempting to navigate around it in the current notch design. In Experiment 3, we showed that modifying the notch to an area where the cursor cannot enter can greatly improve pointing speed and accuracy when the target is adjacent to the notch. In fact, the outer edge of the notch can effectively stop the cursor, resulting in faster and more accurate target-pointing. Overall, our findings suggest that the notch should be designed to prevent cursor entry."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "instruction": "Improve the words using in this paragraph", "revised_paragraph": "Revised paragraph: Although the mouse cursor can penetrate the notch area at the top of the MacBook Pro (2021) display, it is partially or entirely obscured by the notch. To navigate this obstacle, users must either avoid the notch or move the cursor cautiously around it, which can increase movement time. In this study, we conducted a series of experiments to investigate the impact of the notch on mouse cursor movement. Experiment 1 revealed that the notch significantly prolongs pointing movement time in specific situations. Experiment 2 demonstrated that avoiding the notch is more effective than entering it, given the current notch design. Experiment 3 showed that modifying the notch to an area inaccessible to the cursor enables faster and more accurate target-pointing, particularly when the target is adjacent to the notch. Consequently, the notch's outer edge effectively halts the cursor, resulting in faster and more accurate target-pointing. Therefore, the notch should be designed to prevent cursor entry, thereby enhancing overall user experience.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.00", "instruction": "Modify this paragraph to make it more direct and easy to read.", "revised_paragraph": "Revised paragraph: The MacBook Pro's (2021) notch area at the top of the display can partially or fully obscure the mouse cursor, increasing movement time if not avoided. To assess the impact of the notch, we conducted three experiments. Experiment 1 revealed that the notch prolongs pointing movement time in specific situations. Experiment 2 showed that avoiding the notch is more effective than entering it in the current configuration. Experiment 3 demonstrated that modifying the notch to prevent cursor entry enables faster and more accurate target-pointing when the target is adjacent to the notch. As a result, the notch's outer edge halts the cursor, resulting in faster and more accurate target-pointing.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Despite achieving remarkable success in known contexts, modern deep neural networks often lack awareness of their limitations, as highlighted by Nguyen et al. (2015). Specifically, neural networks have been found to assign high posterior probabilities to out-of-distribution (OOD) test inputs, which is counterintuitive and should not occur. For instance, a self-driving car's object detection model trained to recognize in-distribution objects (e.g., cars, stop signs) may produce a high-confidence prediction for an unseen object like a moose (as illustrated in Figure 1(a)). This failure scenario raises concerns about model reliability and underscores the potential for catastrophic consequences in safety-critical applications.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Despite achieving remarkable success in known contexts, modern deep neural networks often lack awareness of their limitations, as highlighted by Nguyen et al. (2015). Specifically, neural networks have been found to assign high posterior probabilities to out-of-distribution (OOD) test inputs, which is counterintuitive and should not occur. For instance, a self-driving car's object detection model trained to recognize in-distribution objects (e.g., cars, stop signs) may produce a high-confidence prediction for an unseen object like a moose (as illustrated in Figure 1(a)). This failure scenario raises concerns about model reliability and underscores the potential for catastrophic consequences in safety-critical applications.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Despite achieving remarkable success in known contexts, modern deep neural networks often lack awareness of their limitations, as highlighted by Nguyen et al. (2015). Specifically, neural networks have been found to assign high posterior probabilities to out-of-distribution (OOD) test inputs, which is counterintuitive and should not occur. For instance, a self-driving car's object detection model trained to recognize in-distribution objects (e.g., cars, stop signs) may produce a high-confidence prediction for an unseen object like a moose (as illustrated in Figure 1(a)). This failure scenario raises concerns about model reliability and underscores the potential for catastrophic consequences in safety-critical applications.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Despite achieving remarkable success in known contexts, modern deep neural networks often lack awareness of their limitations, as highlighted by Nguyen et al. (2015). Specifically, neural networks have been found to assign high posterior probabilities to out-of-distribution (OOD) test inputs, which is counterintuitive and should not occur. For instance, a self-driving car's object detection model trained to recognize in-distribution objects (e.g., cars, stop signs) may produce a high-confidence prediction for an unseen object like a moose (as illustrated in Figure 1(a)). This failure scenario raises concerns about model reliability and underscores the potential for catastrophic consequences in safety-critical applications.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Despite achieving remarkable success in known contexts, modern deep neural networks often lack awareness of their limitations, as highlighted by Nguyen et al. (2015). Specifically, neural networks have been found to assign high posterior probabilities to out-of-distribution (OOD) test inputs, which is counterintuitive and should not occur. For instance, a self-driving car's object detection model trained to recognize in-distribution objects (e.g., cars, stop signs) may produce a high-confidence prediction for an unseen object like a moose (as illustrated in Figure 1(a)). This failure scenario raises concerns about model reliability and underscores the potential for catastrophic consequences in safety-critical applications.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Despite achieving remarkable success in known contexts, modern deep neural networks often lack awareness of their limitations, as highlighted by Nguyen et al. (2015). Specifically, neural networks have been found to assign high posterior probabilities to out-of-distribution (OOD) test inputs, which is counterintuitive and should not occur. For instance, a self-driving car's object detection model trained to recognize in-distribution objects (e.g., cars, stop signs) may produce a high-confidence prediction for an unseen object like a moose (as illustrated in Figure 1(a)). This failure scenario raises concerns about model reliability and underscores the potential for catastrophic consequences in safety-critical applications.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Despite achieving remarkable success in known contexts, modern deep neural networks often lack awareness of their limitations, as highlighted by Nguyen et al. (2015). Specifically, neural networks have been found to assign high posterior probabilities to out-of-distribution (OOD) test inputs, which is counterintuitive and should not occur. For instance, a self-driving car's object detection model trained to recognize in-distribution objects (e.g., cars, stop signs) may produce a high-confidence prediction for an unseen object like a moose (as illustrated in Figure 1(a)). This failure scenario raises concerns about model reliability and underscores the potential for catastrophic consequences in safety-critical applications.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Despite achieving remarkable success in known contexts, modern deep neural networks often lack awareness of their limitations, as highlighted by Nguyen et al. (2015). Specifically, neural networks have been found to assign high posterior probabilities to out-of-distribution (OOD) test inputs, which is counterintuitive and should not occur. For instance, a self-driving car's object detection model trained to recognize in-distribution objects (e.g., cars, stop signs) may produce a high-confidence prediction for an unseen object like a moose (as illustrated in Figure 1(a)). This failure scenario raises concerns about model reliability and underscores the potential for catastrophic consequences in safety-critical applications.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "Revised paragraph: Modern deep neural networks have achieved remarkable success in known contexts for which they are trained, but they often lack awareness of their own limitations (Nguyen et al., 2015). Specifically, neural networks have been found to assign high posterior probabilities to out-of-distribution (OOD) test inputs, which is inconsistent with the model's capabilities. For instance, an object detection model trained to recognize in-distribution objects, such as cars and stop signs, can produce a high-confidence prediction for an unseen object like a moose (as depicted in Figure 1(a)). This failure scenario raises concerns about model reliability and underscores the potential for catastrophic consequences when deployed in safety-critical applications.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "zzdwUcxTjWY.rVxmgW1FRK.00", "instruction": "Make this paragraph more formal and fitting to academic style.", "revised_paragraph": "Revised paragraph: Modern deep neural networks have demonstrated remarkable performance in known contexts for which they are trained, yet they lack the capacity to identify the boundaries of their knowledge (Nguyen et al., 2015). Specifically, neural networks have been shown to generate high posterior probabilities for out-of-distribution (OOD) test inputs, which is a phenomenon that contravenes their expected behavior. For instance, an object detection model trained to recognize in-distribution objects, such as cars and stop signs, may produce a high-confidence prediction for an unseen object, such as a moose (see Figure 1(a)). This failure case raises concerns regarding model reliability and, more alarmingly, may have catastrophic consequences when deployed in safety-critical applications.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally verify that controllable noise n c = \u03b7/S controls the width and height of the minima towards which SGD converges, affecting memorization. We also show that \u03b7 and S are exchangeable as long as the controllable noise remains the same, regardless of cyclic or constant schedules. Additionally, we observe hints of cyclical learning rates oscillating between sharp/deep and wide/shallow minima, as long as the stage of increased noise allows for mixing.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: After theoretically deriving the relationships between learning rate, batch size, gradient covariance, and the properties of minima, including loss and width, we experimentally validate that the controllable noise n_c = \u03b7/S controls the width and height of the minima towards which stochastic gradient descent (SGD) converges. We also investigate the impact of controllable noise on the memorization phenomenon. Moreover, we discuss the limitations of the theory and identify scenarios where it breaks down, exemplified by large learning rates. Additionally, we experimentally demonstrate that \u03b7 and S are interchangeable as long as the controllable noise \u03b7/S remains constant, a finding that applies to both cyclic and constant learning rate schedules. Notably, in the cyclic case, our experiments suggest that oscillations between sharp/deep and wide/shallow minima occur as long as the stage of increased noise is sufficient to facilitate mixing."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally verify that controllable noise n c = \u03b7/S controls the width and height of the minima towards which SGD converges, affecting memorization. We also show that \u03b7 and S are exchangeable as long as the controllable noise remains the same, regardless of cyclic or constant schedules. Additionally, we observe hints of cyclical learning rates oscillating between sharp/deep and wide/shallow minima, as long as the stage of increased noise allows for mixing.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: After theoretically deriving the relationships between learning rate, batch size, gradient covariance, and the properties of minima, including loss and width, we experimentally validate that the controllable noise n_c = \u03b7/S controls the width and height of the minima towards which stochastic gradient descent (SGD) converges. We also investigate the impact of controllable noise on the memorization phenomenon. Moreover, we discuss the limitations of the theory and identify scenarios where it breaks down, exemplified by large learning rates. Additionally, we experimentally demonstrate that \u03b7 and S are interchangeable as long as the controllable noise \u03b7/S remains constant, a finding that applies to both cyclic and constant learning rate schedules. Notably, in the cyclic case, our experiments suggest that oscillations between sharp/deep and wide/shallow minima occur as long as the stage of increased noise is sufficient to facilitate mixing."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally verify that controllable noise n c = \u03b7/S controls the width and height of the minima towards which SGD converges, affecting memorization. We also show that \u03b7 and S are exchangeable as long as the controllable noise remains the same, regardless of cyclic or constant schedules. Additionally, we observe hints of cyclical learning rates oscillating between sharp/deep and wide/shallow minima, as long as the stage of increased noise allows for mixing.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: After theoretically deriving the relationships between learning rate, batch size, gradient covariance, and the properties of minima, including loss and width, we experimentally validate that the controllable noise n_c = \u03b7/S controls the width and height of the minima towards which stochastic gradient descent (SGD) converges. We also investigate the impact of controllable noise on the memorization phenomenon. Moreover, we discuss the limitations of the theory and identify scenarios where it breaks down, exemplified by large learning rates. Additionally, we experimentally demonstrate that \u03b7 and S are interchangeable as long as the controllable noise \u03b7/S remains constant, a finding that applies to both cyclic and constant learning rate schedules. Notably, in the cyclic case, our experiments suggest that oscillations between sharp/deep and wide/shallow minima occur as long as the stage of increased noise is sufficient to facilitate mixing."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally verify that controllable noise n c = \u03b7/S controls the width and height of the minima towards which SGD converges, affecting memorization. We also show that \u03b7 and S are exchangeable as long as the controllable noise remains the same, regardless of cyclic or constant schedules. Additionally, we observe hints of cyclical learning rates oscillating between sharp/deep and wide/shallow minima, as long as the stage of increased noise allows for mixing.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: After theoretically deriving the relationships between learning rate, batch size, gradient covariance, and the properties of minima, including loss and width, we experimentally validate that the controllable noise n_c = \u03b7/S controls the width and height of the minima towards which stochastic gradient descent (SGD) converges. We also investigate the impact of controllable noise on the memorization phenomenon. Moreover, we discuss the limitations of the theory and identify scenarios where it breaks down, exemplified by large learning rates. Additionally, we experimentally demonstrate that \u03b7 and S are interchangeable as long as the controllable noise \u03b7/S remains constant, a finding that applies to both cyclic and constant learning rate schedules. Notably, in the cyclic case, our experiments suggest that oscillations between sharp/deep and wide/shallow minima occur as long as the stage of increased noise is sufficient to facilitate mixing."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally verify that controllable noise n c = \u03b7/S controls the width and height of the minima towards which SGD converges, affecting memorization. We also show that \u03b7 and S are exchangeable as long as the controllable noise remains the same, regardless of cyclic or constant schedules. Additionally, we observe hints of cyclical learning rates oscillating between sharp/deep and wide/shallow minima, as long as the stage of increased noise allows for mixing.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We experimentally demonstrate that the controllable noise, nc = \u03b7/S, regulates the width and height of the minima towards which stochastic gradient descent (SGD) converges, thereby influencing memorization. Notably, we find that \u03b7 and S are interchangeable parameters as long as the controllable noise remains constant, regardless of whether the noise is scheduled cyclically or constantly. Furthermore, our results hint at the existence of cyclical learning rate oscillations between sharp/deep and wide/shallow minima, which are facilitated by the stage of increased noise that allows for mixing.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally verify that controllable noise n c = \u03b7/S controls the width and height of the minima towards which SGD converges, affecting memorization. We also show that \u03b7 and S are exchangeable as long as the controllable noise remains the same, regardless of cyclic or constant schedules. Additionally, we observe hints of cyclical learning rates oscillating between sharp/deep and wide/shallow minima, as long as the stage of increased noise allows for mixing.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We experimentally demonstrate that the controllable noise, nc = \u03b7/S, regulates the width and height of the minima towards which stochastic gradient descent (SGD) converges, thereby influencing memorization. Notably, we find that \u03b7 and S are interchangeable parameters as long as the controllable noise remains constant, regardless of whether the noise is scheduled cyclically or constantly. Furthermore, our results hint at the existence of cyclical learning rate oscillations between sharp/deep and wide/shallow minima, which are facilitated by the stage of increased noise that allows for mixing.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally verify that controllable noise n c = \u03b7/S controls the width and height of the minima towards which SGD converges, affecting memorization. We also show that \u03b7 and S are exchangeable as long as the controllable noise remains the same, regardless of cyclic or constant schedules. Additionally, we observe hints of cyclical learning rates oscillating between sharp/deep and wide/shallow minima, as long as the stage of increased noise allows for mixing.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We experimentally demonstrate that the controllable noise, nc = \u03b7/S, regulates the width and height of the minima towards which stochastic gradient descent (SGD) converges, thereby influencing memorization. Notably, we find that \u03b7 and S are interchangeable parameters as long as the controllable noise remains constant, regardless of whether the noise is scheduled cyclically or constantly. Furthermore, our results hint at the existence of cyclical learning rate oscillations between sharp/deep and wide/shallow minima, which are facilitated by the stage of increased noise that allows for mixing.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally verify that controllable noise n c = \u03b7/S controls the width and height of the minima towards which SGD converges, affecting memorization. We also show that \u03b7 and S are exchangeable as long as the controllable noise remains the same, regardless of cyclic or constant schedules. Additionally, we observe hints of cyclical learning rates oscillating between sharp/deep and wide/shallow minima, as long as the stage of increased noise allows for mixing.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We experimentally demonstrate that the controllable noise, nc = \u03b7/S, regulates the width and height of the minima towards which stochastic gradient descent (SGD) converges, thereby influencing memorization. Notably, we find that \u03b7 and S are interchangeable parameters as long as the controllable noise remains constant, regardless of whether the noise is scheduled cyclically or constantly. Furthermore, our results hint at the existence of cyclical learning rate oscillations between sharp/deep and wide/shallow minima, which are facilitated by the stage of increased noise that allows for mixing.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "instruction": "I want to make my paragraph shorter and clearer.", "revised_paragraph": "Revised paragraph: After deriving the theoretical relation between learning rate, batch size, and properties of the minima, we experimentally verify that controllable noise controls the width and height of the minima towards which SGD converges. We also demonstrate the impact of controllable noise on memorization and discuss its limitations, including situations where the theory breaks down, such as large learning rates. Additionally, we show that \u03b7 and S are exchangeable as long as the controllable noise remains the same, with hints that cyclical learning rates oscillate between sharp/deep and wide/shallow minima in the cyclic case.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "ByZyHzZC-.HktKf7-AW.04", "instruction": "Delete the context in the first sentence. Delete the second sentence from the end. Smooth out the writing.", "revised_paragraph": "Revised paragraph: We experimentally verify that the controllable noise n c = \u03b7/S controls the width and height of the minima towards which SGD converges. The noise also impacts the memorization phenomenon. We demonstrate that the theory holds true for both cyclic and constant schedules, with hints of cyclical learning rates oscillating between sharp/deep and wide/shallow minima when the stage of increased noise is long enough to allow for mixing.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To train our proposed architecture, we address the non-differentiability of the statistical distance by using a differentiable proxy. Specifically, we employ Pinsker's inequality to bound the statistical distance between Z and Z1 using the symmetrized KL divergence between Z0 and Z1. Our training procedure, outlined in Algorithm 1, involves sampling batches of data, encoding them to representations, and minimizing a joint loss combining symmetrized KL-divergence and classification loss with a tradeoff parameter \u03b3. Our approach is compatible with various scalarization schemes, as demonstrated in Appendix C.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To train our proposed architecture, we address the non-differentiability of the statistical distance by using a differentiable proxy. Specifically, we employ Pinsker's inequality to bound the statistical distance between Z and Z1 using the symmetrized KL divergence between Z0 and Z1. Our training procedure, outlined in Algorithm 1, involves sampling batches of data, encoding them to representations, and minimizing a joint loss combining symmetrized KL-divergence and classification loss with a tradeoff parameter \u03b3. Our approach is compatible with various scalarization schemes, as demonstrated in Appendix C.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To train our proposed architecture, we address the non-differentiability of the statistical distance by using a differentiable proxy. Specifically, we employ Pinsker's inequality to bound the statistical distance between Z and Z1 using the symmetrized KL divergence between Z0 and Z1. Our training procedure, outlined in Algorithm 1, involves sampling batches of data, encoding them to representations, and minimizing a joint loss combining symmetrized KL-divergence and classification loss with a tradeoff parameter \u03b3. Our approach is compatible with various scalarization schemes, as demonstrated in Appendix C.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To train our proposed architecture, we address the non-differentiability of the statistical distance by using a differentiable proxy. Specifically, we employ Pinsker's inequality to bound the statistical distance between Z and Z1 using the symmetrized KL divergence between Z0 and Z1. Our training procedure, outlined in Algorithm 1, involves sampling batches of data, encoding them to representations, and minimizing a joint loss combining symmetrized KL-divergence and classification loss with a tradeoff parameter \u03b3. Our approach is compatible with various scalarization schemes, as demonstrated in Appendix C.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To train our proposed architecture, we address the non-differentiability of the statistical distance by using a differentiable proxy. Specifically, we employ Pinsker's inequality to bound the statistical distance between Z and Z1 using the symmetrized KL divergence between Z0 and Z1. Our training procedure, outlined in Algorithm 1, involves sampling batches of data, encoding them to representations, and minimizing a joint loss combining symmetrized KL-divergence and classification loss with a tradeoff parameter \u03b3. Our approach is compatible with various scalarization schemes, as demonstrated in Appendix C.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To train our proposed architecture, we address the non-differentiability of the statistical distance by using a differentiable proxy. Specifically, we employ Pinsker's inequality to bound the statistical distance between Z and Z1 using the symmetrized KL divergence between Z0 and Z1. Our training procedure, outlined in Algorithm 1, involves sampling batches of data, encoding them to representations, and minimizing a joint loss combining symmetrized KL-divergence and classification loss with a tradeoff parameter \u03b3. Our approach is compatible with various scalarization schemes, as demonstrated in Appendix C.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To train our proposed architecture, we address the non-differentiability of the statistical distance by using a differentiable proxy. Specifically, we employ Pinsker's inequality to bound the statistical distance between Z and Z1 using the symmetrized KL divergence between Z0 and Z1. Our training procedure, outlined in Algorithm 1, involves sampling batches of data, encoding them to representations, and minimizing a joint loss combining symmetrized KL-divergence and classification loss with a tradeoff parameter \u03b3. Our approach is compatible with various scalarization schemes, as demonstrated in Appendix C.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To train our proposed architecture, we address the non-differentiability of the statistical distance by using a differentiable proxy. Specifically, we employ Pinsker's inequality to bound the statistical distance between Z and Z1 using the symmetrized KL divergence between Z0 and Z1. Our training procedure, outlined in Algorithm 1, involves sampling batches of data, encoding them to representations, and minimizing a joint loss combining symmetrized KL-divergence and classification loss with a tradeoff parameter \u03b3. Our approach is compatible with various scalarization schemes, as demonstrated in Appendix C.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "instruction": "Review this paragraph, remove unnecessary details", "revised_paragraph": "Revised paragraph: \"The training procedure for our proposed architecture is designed to address the non-differentiability of the statistical distance. We replace it with a differentiable proxy using Pinsker's inequality, which bounds the statistical distance between Z and Z1 using symmetrized KL divergence between Z0 and Z1 (see Appendix A for proof). Our training procedure is outlined in Algorithm 1, which involves sampling batches from the distributions, encoding them to representations, estimating the symmetrized KL-divergence, combining it with a classification loss using a tradeoff parameter \u03b3, and minimizing the joint loss via gradient descent. This approach is independent of the concrete multi-objective optimization objective and is compatible with other scalarization schemes, as demonstrated in Appendix C.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "XwpokDSFR.0bM_dGxEwf.00", "instruction": "Make the second sentence more concise and fitting to the academic style.", "revised_paragraph": "Revised paragraph: \"Training flow-based encoders requires a novel training procedure for our proposed architecture. To address this, we replace the non-differentiable statistical distance with a differentiable proxy, leveraging Pinsker's inequality to bound the symmetrized KL divergence between the distributions. Our training procedure, outlined in Algorithm 1, involves sampling batches from the input distributions, encoding them into representations, and estimating the symmetrized KL-divergence and classification loss. We then minimize the joint loss using a convex scalarization scheme, which can be extended to other scalarization schemes as demonstrated in Appendix C.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. With Design A, three participants complained about the need to vertically scroll to view the entire calendar, citing difficulties in navigating the large amount of information. In contrast, Design B's daily medication summaries were found helpful by three participants, who appreciated the concise overview of their medication schedule. However, three participants also noted that the lines demarcating days were unclear, making it challenging to differentiate between days of the week."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Participants found Design A's vertical scrolling feature challenging, with three participants complaining about the need to scroll extensively to view all entries. For example, P3 and P8 suggested that the calendar should allow for a consolidated view of the entire day. In contrast, Design B's daily medication summaries were found helpful by three participants, such as P9, who appreciated the clear organization of medications by day. However, three participants also reported difficulty differentiating between days in Design B due to unclear line demarcations, as noted by P4."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. With Design A, three participants complained about the need to vertically scroll to view the entire calendar, citing difficulties in navigating the large amount of information. In contrast, Design B's daily medication summaries were found helpful by three participants, who appreciated the concise overview of their medication schedule. However, three participants also noted that the lines demarcating days were unclear, making it challenging to differentiate between days of the week."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. With Design A, three participants complained about the need to vertically scroll to view the entire calendar, citing difficulties in navigating the large amount of information. In contrast, Design B's daily medication summaries were found helpful by three participants, who appreciated the concise overview of their medication schedule. However, three participants also noted that the lines demarcating days were unclear, making it challenging to differentiate between days of the week."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Participants found Design A's vertical scrolling feature challenging, with three participants complaining about the need to scroll extensively to view all entries. For example, P3 and P8 suggested that the calendar should allow for a consolidated view of the entire day. In contrast, Design B's daily medication summaries were found helpful by three participants, such as P9, who appreciated the clear organization of medications by day. However, three participants also reported difficulty differentiating between days in Design B due to unclear line demarcations, as noted by P4."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. With Design A, three participants complained about the need to vertically scroll to view the entire calendar, citing difficulties in navigating the large amount of information. In contrast, Design B's daily medication summaries were found helpful by three participants, who appreciated the concise overview of their medication schedule. However, three participants also noted that the lines demarcating days were unclear, making it challenging to differentiate between days of the week."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. With Design A, three participants complained about the need to vertically scroll to view the entire calendar, citing difficulties in navigating the large amount of information. In contrast, Design B's daily medication summaries were found helpful by three participants, who appreciated the concise overview of their medication schedule. However, three participants also noted that the lines demarcating days were unclear, making it challenging to differentiate between days of the week."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. While Design A was criticized for requiring vertical scrolling, Design B's daily medication summaries were appreciated for providing a concise overview of medication schedules. However, some participants found the lines demarcating days unclear, making it difficult to differentiate between days of the week."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. With Design A, three participants complained about the need to vertically scroll to view the entire calendar, citing difficulties in navigating the large amount of information. In contrast, Design B's daily medication summaries were found helpful by three participants, who appreciated the concise overview of their medication schedule. However, three participants also noted that the lines demarcating days were unclear, making it challenging to differentiate between days of the week."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. With Design A, three participants complained about the need to vertically scroll to view the entire calendar, citing difficulties in navigating the large amount of information. In contrast, Design B's daily medication summaries were found helpful by three participants, who appreciated the concise overview of their medication schedule. However, three participants also noted that the lines demarcating days were unclear, making it challenging to differentiate between days of the week."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. While Design A was criticized for requiring vertical scrolling, Design B's daily medication summaries were appreciated for providing a concise overview of medication schedules. However, some participants found the lines demarcating days unclear, making it difficult to differentiate between days of the week."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' experiences with the three design prototypes varied. With Design A, three participants complained about the need to vertically scroll to view the entire calendar, citing difficulties in navigating the large amount of information. In contrast, Design B's daily medication summaries were found helpful by three participants, who appreciated the concise overview of their medication schedule. However, three participants also noted that the lines demarcating days were unclear, making it challenging to differentiate between days of the week."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "instruction": "Remove unnecessary details for the paragraph.", "revised_paragraph": "Revised paragraph: Participants' feedback revealed usability issues with Designs A and B. With Design A, three participants complained about the excessive scrolling required to view the entire calendar, citing difficulties in seeing the entire day's entries at once. In contrast, Design B's daily medication summaries were found helpful by three participants, who appreciated the concise overview they provided. However, three participants also noted that the lines demarcating days were unclear, making it harder to differentiate between days of the week.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.12", "instruction": "The first sentence is a bit unclear.", "revised_paragraph": "Revised paragraph: Participants experienced varying levels of difficulty when completing the task with Designs A and B. With Design A, three participants (P3, P5, and P7) reported frustration with the need to vertically scroll to the end of the day to view all entries, citing the need for a condensed or consolidated view. For instance, P3 and P8 expressed concerns about the large time frames, which made it difficult to see the entire calendar at once. In contrast, Design B provided daily medication summaries at the top, which three participants (P1, P6, and P9) found helpful in performing the task. P9 specifically praised the idea of dedicating the first row of the calendar to medications to be taken, which provided a clear overview of the day's regimen. However, three participants (P3, P4, and P5) also noted that the lines demarcating days were not clear, making it challenging to differentiate between days of the week, as P4 exemplified.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work is closely related to recent dynamic sparse reparameterization techniques that adaptively alter reparameterization during training. These methods, such as Sparse Evolutionary Training (Mocanu et al., 2018), NeST (Dai et al., 2017; 2018), and Deep Rewiring (Bellec et al., 2017), primarily focused on sparsifying fully connected layers in small and shallow networks. In contrast, our method, which is more scalable and computationally efficient, achieves for the first time a closed generalization gap between training a compact sparse network and compressing a large deep CNN, as discussed in Section 5.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work is closely related to recent dynamic sparse reparameterization techniques that adaptively alter reparameterization during training. These methods, such as Sparse Evolutionary Training (Mocanu et al., 2018), NeST (Dai et al., 2017; 2018), and Deep Rewiring (Bellec et al., 2017), primarily focused on sparsifying fully connected layers in small and shallow networks. In contrast, our method, which is more scalable and computationally efficient, achieves for the first time a closed generalization gap between training a compact sparse network and compressing a large deep CNN, as discussed in Section 5.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work is closely related to recent dynamic sparse reparameterization techniques that adaptively alter reparameterization during training. These methods, such as Sparse Evolutionary Training (Mocanu et al., 2018), NeST (Dai et al., 2017; 2018), and Deep Rewiring (Bellec et al., 2017), primarily focused on sparsifying fully connected layers in small and shallow networks. In contrast, our method, which is more scalable and computationally efficient, achieves for the first time a closed generalization gap between training a compact sparse network and compressing a large deep CNN, as discussed in Section 5.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work is closely related to recent dynamic sparse reparameterization techniques that adaptively alter reparameterization during training. These methods, such as Sparse Evolutionary Training (Mocanu et al., 2018), NeST (Dai et al., 2017; 2018), and Deep Rewiring (Bellec et al., 2017), primarily focused on sparsifying fully connected layers in small and shallow networks. In contrast, our method, which is more scalable and computationally efficient, achieves for the first time a closed generalization gap between training a compact sparse network and compressing a large deep CNN, as discussed in Section 5.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work is closely related to recent dynamic sparse reparameterization techniques that adaptively alter reparameterization during training. These methods, such as Sparse Evolutionary Training (Mocanu et al., 2018), NeST (Dai et al., 2017; 2018), and Deep Rewiring (Bellec et al., 2017), primarily focused on sparsifying fully connected layers in small and shallow networks. In contrast, our method, which is more scalable and computationally efficient, achieves for the first time a closed generalization gap between training a compact sparse network and compressing a large deep CNN, as discussed in Section 5.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work is closely related to recent dynamic sparse reparameterization techniques that adaptively alter reparameterization during training. These methods, such as Sparse Evolutionary Training (Mocanu et al., 2018), NeST (Dai et al., 2017; 2018), and Deep Rewiring (Bellec et al., 2017), primarily focused on sparsifying fully connected layers in small and shallow networks. In contrast, our method, which is more scalable and computationally efficient, achieves for the first time a closed generalization gap between training a compact sparse network and compressing a large deep CNN, as discussed in Section 5.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work is closely related to recent dynamic sparse reparameterization techniques that adaptively alter reparameterization during training. These methods, such as Sparse Evolutionary Training (Mocanu et al., 2018), NeST (Dai et al., 2017; 2018), and Deep Rewiring (Bellec et al., 2017), primarily focused on sparsifying fully connected layers in small and shallow networks. In contrast, our method, which is more scalable and computationally efficient, achieves for the first time a closed generalization gap between training a compact sparse network and compressing a large deep CNN, as discussed in Section 5.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work is closely related to recent dynamic sparse reparameterization techniques that adaptively alter reparameterization during training. These methods, such as Sparse Evolutionary Training (Mocanu et al., 2018), NeST (Dai et al., 2017; 2018), and Deep Rewiring (Bellec et al., 2017), primarily focused on sparsifying fully connected layers in small and shallow networks. In contrast, our method, which is more scalable and computationally efficient, achieves for the first time a closed generalization gap between training a compact sparse network and compressing a large deep CNN, as discussed in Section 5.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "instruction": "Edit the last sentence of this paragraph to make it shorter and remove the reference to Section 5.", "revised_paragraph": "Revised paragraph: \"Most closely related to our work are dynamic sparse reparameterization techniques that emerged recently. Like ours, these methods adaptively alter reparameterization during training, guided by heuristic rules. Sparse evolutionary training (Mocanu et al., 2018) and NeST (Dai et al., 2017; 2018) iteratively grew and pruned parameters and neurons during training. Deep rewiring (Bellec et al., 2017) combined sparse reparameterization with stochastic parameter updates. These methods focused on sparsifying fully connected layers in small and shallow networks. Our method, more scalable and computationally efficient, fully closed the generalization gap between training compact sparse networks and compressing large deep CNNs.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "S1-LZxvKX.rJ009I8RX.03", "instruction": "Rewrite the last sentence to make it more concise.", "revised_paragraph": "Revised paragraph: \"Most closely related to our work are dynamic sparse reparameterization techniques that emerged recently. These methods adaptively alter reparameterization during training, using heuristic rules. Examples include Sparse Evolutionary Training (Mocanu et al., 2018), NeST (Dai et al., 2017; 2018), and Deep Rewiring (Bellec et al., 2017), which primarily focus on sparsifying fully connected layers in small and shallow networks. In contrast, our method, which is more scalable and computationally efficient, is the first to fully close the generalization gap between training a compact sparse network and compressing a large deep CNN, as discussed in Section 5.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The proposed models employ an inference network that processes full video frame sequences to predict 2D object bounding box locations and frame-to-frame displacements, aiming to minimize 2D view prediction error. Unfortunately, we were unable to achieve meaningful results from their inference networks. The success of Hsieh et al. (2018) may be attributed to the use of carefully selected priors for 2D object bounding box location and size parameters, which were tailored to match the statistics of the moving MNIST dataset used in the study, as evident from the publicly available code. In contrast, we do not assume the existence of such object location or size priors for our CARLA dataset.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The proposed models employ an inference network that processes full video frame sequences to predict 2D object bounding box locations and frame-to-frame displacements, aiming to minimize 2D view prediction error. Unfortunately, we were unable to achieve meaningful results from their inference networks. The success of Hsieh et al. (2018) may be attributed to the use of carefully selected priors for 2D object bounding box location and size parameters, which were tailored to match the statistics of the moving MNIST dataset used in the study, as evident from the publicly available code. In contrast, we do not assume the existence of such object location or size priors for our CARLA dataset.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The proposed models employ an inference network that processes full video frame sequences to predict 2D object bounding box locations and frame-to-frame displacements, aiming to minimize 2D view prediction error. Unfortunately, we were unable to achieve meaningful results from their inference networks. The success of Hsieh et al. (2018) may be attributed to the use of carefully selected priors for 2D object bounding box location and size parameters, which were tailored to match the statistics of the moving MNIST dataset used in the study, as evident from the publicly available code. In contrast, we do not assume the existence of such object location or size priors for our CARLA dataset.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The proposed models employ an inference network that processes full video frame sequences to predict 2D object bounding box locations and frame-to-frame displacements, aiming to minimize 2D view prediction error. Unfortunately, we were unable to achieve meaningful results from their inference networks. The success of Hsieh et al. (2018) may be attributed to the use of carefully selected priors for 2D object bounding box location and size parameters, which were tailored to match the statistics of the moving MNIST dataset used in the study, as evident from the publicly available code. In contrast, we do not assume the existence of such object location or size priors for our CARLA dataset.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The proposed models employ an inference network that processes full video frame sequences to predict 2D object bounding box locations and frame-to-frame displacements, aiming to minimize 2D view prediction error. Unfortunately, we were unable to achieve meaningful results from their inference networks. The success of Hsieh et al. (2018) may be attributed to the use of carefully selected priors for 2D object bounding box location and size parameters, which were tailored to match the statistics of the moving MNIST dataset used in the study, as evident from the publicly available code. In contrast, we do not assume the existence of such object location or size priors for our CARLA dataset.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The proposed models employ an inference network that processes full video frame sequences to predict 2D object bounding box locations and frame-to-frame displacements, aiming to minimize 2D view prediction error. Unfortunately, we were unable to achieve meaningful results from their inference networks. The success of Hsieh et al. (2018) may be attributed to the use of carefully selected priors for 2D object bounding box location and size parameters, which were tailored to match the statistics of the moving MNIST dataset used in the study, as evident from the publicly available code. In contrast, we do not assume the existence of such object location or size priors for our CARLA dataset.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The proposed models employ an inference network that processes full video frame sequences to predict 2D object bounding box locations and frame-to-frame displacements, aiming to minimize 2D view prediction error. Unfortunately, we were unable to achieve meaningful results from their inference networks. The success of Hsieh et al. (2018) may be attributed to the use of carefully selected priors for 2D object bounding box location and size parameters, which were tailored to match the statistics of the moving MNIST dataset used in the study, as evident from the publicly available code. In contrast, we do not assume the existence of such object location or size priors for our CARLA dataset.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"The proposed models employ an inference network that processes full video frame sequences to predict 2D object bounding box locations and frame-to-frame displacements, aiming to minimize 2D view prediction error. Unfortunately, we were unable to achieve meaningful results from their inference networks. The success of Hsieh et al. (2018) may be attributed to the use of carefully selected priors for 2D object bounding box location and size parameters, which were tailored to match the statistics of the moving MNIST dataset used in the study, as evident from the publicly available code. In contrast, we do not assume the existence of such object location or size priors for our CARLA dataset.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "instruction": "Rephrase the paragraph", "revised_paragraph": "Revised paragraph: \"The models employ an inference network that processes full video frame sequences to predict 2D object bounding boxes and frame-to-frame displacements, with the goal of minimizing view prediction error in 2D. Unfortunately, our attempts to utilize their inference networks were unsuccessful. The achievement of Hsieh et al. (2018) may be attributed, in part, to the use of carefully selected priors for 2D object bounding box location and object size parameters, which were tailored to the moving MNIST dataset statistics used in their study, as suggested by the publicly available code. In contrast, we do not assume the existence of such object location or size priors for our CARLA data.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "S1BhqsOsB.1mgtDFRDc.02", "instruction": "Make this paragraph more clear and precise.", "revised_paragraph": "Revised paragraph: \n\nThe proposed models employ an inference network that processes full video frame sequences to predict the locations of 2D object bounding boxes and frame-to-frame displacements, aiming to minimize the view prediction error in 2D. Unfortunately, we were unable to generate meaningful results from their inference networks. The success of Hsieh et al. (2018) may be attributed, in part, to the careful selection of priors for 2D object bounding box location and object size parameters that align with the statistics of the moving MNIST dataset used in their study, as suggested by the publicly available code. In contrast, we do not assume the existence or knowledge of such object location or size priors for our CARLA dataset.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assign a semantic label to each unlabeled segment, we identify its nearest labeled segment in the feature space. We denote the resulting labeled set, combined with the original labeled set, as \u02c6C+, where \u02c6C+ includes all segments from the same category as the original segment, excluding the segment itself. This approach relies on three assumptions: a large original labeled set that covers the feature space, uniform distribution of labeled segments in the feature space, and that the embedding already encodes semantic information. We apply this relationship to propagate keypoint annotations in the DensePose dataset, where each body part is annotated with a point."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assign a semantic label to each unlabeled segment, we identify its nearest labeled segment in the feature space. We denote the resulting labeled set, combined with the original labeled set, as \u02c6C+, where \u02c6C+ includes all segments from the same category as the original segment, excluding the segment itself. This approach relies on three assumptions: a large original labeled set that covers the feature space, uniform distribution of labeled segments in the feature space, and that the embedding already encodes semantic information. We apply this relationship to propagate keypoint annotations in the DensePose dataset, where each body part is annotated with a point."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assign a semantic label to each unlabeled segment, we identify its nearest labeled segment in the feature space. We denote the resulting labeled set, combined with the original labeled set, as \u02c6C+, where \u02c6C+ includes all segments from the same category as the original segment, excluding the segment itself. This approach relies on three assumptions: a large original labeled set that covers the feature space, uniform distribution of labeled segments in the feature space, and that the embedding already encodes semantic information. We apply this relationship to propagate keypoint annotations in the DensePose dataset, where each body part is annotated with a point."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assign a semantic label to each unlabeled segment, we identify its nearest labeled segment in the feature space. We denote the resulting labeled set, combined with the original labeled set, as \u02c6C+, where \u02c6C+ includes all segments from the same category as the original segment, excluding the segment itself. This approach relies on three assumptions: a large original labeled set that covers the feature space, uniform distribution of labeled segments in the feature space, and that the embedding already encodes semantic information. We apply this relationship to propagate keypoint annotations in the DensePose dataset, where each body part is annotated with a point."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assign a semantic label to each unlabeled segment, we identify its nearest labeled segment in the feature space. We denote the resulting labeled set, combined with the original labeled set, as \u02c6C+, where \u02c6C+ includes all segments from the same category as the original segment, excluding the segment itself. This approach relies on three assumptions: a large original labeled set that covers the feature space, uniform distribution of labeled segments in the feature space, and that the embedding already encodes semantic information. We apply this relationship to propagate keypoint annotations in the DensePose dataset, where each body part is annotated with a point."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assign a semantic label to each unlabeled segment, we identify its nearest labeled segment in the feature space. We denote the resulting labeled set, combined with the original labeled set, as \u02c6C+, where \u02c6C+ includes all segments from the same category as the original segment, excluding the segment itself. This approach relies on three assumptions: a large original labeled set that covers the feature space, uniform distribution of labeled segments in the feature space, and that the embedding already encodes semantic information. We apply this relationship to propagate keypoint annotations in the DensePose dataset, where each body part is annotated with a point."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assign a semantic label to each unlabeled segment, we identify its nearest labeled segment in the feature space. We denote the resulting labeled set, combined with the original labeled set, as \u02c6C+, where \u02c6C+ includes all segments from the same category as the original segment, excluding the segment itself. This approach relies on three assumptions: a large original labeled set that covers the feature space, uniform distribution of labeled segments in the feature space, and that the embedding already encodes semantic information. We apply this relationship to propagate keypoint annotations in the DensePose dataset, where each body part is annotated with a point."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To assign a semantic label to each unlabeled segment, we identify its nearest labeled segment in the feature space. We denote the resulting labeled set, combined with the original labeled set, as \u02c6C+, where \u02c6C+ includes all segments from the same category as the original segment, excluding the segment itself. This approach relies on three assumptions: a large original labeled set that covers the feature space, uniform distribution of labeled segments in the feature space, and that the embedding already encodes semantic information. We apply this relationship to propagate keypoint annotations in the DensePose dataset, where each body part is annotated with a point."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "instruction": "Rewrite this paragraph to make it considerably clearer.", "revised_paragraph": "Revised paragraph: \n\nTo assign semantic labels to unlabeled segments, we identify the nearest labeled segment in the feature space and assign its label. We denote the updated set of labeled segments, including both the original and new labels, as \u02c6C. This formulation relies on three assumptions: first, that the original labeled set is large enough to cover the feature space; second, that the labeled segments are uniformly distributed in the feature space; and third, that the embedding already contains semantic information. Based on these assumptions, we apply this relationship to propagate keypoint annotations in the DensePose dataset, where each body part is annotated by a point.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.12", "instruction": "Revise this paragraph to improve readability and cohesiveness.", "revised_paragraph": "Revised paragraph: To assign semantic labels to unlabeled segments, we identify the nearest labeled segment in the feature space and use it as a reference. This approach is based on three key assumptions: first, the original labeled set is large enough to cover the feature space; second, the labeled segments are uniformly distributed within the space; and third, the embedding already captures some semantic information. We apply this method to propagate keypoint annotations in the DensePose dataset, where each body part is annotated by a point, as this relationship is well-suited for this specific task.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To accelerate practical use, we must prune Conv layers in residual blocks. A method is needed to align pruned indices in constrained Conv layers. Regularization is a natural solution, given its prevalent use to impose priors on sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"To accelerate the practical use of our model, it is crucial to prune all convolutional layers in residual blocks. To achieve this, we require a method to consistently identify and align the pruned indices across all constrained convolutional layers. Regularization emerges as a natural solution to this problem, given its widespread application in imposing priors on the sparsity structure in pruning, as demonstrated by previous studies (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To accelerate the practical application of our model, it is crucial to prune all convolutional layers in residual blocks. This necessitates a method to align the pruned indices across all constrained convolutional layers. Regularization emerges as a natural solution, as it is commonly used to impose prior sparsity structures in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"To accelerate the practical use of our model, it is crucial to prune all convolutional layers in residual blocks. To achieve this, we require a method to consistently identify and align the pruned indices across all constrained convolutional layers. Regularization emerges as a natural solution to this problem, given its widespread application in imposing priors on the sparsity structure in pruning, as demonstrated by previous studies (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To accelerate the practical application of our model, it is crucial to prune all convolutional layers in residual blocks. This necessitates a method to align the pruned indices across all constrained convolutional layers. Regularization emerges as a natural solution, as it is commonly used to impose prior sparsity structures in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To accelerate practical use, we must prune Conv layers in residual blocks. A method is needed to align pruned indices in constrained Conv layers. Regularization is a natural solution, given its prevalent use to impose priors on sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To accelerate practical use, we must prune Conv layers in residual blocks. A method is needed to align pruned indices in constrained Conv layers. Regularization is a natural solution, given its prevalent use to impose priors on sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To facilitate the practical application of our model, we propose pruning the convolutional layers in residual blocks. To achieve this, we need a method to align the pruned indices in the constrained convolutional layers. Regularization is a suitable solution, as it is commonly used to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021), which is essential for our approach."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To enhance the practical applicability of our model, we suggest pruning the convolutional layers within residual blocks. To accomplish this, a method is required to align the pruned indices in the constrained convolutional layers. Regularization is a suitable solution, as it is frequently employed to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021), which is crucial for our approach."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"To accelerate the practical use of our model, it is crucial to prune all convolutional layers in residual blocks. To achieve this, we require a method to consistently identify and align the pruned indices across all constrained convolutional layers. Regularization emerges as a natural solution to this problem, given its widespread application in imposing priors on the sparsity structure in pruning, as demonstrated by previous studies (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"To accelerate the practical application of our model, it is crucial to prune all convolutional layers in residual blocks. This necessitates a method to align the pruned indices across all constrained convolutional layers. Regularization emerges as a natural solution, as it is commonly used to impose prior sparsity structures in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To accelerate practical application, we propose pruning convolutional layers in residual blocks. A method to align pruned indices across all layers is necessary. Regularization, commonly used to impose sparsity in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021), emerges as a natural solution.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "instruction": "I want to use other words in my paragraph.", "revised_paragraph": "Revised paragraph: In light of this challenge, it is crucial to remove redundant Conv layers in residual blocks to expedite practical deployment. Consequently, we require a strategy to synchronize the pruned indices across all constrained Conv layers. Regularization emerges as a natural solution, given its widespread application in imposing priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.10", "instruction": "Revise this text to make it a little more concise and fitting to the academic style.", "revised_paragraph": "Revised paragraph: To accelerate the practical use of residual blocks, it is essential to prune all Conv layers. A method is required to align the pruned indices across all constrained Conv layers. Regularization emerges as a natural solution, as it is commonly used to impose priors on the sparsity structure in pruning (Reed, 1993; Wen et al., 2016; Wang et al., 2021).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The existing methods for computing the recurrence diameter have a doubly exponential worst-case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), limiting their practical application to small abstractions. Moreover, there is no compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters (Abdulaziz 2017). As a result, the recurrence diameter is not a practical completeness threshold due to the lack of a feasible computation method.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Currently, the existing methods for computing the recurrence diameter have a doubly exponential worst-case running time (Kroening and Strichman, 2003; Abdulaziz and Berger, 2021), making them impractical for large-scale applications. Moreover, these methods are only useful when applied to small abstractions, and are limited to computing upper bounds on other topological properties. Notably, there is no compositional algorithm that can compute upper bounds on the recurrence diameter using the recurrence diameters of abstractions (Abdulaziz, 2017) [Chapter 3, Theorem 2]. Consequently, due to the lack of a practical method to compute or tightly bound the recurrence diameter, it cannot be practically used as a completeness threshold."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The existing methods for computing the recurrence diameter have a doubly exponential worst-case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), limiting their practical application to small abstractions. Moreover, there is no compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters (Abdulaziz 2017). As a result, the recurrence diameter is not a practical completeness threshold due to the lack of a feasible computation method.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Currently, the existing methods for computing the recurrence diameter have a doubly exponential worst-case running time (Kroening and Strichman, 2003; Abdulaziz and Berger, 2021), making them impractical for large-scale applications. Moreover, these methods are only useful when applied to small abstractions, and are limited to computing upper bounds on other topological properties. Notably, there is no compositional algorithm that can compute upper bounds on the recurrence diameter using the recurrence diameters of abstractions (Abdulaziz, 2017) [Chapter 3, Theorem 2]. Consequently, due to the lack of a practical method to compute or tightly bound the recurrence diameter, it cannot be practically used as a completeness threshold."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The existing methods for computing the recurrence diameter have a doubly exponential worst-case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), limiting their practical application to small abstractions. Moreover, there is no compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters (Abdulaziz 2017). As a result, the recurrence diameter is not a practical completeness threshold due to the lack of a feasible computation method.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The current methods for computing the recurrence diameter have a doubly exponential worst-case running time, as demonstrated by Kroening and Strichman (2003) and Abdulaziz and Berger (2021), which severely limits their practical application to small abstractions. Furthermore, no compositional algorithm exists that can compute upper bounds on the recurrence diameter by leveraging the recurrence diameters of individual abstractions, as shown by Abdulaziz (2017). Consequently, the recurrence diameter is not a viable completeness threshold due to the lack of a feasible computation method."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The existing methods for computing the recurrence diameter have a doubly exponential worst-case running time (Kroening and Strichman 2003; Abdulaziz and Berger 2021), limiting their practical application to small abstractions. Moreover, there is no compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters (Abdulaziz 2017). As a result, the recurrence diameter is not a practical completeness threshold due to the lack of a feasible computation method.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Currently, the existing methods for computing the recurrence diameter have a doubly exponential worst-case running time (Kroening and Strichman, 2003; Abdulaziz and Berger, 2021), making them impractical for large-scale applications. Moreover, these methods are only useful when applied to small abstractions, and are limited to computing upper bounds on other topological properties. Notably, there is no compositional algorithm that can compute upper bounds on the recurrence diameter using the recurrence diameters of abstractions (Abdulaziz, 2017) [Chapter 3, Theorem 2]. Consequently, due to the lack of a practical method to compute or tightly bound the recurrence diameter, it cannot be practically used as a completeness threshold."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "instruction": "I want to get rid of unnecessary details.", "revised_paragraph": "Revised paragraph: \"The existing methods to compute the recurrence diameter have a doubly exponential worst-case running time, making them impractical for large abstractions. Moreover, there is no compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters. Consequently, the recurrence diameter cannot be practically used as a completeness threshold.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.03", "instruction": "Remove the references in the second half of the paragraph. Reorder the last sentence to improve readability.", "revised_paragraph": "Revised paragraph: Practically, the existing methods to compute the recurrence diameter have a doubly exponential worst case running time, and they are only useful when applied to small abstractions in the context of compositionally computing upper bounds on other topological properties. Furthermore, there is not a compositional algorithm that can compute upper bounds on the recurrence diameter using abstractions' recurrence diameters. Due to the absence of a practical way to compute it or tightly bound it, the recurrence diameter cannot be practically used as a completeness threshold, accordingly.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Experiment 1, we demonstrated that the notch significantly prolongs pointing movement times in specific contexts. Notably, when the notch is situated between the targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch altogether (avoid-strategy). In Experiment 2, we sought to determine which of these strategies is more effective in the current setup, where the cursor is permitted to enter the notch."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Experiment 1, we demonstrated that the notch significantly prolongs pointing movement times in specific contexts. Notably, when the notch is situated between the targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch altogether (avoid-strategy). In Experiment 2, we sought to determine which of these strategies is more effective in the current setup, where the cursor is permitted to enter the notch."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Experiment 1, we demonstrated that the notch significantly prolongs pointing movement times in specific contexts. Notably, when the notch is situated between the targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch altogether (avoid-strategy). In Experiment 2, we sought to determine which of these strategies is more effective in the current setup, where the cursor is permitted to enter the notch."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Experiment 1, we demonstrated that the notch significantly prolongs pointing movement times in specific contexts. Notably, when the notch is situated between the targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch altogether (avoid-strategy). In Experiment 2, we sought to determine which of these strategies is more effective in the current setup, where the cursor is permitted to enter the notch."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Experiment 1, we demonstrated that the notch significantly prolongs pointing movement times in specific contexts. Notably, when the notch is situated between the targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch altogether (avoid-strategy). In Experiment 2, we sought to determine which of these strategies is more effective in the current setup, where the cursor is permitted to enter the notch."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Experiment 1, we demonstrated that the notch significantly prolongs pointing movement times in specific contexts. Notably, when the notch is situated between the targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch altogether (avoid-strategy). In Experiment 2, we sought to determine which of these strategies is more effective in the current setup, where the cursor is permitted to enter the notch."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Experiment 1, we demonstrated that the notch significantly prolongs pointing movement times in specific contexts. Notably, when the notch is situated between the targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch altogether (avoid-strategy). In Experiment 2, we sought to determine which of these strategies is more effective in the current setup, where the cursor is permitted to enter the notch."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In Experiment 1, we demonstrated that the notch significantly prolongs pointing movement times in specific contexts. Notably, when the notch is situated between the targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch altogether (avoid-strategy). In Experiment 2, we sought to determine which of these strategies is more effective in the current setup, where the cursor is permitted to enter the notch."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "instruction": "Rewrite the second sentence. Replace some words for the better", "revised_paragraph": "Revised paragraph: In experiment 1, we demonstrated that the notch significantly prolongs pointing movement times in specific contexts. Moreover, when the notch is situated between targets, participants employed two primary strategies: (i) moving the cursor along the notch's edge (along-strategy) and (ii) deliberately avoiding the notch (avoid-strategy). In experiment 2, we examined which of these strategies is more effective in the current setup, which permits the cursor to enter the notch.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "instruction": "Make this paragraph more logical and precise.", "revised_paragraph": "Revised paragraph: \"In Experiment 1, we found that the notch significantly prolongs pointing movement times in specific scenarios. Moreover, when the notch is positioned between the targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch altogether (avoid-strategy). In Experiment 2, we aimed to determine which of these strategies is more effective in the context of the current specification, which permits the cursor to enter the notch.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our proposed approach addresses the limitations of existing MRL methods, which either struggle to encode molecule structure information using SMILES strings or overemphasize GNN architectures while neglecting generalization ability. We instead utilize chemical reactions to aid molecule representation learning, preserving the equivalence of molecules in the embedding space by forcing reactant and product embeddings to be equal. This constraint improves embedding space organization and generalization ability, making our model agnostic to GNN architectures. Experimental results demonstrate state-of-the-art performance in various downstream tasks, with significant gains over the best baseline method."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our proposed approach addresses the limitations of existing MRL methods, which either struggle to encode molecule structure information using SMILES strings or overemphasize GNN architectures while neglecting generalization ability. We instead utilize chemical reactions to aid molecule representation learning, preserving the equivalence of molecules in the embedding space by forcing reactant and product embeddings to be equal. This constraint improves embedding space organization and generalization ability, making our model agnostic to GNN architectures. Experimental results demonstrate state-of-the-art performance in various downstream tasks, with significant gains over the best baseline method."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our proposed approach addresses the limitations of existing MRL methods, which either struggle to encode molecule structure information using SMILES strings or overemphasize GNN architectures while neglecting generalization ability. We instead utilize chemical reactions to aid molecule representation learning, preserving the equivalence of molecules in the embedding space by forcing reactant and product embeddings to be equal. This constraint improves embedding space organization and generalization ability, making our model agnostic to GNN architectures. Experimental results demonstrate state-of-the-art performance in various downstream tasks, with significant gains over the best baseline method."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Our proposed approach addresses the limitations of existing MRL methods, which either struggle to encode molecule structure information using SMILES strings or overemphasize GNN architectures while neglecting generalization ability. We instead utilize chemical reactions to aid molecule representation learning, preserving the equivalence of molecules in the embedding space by forcing reactant and product embeddings to be equal. This constraint improves embedding space organization and generalization ability, making our model agnostic to GNN architectures. Experimental results demonstrate state-of-the-art performance in various downstream tasks, with significant gains over the best baseline method."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our proposed approach addresses the limitations of existing MRL methods, which either struggle to encode molecule structure information using SMILES strings or overemphasize GNN architectures while neglecting generalization ability. We instead utilize chemical reactions to aid molecule representation learning, preserving the equivalence of molecules in the embedding space by forcing reactant and product embeddings to be equal. This constraint improves embedding space organization and generalization ability, making our model agnostic to GNN architectures. Experimental results demonstrate state-of-the-art performance in various downstream tasks, with significant gains over the best baseline method."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our proposed approach addresses the limitations of existing MRL methods, which either struggle to encode molecule structure information using SMILES strings or overemphasize GNN architectures while neglecting generalization ability. We instead utilize chemical reactions to aid molecule representation learning, preserving the equivalence of molecules in the embedding space by forcing reactant and product embeddings to be equal. This constraint improves embedding space organization and generalization ability, making our model agnostic to GNN architectures. Experimental results demonstrate state-of-the-art performance in various downstream tasks, with significant gains over the best baseline method."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our proposed approach addresses the limitations of existing MRL methods, which either struggle to encode molecule structure information using SMILES strings or overemphasize GNN architectures while neglecting generalization ability. We instead utilize chemical reactions to aid molecule representation learning, preserving the equivalence of molecules in the embedding space by forcing reactant and product embeddings to be equal. This constraint improves embedding space organization and generalization ability, making our model agnostic to GNN architectures. Experimental results demonstrate state-of-the-art performance in various downstream tasks, with significant gains over the best baseline method."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Our proposed approach addresses the limitations of existing MRL methods, which either struggle to encode molecule structure information using SMILES strings or overemphasize GNN architectures while neglecting generalization ability. We instead utilize chemical reactions to aid molecule representation learning, preserving the equivalence of molecules in the embedding space by forcing reactant and product embeddings to be equal. This constraint improves embedding space organization and generalization ability, making our model agnostic to GNN architectures. Experimental results demonstrate state-of-the-art performance in various downstream tasks, with significant gains over the best baseline method."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "instruction": "Remove unnecessary details on specific numerical performance of the model. Link to https://github.com/hwwang55/MolR instead of supplementary material.", "revised_paragraph": "Revised paragraph: \"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasize the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation. The key idea of our approach is to preserve the equivalence of molecules with respect to chemical reactions in the embedding space, i.e., forcing the sum of reactant embeddings and the sum of product embeddings to be equal for each chemical equation. This constraint is proven effective to keep the embedding space well-organized and improve the generalization ability of molecule embeddings. Moreover, our model can use any GNN as the molecule encoder and is thus agnostic to GNN architectures. The experimental code and results are available at https://github.com/hwwang55/MolR, demonstrating the effectiveness of our method.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "isfcBsgB-H.SBe0hOLmg9.00", "instruction": "Make the second last sentence from the end of this paragraph more concise by removing too precise details.  For the last sentence, the code is now provided on github.", "revised_paragraph": "Revised paragraph: \"Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either struggle to encode molecule structure information or overemphasize GNN architectures while neglecting generalization ability. We propose using chemical reactions to assist learning molecule representation. Our approach preserves the equivalence of molecules with respect to chemical reactions in the embedding space, forcing reactant and product embeddings to be equal for each equation. This constraint improves embedding organization and generalization ability. Our model is agnostic to GNN architectures and can use any GNN as the molecule encoder. Experimental results demonstrate state-of-the-art performance in various downstream tasks, including significant gains in chemical reaction prediction, molecule property prediction, and graph-edit-distance prediction. The experimental code is available on GitHub.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To achieve this goal, we introduce a novel (\u03c3, \u03b4)-measure to mathematically quantify the effects of data augmentation, and subsequently derive an upper bound on the downstream classification error rate based on this measure. Our analysis reveals that the generalization capabilities of contrastive self-supervised learning are influenced by three critical factors: the alignment of positive samples, the divergence of class centers, and the concentration of augmented data. The first two factors are inherent properties of the learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. Building on these theoretical insights, we investigate two canonical contrastive loss functions, InfoNCE and cross-correlation, to examine how they satisfy the first two factors. Moreover, we conduct a series of experiments to study the impact of the third factor on downstream performance, and observe a strong correlation between the concentration of augmented data and the resulting classification accuracy."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To achieve this goal, we introduce a novel (\u03c3, \u03b4)-measure to mathematically quantify the effects of data augmentation, and subsequently derive an upper bound on the downstream classification error rate based on this measure. Our analysis reveals that the generalization capabilities of contrastive self-supervised learning are influenced by three critical factors: the alignment of positive samples, the divergence of class centers, and the concentration of augmented data. The first two factors are inherent properties of the learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. Building on these theoretical insights, we investigate two canonical contrastive loss functions, InfoNCE and cross-correlation, to examine how they satisfy the first two factors. Moreover, we conduct a series of experiments to study the impact of the third factor on downstream performance, and observe a strong correlation between the concentration of augmented data and the resulting classification accuracy."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To achieve this goal, we introduce a novel (\u03c3, \u03b4)-measure to mathematically quantify the effects of data augmentation, and subsequently derive an upper bound on the downstream classification error rate based on this measure. Our analysis reveals that the generalization capabilities of contrastive self-supervised learning are influenced by three critical factors: the alignment of positive samples, the divergence of class centers, and the concentration of augmented data. The first two factors are inherent properties of the learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. Building on these theoretical insights, we investigate two canonical contrastive loss functions, InfoNCE and cross-correlation, to examine how they satisfy the first two factors. Moreover, we conduct a series of experiments to study the impact of the third factor on downstream performance, and observe a strong correlation between the concentration of augmented data and the resulting classification accuracy."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To achieve this goal, we introduce a novel (\u03c3, \u03b4)-measure to mathematically quantify the effects of data augmentation, and subsequently derive an upper bound on the downstream classification error rate based on this measure. Our analysis reveals that the generalization capabilities of contrastive self-supervised learning are influenced by three critical factors: the alignment of positive samples, the divergence of class centers, and the concentration of augmented data. The first two factors are inherent properties of the learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. Building on these theoretical insights, we investigate two canonical contrastive loss functions, InfoNCE and cross-correlation, to examine how they satisfy the first two factors. Moreover, we conduct a series of experiments to study the impact of the third factor on downstream performance, and observe a strong correlation between the concentration of augmented data and the resulting classification accuracy."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To achieve this goal, we introduce a novel (\u03c3, \u03b4)-measure to mathematically quantify the effects of data augmentation, and subsequently derive an upper bound on the downstream classification error rate based on this measure. Our analysis reveals that the generalization capabilities of contrastive self-supervised learning are influenced by three critical factors: the alignment of positive samples, the divergence of class centers, and the concentration of augmented data. The first two factors are inherent properties of the learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. Building on these theoretical insights, we investigate two canonical contrastive loss functions, InfoNCE and cross-correlation, to examine how they satisfy the first two factors. Moreover, we conduct a series of experiments to study the impact of the third factor on downstream performance, and observe a strong correlation between the concentration of augmented data and the resulting classification accuracy."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To achieve this goal, we introduce a novel (\u03c3, \u03b4)-measure to mathematically quantify the effects of data augmentation, and subsequently derive an upper bound on the downstream classification error rate based on this measure. Our analysis reveals that the generalization capabilities of contrastive self-supervised learning are influenced by three critical factors: the alignment of positive samples, the divergence of class centers, and the concentration of augmented data. The first two factors are inherent properties of the learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. Building on these theoretical insights, we investigate two canonical contrastive loss functions, InfoNCE and cross-correlation, to examine how they satisfy the first two factors. Moreover, we conduct a series of experiments to study the impact of the third factor on downstream performance, and observe a strong correlation between the concentration of augmented data and the resulting classification accuracy."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To achieve this goal, we introduce a novel (\u03c3, \u03b4)-measure to mathematically quantify the effects of data augmentation, and subsequently derive an upper bound on the downstream classification error rate based on this measure. Our analysis reveals that the generalization capabilities of contrastive self-supervised learning are influenced by three critical factors: the alignment of positive samples, the divergence of class centers, and the concentration of augmented data. The first two factors are inherent properties of the learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. Building on these theoretical insights, we investigate two canonical contrastive loss functions, InfoNCE and cross-correlation, to examine how they satisfy the first two factors. Moreover, we conduct a series of experiments to study the impact of the third factor on downstream performance, and observe a strong correlation between the concentration of augmented data and the resulting classification accuracy."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To achieve this goal, we introduce a novel (\u03c3, \u03b4)-measure to mathematically quantify the effects of data augmentation, and subsequently derive an upper bound on the downstream classification error rate based on this measure. Our analysis reveals that the generalization capabilities of contrastive self-supervised learning are influenced by three critical factors: the alignment of positive samples, the divergence of class centers, and the concentration of augmented data. The first two factors are inherent properties of the learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. Building on these theoretical insights, we investigate two canonical contrastive loss functions, InfoNCE and cross-correlation, to examine how they satisfy the first two factors. Moreover, we conduct a series of experiments to study the impact of the third factor on downstream performance, and observe a strong correlation between the concentration of augmented data and the resulting classification accuracy."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "instruction": "Use accurate words.", "revised_paragraph": "Revised paragraph: To achieve this goal, we introduce a novel (\u03c3, \u03b4)-measure to mathematically quantify the data augmentation process and establish an upper bound on the downstream classification error rate based on this measure. Our analysis reveals that the generalization ability of contrastive self-supervised learning is influenced by three crucial factors: the alignment of positive samples, the divergence of class centers, and the concentration of augmented data. The first two factors are inherent properties of the learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. Building on these theoretical insights, we subsequently investigate two canonical contrastive losses, InfoNCE and cross-correlation, to examine how they satisfy the first two factors. Moreover, we conduct a range of experiments to study the impact of the third factor on downstream performance, finding a strong correlation between the concentration of augmented data and the achieved results.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.00", "instruction": "Make the second half of this paragraph more precise and direct.", "revised_paragraph": "Revised paragraph: \"To mathematically quantify data augmentation, we introduce a (\u03c3, \u03b4)-measure, which enables us to establish an upper bound on the downstream classification error rate. Our analysis reveals that the generalization ability of contrastive self-supervised learning is influenced by three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are inherent properties of learned representations, whereas the third factor is determined by the pre-defined data augmentation strategy. We then investigate two canonical contrastive losses, InfoNCE and cross-correlation, to examine their alignment with the first two factors. Experimental results further confirm the significance of the third factor, demonstrating a strong correlation between the concentration of augmented data and downstream performance.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Anomaly detection in images is evaluated on MVTec-AD using EfficientNet-b4. The model processes 224 \u00d7 224 images, resizing feature maps from stage-1 to stage-4 (24, 32, 56, and 160 channels) to a 272-channel feature map. AdamW optimizer with weight decay 1 \u00d7 10 \u2212 4 is used for training, with a batch size of 64 and learning rate 1 \u00d7 10 \u2212 4 (dropping by 0.1 after 800 epochs). The model is trained for 1000 epochs on 8 GPUs with 5 random seeds."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Anomaly detection in images is evaluated on MVTec-AD using EfficientNet-b4. The model processes 224 \u00d7 224 images, resizing feature maps from stage-1 to stage-4 (24, 32, 56, and 160 channels) to a 272-channel feature map. AdamW optimizer with weight decay 1 \u00d7 10 \u2212 4 is used for training, with a batch size of 64 and learning rate 1 \u00d7 10 \u2212 4 (dropping by 0.1 after 800 epochs). The model is trained for 1000 epochs on 8 GPUs with 5 random seeds."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Anomaly detection in images is evaluated on MVTec-AD using EfficientNet-b4. The model processes 224 \u00d7 224 images, resizing feature maps from stage-1 to stage-4 (24, 32, 56, and 160 channels) to a 272-channel feature map. AdamW optimizer with weight decay 1 \u00d7 10 \u2212 4 is used for training, with a batch size of 64 and learning rate 1 \u00d7 10 \u2212 4 (dropping by 0.1 after 800 epochs). The model is trained for 1000 epochs on 8 GPUs with 5 random seeds."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Anomaly detection in images is evaluated on MVTec-AD using EfficientNet-b4. The model processes 224 \u00d7 224 images, resizing feature maps from stage-1 to stage-4 (24, 32, 56, and 160 channels) to a 272-channel feature map. AdamW optimizer with weight decay 1 \u00d7 10 \u2212 4 is used for training, with a batch size of 64 and learning rate 1 \u00d7 10 \u2212 4 (dropping by 0.1 after 800 epochs). The model is trained for 1000 epochs on 8 GPUs with 5 random seeds."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Anomaly detection in images is evaluated on MVTec-AD using EfficientNet-b4. The model processes 224 \u00d7 224 images, resizing feature maps from stage-1 to stage-4 (24, 32, 56, and 160 channels) to a 272-channel feature map. AdamW optimizer with weight decay 1 \u00d7 10 \u2212 4 is used for training, with a batch size of 64 and learning rate 1 \u00d7 10 \u2212 4 (dropping by 0.1 after 800 epochs). The model is trained for 1000 epochs on 8 GPUs with 5 random seeds."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Anomaly detection in images is evaluated on MVTec-AD using EfficientNet-b4. The model processes 224 \u00d7 224 images, resizing feature maps from stage-1 to stage-4 (24, 32, 56, and 160 channels) to a 272-channel feature map. AdamW optimizer with weight decay 1 \u00d7 10 \u2212 4 is used for training, with a batch size of 64 and learning rate 1 \u00d7 10 \u2212 4 (dropping by 0.1 after 800 epochs). The model is trained for 1000 epochs on 8 GPUs with 5 random seeds."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Anomaly detection in images is evaluated on MVTec-AD using EfficientNet-b4. The model processes 224 \u00d7 224 images, resizing feature maps from stage-1 to stage-4 (24, 32, 56, and 160 channels) to a 272-channel feature map. AdamW optimizer with weight decay 1 \u00d7 10 \u2212 4 is used for training, with a batch size of 64 and learning rate 1 \u00d7 10 \u2212 4 (dropping by 0.1 after 800 epochs). The model is trained for 1000 epochs on 8 GPUs with 5 random seeds."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Anomaly detection in images is evaluated on MVTec-AD using EfficientNet-b4. The model processes 224 \u00d7 224 images, resizing feature maps from stage-1 to stage-4 (24, 32, 56, and 160 channels) to a 272-channel feature map. AdamW optimizer with weight decay 1 \u00d7 10 \u2212 4 is used for training, with a batch size of 64 and learning rate 1 \u00d7 10 \u2212 4 (dropping by 0.1 after 800 epochs). The model is trained for 1000 epochs on 8 GPUs with 5 random seeds."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "instruction": "Remove some details on model training to make the paragraph more concise.", "revised_paragraph": "Revised paragraph: Anomaly detection is evaluated on MVTec-AD [3] with images resized to 224 \u00d7 224. The feature maps from EfficientNet-b4 [37] are concatenated and resized, resulting in a 272-channel feature map. The model is trained using AdamW optimizer [18] with weight decay 1 \u00d7 10 \u2212 4 for 1000 epochs on 8 GPUs with a batch size of 64. The learning rate is initially set to 1 \u00d7 10 \u2212 4 and dropped by 0.1 after 800 epochs.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "33RNh69fYq.kMvWVl725x.02", "instruction": "Remove unnecessary details to shorten this paragraph.", "revised_paragraph": "Revised paragraph: Anomaly detection is evaluated on MVTec-AD using EfficientNet-b4, with feature maps from stages 1-4 concatenated and resized to a 272-channel feature map. The model is trained for 1000 epochs with AdamW optimizer, weight decay 1e-4, and a batch size of 64 on 8 GPUs. The learning rate is initially 1e-4, dropping by 0.1 after 800 epochs.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Semantic co-occurrence is characterized by the union of object classes in each image, which can be used to group and separate pixels. By leveraging this context, we can impose global regularization in the latent feature space, even without label locations, ensuring that pixel-wise feature embeddings are separated from those of non-overlapping object categories."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Semantic co-occurrence plays a crucial role in characterizing the relationships between different objects, enabling the grouping and separation of pixels. We define semantic context as the collective union of object classes within each image. Notably, even without explicit label information, semantic context can be leveraged to impose global regularization in the latent feature space, ensuring that pixel-wise feature embeddings are distinct from those of pixels from images featuring non-overlapping object categories.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Semantic co-occurrence is characterized by the union of object classes in each image, which can be used to group and separate pixels. By leveraging this context, we can impose global regularization in the latent feature space, even without label locations, ensuring that pixel-wise feature embeddings are separated from those of non-overlapping object categories."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Semantic co-occurrence is characterized by the union of object classes in each image, which can be used to group and separate pixels. By leveraging this context, we can impose global regularization in the latent feature space, even without label locations, ensuring that pixel-wise feature embeddings are separated from those of non-overlapping object categories."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Semantic co-occurrence plays a crucial role in characterizing the relationships between different objects, enabling the grouping and separation of pixels. We define semantic context as the collective union of object classes within each image. Notably, even without explicit label information, semantic context can be leveraged to impose global regularization in the latent feature space, ensuring that pixel-wise feature embeddings are distinct from those of pixels from images featuring non-overlapping object categories.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Semantic co-occurrence is characterized by the union of object classes in each image, which can be used to group and separate pixels. By leveraging this context, we can impose global regularization in the latent feature space, even without label locations, ensuring that pixel-wise feature embeddings are separated from those of non-overlapping object categories."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Semantic co-occurrence is characterized by the union of object classes in each image, which can be used to group and separate pixels. By leveraging this context, we can impose global regularization in the latent feature space, even without label locations, ensuring that pixel-wise feature embeddings are separated from those of non-overlapping object categories."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Semantic co-occurrence is defined by the combination of object classes within each image, enabling the grouping and separation of pixels. By exploiting this contextual information, we can introduce global regularization in the latent feature space, even without the need for labeled locations, thereby ensuring that pixel-wise feature embeddings are distinct from those of non-overlapping object categories."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Semantic co-occurrence is characterized by the union of object classes in each image, which can be used to group and separate pixels. By leveraging this context, we can impose global regularization in the latent feature space, even without label locations, ensuring that pixel-wise feature embeddings are separated from those of non-overlapping object categories."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Semantic co-occurrence is characterized by the union of object classes in each image, which can be used to group and separate pixels. By leveraging this context, we can impose global regularization in the latent feature space, even without label locations, ensuring that pixel-wise feature embeddings are separated from those of non-overlapping object categories."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Semantic co-occurrence plays a crucial role in characterizing the relationships between different objects, enabling the grouping and separation of pixels. We define semantic context as the collective union of object classes within each image. Notably, even without explicit label information, semantic context can be leveraged to impose global regularization in the latent feature space, ensuring that pixel-wise feature embeddings are distinct from those of pixels from images featuring non-overlapping object categories.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Semantic co-occurrence is essential for characterizing object relationships, facilitating pixel grouping and separation. We define semantic context as the collective object classes within an image. This context can be leveraged to impose global regularization in the latent feature space, even without explicit labels, ensuring distinct feature embeddings for pixels from non-overlapping object categories.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "instruction": "Rewrite this paragraph to be more concise.", "revised_paragraph": "Revised paragraph: \"Semantic co-occurrence, defined as the union of object classes in each image, enables grouping and separating pixels without requiring label locations. This context can impose global regularization in the latent feature space, ensuring that pixel-wise feature embeddings are distinct from those of non-overlapping object categories.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.09", "instruction": "Split the last sentence and make it slightly shorter. Improve the english.", "revised_paragraph": "Revised paragraph: Semantic co-occurrence is characterized by the context in which different objects appear together. We define semantic context as the union of object classes within an image. This context can be leveraged to impose global regularization in the latent feature space, even without knowing the exact location of labels. The pixel-wise feature embedding should be separated from pixels in images without overlapping object categories, promoting distinct representations.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally evaluate the impact of hierarchical modules on our Point-M2AE framework by removing each component individually. Specifically, we replace the encoder and decoder with 1-stage plain architectures similar to MAE. Our results show that the absence of multi-stage structures in either the encoder or decoder hurts performance, while the hierarchical encoder plays a more critical role than the decoder. Additionally, skip connections and local spatial self-attention layers provide complementary information and local inductive bias, benefiting the network.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Hierarchical Modules. As demonstrated in Table 7, we conduct an ablation study on our Point-M2AE framework by removing each component in turn. Specifically, we replace the hierarchical encoder and decoder with 1-stage plain architectures similar to MAE, comprising 15 and 2 blocks of vanilla self-attention layers, respectively. The results indicate that the absence of multi-stage structures in either the encoder or decoder significantly impairs performance. Notably, the hierarchical encoder has a more pronounced impact than the decoder. Furthermore, the skip connections and local spatial self-attention layers contribute positively to the network by providing complementary information and local inductive bias.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally evaluate the impact of hierarchical modules on our Point-M2AE framework by removing each component individually. Specifically, we replace the encoder and decoder with 1-stage plain architectures similar to MAE. Our results show that the absence of multi-stage structures in either the encoder or decoder hurts performance, while the hierarchical encoder plays a more critical role than the decoder. Additionally, skip connections and local spatial self-attention layers provide complementary information and local inductive bias, benefiting the network.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Hierarchical Modules. As demonstrated in Table 7, we conduct an ablation study on our Point-M2AE framework by removing each component in turn. Specifically, we replace the hierarchical encoder and decoder with 1-stage plain architectures similar to MAE, comprising 15 and 2 blocks of vanilla self-attention layers, respectively. The results indicate that the absence of multi-stage structures in either the encoder or decoder significantly impairs performance. Notably, the hierarchical encoder has a more pronounced impact than the decoder. Furthermore, the skip connections and local spatial self-attention layers contribute positively to the network by providing complementary information and local inductive bias.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally evaluate the impact of hierarchical modules on our Point-M2AE framework by removing each component individually. Specifically, we replace the encoder and decoder with 1-stage plain architectures similar to MAE. Our results show that the absence of multi-stage structures in either the encoder or decoder hurts performance, while the hierarchical encoder plays a more critical role than the decoder. Additionally, skip connections and local spatial self-attention layers provide complementary information and local inductive bias, benefiting the network.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally evaluate the impact of hierarchical modules on our Point-M2AE framework by removing each component individually. Specifically, we replace the encoder and decoder with 1-stage plain architectures similar to MAE. Our results show that the absence of multi-stage structures in either the encoder or decoder hurts performance, while the hierarchical encoder plays a more critical role than the decoder. Additionally, skip connections and local spatial self-attention layers provide complementary information and local inductive bias, benefiting the network.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally evaluate the impact of hierarchical modules on our Point-M2AE framework by removing each component individually. Specifically, we replace the encoder and decoder with 1-stage plain architectures similar to MAE. Our results show that the absence of multi-stage structures in either the encoder or decoder hurts performance, while the hierarchical encoder plays a more critical role than the decoder. Additionally, skip connections and local spatial self-attention layers provide complementary information and local inductive bias, benefiting the network.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We investigate the effects of hierarchical modules on our Point-M2AE framework by individually removing each component and replacing it with a 1-stage plain architecture similar to MAE. Our results demonstrate that the absence of multi-stage structures in either the encoder or decoder significantly impairs performance, with the hierarchical encoder exerting a more substantial influence than the decoder. Furthermore, the incorporation of skip connections and local spatial self-attention layers provides complementary information and local inductive bias, thereby enhancing the network's performance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally evaluate the impact of hierarchical modules on our Point-M2AE framework by removing each component individually. Specifically, we replace the encoder and decoder with 1-stage plain architectures similar to MAE. Our results show that the absence of multi-stage structures in either the encoder or decoder hurts performance, while the hierarchical encoder plays a more critical role than the decoder. Additionally, skip connections and local spatial self-attention layers provide complementary information and local inductive bias, benefiting the network.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Hierarchical Modules. As demonstrated in Table 7, we conduct an ablation study on our Point-M2AE framework by removing each component in turn. Specifically, we replace the hierarchical encoder and decoder with 1-stage plain architectures similar to MAE, comprising 15 and 2 blocks of vanilla self-attention layers, respectively. The results indicate that the absence of multi-stage structures in either the encoder or decoder significantly impairs performance. Notably, the hierarchical encoder has a more pronounced impact than the decoder. Furthermore, the skip connections and local spatial self-attention layers contribute positively to the network by providing complementary information and local inductive bias.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We conduct an ablation study on our Point-M2AE framework, removing each component in turn. Results show that the absence of hierarchical structures in either the encoder or decoder significantly impairs performance, with the hierarchical encoder having a more pronounced impact. Skip connections and local spatial self-attention layers also contribute positively, providing complementary information and local inductive bias.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We experimentally evaluate the impact of hierarchical modules on our Point-M2AE framework by removing each component individually. Specifically, we replace the encoder and decoder with 1-stage plain architectures similar to MAE. Our results show that the absence of multi-stage structures in either the encoder or decoder hurts performance, while the hierarchical encoder plays a more critical role than the decoder. Additionally, skip connections and local spatial self-attention layers provide complementary information and local inductive bias, benefiting the network.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "instruction": "Rewrite the last sentence to make it more concise.", "revised_paragraph": "Revised paragraph: Hierarchical Modules. As reported in Table 7, we experimentally remove individual components from our Point-M2AE framework, replacing them with 1-stage plain architectures similar to MAE. Results show that the absence of multi-stage structures hurts performance, with the hierarchical encoder playing a more critical role than the decoder.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "Sx6SnclSL.nQLOUHvx8n.04", "instruction": "Make the paragraph shorter.", "revised_paragraph": "Revised paragraph: Hierarchical Modules. We experimentally evaluate the importance of each component in our Point-M2AE framework by removing modules one by one. Specifically, we replace the encoder and decoder with 1-stage plain architectures similar to MAE. Our results show that the absence of multi-stage structures hurts performance, and the hierarchical encoder plays a more critical role than the decoder. Additionally, skip connections and local spatial self-attention layers provide complementary information and local inductive bias, benefiting the network.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We investigate the impact of activation functions on PINNs for solving PDE/ODE systems, evaluating and comparing the effectiveness of several common functions on simple problems with analytical solutions. Our results show that activation function choice is crucial and problem-dependent, leading us to propose learning specialized functions for different PDE systems.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We investigate the impact of activation functions on PINNs for solving PDE/ODE systems, evaluating and comparing the effectiveness of several common functions on simple problems with analytical solutions. Our results show that activation function choice is crucial and problem-dependent, leading us to propose learning specialized functions for different PDE systems.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We investigate the impact of activation functions on PINNs for solving PDE/ODE systems, evaluating and comparing the effectiveness of several common functions on simple problems with analytical solutions. Our results show that activation function choice is crucial and problem-dependent, leading us to propose learning specialized functions for different PDE systems.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We investigate the impact of activation functions on PINNs for solving PDE/ODE systems, evaluating and comparing the effectiveness of several common functions on simple problems with analytical solutions. Our results show that activation function choice is crucial and problem-dependent, leading us to propose learning specialized functions for different PDE systems.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We investigate the impact of activation functions on PINNs for solving PDE/ODE systems, evaluating and comparing the effectiveness of several common functions on simple problems with analytical solutions. Our results show that activation function choice is crucial and problem-dependent, leading us to propose learning specialized functions for different PDE systems.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We investigate the impact of activation functions on PINNs for solving PDE/ODE systems, evaluating and comparing the effectiveness of several common functions on simple problems with analytical solutions. Our results show that activation function choice is crucial and problem-dependent, leading us to propose learning specialized functions for different PDE systems.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We investigate the impact of activation functions on PINNs for solving PDE/ODE systems, evaluating and comparing the effectiveness of several common functions on simple problems with analytical solutions. Our results show that activation function choice is crucial and problem-dependent, leading us to propose learning specialized functions for different PDE systems.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We investigate the impact of activation functions on PINNs for solving PDE/ODE systems, evaluating and comparing the effectiveness of several common functions on simple problems with analytical solutions. Our results show that activation function choice is crucial and problem-dependent, leading us to propose learning specialized functions for different PDE systems.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "instruction": "Remove the second sentence", "revised_paragraph": "Revised paragraph: The results show that the choice of activation functions is crucial for PINNs and depends on the problem. Motivated by this observation, we propose to learn specialized activation function for different PDE systems.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "NvI7ejSHFe.ppieLd2M4a.01", "instruction": "Remove unnecessary details to make this paragraph shorter.", "revised_paragraph": "Revised paragraph: \"We investigate the influence of activation functions in Physics-Informed Neural Networks (PINNs) for solving PDE/ODE systems. We compare the effectiveness of various activation functions on simple problems with analytical solutions, demonstrating that the choice of activation function is crucial and problem-dependent. This motivates the proposal of learning specialized activation functions for different PDE systems.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: MIMO's experiments are based on the Uncertainty Baselines framework, which enables us to evaluate and compare the performance of our methods against high-quality, well-optimized implementations of baseline techniques. Specifically, we examined three model-dataset combinations: ResNet28-10 with CIFAR10, ResNet28-10 with CIFAR100, and ResNet50 with ImageNet. Our code will be made publicly available."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: MIMO's experiments are based on the Uncertainty Baselines framework, which enables us to evaluate and compare the performance of our methods against high-quality, well-optimized implementations of baseline techniques. Specifically, we examined three model-dataset combinations: ResNet28-10 with CIFAR10, ResNet28-10 with CIFAR100, and ResNet50 with ImageNet. Our code will be made publicly available."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: MIMO's experiments are based on the Uncertainty Baselines framework, which enables us to evaluate and compare the performance of our methods against high-quality, well-optimized implementations of baseline techniques. Specifically, we examined three model-dataset combinations: ResNet28-10 with CIFAR10, ResNet28-10 with CIFAR100, and ResNet50 with ImageNet. Our code will be made publicly available."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: MIMO's experiments are based on the Uncertainty Baselines framework, which enables us to evaluate and compare the performance of our methods against high-quality, well-optimized implementations of baseline techniques. Specifically, we examined three model-dataset combinations: ResNet28-10 with CIFAR10, ResNet28-10 with CIFAR100, and ResNet50 with ImageNet. Our code will be made publicly available."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: MIMO's experiments are based on the Uncertainty Baselines framework, which enables us to evaluate and compare the performance of our methods against high-quality, well-optimized implementations of baseline techniques. Specifically, we examined three model-dataset combinations: ResNet28-10 with CIFAR10, ResNet28-10 with CIFAR100, and ResNet50 with ImageNet. Our code will be made publicly available."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: MIMO's experiments are based on the Uncertainty Baselines framework, which enables us to evaluate and compare the performance of our methods against high-quality, well-optimized implementations of baseline techniques. Specifically, we examined three model-dataset combinations: ResNet28-10 with CIFAR10, ResNet28-10 with CIFAR100, and ResNet50 with ImageNet. Our code will be made publicly available."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: MIMO's experiments are based on the Uncertainty Baselines framework, which enables us to evaluate and compare the performance of our methods against high-quality, well-optimized implementations of baseline techniques. Specifically, we examined three model-dataset combinations: ResNet28-10 with CIFAR10, ResNet28-10 with CIFAR100, and ResNet50 with ImageNet. Our code will be made publicly available."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: MIMO's experiments are based on the Uncertainty Baselines framework, which enables us to evaluate and compare the performance of our methods against high-quality, well-optimized implementations of baseline techniques. Specifically, we examined three model-dataset combinations: ResNet28-10 with CIFAR10, ResNet28-10 with CIFAR100, and ResNet50 with ImageNet. Our code will be made publicly available."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "instruction": "Rewrite the first sentence to also explain the structure of the section.", "revised_paragraph": "Revised paragraph: This section provides an overview of the experiments conducted by MIMO, which are built upon the Uncertainty Baselines framework. This framework enables us to benchmark the performance and compare against high-quality, well-optimized implementations of baseline methods, as outlined in the framework (additional baselines are available for further reference). The experiments involve three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. Finally, the MIMO code will be open-sourced for further exploration and replication.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "instruction": "Rewrite the first sentence to better introduce the section.", "revised_paragraph": "Revised paragraph: This section presents the experimental results of MIMO, which leverages the Uncertainty Baselines framework to evaluate its performance and compare it against high-quality, well-optimized implementations of baseline methods. The framework provides a comprehensive benchmarking platform, allowing for the comparison of various approaches. In this study, we examined three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. Additionally, the MIMO code will be made publicly available to facilitate further research and development.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: To mitigate the burden of data labeling, we focus on improving data efficiency for both classification and regression in deep learning. While most attention has been paid to classification, we note that regression often requires more human effort for labeling due to its continuous label space. We found that existing data-efficient methods in deep learning either encourage invariance to data stochasticity or model stochasticity. To leverage the benefits of both, we propose a novel \u03c7 -model that simultaneously encourages invariance to data and model stochasticity. Extensive experiments demonstrate the superiority of the \u03c7 -model across various tasks, including age estimation, keypoint localization, and multi-category object recognition."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: To mitigate the burden of data labeling, we focus on improving data efficiency for both classification and regression in deep learning. While most attention has been paid to classification, we note that regression often requires more human effort for labeling due to its continuous label space. We found that existing data-efficient methods in deep learning either encourage invariance to data stochasticity or model stochasticity. To leverage the benefits of both, we propose a novel \u03c7 -model that simultaneously encourages invariance to data and model stochasticity. Extensive experiments demonstrate the superiority of the \u03c7 -model across various tasks, including age estimation, keypoint localization, and multi-category object recognition."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: To mitigate the burden of data labeling, we focus on improving data efficiency for both classification and regression in deep learning. While most attention has been paid to classification, we note that regression often requires more human effort for labeling due to its continuous label space. We found that existing data-efficient methods in deep learning either encourage invariance to data stochasticity or model stochasticity. To leverage the benefits of both, we propose a novel \u03c7 -model that simultaneously encourages invariance to data and model stochasticity. Extensive experiments demonstrate the superiority of the \u03c7 -model across various tasks, including age estimation, keypoint localization, and multi-category object recognition."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: To mitigate the burden of data labeling, we focus on improving data efficiency for both classification and regression in deep learning. While most attention has been paid to classification, we note that regression often requires more human effort for labeling due to its continuous label space. We found that existing data-efficient methods in deep learning either encourage invariance to data stochasticity or model stochasticity. To leverage the benefits of both, we propose a novel \u03c7 -model that simultaneously encourages invariance to data and model stochasticity. Extensive experiments demonstrate the superiority of the \u03c7 -model across various tasks, including age estimation, keypoint localization, and multi-category object recognition."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: To mitigate the burden of data labeling, we focus on improving data efficiency for both classification and regression in deep learning. While most attention has been paid to classification, we note that regression often requires more human effort for labeling due to its continuous label space. We found that existing data-efficient methods in deep learning either encourage invariance to data stochasticity or model stochasticity. To leverage the benefits of both, we propose a novel \u03c7 -model that simultaneously encourages invariance to data and model stochasticity. Extensive experiments demonstrate the superiority of the \u03c7 -model across various tasks, including age estimation, keypoint localization, and multi-category object recognition."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: To mitigate the burden of data labeling, we focus on improving data efficiency for both classification and regression in deep learning. While most attention has been paid to classification, we note that regression often requires more human effort for labeling due to its continuous label space. We found that existing data-efficient methods in deep learning either encourage invariance to data stochasticity or model stochasticity. To leverage the benefits of both, we propose a novel \u03c7 -model that simultaneously encourages invariance to data and model stochasticity. Extensive experiments demonstrate the superiority of the \u03c7 -model across various tasks, including age estimation, keypoint localization, and multi-category object recognition."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: To mitigate the burden of data labeling, we focus on improving data efficiency for both classification and regression in deep learning. While most attention has been paid to classification, we note that regression often requires more human effort for labeling due to its continuous label space. We found that existing data-efficient methods in deep learning either encourage invariance to data stochasticity or model stochasticity. To leverage the benefits of both, we propose a novel \u03c7 -model that simultaneously encourages invariance to data and model stochasticity. Extensive experiments demonstrate the superiority of the \u03c7 -model across various tasks, including age estimation, keypoint localization, and multi-category object recognition."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: To mitigate the burden of data labeling, we focus on improving data efficiency for both classification and regression in deep learning. While most attention has been paid to classification, we note that regression often requires more human effort for labeling due to its continuous label space. We found that existing data-efficient methods in deep learning either encourage invariance to data stochasticity or model stochasticity. To leverage the benefits of both, we propose a novel \u03c7 -model that simultaneously encourages invariance to data and model stochasticity. Extensive experiments demonstrate the superiority of the \u03c7 -model across various tasks, including age estimation, keypoint localization, and multi-category object recognition."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "instruction": "Remove the second-to-last sentence.", "revised_paragraph": "Revised paragraph: \"To mitigate the burden of data labeling, we aim at improving data ef\ufb01ciency for both classi\ufb01cation and regression setups in deep learning. However, the current focus is on classi\ufb01cation problems while rare attention has been paid to deep regression, which usually requires more human effort to labeling. Further, due to the intrinsic difference between categorical and continuous label space, the common intuitions for classi\ufb01cation, e.g. cluster assumptions or pseudo labeling strategies, cannot be naturally adapted into deep regression. To this end, we propose a novel \u03c7 -model by simultaneously encouraging the invariance to data stochasticity and model stochasticity. Extensive experiments verify the superiority of the \u03c7 -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "vokZIVWUXN.zMdXRtaisu.00", "instruction": "Delete the sentence about the minmax game.", "revised_paragraph": "Revised paragraph: \"To mitigate the burden of data labeling, we aim at improving data ef\ufb01ciency for both classi\ufb01cation and regression setups in deep learning. However, the current focus is on classi\ufb01cation problems while rare attention has been paid to deep regression, which usually requires more human effort to labeling. Further, due to the intrinsic difference between categorical and continuous label space, the common intuitions for classi\ufb01cation, e.g. cluster assumptions or pseudo labeling strategies, cannot be naturally adapted into deep regression. To this end, we \ufb01rst delved into the existing data-ef\ufb01cient methods in deep learning and found that they either encourage invariance to data stochasticity (e.g., consistency regularization under different augmentations) or model stochasticity (e.g., difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel \u03c7 -model by simultaneously encouraging the invariance to data stochasticity and model stochasticity. Extensive experiments verify the superiority of the \u03c7 -model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nOur study demonstrates that the implicit curriculum, where examples are learned in a consistent order, is robust across different runs, training methods, and architectures. However, we show that this order can be altered by changing the presentation order during training. Furthermore, we establish that well-known notions of sample difficulty are highly correlated. In the standard setting, curriculum learning, random, and anti-curriculum learning perform similarly, and removing examples from the training set does not improve performance. In contrast, curriculum learning outperforms standard training when training time is limited or in noisy regimes, where label noise is introduced."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We demonstrate that the order in which examples are learned is consistent across runs, training methods, and architectures, and that this order can be changed by presenting examples in a different order during training. Furthermore, we show that well-known notions of sample difficulty are highly correlated with each other. In the standard setting, curriculum learning, random, and anti-curriculum learning perform almost equally well, and removing examples from the training set does not improve performance. However, when training time is limited or in noisy regimes, curriculum learning has a clear advantage over standard training, as demonstrated by our experiments."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We demonstrate that the order in which examples are learned is consistent across runs, training methods, and architectures, and that this order can be changed by presenting examples in a different order during training. Furthermore, we show that well-known notions of sample difficulty are highly correlated with each other. In the standard setting, curriculum learning, random, and anti-curriculum learning perform almost equally well, and removing examples from the training set does not improve performance. However, when training time is limited or in noisy regimes, curriculum learning has a clear advantage over standard training, as demonstrated by our experiments."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nOur study demonstrates that the implicit curriculum, where examples are learned in a consistent order, is robust across different runs, training methods, and architectures. However, we show that this order can be altered by changing the presentation order during training. Furthermore, we establish that well-known notions of sample difficulty are highly correlated. In the standard setting, curriculum learning, random, and anti-curriculum learning perform similarly, and removing examples from the training set does not improve performance. In contrast, curriculum learning outperforms standard training when training time is limited or in noisy regimes, where label noise is introduced."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We demonstrate that the order in which examples are learned is consistent across runs, training methods, and architectures, and that this order can be changed by presenting examples in a different order during training. Furthermore, we show that well-known notions of sample difficulty are highly correlated with each other. In the standard setting, curriculum learning, random, and anti-curriculum learning perform almost equally well, and removing examples from the training set does not improve performance. However, when training time is limited or in noisy regimes, curriculum learning has a clear advantage over standard training, as demonstrated by our experiments."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We demonstrate that the order in which examples are learned is consistent across runs, training methods, and architectures, and that this order can be changed by presenting examples in a different order during training. Furthermore, we show that well-known notions of sample difficulty are highly correlated with each other. In the standard setting, curriculum learning, random, and anti-curriculum learning perform almost equally well, and removing examples from the training set does not improve performance. However, when training time is limited or in noisy regimes, curriculum learning has a clear advantage over standard training, as demonstrated by our experiments."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nOur study demonstrates that the implicit curriculum, where examples are learned in a consistent order, is robust across different runs, training methods, and architectures. However, we show that this order can be altered by changing the presentation order during training. Furthermore, we establish that well-known notions of sample difficulty are highly correlated. In the standard setting, curriculum learning, random, and anti-curriculum learning perform similarly, and removing examples from the training set does not improve performance. In contrast, curriculum learning outperforms standard training when training time is limited or in noisy regimes, where label noise is introduced."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our study shows that the implicit curriculum is robust across different runs, training methods, and architectures. However, we found that altering the presentation order during training can change this order. Notably, we observed that well-known notions of sample difficulty are highly correlated. Our results also indicate that curriculum learning outperforms standard training in limited training time or noisy regimes, but performs similarly to other methods in the standard setting."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We demonstrate that the order in which examples are learned is consistent across runs, training methods, and architectures, and that this order can be changed by presenting examples in a different order during training. Furthermore, we show that well-known notions of sample difficulty are highly correlated with each other. In the standard setting, curriculum learning, random, and anti-curriculum learning perform almost equally well, and removing examples from the training set does not improve performance. However, when training time is limited or in noisy regimes, curriculum learning has a clear advantage over standard training, as demonstrated by our experiments."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nOur study demonstrates that the implicit curriculum, where examples are learned in a consistent order, is robust across different runs, training methods, and architectures. However, we show that this order can be altered by changing the presentation order during training. Furthermore, we establish that well-known notions of sample difficulty are highly correlated. In the standard setting, curriculum learning, random, and anti-curriculum learning perform similarly, and removing examples from the training set does not improve performance. In contrast, curriculum learning outperforms standard training when training time is limited or in noisy regimes, where label noise is introduced."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Our study shows that the implicit curriculum is robust across different runs, training methods, and architectures. However, we found that altering the presentation order during training can change this order. Notably, we observed that well-known notions of sample difficulty are highly correlated. Our results also indicate that curriculum learning outperforms standard training in limited training time or noisy regimes, but performs similarly to other methods in the standard setting."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We demonstrate that the order in which examples are learned is consistent across runs, training methods, and architectures, and that this order can be changed by presenting examples in a different order during training. Furthermore, we show that well-known notions of sample difficulty are highly correlated with each other. In the standard setting, curriculum learning, random, and anti-curriculum learning perform almost equally well, and removing examples from the training set does not improve performance. However, when training time is limited or in noisy regimes, curriculum learning has a clear advantage over standard training, as demonstrated by our experiments."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "instruction": "Remove the less important details in the results.", "revised_paragraph": "Revised paragraph: \"Our results show that the order in which examples are learned plays a crucial role in the learning process. We demonstrate that the order is consistent across runs, training methods, and architectures, and can be modified by changing the presentation order during training. Furthermore, we find that well-known notions of sample difficulty are highly correlated with each other. While curriculum learning does not improve performance in the standard setting, it outperforms standard training when training time is limited and in noisy regimes, where label noise is introduced. These findings highlight the importance of considering the order of examples in machine learning.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7VIguXRv9h.yPdniQMisK.00", "instruction": "Remove unnecessary details.", "revised_paragraph": "Revised paragraph: We demonstrate that the implicit curriculum, where examples are learned in a consistent order, is robust across different runs, training methods, and architectures. Furthermore, we show that the order in which examples are presented during training can be changed to achieve different curricula. In contrast, our experiments reveal that curricula achieve almost no improvement in the standard setting, performing similarly to random and anti-curriculum learning. However, when training time is limited or in noisy regimes, curriculum learning outperforms standard training, providing a clear advantage.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The user model takes user information (concatenating attributes and interactions) and item embeddings as input. A single-layer GRU network followed by a 2-layer MLP extracts the user's compact state representation. The item embeddings are processed similarly, and the two embeddings are concatenated and fed into a 2-layer MLP to produce item scores, transformed by the sigmoid function to obtain individual click likelihoods."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The user model takes user information (concatenating attributes and interactions) and item embeddings as input. A single-layer GRU network followed by a 2-layer MLP extracts the user's compact state representation. The item embeddings are processed similarly, and the two embeddings are concatenated and fed into a 2-layer MLP to produce item scores, transformed by the sigmoid function to obtain individual click likelihoods."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The user model takes user information (concatenating attributes and interactions) and item embeddings as input. A single-layer GRU network followed by a 2-layer MLP extracts the user's compact state representation. The item embeddings are processed similarly, and the two embeddings are concatenated and fed into a 2-layer MLP to produce item scores, transformed by the sigmoid function to obtain individual click likelihoods."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The user model takes user information (concatenating attributes and interactions) and item embeddings as input. A single-layer GRU network followed by a 2-layer MLP extracts the user's compact state representation. The item embeddings are processed similarly, and the two embeddings are concatenated and fed into a 2-layer MLP to produce item scores, transformed by the sigmoid function to obtain individual click likelihoods."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The user model takes user information (concatenating attributes and interactions) and item embeddings as input. A single-layer GRU network followed by a 2-layer MLP extracts the user's compact state representation. The item embeddings are processed similarly, and the two embeddings are concatenated and fed into a 2-layer MLP to produce item scores, transformed by the sigmoid function to obtain individual click likelihoods."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The user model takes user information (concatenating attributes and interactions) and item embeddings as input. A single-layer GRU network followed by a 2-layer MLP extracts the user's compact state representation. The item embeddings are processed similarly, and the two embeddings are concatenated and fed into a 2-layer MLP to produce item scores, transformed by the sigmoid function to obtain individual click likelihoods."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The user model takes user information (concatenating attributes and interactions) and item embeddings as input. A single-layer GRU network followed by a 2-layer MLP extracts the user's compact state representation. The item embeddings are processed similarly, and the two embeddings are concatenated and fed into a 2-layer MLP to produce item scores, transformed by the sigmoid function to obtain individual click likelihoods."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The user model takes user information (concatenating attributes and interactions) and item embeddings as input. A single-layer GRU network followed by a 2-layer MLP extracts the user's compact state representation. The item embeddings are processed similarly, and the two embeddings are concatenated and fed into a 2-layer MLP to produce item scores, transformed by the sigmoid function to obtain individual click likelihoods."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "instruction": "Make the third sentence shorter and easier to understand", "revised_paragraph": "Revised paragraph: \"The user model takes as input user information and a set of item embeddings. It processes this information using a single-layer GRU followed by a 2-layer MLP to extract a compact state representation. The item embeddings are also processed by a separate GRU network, and then concatenated with the state representation and passed through a 2-layer MLP to produce item scores, which are transformed into individual click likelihoods using the sigmoid function.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.23", "instruction": "Simplify the convoluted sentences to make the paragraph more concise.", "revised_paragraph": "Revised paragraph: The user model takes user information, comprising a concatenation of attributes and interaction sequences, and a list of item embeddings as input. This information is processed by a single-layer GRU network followed by a 2-layer MLP to extract a compact state representation. The item embeddings are similarly processed using the same GRU architecture, but initialized differently. The final output is generated by concatenating the state and list embeddings and passing them through a 2-layer MLP, followed by the sigmoid function to produce individual click likelihood scores.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The lemma shows that activation functions with quickly decaying Hermite coefficients, such as \u03c9 \u03c3, lead to faster decay of NTK coefficients. While analyzing rates of decay for l \u2265 3 is challenging due to the complexity of the calculation, preliminary results in Appendix B illustrate how depth can lead to slower coefficient decay in specific settings."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The trend emerging from Lemma 3.2 is that activation functions with rapidly decaying Hermite coefficients, such as \u03c9\u03c3, lead to a faster decay of the NTK coefficients. Notably, the analysis of decay rates for l \u2265 3 is hindered by the complexity of calculating F(p, k, \u00af\u03b1l\u22121) (equation 4). In Appendix B, we present some preliminary findings that demonstrate how, in a specific scenario, increasing depth can result in slower coefficient decay. Furthermore, we show in Appendix B.4 that the zeroth coefficient strictly increases with depth. We pause briefly to highlight the potential for using a truncation of equation (5) to enable efficient numerical approximation of the infinite-width NTK.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The lemma shows that activation functions with quickly decaying Hermite coefficients, such as \u03c9 \u03c3, lead to faster decay of NTK coefficients. While analyzing rates of decay for l \u2265 3 is challenging due to the complexity of the calculation, preliminary results in Appendix B illustrate how depth can lead to slower coefficient decay in specific settings."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The trend emerging from Lemma 3.2 is that activation functions with rapidly decaying Hermite coefficients, such as \u03c9\u03c3, lead to a faster decay of the NTK coefficients. Notably, the analysis of decay rates for l \u2265 3 is hindered by the complexity of calculating F(p, k, \u00af\u03b1l\u22121) (equation 4). In Appendix B, we present some preliminary findings that demonstrate how, in a specific scenario, increasing depth can result in slower coefficient decay. Furthermore, we show in Appendix B.4 that the zeroth coefficient strictly increases with depth. We pause briefly to highlight the potential for using a truncation of equation (5) to enable efficient numerical approximation of the infinite-width NTK.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The lemma shows that activation functions with quickly decaying Hermite coefficients, such as \u03c9 \u03c3, lead to faster decay of NTK coefficients. While analyzing rates of decay for l \u2265 3 is challenging due to the complexity of the calculation, preliminary results in Appendix B illustrate how depth can lead to slower coefficient decay in specific settings."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The trend emerging from Lemma 3.2 is that activation functions with rapidly decaying Hermite coefficients, such as \u03c9\u03c3, lead to a faster decay of the NTK coefficients. Notably, the analysis of decay rates for l \u2265 3 is hindered by the complexity of calculating F(p, k, \u00af\u03b1l\u22121) (equation 4). In Appendix B, we present some preliminary findings that demonstrate how, in a specific scenario, increasing depth can result in slower coefficient decay. Furthermore, we show in Appendix B.4 that the zeroth coefficient strictly increases with depth. We pause briefly to highlight the potential for using a truncation of equation (5) to enable efficient numerical approximation of the infinite-width NTK.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The lemma shows that activation functions with quickly decaying Hermite coefficients, such as \u03c9 \u03c3, lead to faster decay of NTK coefficients. While analyzing rates of decay for l \u2265 3 is challenging due to the complexity of the calculation, preliminary results in Appendix B illustrate how depth can lead to slower coefficient decay in specific settings."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The trend emerging from Lemma 3.2 is that activation functions with rapidly decaying Hermite coefficients, such as \u03c9\u03c3, lead to a faster decay of the NTK coefficients. Notably, the analysis of decay rates for l \u2265 3 is hindered by the complexity of calculating F(p, k, \u00af\u03b1l\u22121) (equation 4). In Appendix B, we present some preliminary findings that demonstrate how, in a specific scenario, increasing depth can result in slower coefficient decay. Furthermore, we show in Appendix B.4 that the zeroth coefficient strictly increases with depth. We pause briefly to highlight the potential for using a truncation of equation (5) to enable efficient numerical approximation of the infinite-width NTK.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The lemma shows that activation functions with quickly decaying Hermite coefficients, such as \u03c9 \u03c3, lead to faster decay of NTK coefficients. While analyzing rates of decay for l \u2265 3 is challenging due to the complexity of the calculation, preliminary results in Appendix B illustrate how depth can lead to slower coefficient decay in specific settings."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The lemma reveals that activation functions with rapidly decaying Hermite coefficients, such as \u03c9\u03c3, exhibit faster decay of NTK coefficients. Although calculating decay rates for l \u2265 3 is computationally demanding due to the complexity of the calculation, preliminary results presented in Appendix B demonstrate how increasing depth can result in slower coefficient decay in specific scenarios."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The lemma shows that activation functions with quickly decaying Hermite coefficients, such as \u03c9 \u03c3, lead to faster decay of NTK coefficients. While analyzing rates of decay for l \u2265 3 is challenging due to the complexity of the calculation, preliminary results in Appendix B illustrate how depth can lead to slower coefficient decay in specific settings."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The lemma reveals that activation functions with rapidly decaying Hermite coefficients, such as \u03c9\u03c3, exhibit faster decay of NTK coefficients. Although calculating decay rates for l \u2265 3 is computationally demanding due to the complexity of the calculation, preliminary results presented in Appendix B demonstrate how increasing depth can result in slower coefficient decay in specific scenarios."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The lemma shows that activation functions with quickly decaying Hermite coefficients, such as \u03c9 \u03c3, lead to faster decay of NTK coefficients. While analyzing rates of decay for l \u2265 3 is challenging due to the complexity of the calculation, preliminary results in Appendix B illustrate how depth can lead to slower coefficient decay in specific settings."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The lemma reveals that activation functions with rapidly decaying Hermite coefficients, such as \u03c9\u03c3, exhibit faster decay of NTK coefficients. Although calculating decay rates for l \u2265 3 is computationally demanding due to the complexity of the calculation, preliminary results presented in Appendix B demonstrate how increasing depth can result in slower coefficient decay in specific scenarios."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The lemma shows that activation functions with quickly decaying Hermite coefficients, such as \u03c9 \u03c3, lead to faster decay of NTK coefficients. While analyzing rates of decay for l \u2265 3 is challenging due to the complexity of the calculation, preliminary results in Appendix B illustrate how depth can lead to slower coefficient decay in specific settings."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The lemma reveals that activation functions with rapidly decaying Hermite coefficients, such as \u03c9\u03c3, exhibit faster decay of NTK coefficients. Although calculating decay rates for l \u2265 3 is computationally demanding due to the complexity of the calculation, preliminary results presented in Appendix B demonstrate how increasing depth can result in slower coefficient decay in specific scenarios."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "instruction": "Remove the second last sentence ", "revised_paragraph": "Revised paragraph: The trend we observe from Lemma 3.2 is that activation functions whose Hermite coefficients decay quickly, such as \u03c9 \u03c3, result in a faster decay of the NTK coefficients. We remark that analyzing the rates of decay for l \u2265 3 is challenging due to the calculation of F ( p, k, \u00af \u03b1 l \u2212 1 ) (4). Additionally, in Appendix B, we provide some preliminary results in this direction, illustrating how, in a specific setting, depth can lead to slower coefficient decay.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "LWsBC35BgW.r1AX7JdZ0.00", "instruction": "Remove unnecessary information, use accurate expression and evidence.", "revised_paragraph": "Revised paragraph: The analysis of Lemma 3.2 reveals that activation functions with quickly decaying Hermite coefficients, such as \u03c9\u03c3, lead to faster decay of NTK coefficients. While calculating rates of decay for l \u2265 3 is challenging due to the complexity of F(p, k, \u00af\u03b1l\u22121), preliminary results in Appendix B illustrate the impact of depth on coefficient decay in a specific setting. Notably, the zeroth coefficient strictly increases with depth, as shown in Appendix B.4.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Conventional TCP congestion control (CC) uses heuristic functions manually crafted to adjust traffic rates deterministically. Some proposals, such as Cubic, Reno, and NewReno, rely on packet loss as a congestion signal, while others, like Vegas, use delay variation. Combining packet loss and delay is also common."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Conventional TCP congestion control (CC) uses heuristic functions manually crafted to adjust traffic rates deterministically. Some proposals, such as Cubic, Reno, and NewReno, rely on packet loss as a congestion signal, while others, like Vegas, use delay variation. Combining packet loss and delay is also common."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Conventional TCP congestion control (CC) uses heuristic functions manually crafted to adjust traffic rates deterministically. Some proposals, such as Cubic, Reno, and NewReno, rely on packet loss as a congestion signal, while others, like Vegas, use delay variation. Combining packet loss and delay is also common."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Conventional TCP congestion control (CC) uses heuristic functions manually crafted to adjust traffic rates deterministically. Some proposals, such as Cubic, Reno, and NewReno, rely on packet loss as a congestion signal, while others, like Vegas, use delay variation. Combining packet loss and delay is also common."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Conventional TCP congestion control (CC) uses heuristic functions manually crafted to adjust traffic rates deterministically. Some proposals, such as Cubic, Reno, and NewReno, rely on packet loss as a congestion signal, while others, like Vegas, use delay variation. Combining packet loss and delay is also common."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Conventional TCP congestion control (CC) uses heuristic functions manually crafted to adjust traffic rates deterministically. Some proposals, such as Cubic, Reno, and NewReno, rely on packet loss as a congestion signal, while others, like Vegas, use delay variation. Combining packet loss and delay is also common."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Conventional TCP congestion control (CC) uses heuristic functions manually crafted to adjust traffic rates deterministically. Some proposals, such as Cubic, Reno, and NewReno, rely on packet loss as a congestion signal, while others, like Vegas, use delay variation. Combining packet loss and delay is also common."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Conventional TCP congestion control (CC) uses heuristic functions manually crafted to adjust traffic rates deterministically. Some proposals, such as Cubic, Reno, and NewReno, rely on packet loss as a congestion signal, while others, like Vegas, use delay variation. Combining packet loss and delay is also common."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "instruction": "Make the last sentence slightly shorter.", "revised_paragraph": "Revised paragraph: \"Conventional TCP CC adopts a heuristic-based approach where the heuristic functions are manually crafted to adjust the traffic rate in a deterministic manner. Some proposals use packet loss as a signal for network congestion, such as Cubic, Reno, and NewReno, while others rely on delay variation, like Vegas. Other CC designs combine packet loss and delay. Specialized techniques for data-center networks have also been proposed.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.01", "instruction": "Make the paragraph slightly shorter.", "revised_paragraph": "Revised paragraph: \"Traditional TCP congestion control (CC) relies on heuristic functions manually crafted to adjust traffic rates deterministically. Some approaches use packet loss as a congestion signal, such as Cubic, Reno, and NewReno, while others rely on delay variation, like Vegas. Some designs combine packet loss and delay. More recently, specialized CC techniques have been proposed for data-center networks [2, 3, 23].\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results. As illustrated in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora for various \u0394. Notably, text without articles is often judged to be of better quality than GPT-2 XL's by most cluster-based divergence metrics. Furthermore, while this perturbation undoubtedly affects the text's fluency, its influence on the divergence is less pronounced than that of truncating texts. This outcome is counterintuitive, as a metric of text quality should prioritize fluency over surface-level statistics, such as length.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results. As illustrated in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora for various \u0394. Notably, text without articles is often judged to be of better quality than GPT-2 XL's by most cluster-based divergence metrics. Furthermore, while this perturbation undoubtedly affects the text's fluency, its influence on the divergence is less pronounced than that of truncating texts. This outcome is counterintuitive, as a metric of text quality should prioritize fluency over surface-level statistics, such as length.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results. As illustrated in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora for various \u0394. Notably, text without articles is often judged to be of better quality than GPT-2 XL's by most cluster-based divergence metrics. Furthermore, while this perturbation undoubtedly affects the text's fluency, its influence on the divergence is less pronounced than that of truncating texts. This outcome is counterintuitive, as a metric of text quality should prioritize fluency over surface-level statistics, such as length.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results. As illustrated in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora for various \u0394. Notably, text without articles is often judged to be of better quality than GPT-2 XL's by most cluster-based divergence metrics. Furthermore, while this perturbation undoubtedly affects the text's fluency, its influence on the divergence is less pronounced than that of truncating texts. This outcome is counterintuitive, as a metric of text quality should prioritize fluency over surface-level statistics, such as length.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results. As illustrated in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora for various \u0394. Notably, text without articles is often judged to be of better quality than GPT-2 XL's by most cluster-based divergence metrics. Furthermore, while this perturbation undoubtedly affects the text's fluency, its influence on the divergence is less pronounced than that of truncating texts. This outcome is counterintuitive, as a metric of text quality should prioritize fluency over surface-level statistics, such as length.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results. As illustrated in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora for various \u0394. Notably, text without articles is often judged to be of better quality than GPT-2 XL's by most cluster-based divergence metrics. Furthermore, while this perturbation undoubtedly affects the text's fluency, its influence on the divergence is less pronounced than that of truncating texts. This outcome is counterintuitive, as a metric of text quality should prioritize fluency over surface-level statistics, such as length.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results. As illustrated in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora for various \u0394. Notably, text without articles is often judged to be of better quality than GPT-2 XL's by most cluster-based divergence metrics. Furthermore, while this perturbation undoubtedly affects the text's fluency, its influence on the divergence is less pronounced than that of truncating texts. This outcome is counterintuitive, as a metric of text quality should prioritize fluency over surface-level statistics, such as length.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Results. As illustrated in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora for various \u0394. Notably, text without articles is often judged to be of better quality than GPT-2 XL's by most cluster-based divergence metrics. Furthermore, while this perturbation undoubtedly affects the text's fluency, its influence on the divergence is less pronounced than that of truncating texts. This outcome is counterintuitive, as a metric of text quality should prioritize fluency over surface-level statistics, such as length.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "instruction": "Make the concepts a bit more specific, such that some vague ideas are more clear.", "revised_paragraph": "Revised paragraph: \"Results. As depicted in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora across various \u0394 values. Interestingly, the text without articles is often ranked higher than GPT-2 XL's performance by most cluster-based divergence metrics. Furthermore, while this perturbation significantly affects the text's fluency, its influence on the divergence is less pronounced compared to truncating texts. This finding suggests that the metric may prioritize surface-level statistics, such as length, over fluency, which is arguably undesirable for a measure of text quality.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.02", "instruction": "Revise the writing for better readability.", "revised_paragraph": "Revised paragraph: As illustrated in Fig. 4, the removal of articles from the evaluated text has a negligible impact on the divergence between our reference and test corpora across various \u0394. Notably, texts without articles are often judged to be of higher quality than those generated by GPT-2 XL by most cluster-based divergences. While this perturbation does affect the text's fluency, its influence on the divergence is surprisingly less pronounced than that of truncating texts. This outcome is arguably undesirable, as a metric of text quality should prioritize fluency over surface-level statistics, such as length.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Visual comparisons are provided in Fig. 4 to illustrate the performance of our method on challenging cases. The figure shows that most compared methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, our SRPN-L approach is able to effectively mitigate these blurring artifacts and recover more structural information. The visual comparisons are consistent with the quantitative results, further demonstrating the superiority of our SRP method.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Visual comparisons are provided in Fig. 4 to illustrate the performance of our method on challenging cases. The figure shows that most compared methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, our SRPN-L approach is able to effectively mitigate these blurring artifacts and recover more structural information. The visual comparisons are consistent with the quantitative results, further demonstrating the superiority of our SRP method.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Visual comparisons are provided in Fig. 4 to illustrate the performance of our method on challenging cases. The figure shows that most compared methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, our SRPN-L approach is able to effectively mitigate these blurring artifacts and recover more structural information. The visual comparisons are consistent with the quantitative results, further demonstrating the superiority of our SRP method.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Visual comparisons are provided in Fig. 4 to illustrate the performance of our method on challenging cases. The figure shows that most compared methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, our SRPN-L approach is able to effectively mitigate these blurring artifacts and recover more structural information. The visual comparisons are consistent with the quantitative results, further demonstrating the superiority of our SRP method.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Visual comparisons are provided in Fig. 4 to illustrate the performance of our method on challenging cases. The figure shows that most compared methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, our SRPN-L approach is able to effectively mitigate these blurring artifacts and recover more structural information. The visual comparisons are consistent with the quantitative results, further demonstrating the superiority of our SRP method.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Visual comparisons are provided in Fig. 4 to illustrate the performance of our method on challenging cases. The figure shows that most compared methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, our SRPN-L approach is able to effectively mitigate these blurring artifacts and recover more structural information. The visual comparisons are consistent with the quantitative results, further demonstrating the superiority of our SRP method.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Visual comparisons are provided in Fig. 4 to illustrate the performance of our method on challenging cases. The figure shows that most compared methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, our SRPN-L approach is able to effectively mitigate these blurring artifacts and recover more structural information. The visual comparisons are consistent with the quantitative results, further demonstrating the superiority of our SRP method.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Visual comparisons are provided in Fig. 4 to illustrate the performance of our method on challenging cases. The figure shows that most compared methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, our SRPN-L approach is able to effectively mitigate these blurring artifacts and recover more structural information. The visual comparisons are consistent with the quantitative results, further demonstrating the superiority of our SRP method.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "instruction": "Please, review the following paragraph, rewrite it in a clearer way", "revised_paragraph": "Revised paragraph: \"To facilitate a deeper understanding of the performance of our SRPN-L, we provide visual comparisons with four challenging cases in Fig. 4. These comparisons reveal that most competing methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, our SRPN-L effectively mitigates these blurring artifacts and recovers more structural information. The visual results are in line with the quantitative findings, conclusively demonstrating the superiority of our SRP method.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.21", "instruction": "Rephrase the text and change SRPN-L to SRPN-Lite", "revised_paragraph": "Revised paragraph: \"Visual comparisons (\u00d7 4) in Fig. 4 illustrate the performance of our approach on challenging cases. Notably, most compared methods struggle to recover structural details with accurate directions and are plagued by blurring artifacts. In contrast, SRPN-Lite effectively mitigates these blurring artifacts and recovers more structural information. These visual comparisons align with the quantitative results, thereby substantiating the superiority of our SRPN-Lite method.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To ensure the reliability of our results, we used different apparatus for experiments 1 and 2, and our analysis revealed that this did not have a significant impact on our conclusions. For the experiments, we employed a desktop PC equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display used was an AOPEN model 25XV2QFbmiiprx, featuring a 24.5\u201d diagonal and 1920 \u00d7 1080 pixels resolution, with a refresh rate set at 360 Hz. We utilized an optical mouse, specifically the Logitech Gaming Mouse G300s, with a 1600 DPI resolution. The mouse cursor speed was set to the middle of the slider in the control-display settings, and the \"Enhance pointer precision\" option was enabled to match the participants' usual settings. The experimental system was implemented using Hot Soup Processor 3.6 and run in full-screen mode."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conducted experiments 1 and 2 using distinct apparatus, which did not have a significant impact on the study's conclusions. The desktop PC employed in this study was a desktop computer equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display device was manufactured by AOPEN (model 25XV2QFbmiiprx) and featured a 24.5-inch diagonal and 1920 \u00d7 1080 pixel resolution, with a refresh rate set at 360 Hz. A Logitech Gaming Mouse (G300s) with 1600 DPI was used as the input device, and the mouse cursor speed was set to the middle of the slider in the control-display settings, with the \"Enhance pointer precision\" option enabled to match the participants' typical settings. The experimental system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conducted experiments 1 and 2 using distinct apparatus, which did not have a significant impact on the study's conclusions. The desktop PC employed in this study was a desktop computer equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display device was manufactured by AOPEN (model 25XV2QFbmiiprx) and featured a 24.5-inch diagonal and 1920 \u00d7 1080 pixel resolution, with a refresh rate set at 360 Hz. A Logitech Gaming Mouse (G300s) with 1600 DPI was used as the input device, and the mouse cursor speed was set to the middle of the slider in the control-display settings, with the \"Enhance pointer precision\" option enabled to match the participants' typical settings. The experimental system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conducted experiments 1 and 2 using distinct apparatus, which did not have a significant impact on the study's conclusions. The desktop PC employed in this study was a desktop computer equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display device was manufactured by AOPEN (model 25XV2QFbmiiprx) and featured a 24.5-inch diagonal and 1920 \u00d7 1080 pixel resolution, with a refresh rate set at 360 Hz. A Logitech Gaming Mouse (G300s) with 1600 DPI was used as the input device, and the mouse cursor speed was set to the middle of the slider in the control-display settings, with the \"Enhance pointer precision\" option enabled to match the participants' typical settings. The experimental system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To ensure the reliability of our results, we used different apparatus for experiments 1 and 2, and our analysis revealed that this did not have a significant impact on our conclusions. For the experiments, we employed a desktop PC equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display used was an AOPEN model 25XV2QFbmiiprx, featuring a 24.5\u201d diagonal and 1920 \u00d7 1080 pixels resolution, with a refresh rate set at 360 Hz. We utilized an optical mouse, specifically the Logitech Gaming Mouse G300s, with a 1600 DPI resolution. The mouse cursor speed was set to the middle of the slider in the control-display settings, and the \"Enhance pointer precision\" option was enabled to match the participants' usual settings. The experimental system was implemented using Hot Soup Processor 3.6 and run in full-screen mode."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conducted experiments 1 and 2 using distinct apparatus, which did not have a significant impact on the study's conclusions. The desktop PC employed in this study was a desktop computer equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display device was manufactured by AOPEN (model 25XV2QFbmiiprx) and featured a 24.5-inch diagonal and 1920 \u00d7 1080 pixel resolution, with a refresh rate set at 360 Hz. A Logitech Gaming Mouse (G300s) with 1600 DPI was used as the input device, and the mouse cursor speed was set to the middle of the slider in the control-display settings, with the \"Enhance pointer precision\" option enabled to match the participants' typical settings. The experimental system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To ensure the reliability of our results, we used different apparatus for experiments 1 and 2, and our analysis revealed that this did not have a significant impact on our conclusions. For the experiments, we employed a desktop PC equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display used was an AOPEN model 25XV2QFbmiiprx, featuring a 24.5\u201d diagonal and 1920 \u00d7 1080 pixels resolution, with a refresh rate set at 360 Hz. We utilized an optical mouse, specifically the Logitech Gaming Mouse G300s, with a 1600 DPI resolution. The mouse cursor speed was set to the middle of the slider in the control-display settings, and the \"Enhance pointer precision\" option was enabled to match the participants' usual settings. The experimental system was implemented using Hot Soup Processor 3.6 and run in full-screen mode."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To ensure the reliability of our results, we employed distinct apparatus for experiments 1 and 2, and our analysis revealed that this did not have a significant impact on our conclusions. For the experiments, we utilized a desktop PC equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and a Windows 10 Home operating system. The display used was an AOPEN model 25XV2QFbmiiprx, featuring a 24.5-inch diagonal and 1920 \u00d7 1080 pixels resolution, with a refresh rate set at 360 Hz. We utilized an optical mouse, specifically the Logitech Gaming Mouse G300s, with a 1600 DPI resolution. The mouse cursor speed was set to the middle of the slider in the control-display settings, and the \"Enhance pointer precision\" option was enabled to match the participants' usual settings. The experimental system was implemented using Hot Soup Processor 3.6 and run in full-screen mode."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conducted experiments 1 and 2 using distinct apparatus, which did not have a significant impact on the study's conclusions. The desktop PC employed in this study was a desktop computer equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display device was manufactured by AOPEN (model 25XV2QFbmiiprx) and featured a 24.5-inch diagonal and 1920 \u00d7 1080 pixel resolution, with a refresh rate set at 360 Hz. A Logitech Gaming Mouse (G300s) with 1600 DPI was used as the input device, and the mouse cursor speed was set to the middle of the slider in the control-display settings, with the \"Enhance pointer precision\" option enabled to match the participants' typical settings. The experimental system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We conducted experiments 1 and 2 using distinct apparatus, which did not have a significant impact on the study's conclusions. The desktop PC employed in this study was a desktop computer equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display device was manufactured by AOPEN (model 25XV2QFbmiiprx) and featured a 24.5-inch diagonal and 1920 \u00d7 1080 pixel resolution, with a refresh rate set at 360 Hz. A Logitech Gaming Mouse (G300s) with 1600 DPI was used as the input device, and the mouse cursor speed was set to the middle of the slider in the control-display settings, with the \"Enhance pointer precision\" option enabled to match the participants' typical settings. The experimental system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To ensure the reliability of our results, we used different apparatus for experiments 1 and 2, and our analysis revealed that this did not have a significant impact on our conclusions. For the experiments, we employed a desktop PC equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display used was an AOPEN model 25XV2QFbmiiprx, featuring a 24.5\u201d diagonal and 1920 \u00d7 1080 pixels resolution, with a refresh rate set at 360 Hz. We utilized an optical mouse, specifically the Logitech Gaming Mouse G300s, with a 1600 DPI resolution. The mouse cursor speed was set to the middle of the slider in the control-display settings, and the \"Enhance pointer precision\" option was enabled to match the participants' usual settings. The experimental system was implemented using Hot Soup Processor 3.6 and run in full-screen mode."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To ensure the reliability of our results, we employed distinct apparatus for experiments 1 and 2, and our analysis revealed that this did not have a significant impact on our conclusions. For the experiments, we utilized a desktop PC equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and a Windows 10 Home operating system. The display used was an AOPEN model 25XV2QFbmiiprx, featuring a 24.5-inch diagonal and 1920 \u00d7 1080 pixels resolution, with a refresh rate set at 360 Hz. We utilized an optical mouse, specifically the Logitech Gaming Mouse G300s, with a 1600 DPI resolution. The mouse cursor speed was set to the middle of the slider in the control-display settings, and the \"Enhance pointer precision\" option was enabled to match the participants' usual settings. The experimental system was implemented using Hot Soup Processor 3.6 and run in full-screen mode."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "instruction": "Improve the English in this paragraph by choosing better words", "revised_paragraph": "Revised paragraph: \"In experiments 1 and 2, we employed distinct equipment, which did not significantly influence the study's conclusions. The desktop PC used was equipped with an Intel Core i9-12900KF processor, a GeForce RTX 3070 Ti graphics card, 32GB of RAM, and Windows 10 Home operating system. The display, manufactured by AOPEN (model 25XV2QFbmiiprx), featured a 24.5-inch diagonal and 1920 \u00d7 1080 pixels resolution, with a refresh rate set at 360 Hz. For input, we utilized a Logitech Gaming Mouse (G300s) with 1600 DPI and adjusted the mouse-cursor speed via the operating system setting to the middle of the slider, ensuring that the \"Enhance pointer precision\" feature was enabled, as is typical for participants. The experimental system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.18", "instruction": "Improve the liking between phrases.", "revised_paragraph": "Revised paragraph: We conducted experiments 1 and 2 using distinct apparatus, which did not influence the study's conclusions. The desktop PC employed in the study was a desktop PC (Intel Core i9-12900KF, GeForce RTX 3070 Ti, 32GB RAM, Windows 10 Home). The display, manufactured by AOPEN (model 25XV2QFbmiiprx; 24.5\u201d diagonal, 1920 \u00d7 1080 pixels), was set to a refresh rate of 360 Hz. An optical mouse, the Logitech Gaming Mouse (G300s; 1600 DPI), was used, and the mouse-cursor speed was set to the middle of the slider in the control-display and \"Enhance pointer precision\" setting was enabled to match the participants' usual settings. The experimental system was implemented using Hot Soup Processor 3.6 and operated in full-screen mode.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role, rather than being the primary identifier for medication entries. Solid dull colors were effective for indicating busy slots, but color fills for medication entries were cluttering. To minimize visual overload, medication identification information should be reduced, with labels abstracted from the overview and made available as details on demand.\""}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"To improve medication entry design, color should not be used as the primary identifier. Instead, a solid dull color can be used to indicate busy slots. The amount of medication identification information should be minimized to avoid clutter. Medication labels, including name and dosage, should be abstracted from the overview and made available as details on demand to reduce confusion.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role, rather than being the primary identifier for medication entries. Solid dull colors were effective for indicating busy slots, but color fills for medication entries were cluttering. To minimize visual overload, medication identification information should be reduced, with labels abstracted from the overview and made available as details on demand.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role, rather than being the primary identifier for medication entries. Solid dull colors were effective for indicating busy slots, but color fills for medication entries were cluttering. To minimize visual overload, medication identification information should be reduced, with labels abstracted from the overview and made available as details on demand.\""}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"To improve medication entry design, color should not be used as the primary identifier. Instead, a solid dull color can be used to indicate busy slots. The amount of medication identification information should be minimized to avoid clutter. Medication labels, including name and dosage, should be abstracted from the overview and made available as details on demand to reduce confusion.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role, rather than being the primary identifier for medication entries. Solid dull colors were effective for indicating busy slots, but color fills for medication entries were cluttering. To minimize visual overload, medication identification information should be reduced, with labels abstracted from the overview and made available as details on demand.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role, rather than being the primary identifier for medication entries. Solid dull colors were effective for indicating busy slots, but color fills for medication entries were cluttering. To minimize visual overload, medication identification information should be reduced, with labels abstracted from the overview and made available as details on demand.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role. Solid dull colors effectively indicate busy slots, while minimizing clutter. Medication identification information should be reduced and made available as details on demand.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role, rather than being the primary identifier for medication entries. Solid dull colors were effective for indicating busy slots, but color fills for medication entries were cluttering. To minimize visual overload, medication identification information should be reduced, with labels abstracted from the overview and made available as details on demand.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role, rather than being the primary identifier for medication entries. Solid dull colors were effective for indicating busy slots, but color fills for medication entries were cluttering. To minimize visual overload, medication identification information should be reduced, with labels abstracted from the overview and made available as details on demand.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role. Solid dull colors effectively indicate busy slots, while minimizing clutter. Medication identification information should be reduced and made available as details on demand.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"To improve the design, color should play a secondary role, rather than being the primary identifier for medication entries. Solid dull colors were effective for indicating busy slots, but color fills for medication entries were cluttering. To minimize visual overload, medication identification information should be reduced, with labels abstracted from the overview and made available as details on demand.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "instruction": "Remove unnecessary details and explanations.", "revised_paragraph": "Revised paragraph: \"To improve the medication calendar design, color should not be the primary identifier for medication entries. Solid dull colors effectively indicate busy slots, but color fills for medication entries are cluttering. To minimize visual overload, medication identification information should be reduced. Medication labels, including name and dosage, often overflow the containing entry, causing confusion when multiple entries occupy the same cell. Instead, labels should be abstracted from the overview and made available as details on demand.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.18", "instruction": "I want to restate my third sentence.", "revised_paragraph": "Revised paragraph: To improve the medication calendar's design, the prominence of color should be reduced, and it should not be relied upon as the primary means of identifying medication entries. While a solid, dull color was effective in highlighting busy slots, the use of color fills for medication entries resulted in visual clutter. To minimize visual overload, the amount of medication identification information displayed in the calendar entry should be limited. Medication labels, including the name and dosage, often overflowed the containing entry, causing confusion when multiple entries occupied the same cell. To address this issue, labels should be abstracted from the overview and instead made available as detailed information on demand.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We derive an upper bound for PEHE in the stochastic batch form using Theorem 3.1, building on Uri et al. (2017). This bound shows that PEHE can be optimized by iteratively minimizing factual outcome estimation error and optimal transport discrepancy at the mini-batch level."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We derive an upper bound on the propensity score estimation error (PEHE) in the stochastic batch form, as shown in Theorem 3.1, which builds upon the work of Uri et al. (2017). Specifically, this bound is achieved by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at the mini-batch level, thereby optimizing the PEHE."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We derive an upper bound on the propensity score estimation error (PEHE) in the stochastic batch form, as shown in Theorem 3.1, which builds upon the work of Uri et al. (2017). Specifically, this bound is achieved by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at the mini-batch level, thereby optimizing the PEHE."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We derive an upper bound on the propensity score estimation error (PEHE) in the stochastic batch form, as shown in Theorem 3.1, which builds upon the work of Uri et al. (2017). Specifically, this bound is achieved by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at the mini-batch level, thereby optimizing the PEHE."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We derive an upper bound for PEHE in the stochastic batch form using Theorem 3.1, building on Uri et al. (2017). This bound shows that PEHE can be optimized by iteratively minimizing factual outcome estimation error and optimal transport discrepancy at the mini-batch level."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We derive an upper bound on the propensity score estimation error (PEHE) in the stochastic batch form, as shown in Theorem 3.1, which builds upon the work of Uri et al. (2017). Specifically, this bound is achieved by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at the mini-batch level, thereby optimizing the PEHE."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We derive an upper bound for PEHE in the stochastic batch form using Theorem 3.1, building on Uri et al. (2017). This bound shows that PEHE can be optimized by iteratively minimizing factual outcome estimation error and optimal transport discrepancy at the mini-batch level."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We establish an upper bound for the propensity score estimation error in the stochastic batch setting, leveraging Theorem 3.1 and the work of Uri et al. (2017). This bound reveals that PEHE can be minimized by iteratively reducing factual outcome estimation errors and optimal transport discrepancies at the mini-batch level."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We derive an upper bound on the propensity score estimation error (PEHE) in the stochastic batch form, as shown in Theorem 3.1, which builds upon the work of Uri et al. (2017). Specifically, this bound is achieved by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at the mini-batch level, thereby optimizing the PEHE."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We derive an upper bound on the propensity score estimation error (PEHE) in the stochastic batch form, as shown in Theorem 3.1, which builds upon the work of Uri et al. (2017). Specifically, this bound is achieved by iteratively minimizing the factual outcome estimation error and the optimal transport discrepancy at the mini-batch level, thereby optimizing the PEHE."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We derive an upper bound for PEHE in the stochastic batch form using Theorem 3.1, building on Uri et al. (2017). This bound shows that PEHE can be optimized by iteratively minimizing factual outcome estimation error and optimal transport discrepancy at the mini-batch level."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We establish an upper bound for the propensity score estimation error in the stochastic batch setting, leveraging Theorem 3.1 and the work of Uri et al. (2017). This bound reveals that PEHE can be minimized by iteratively reducing factual outcome estimation errors and optimal transport discrepancies at the mini-batch level."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "instruction": "At the last part, state that the proof will be shown in the appendix. Also, make the sentence more sophisticated.", "revised_paragraph": "Revised paragraph: By leveraging the stochastic batch framework, we establish an upper bound on the predictive error of heterogeneous effect (PEHE) as stated in Theorem 3.1, building upon the theoretical foundations laid out by Uri et al. (2017). Specifically, we demonstrate that PEHE can be optimized through an iterative process of minimizing the factual outcome estimation error and the optimal transport discrepancy at the mini-batch level. The proof of this theorem is provided in the appendix.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.09", "instruction": "Make this sentence more concise. Add a reference to Appendix A.3. where the proof is.", "revised_paragraph": "Revised paragraph: We derive the upper bound of PEHE in the stochastic batch form using Theorem 3.1, as shown in Appendix A.3, which builds upon Uri et al. (2017) and optimizes PEHE by iteratively minimizing factual outcome estimation error and optimal transport discrepancy at the mini-batch level.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The only set prediction model that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). We do not compare with DESP (Zhang et al., 2021), which is also multiset-equivariant but uses a different approach to learn set energies without a traditional set loss.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The only set prediction model that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). We do not compare with DESP (Zhang et al., 2021), which is also multiset-equivariant but uses a different approach to learn set energies without a traditional set loss.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The only set prediction model that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). We do not compare with DESP (Zhang et al., 2021), which is also multiset-equivariant but uses a different approach to learn set energies without a traditional set loss.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The only set prediction model that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). We do not compare with DESP (Zhang et al., 2021), which is also multiset-equivariant but uses a different approach to learn set energies without a traditional set loss.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The only set prediction model that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). We do not compare with DESP (Zhang et al., 2021), which is also multiset-equivariant but uses a different approach to learn set energies without a traditional set loss.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The only set prediction model that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). We do not compare with DESP (Zhang et al., 2021), which is also multiset-equivariant but uses a different approach to learn set energies without a traditional set loss.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The only set prediction model that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). We do not compare with DESP (Zhang et al., 2021), which is also multiset-equivariant but uses a different approach to learn set energies without a traditional set loss.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The only set prediction model that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). We do not compare with DESP (Zhang et al., 2021), which is also multiset-equivariant but uses a different approach to learn set energies without a traditional set loss.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "instruction": "Make this paragraph more concise by using more direct formulations", "revised_paragraph": "Revised paragraph: DSPN (Zhang et al., 2019; Huang et al., 2020) is the only exclusively multiset-equivariant set prediction model we are aware of. DESP (Zhang et al., 2021) is another multiset-equivariant model, but it does not fit the traditional set prediction framework, instead using the Jacobian of sorting for diverse sampling. We do not compare it with our model in the experiments.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.18", "instruction": "Make the paragraph shorter but don't touch at the first sentence.", "revised_paragraph": "Revised paragraph: \"The only set prediction model we are aware of that can be exclusively multiset-equivariant is DSPN (Zhang et al., 2019; Huang et al., 2020). We do not compare our approach with DESP (Zhang et al., 2021) in the experiments as it has a different goal of diverse sampling by learning set energies without a traditional set loss.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: These fusion modules facilitate the exchange of information between different branches of the network. The employed network architecture utilizes intermediate fusion, a categorization of multi-modal fusion strategies in deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Notably, it has shown competitive performance compared to multi-modal DNNs with late fusion in numerous tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: These fusion modules facilitate the exchange of information between different branches of the network. The employed network architecture utilizes intermediate fusion, a categorization of multi-modal fusion strategies in deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Notably, it has shown competitive performance compared to multi-modal DNNs with late fusion in numerous tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: These fusion modules facilitate the exchange of information between different branches of the network. The employed network architecture utilizes intermediate fusion, a categorization of multi-modal fusion strategies in deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Notably, it has shown competitive performance compared to multi-modal DNNs with late fusion in numerous tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: These fusion modules facilitate the exchange of information between different branches of the network. The employed network architecture utilizes intermediate fusion, a categorization of multi-modal fusion strategies in deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Notably, it has shown competitive performance compared to multi-modal DNNs with late fusion in numerous tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: These fusion modules facilitate the exchange of information between different branches of the network. The employed network architecture utilizes intermediate fusion, a categorization of multi-modal fusion strategies in deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Notably, it has shown competitive performance compared to multi-modal DNNs with late fusion in numerous tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: These fusion modules facilitate the exchange of information between different branches of the network. The employed network architecture utilizes intermediate fusion, a categorization of multi-modal fusion strategies in deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Notably, it has shown competitive performance compared to multi-modal DNNs with late fusion in numerous tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: These fusion modules facilitate the exchange of information between different branches of the network. The employed network architecture utilizes intermediate fusion, a categorization of multi-modal fusion strategies in deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Notably, it has shown competitive performance compared to multi-modal DNNs with late fusion in numerous tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: These fusion modules facilitate the exchange of information between different branches of the network. The employed network architecture utilizes intermediate fusion, a categorization of multi-modal fusion strategies in deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Notably, it has shown competitive performance compared to multi-modal DNNs with late fusion in numerous tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "instruction": "Explain the concept more clearly.", "revised_paragraph": "Revised paragraph: The proposed network architecture incorporates fusion modules that facilitate information exchange between different branches. This design adheres to the intermediate fusion category, a well-established approach in deep learning research (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Notably, our approach has been shown to yield competitive performance in various tasks compared to late fusion-based multi-modal DNNs (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.02", "instruction": "Rewrite this paragraph to improve its clarity.", "revised_paragraph": "Revised paragraph: \"The proposed network architecture employs an intermediate fusion strategy, which enables information flow between branches. This approach is categorized as a multi-modal fusion strategy, as described in the deep learning literature (Ngiam et al., 2011; Atrey et al., 2010; Baltru\u0161aitis et al., 2018). Our method has been shown to achieve competitive performance compared to late fusion-based multi-modal DNNs in various tasks (Perez et al., 2018; Joze et al., 2020; Anderson et al., 2018; Wang et al., 2020b).\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Proteins often collaborate with other proteins to regulate biological processes, as demonstrated by Alberts and Miake-Lye (1992) and Kastritis and Bonvin (2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to proteins on their surface and trigger immune responses by interacting with the receptor protein of immune cells, as shown by Lu et al. (2018). Since protein-protein interactions are crucial for many biological functions, developing methods to modulate these interactions is essential. One common approach is to mutate amino acids on the interface, which can either strengthen or weaken the interaction, depending on the specific goals of the biologist. For example, to enhance the effect of a neutralizing antibody against a virus, it is typically necessary to increase the binding strength between the antibody and the viral protein. However, with the vast number of possible amino acid mutations, it is often impractical and costly to conduct wet-lab assays to test all viable mutations. Therefore, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, measured by the change in binding free energy (\u2206\u2206G)."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Proteins rarely function independently, instead, they frequently interact with other proteins to orchestrate complex biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to specific proteins on their surface and elicit immune responses through interactions with the receptor protein of immune cells (Lu et al., 2018). Given that protein-protein interactions underpin a significant proportion of biological functions, developing methods to modulate these interactions is crucial. One common approach to modulate protein-protein interactions is to mutate amino acids on the interface, where some mutations enhance binding strength while others weaken or disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists may choose to either increase or decrease binding strength depending on specific goals. For example, to enhance the effect of a neutralizing antibody against a virus, it is typically necessary to increase the binding strength between the antibody and the viral protein. However, the large combinatorial space of amino acid mutations renders it often impractical or cost-prohibitive to conduct wet-lab assays to test all viable mutations. Consequently, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, as measured by the change in binding free energy (\u2206\u2206G)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Proteins often collaborate with other proteins to regulate biological processes, as demonstrated by Alberts and Miake-Lye (1992) and Kastritis and Bonvin (2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to proteins on their surface and trigger immune responses by interacting with the receptor protein of immune cells, as shown by Lu et al. (2018). Since protein-protein interactions are crucial for many biological functions, developing methods to modulate these interactions is essential. One common approach is to mutate amino acids on the interface, which can either strengthen or weaken the interaction, depending on the specific goals of the biologist. For example, to enhance the effect of a neutralizing antibody against a virus, it is typically necessary to increase the binding strength between the antibody and the viral protein. However, with the vast number of possible amino acid mutations, it is often impractical and costly to conduct wet-lab assays to test all viable mutations. Therefore, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, measured by the change in binding free energy (\u2206\u2206G)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Proteins rarely function independently, instead, they frequently interact with other proteins to orchestrate complex biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to specific proteins on their surface and elicit immune responses through interactions with the receptor protein of immune cells (Lu et al., 2018). Given that protein-protein interactions underpin a significant proportion of biological functions, developing methods to modulate these interactions is crucial. One common approach to modulate protein-protein interactions is to mutate amino acids on the interface, where some mutations enhance binding strength while others weaken or disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists may choose to either increase or decrease binding strength depending on specific goals. For example, to enhance the effect of a neutralizing antibody against a virus, it is typically necessary to increase the binding strength between the antibody and the viral protein. However, the large combinatorial space of amino acid mutations renders it often impractical or cost-prohibitive to conduct wet-lab assays to test all viable mutations. Consequently, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, as measured by the change in binding free energy (\u2206\u2206G)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Proteins often collaborate with other proteins to regulate biological processes, as demonstrated by Alberts and Miake-Lye (1992) and Kastritis and Bonvin (2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to proteins on their surface and trigger immune responses by interacting with the receptor protein of immune cells, as shown by Lu et al. (2018). Since protein-protein interactions are crucial for many biological functions, developing methods to modulate these interactions is essential. One common approach is to mutate amino acids on the interface, which can either strengthen or weaken the interaction, depending on the specific goals of the biologist. For example, to enhance the effect of a neutralizing antibody against a virus, it is typically necessary to increase the binding strength between the antibody and the viral protein. However, with the vast number of possible amino acid mutations, it is often impractical and costly to conduct wet-lab assays to test all viable mutations. Therefore, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, measured by the change in binding free energy (\u2206\u2206G)."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Proteins often collaborate with other proteins to regulate biological processes, as exemplified by Alberts and Miake-Lye (1992) and Kastritis and Bonvin (2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to proteins on their surface and trigger immune responses through interactions with the receptor protein of immune cells, as demonstrated by Lu et al. (2018). Since protein-protein interactions are crucial for many biological functions, developing methods to modulate these interactions is essential. One common approach is to mutate amino acids on the interface, which can either strengthen or weaken the interaction, depending on the specific goals of the biologist. For example, to enhance the effect of a neutralizing antibody against a virus, it is typically necessary to increase the binding strength between the antibody and the viral protein. However, with the vast number of possible amino acid mutations, it is often impractical and costly to conduct wet-lab assays to test all viable mutations. Therefore, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, as measured by the change in binding free energy (\u2206\u2206G)."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Proteins often collaborate with other proteins to regulate biological processes, as demonstrated by Alberts and Miake-Lye (1992) and Kastritis and Bonvin (2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to proteins on their surface and trigger immune responses by interacting with the receptor protein of immune cells, as shown by Lu et al. (2018). Since protein-protein interactions are crucial for many biological functions, developing methods to modulate these interactions is essential. One common approach is to mutate amino acids on the interface, which can either strengthen or weaken the interaction, depending on the specific goals of the biologist. For example, to enhance the effect of a neutralizing antibody against a virus, it is typically necessary to increase the binding strength between the antibody and the viral protein. However, with the vast number of possible amino acid mutations, it is often impractical and costly to conduct wet-lab assays to test all viable mutations. Therefore, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, measured by the change in binding free energy (\u2206\u2206G)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Proteins rarely function independently, instead, they frequently interact with other proteins to orchestrate complex biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to specific proteins on their surface and elicit immune responses through interactions with the receptor protein of immune cells (Lu et al., 2018). Given that protein-protein interactions underpin a significant proportion of biological functions, developing methods to modulate these interactions is crucial. One common approach to modulate protein-protein interactions is to mutate amino acids on the interface, where some mutations enhance binding strength while others weaken or disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists may choose to either increase or decrease binding strength depending on specific goals. For example, to enhance the effect of a neutralizing antibody against a virus, it is typically necessary to increase the binding strength between the antibody and the viral protein. However, the large combinatorial space of amino acid mutations renders it often impractical or cost-prohibitive to conduct wet-lab assays to test all viable mutations. Consequently, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, as measured by the change in binding free energy (\u2206\u2206G)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "instruction": "Improve the English in this paragraph for better readability.", "revised_paragraph": "Revised paragraph: Proteins rarely operate independently, instead often interacting with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). As protein-protein interactions play a crucial role in determining a large number of biological functions, developing methods to modulate these interactions is essential. One common approach to modulate protein-protein interactions is to mutate amino acids on the interface \u2013 some mutations enhance the binding strength, while others weaken or disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists can choose to either increase or decrease the binding strength depending on their specific goals. For example, to enhance the effect of a neutralizing antibody against a virus, it is often necessary to increase the binding strength between the antibody and the viral protein. However, with the vast combinatorial space of amino acid mutations, it is not always feasible or affordable to conduct wet-lab assays to test all viable mutations. Consequently, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, as measured by the change in binding free energy (\u2206\u2206G).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "instruction": "Lightly revise this paragraph to make it more clear and precise while keeping the academic style.", "revised_paragraph": "Revised paragraph: Protein-protein interactions are a ubiquitous feature of biological processes, with proteins often acting in concert to orchestrate complex functions (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to surface-expressed proteins and elicit immune responses through interactions with receptor proteins on immune cells (Lu et al., 2018). The modulation of protein-protein interactions is crucial, as it determines a significant proportion of biological functions. One common approach to modulate these interactions is through the mutation of amino acids on the protein-protein interface, with some mutations enhancing binding strength while others weaken or disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists may aim to either increase or decrease binding strength depending on specific goals. For example, to enhance the effect of a neutralizing antibody against a virus, it is often necessary to increase the binding strength between the antibody and the viral protein. However, the large combinatorial space of amino acid mutations makes it impractical and costly to conduct exhaustive wet-lab assays to test all viable mutations. Consequently, computational approaches are essential to guide the identification of desirable mutations by predicting the mutational effect on binding strength, as measured by the change in binding free energy (\u2206\u2206G).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \nWe used a neural network with 2000 neurons to update its weights and biases in an unsupervised manner. The network was trained for 100 epochs with a learning rate that decreased linearly from 0.03 to 0. We found that softmax with a base of 1000 performed best in validation testing. Each experiment was repeated five times with varying random initializations and input order, and we report the mean and standard deviation of accuracies. We tested the network in two ways: a single-layer approach, where we assigned labels to neurons based on their winning frequency, and a two-layer approach, where a supervised classi\ufb01er was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: The neural network was trained using the Euclidean norm and an unsupervised plasticity rule, with 2000 neurons and a learning rate that decreased linearly from 0.03 to 0. We used softmax with a base of 1000 and repeated each experiment five times with varying initializations and input orders. Two approaches were used to infer input labels: a single-layer approach, where labels were assigned to each neuron based on its most frequent winning label, and a two-layer approach, where a supervised perceptron classifier was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively, outperforming a hard-WTA setup."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \nWe used a neural network with 2000 neurons to update its weights and biases in an unsupervised manner. The network was trained for 100 epochs with a learning rate that decreased linearly from 0.03 to 0. We found that softmax with a base of 1000 performed best in validation testing. Each experiment was repeated five times with varying random initializations and input order, and we report the mean and standard deviation of accuracies. We tested the network in two ways: a single-layer approach, where we assigned labels to neurons based on their winning frequency, and a two-layer approach, where a supervised classi\ufb01er was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \nWe used a neural network with 2000 neurons to update its weights and biases in an unsupervised manner. The network was trained for 100 epochs with a learning rate that decreased linearly from 0.03 to 0. We found that softmax with a base of 1000 performed best in validation testing. Each experiment was repeated five times with varying random initializations and input order, and we report the mean and standard deviation of accuracies. We tested the network in two ways: a single-layer approach, where we assigned labels to neurons based on their winning frequency, and a two-layer approach, where a supervised classi\ufb01er was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: The neural network was trained using the Euclidean norm and an unsupervised plasticity rule, with 2000 neurons and a learning rate that decreased linearly from 0.03 to 0. We used softmax with a base of 1000 and repeated each experiment five times with varying initializations and input orders. Two approaches were used to infer input labels: a single-layer approach, where labels were assigned to each neuron based on its most frequent winning label, and a two-layer approach, where a supervised perceptron classifier was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively, outperforming a hard-WTA setup."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \nWe used a neural network with 2000 neurons to update its weights and biases in an unsupervised manner. The network was trained for 100 epochs with a learning rate that decreased linearly from 0.03 to 0. We found that softmax with a base of 1000 performed best in validation testing. Each experiment was repeated five times with varying random initializations and input order, and we report the mean and standard deviation of accuracies. We tested the network in two ways: a single-layer approach, where we assigned labels to neurons based on their winning frequency, and a two-layer approach, where a supervised classi\ufb01er was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \nWe used a neural network with 2000 neurons to update its weights and biases in an unsupervised manner. The network was trained for 100 epochs with a learning rate that decreased linearly from 0.03 to 0. We found that softmax with a base of 1000 performed best in validation testing. Each experiment was repeated five times with varying random initializations and input order, and we report the mean and standard deviation of accuracies. We tested the network in two ways: a single-layer approach, where we assigned labels to neurons based on their winning frequency, and a two-layer approach, where a supervised classi\ufb01er was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: We trained a neural network with 2000 neurons in an unsupervised manner for 100 epochs, using a decreasing learning rate. The best performing activation function was softmax with a base of 1000, as validated through repeated experiments with varying initializations and input orders. The network achieved an accuracy of (96.18 \u00b1 0.06)% in its single-layer form and (96.94 \u00b1 0.02)% in its two-layer form."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \nWe used a neural network with 2000 neurons to update its weights and biases in an unsupervised manner. The network was trained for 100 epochs with a learning rate that decreased linearly from 0.03 to 0. We found that softmax with a base of 1000 performed best in validation testing. Each experiment was repeated five times with varying random initializations and input order, and we report the mean and standard deviation of accuracies. We tested the network in two ways: a single-layer approach, where we assigned labels to neurons based on their winning frequency, and a two-layer approach, where a supervised classi\ufb01er was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \nWe used a neural network with 2000 neurons to update its weights and biases in an unsupervised manner. The network was trained for 100 epochs with a learning rate that decreased linearly from 0.03 to 0. We found that softmax with a base of 1000 performed best in validation testing. Each experiment was repeated five times with varying random initializations and input order, and we report the mean and standard deviation of accuracies. We tested the network in two ways: a single-layer approach, where we assigned labels to neurons based on their winning frequency, and a two-layer approach, where a supervised classi\ufb01er was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: We trained a neural network with 2000 neurons in an unsupervised manner for 100 epochs, using a decreasing learning rate. The best performing activation function was softmax with a base of 1000, as validated through repeated experiments with varying initializations and input orders. The network achieved an accuracy of (96.18 \u00b1 0.06)% in its single-layer form and (96.94 \u00b1 0.02)% in its two-layer form."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \nWe used a neural network with 2000 neurons to update its weights and biases in an unsupervised manner. The network was trained for 100 epochs with a learning rate that decreased linearly from 0.03 to 0. We found that softmax with a base of 1000 performed best in validation testing. Each experiment was repeated five times with varying random initializations and input order, and we report the mean and standard deviation of accuracies. We tested the network in two ways: a single-layer approach, where we assigned labels to neurons based on their winning frequency, and a two-layer approach, where a supervised classi\ufb01er was trained on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "instruction": "Remove training details. Rewrite last paragraph to shorten.", "revised_paragraph": "Revised paragraph: SoftHebb achieved an accuracy of (96.18 \u00b1 0.06)% and (96.94 \u00b1 0.02)% in its 1- and 2-layer forms, respectively. We also compared the performance of the soft WTA approach with a hard-WTA setup, where the strongest-activated neuron's output is 1 and others are suppressed to 0. The results showed that SoftHebb outperformed the hard WTA (Fig. 1A).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "8_oadXCaRE.Kt4-LpYuM.03", "instruction": "Remove unnecessary details to make the paragraph shorter.", "revised_paragraph": "Revised paragraph: We trained a WTA network with 2000 neurons using the Euclidean norm and an unsupervised plasticity rule. We used K = 2000 neurons and trained the network for 100 epochs with a linearly decreasing learning rate from 0.03 to 0. We repeated each experiment five times with varying random initializations and input order, reporting the mean and standard deviation of accuracies. We tested the network in two ways: a single-layer approach, where we assigned labels to neurons based on their most frequent winning label, and a two-layer approach, where we trained a supervised classi\ufb01er on top of the WTA layer. The SoftHebb model achieved an accuracy of (96.18 \u00b1 0.06)% in its 1-layer form and (96.94 \u00b1 0.02)% in its 2-layer form, outperforming a hard-WTA setup.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We validate the choice of graph attention network (GAT) as the relational architecture. In Figure 7, we compare GAT with graph convolutional network (GCN) (Kipf & Welling, 2016) on the AGILE action graph. While GCN achieves optimal performance in simple tasks, GAT outperforms it in tasks with large action spaces, such as CREATE and RecSim-pairing, due to its ability to ease RL training through sparse attention."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We justify the selection of graph attention network (GAT) as the relational architecture by comparing it to a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE (Figure 7). Our results show that GCN outperforms GAT in simple grid world and RecSim tasks, likely due to its ability to act as a summarizer, even without learned edge weights. However, GCN struggles in CREATE and RecSim-pairing tasks (Figure 16), which involve large action spaces and diverse action relations. Moreover, we hypothesize that GAT's attention mechanism helps to create a sparse graph, making it easier to train reinforcement learning models, whereas a fully-connected GCN would be more challenging to train."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We justify the selection of graph attention network (GAT) as the relational architecture by comparing it to a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE (Figure 7). Our results show that GCN outperforms GAT in simple grid world and RecSim tasks, likely due to its ability to act as a summarizer, even without learned edge weights. However, GCN struggles in CREATE and RecSim-pairing tasks (Figure 16), which involve large action spaces and diverse action relations. Moreover, we hypothesize that GAT's attention mechanism helps to create a sparse graph, making it easier to train reinforcement learning models, whereas a fully-connected GCN would be more challenging to train."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We justify the selection of graph attention network (GAT) as the relational architecture by comparing it to a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE (Figure 7). Our results show that GCN outperforms GAT in simple grid world and RecSim tasks, likely due to its ability to act as a summarizer, even without learned edge weights. However, GCN struggles in CREATE and RecSim-pairing tasks (Figure 16), which involve large action spaces and diverse action relations. Moreover, we hypothesize that GAT's attention mechanism helps to create a sparse graph, making it easier to train reinforcement learning models, whereas a fully-connected GCN would be more challenging to train."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We validate the choice of graph attention network (GAT) as the relational architecture. In Figure 7, we compare GAT with graph convolutional network (GCN) (Kipf & Welling, 2016) on the AGILE action graph. While GCN achieves optimal performance in simple tasks, GAT outperforms it in tasks with large action spaces, such as CREATE and RecSim-pairing, due to its ability to ease RL training through sparse attention."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We justify the selection of graph attention network (GAT) as the relational architecture by comparing it to a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE (Figure 7). Our results show that GCN outperforms GAT in simple grid world and RecSim tasks, likely due to its ability to act as a summarizer, even without learned edge weights. However, GCN struggles in CREATE and RecSim-pairing tasks (Figure 16), which involve large action spaces and diverse action relations. Moreover, we hypothesize that GAT's attention mechanism helps to create a sparse graph, making it easier to train reinforcement learning models, whereas a fully-connected GCN would be more challenging to train."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We validate the choice of graph attention network (GAT) as the relational architecture. In Figure 7, we compare GAT with graph convolutional network (GCN) (Kipf & Welling, 2016) on the AGILE action graph. While GCN achieves optimal performance in simple tasks, GAT outperforms it in tasks with large action spaces, such as CREATE and RecSim-pairing, due to its ability to ease RL training through sparse attention."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We justify the selection of the graph attention network (GAT) as our relational architecture of choice. Figure 7 compares GAT with graph convolutional network (GCN) (Kipf & Welling, 2016) on the AGILE action graph. Notably, GCN excels in simple tasks, whereas GAT outperforms it in tasks with large action spaces, such as CREATE and RecSim-pairing, due to its ability to facilitate RL training through sparse attention mechanisms."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We justify the selection of graph attention network (GAT) as the relational architecture by comparing it to a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE (Figure 7). Our results show that GCN outperforms GAT in simple grid world and RecSim tasks, likely due to its ability to act as a summarizer, even without learned edge weights. However, GCN struggles in CREATE and RecSim-pairing tasks (Figure 16), which involve large action spaces and diverse action relations. Moreover, we hypothesize that GAT's attention mechanism helps to create a sparse graph, making it easier to train reinforcement learning models, whereas a fully-connected GCN would be more challenging to train."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We justify the selection of graph attention network (GAT) as the relational architecture by comparing it to a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE (Figure 7). Our results show that GCN outperforms GAT in simple grid world and RecSim tasks, likely due to its ability to act as a summarizer, even without learned edge weights. However, GCN struggles in CREATE and RecSim-pairing tasks (Figure 16), which involve large action spaces and diverse action relations. Moreover, we hypothesize that GAT's attention mechanism helps to create a sparse graph, making it easier to train reinforcement learning models, whereas a fully-connected GCN would be more challenging to train."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We validate the choice of graph attention network (GAT) as the relational architecture. In Figure 7, we compare GAT with graph convolutional network (GCN) (Kipf & Welling, 2016) on the AGILE action graph. While GCN achieves optimal performance in simple tasks, GAT outperforms it in tasks with large action spaces, such as CREATE and RecSim-pairing, due to its ability to ease RL training through sparse attention."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: We justify the selection of the graph attention network (GAT) as our relational architecture of choice. Figure 7 compares GAT with graph convolutional network (GCN) (Kipf & Welling, 2016) on the AGILE action graph. Notably, GCN excels in simple tasks, whereas GAT outperforms it in tasks with large action spaces, such as CREATE and RecSim-pairing, due to its ability to facilitate RL training through sparse attention mechanisms."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "instruction": "Rewrite the middle part of this paragraph and improve the English in the remainder", "revised_paragraph": "Revised paragraph: We validate the choice of using a graph attention network (GAT) as the relational architecture by comparing it to a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. As shown in Figure 7, while GCN achieves optimal performance in simple grid world and RecSim tasks, GAT outperforms GCN in the more challenging CREATE and RecSim-pairing tasks (Figure 16), where a large action space requires diverse action relations. This is because the attention mechanism in GAT enables the model to selectively focus on relevant information, leading to a sparser graph that eases reinforcement learning training, whereas GCN's fully connected architecture can be more difficult to train in such scenarios.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "instruction": "Make this paragraph a bit more concise.", "revised_paragraph": "Revised paragraph: We validate the choice of graph attention network (GAT) as the relational architecture by comparing it to a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. While GCN achieves optimal performance in simple grid world and RecSim tasks, GAT outperforms it in CREATE and RecSim-pairing tasks with large action spaces, where diverse action relations are required. We attribute this to GAT's ability to make the graph sparse, easing RL training, which is more challenging in a fully-connected GCN.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"TERGM models often struggle to replicate realistic dynamics in online social networks due to limitations in their ability to capture triadic network properties. We propose TTERGM, a novel approach that integrates dynamics between influencers and followers to sequentially predict network probabilities (Code available at https://github.com/alvin68633466/TTERGM-Social-Theory-Driven-network-simulation). Figure 2 illustrates the TTERGM framework, comprising five components: data collection, network processing, feature extraction, pattern analysis, and a generative network module. The data collection module is discussed in Section 3.3.\""}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"TERGM models often struggle to replicate realistic dynamics in online social networks due to limitations in their Markov chain assumption. We hypothesized that incorporating triadic network properties would improve the model's accuracy. To address this, we propose TTERGM, a novel approach that integrates influencer-follower dynamics to sequentially predict network probabilities. Figure 2 illustrates the TTERGM framework, comprising five components: data collection, network processing, feature extraction, pattern analysis, and generative network modules.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"TERGM models often struggle to replicate realistic dynamics in online social networks due to limitations in their ability to capture triadic network properties. We propose TTERGM, a novel approach that integrates dynamics between influencers and followers to sequentially predict network probabilities (Code available at https://github.com/alvin68633466/TTERGM-Social-Theory-Driven-network-simulation). Figure 2 illustrates the TTERGM framework, comprising five components: data collection, network processing, feature extraction, pattern analysis, and a generative network module. The data collection module is discussed in Section 3.3.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"TERGM models often struggle to replicate realistic dynamics in online social networks due to limitations in their Markov chain assumption. We hypothesized that incorporating triadic network properties would improve the model's accuracy. To address this, we propose TTERGM, a novel approach that integrates influencer-follower dynamics to sequentially predict network probabilities. Figure 2 illustrates the TTERGM framework, comprising five components: data collection, network processing, feature extraction, pattern analysis, and generative network modules.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"TERGM models often struggle to replicate realistic dynamics in online social networks due to limitations in their ability to capture triadic network properties. We propose TTERGM, a novel approach that integrates dynamics between influencers and followers to sequentially predict network probabilities (Code available at https://github.com/alvin68633466/TTERGM-Social-Theory-Driven-network-simulation). Figure 2 illustrates the TTERGM framework, comprising five components: data collection, network processing, feature extraction, pattern analysis, and a generative network module. The data collection module is discussed in Section 3.3.\""}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"TERGM models often struggle to replicate realistic dynamics in online social networks due to limitations in capturing triadic network properties. We propose TTERGM, a novel approach that integrates dynamics between influencers and followers to sequentially predict network probabilities. The framework, illustrated in Figure 2, comprises five components: data processing, feature extraction, pattern analysis, and a generative network module.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"TERGM models often struggle to replicate realistic dynamics in online social networks due to limitations in their ability to capture triadic network properties. We propose TTERGM, a novel approach that integrates dynamics between influencers and followers to sequentially predict network probabilities (Code available at https://github.com/alvin68633466/TTERGM-Social-Theory-Driven-network-simulation). Figure 2 illustrates the TTERGM framework, comprising five components: data collection, network processing, feature extraction, pattern analysis, and a generative network module. The data collection module is discussed in Section 3.3.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"TERGM models often struggle to replicate realistic dynamics in online social networks due to limitations in their Markov chain assumption. We hypothesized that incorporating triadic network properties would improve the model's accuracy. To address this, we propose TTERGM, a novel approach that integrates influencer-follower dynamics to sequentially predict network probabilities. Figure 2 illustrates the TTERGM framework, comprising five components: data collection, network processing, feature extraction, pattern analysis, and generative network modules.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "instruction": "Remove the information about the code. And remove the last sentence.", "revised_paragraph": "Revised paragraph: We hypothesized that increasing the model\u2019s capacity to describe triadic network properties would reduce the error between the model and empirical observations. We propose TTERGM here to sequentially predict network probabilities by integrating the dynamics between influencers and followers. TTERGM was run on a computer with 12900K CPU, 1080TI and 128GB RAM. Figure 2 shows the framework of TTERGM, which consists of five major components: data collection module, network processing module, feature extraction module, pattern analysis module, and a generative network module.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.03", "instruction": "Remove the mentions to the code and to other sections.", "revised_paragraph": "Revised paragraph: \"TERGM models estimated within the Markov chain assumption are typically incapable of generating and reproducing realistic dynamics observed in real-world online social networks. We hypothesized that increasing the model's capacity to describe triadic network properties would reduce the error between the model and empirical observations. To address this limitation, we propose TTERGM, a novel approach that sequentially predicts network probabilities by integrating the dynamics between influencers and followers. The framework of TTERGM consists of five major components: data collection, network processing, feature extraction, pattern analysis, and a generative network module.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: It is well established that placing a target adjacent to the edge of the screen, known as an edge target, can significantly reduce movement time [3,9,10,24,25]. In contrast, pointing at a target in the center of the screen requires the cursor to come to a complete stop within the target. When pointing at an edge target, the cursor simply stops at the edge, allowing the user to complete the pointing action by moving the cursor horizontally relative to the edge. Furthermore, targets placed adjacent to the corner of the screen can be pointed to quickly by simply moving the cursor to the corner, as the target is easily accessible [24]."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: It is well established that placing the target adjacent to the edge of the screen, also known as the edge target, can significantly reduce movement time [3, 9, 10, 24, 25]. In contrast to center-located targets, which require the cursor to be precisely stopped within the target, edge targets enable the cursor to stop at the edge, allowing for a more efficient pointing motion. Furthermore, when the target is positioned at the corner of the screen, the cursor can be rapidly directed towards it by simply moving it to the corner, as demonstrated by [24]."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: It is well established that placing the target adjacent to the edge of the screen, also known as the edge target, can significantly reduce movement time [3, 9, 10, 24, 25]. In contrast to center-located targets, which require the cursor to be precisely stopped within the target, edge targets enable the cursor to stop at the edge, allowing for a more efficient pointing motion. Furthermore, when the target is positioned at the corner of the screen, the cursor can be rapidly directed towards it by simply moving it to the corner, as demonstrated by [24]."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: It is well established that placing a target adjacent to the edge of the screen, known as an edge target, can significantly reduce movement time [3,9,10,24,25]. In contrast, pointing at a target in the center of the screen requires the cursor to come to a complete stop within the target. When pointing at an edge target, the cursor simply stops at the edge, allowing the user to complete the pointing action by moving the cursor horizontally relative to the edge. Furthermore, targets placed adjacent to the corner of the screen can be pointed to quickly by simply moving the cursor to the corner, as the target is easily accessible [24]."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: It is well established that placing a target adjacent to the edge of the screen, known as an edge target, can significantly reduce movement time [3,9,10,24,25]. In contrast, pointing at a target in the center of the screen requires the cursor to come to a complete stop within the target. When pointing at an edge target, the cursor simply stops at the edge, allowing the user to complete the pointing action by moving the cursor horizontally relative to the edge. Furthermore, targets placed adjacent to the corner of the screen can be pointed to quickly by simply moving the cursor to the corner, as the target is easily accessible [24]."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: It is well established that edge targets, placed adjacent to the screen's edge, can significantly reduce movement time [3,9,10,24,25]. In contrast, center-screen targets require the cursor to come to a complete stop within the target. When pointing at an edge target, the cursor simply stops at the edge, allowing the user to complete the pointing action by moving the cursor horizontally relative to the edge. Moreover, corner-placed targets can be pointed to quickly by simply moving the cursor to the corner, as they are easily accessible [24]."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: It is well established that placing the target adjacent to the edge of the screen, also known as the edge target, can significantly reduce movement time [3, 9, 10, 24, 25]. In contrast to center-located targets, which require the cursor to be precisely stopped within the target, edge targets enable the cursor to stop at the edge, allowing for a more efficient pointing motion. Furthermore, when the target is positioned at the corner of the screen, the cursor can be rapidly directed towards it by simply moving it to the corner, as demonstrated by [24]."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: It is well established that placing a target adjacent to the edge of the screen, known as an edge target, can significantly reduce movement time [3,9,10,24,25]. In contrast, pointing at a target in the center of the screen requires the cursor to come to a complete stop within the target. When pointing at an edge target, the cursor simply stops at the edge, allowing the user to complete the pointing action by moving the cursor horizontally relative to the edge. Furthermore, targets placed adjacent to the corner of the screen can be pointed to quickly by simply moving the cursor to the corner, as the target is easily accessible [24]."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "instruction": "Rewrite this paragraph and choose better words", "revised_paragraph": "Revised paragraph: \"It is well-established that placing a target at the edge of the screen can significantly reduce movement time [3, 9, 10, 24, 25]. When a target is positioned in the center of the screen, the cursor must be stopped precisely within the target's boundaries. In contrast, when a target is placed at the edge, the cursor can be stopped at the edge itself, allowing for faster completion of the pointing task. Furthermore, when a target is situated at a corner, the cursor can be quickly directed to the target by simply moving it to the corner, eliminating the need for precise targeting [24].\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.06", "instruction": "Reorganise the flow of ideas when a sentence is confusing. Try to shorten the paragraph a bit.", "revised_paragraph": "Revised paragraph: The edge target, placed adjacent to the screen's edge, has been shown to reduce movement time [3,9,10,24,25]. Unlike center targets, which require the cursor to stop inside the target, edge targets allow the cursor to stop at the edge, enabling horizontal movement to complete the pointing task. Furthermore, targets adjacent to the corner of the screen can be pointed quickly by simply hitting the corner with the cursor [24].", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nThe proposed methods for handling action unavailability in listwise RL can be categorized into four approaches. The Mask-Output method assumes a fixed action space and masks out unavailable actions, which is similar to previous works by Boutilier et al. and Chandak et al. (2020a) and Huang & Onta\u00f1\u00f3n (2020). The Mask-Input-Output method extends this approach by incorporating a binary availability mask into the state input. In contrast, the Utility-Policy method proposed by Jain et al. (2020) computes the utility of each action independently, ignoring any interdependencies between actions. Finally, the Simple DQN method is a baseline that selects the top-K items without considering action interdependencies or reasoning about the overall list."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nThe proposed methods for handling action unavailability in listwise RL can be categorized into four approaches. The Mask-Output method assumes a fixed action space and masks out unavailable actions, which is similar to previous works by Boutilier et al. and Chandak et al. (2020a) and Huang & Onta\u00f1\u00f3n (2020). The Mask-Input-Output method extends this approach by incorporating a binary availability mask into the state input. In contrast, the Utility-Policy method proposed by Jain et al. (2020) computes the utility of each action independently, ignoring any interdependencies between actions. Finally, the Simple DQN method is a baseline that selects the top-K items without considering action interdependencies or reasoning about the overall list."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nThe proposed methods for handling action unavailability in listwise RL can be categorized into four approaches. The Mask-Output method assumes a fixed action space and masks out unavailable actions, which is similar to previous works by Boutilier et al. and Chandak et al. (2020a) and Huang & Onta\u00f1\u00f3n (2020). The Mask-Input-Output method extends this approach by incorporating a binary availability mask into the state input. In contrast, the Utility-Policy method proposed by Jain et al. (2020) computes the utility of each action independently, ignoring any interdependencies between actions. Finally, the Simple DQN method is a baseline that selects the top-K items without considering action interdependencies or reasoning about the overall list."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nThe proposed methods for handling action unavailability in listwise RL can be categorized into four approaches. The Mask-Output method assumes a fixed action space and masks out unavailable actions, which is similar to previous works by Boutilier et al. and Chandak et al. (2020a) and Huang & Onta\u00f1\u00f3n (2020). The Mask-Input-Output method extends this approach by incorporating a binary availability mask into the state input. In contrast, the Utility-Policy method proposed by Jain et al. (2020) computes the utility of each action independently, ignoring any interdependencies between actions. Finally, the Simple DQN method is a baseline that selects the top-K items without considering action interdependencies or reasoning about the overall list."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nThe proposed methods for handling action unavailability in listwise RL can be categorized into four approaches. The Mask-Output method assumes a fixed action space and masks out unavailable actions, which is similar to previous works by Boutilier et al. and Chandak et al. (2020a) and Huang & Onta\u00f1\u00f3n (2020). The Mask-Input-Output method extends this approach by incorporating a binary availability mask into the state input. In contrast, the Utility-Policy method proposed by Jain et al. (2020) computes the utility of each action independently, ignoring any interdependencies between actions. Finally, the Simple DQN method is a baseline that selects the top-K items without considering action interdependencies or reasoning about the overall list."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nThe proposed methods for handling action unavailability in listwise RL can be categorized into four approaches. The Mask-Output method assumes a fixed action space and masks out unavailable actions, which is similar to previous works by Boutilier et al. and Chandak et al. (2020a) and Huang & Onta\u00f1\u00f3n (2020). The Mask-Input-Output method extends this approach by incorporating a binary availability mask into the state input. In contrast, the Utility-Policy method proposed by Jain et al. (2020) computes the utility of each action independently, ignoring any interdependencies between actions. Finally, the Simple DQN method is a baseline that selects the top-K items without considering action interdependencies or reasoning about the overall list."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nThe proposed methods for handling action unavailability in listwise RL can be categorized into four approaches. The Mask-Output method assumes a fixed action space and masks out unavailable actions, which is similar to previous works by Boutilier et al. and Chandak et al. (2020a) and Huang & Onta\u00f1\u00f3n (2020). The Mask-Input-Output method extends this approach by incorporating a binary availability mask into the state input. In contrast, the Utility-Policy method proposed by Jain et al. (2020) computes the utility of each action independently, ignoring any interdependencies between actions. Finally, the Simple DQN method is a baseline that selects the top-K items without considering action interdependencies or reasoning about the overall list."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nThe proposed methods for handling action unavailability in listwise RL can be categorized into four approaches. The Mask-Output method assumes a fixed action space and masks out unavailable actions, which is similar to previous works by Boutilier et al. and Chandak et al. (2020a) and Huang & Onta\u00f1\u00f3n (2020). The Mask-Input-Output method extends this approach by incorporating a binary availability mask into the state input. In contrast, the Utility-Policy method proposed by Jain et al. (2020) computes the utility of each action independently, ignoring any interdependencies between actions. Finally, the Simple DQN method is a baseline that selects the top-K items without considering action interdependencies or reasoning about the overall list."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "instruction": "Rewrite the middle sentences, preferring active formulations over passive ones.", "revised_paragraph": "Revised paragraph: \"\u2022 Mask-Output (No representations, No input action set): We mask out q-values or policy probabilities for unavailable actions, assuming a fixed action space in the output. This approach represents prior SAS-MDP works, as seen in Boutilier et al. and Chandak et al. (2020a), Huang & Onta\u00f1\u00f3n (2020). \u2022 Mask-Input-Output (No representations): We augment the binary availability mask of given actions, with 1s for available indices and 0s for unavailable, to the state input of Mask-Output. \u2022 Utility-Policy (No input action set): Jain et al. (2020) proposed using action representations independently to compute each action's utility, ignoring any interdependence. \u2022 Simple DQN (No cascade, No input action set): For listwise RL specifically, we include a DQN baseline that selects top-K items, rather than reasoning about the overall list, thus ignoring both action interdependences: (i) on other available actions, (ii) on other items in the list.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.13", "instruction": "\"No representations\" become \"No action representations\". Rewrite the \"Mask-Input-Output\" and \"Utility-Policy\" points in the list for better readability. Uniformise the language in the paragraph.", "revised_paragraph": "Revised paragraph: \n\nThis paper presents various methods for addressing action interdependencies in listwise reinforcement learning. The \"Mask-Input-Output\" approach involves augmenting the binary availability mask of given actions to the state input, while the \"Utility-Policy\" method uses action representations independently to compute each action's utility, disregarding interdependencies. In contrast, the \"Simple DQN\" baseline selects the top-K items without considering action interdependencies. These methods build upon previous works, including those by Boutilier et al., Chandak et al. (2020a), Huang & Onta\u00f1\u00f3n (2020), and Jain et al. (2020).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Let S = {s_k | s_k \u2208 Z^3} denote a series of window sizes, where s_0 is the size of the query window and s_1,..., s_M are the sizes of M successively larger key windows. The input voxel set V = {(x_i, f_i) | i = 1}^{|V|} consists of voxels with xyz coordinates x_i \u2208 Z^3 and feature vectors f_i \u2208 R^C. We partition V into non-overlapping 3D windows of size s_0 and identify non-empty ones as query windows with centers {c_i | c_i \u2208 Z^3}^L_0, where L is the total number of query windows. For each query window centered on c_i, we gather all non-empty voxels within the window to form the query set V_c_i, s_0. To maintain efficiency, we introduce a novel chessboard sampling strategy, which is detailed in Section 3.1.2."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Let S = {s_k | s_k \u2208 Z^3} denote a series of window sizes, where s_0 is the size of the query window and s_1,..., s_M are the sizes of M successively larger key windows. The input voxel set V = {(x_i, f_i) | i = 1}^{|V|} consists of voxels with xyz coordinates x_i \u2208 Z^3 and feature vectors f_i \u2208 R^C. We partition V into non-overlapping 3D windows of size s_0 and identify non-empty ones as query windows with centers {c_i | c_i \u2208 Z^3}^L_0, where L is the total number of query windows. For each query window centered on c_i, we gather all non-empty voxels within the window to form the query set V_c_i, s_0. To maintain efficiency, we introduce a novel chessboard sampling strategy, which is detailed in Section 3.1.2."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Let S = {s_k | s_k \u2208 Z^3} denote a series of window sizes, where s_0 is the size of the query window and s_1,..., s_M are the sizes of M successively larger key windows. The input voxel set V = {(x_i, f_i) | i = 1}^{|V|} consists of voxels with xyz coordinates x_i \u2208 Z^3 and feature vectors f_i \u2208 R^C. We partition V into non-overlapping 3D windows of size s_0 and identify non-empty ones as query windows with centers {c_i | c_i \u2208 Z^3}^L_0, where L is the total number of query windows. For each query window centered on c_i, we gather all non-empty voxels within the window to form the query set V_c_i, s_0. To maintain efficiency, we introduce a novel chessboard sampling strategy, which is detailed in Section 3.1.2."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Let S = {s_k | s_k \u2208 Z^3} denote a series of window sizes, where s_0 is the size of the query window and s_1,..., s_M are the sizes of M successively larger key windows. The input voxel set V = {(x_i, f_i) | i = 1}^{|V|} consists of voxels with xyz coordinates x_i \u2208 Z^3 and feature vectors f_i \u2208 R^C. We partition V into non-overlapping 3D windows of size s_0 and identify non-empty ones as query windows with centers {c_i | c_i \u2208 Z^3}^L_0, where L is the total number of query windows. For each query window centered on c_i, we gather all non-empty voxels within the window to form the query set V_c_i, s_0. To maintain efficiency, we introduce a novel chessboard sampling strategy, which is detailed in Section 3.1.2."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Let S = {s_k | s_k \u2208 Z^3} denote a series of window sizes, where s_0 is the size of the query window and s_1,..., s_M are the sizes of M successively larger key windows. The input voxel set V = {(x_i, f_i) | i = 1}^{|V|} consists of voxels with xyz coordinates x_i \u2208 Z^3 and feature vectors f_i \u2208 R^C. We partition V into non-overlapping 3D windows of size s_0 and identify non-empty ones as query windows with centers {c_i | c_i \u2208 Z^3}^L_0, where L is the total number of query windows. For each query window centered on c_i, we gather all non-empty voxels within the window to form the query set V_c_i, s_0. To maintain efficiency, we introduce a novel chessboard sampling strategy, which is detailed in Section 3.1.2."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Let S = {s_k | s_k \u2208 Z^3} denote a series of window sizes, where s_0 is the size of the query window and s_1,..., s_M are the sizes of M successively larger key windows. The input voxel set V = {(x_i, f_i) | i = 1}^{|V|} consists of voxels with xyz coordinates x_i \u2208 Z^3 and feature vectors f_i \u2208 R^C. We partition V into non-overlapping 3D windows of size s_0 and identify non-empty ones as query windows with centers {c_i | c_i \u2208 Z^3}^L_0, where L is the total number of query windows. For each query window centered on c_i, we gather all non-empty voxels within the window to form the query set V_c_i, s_0. To maintain efficiency, we introduce a novel chessboard sampling strategy, which is detailed in Section 3.1.2."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Let S = {s_k | s_k \u2208 Z^3} denote a series of window sizes, where s_0 is the size of the query window and s_1,..., s_M are the sizes of M successively larger key windows. The input voxel set V = {(x_i, f_i) | i = 1}^{|V|} consists of voxels with xyz coordinates x_i \u2208 Z^3 and feature vectors f_i \u2208 R^C. We partition V into non-overlapping 3D windows of size s_0 and identify non-empty ones as query windows with centers {c_i | c_i \u2208 Z^3}^L_0, where L is the total number of query windows. For each query window centered on c_i, we gather all non-empty voxels within the window to form the query set V_c_i, s_0. To maintain efficiency, we introduce a novel chessboard sampling strategy, which is detailed in Section 3.1.2."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Let S = {s_k | s_k \u2208 Z^3} denote a series of window sizes, where s_0 is the size of the query window and s_1,..., s_M are the sizes of M successively larger key windows. The input voxel set V = {(x_i, f_i) | i = 1}^{|V|} consists of voxels with xyz coordinates x_i \u2208 Z^3 and feature vectors f_i \u2208 R^C. We partition V into non-overlapping 3D windows of size s_0 and identify non-empty ones as query windows with centers {c_i | c_i \u2208 Z^3}^L_0, where L is the total number of query windows. For each query window centered on c_i, we gather all non-empty voxels within the window to form the query set V_c_i, s_0. To maintain efficiency, we introduce a novel chessboard sampling strategy, which is detailed in Section 3.1.2."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "instruction": "Rewrite this paragraph for improved readability.", "revised_paragraph": "Revised paragraph: \n\nThis study introduces a series of window sizes, denoted as {s_k | s_k \u2208 Z_3} Mk = 0, where s_0 represents the query window size and s_1,..., M are the sizes of M successively larger key windows. The input voxel set V = {v_i | v_i = (x_i, f_i)} with |V| = i = 1 is defined, comprising xyz coordinates x_i \u2208 Z_3 and feature vector f_i \u2208 R_C for each voxel i. The voxel set is initially partitioned into non-overlapping 3D windows of size s_0, and the non-empty ones are identified as query windows with their centers denoted as {c_i | c_i \u2208 Z_3} Li = 0, where L is the total number of query windows. For each query window centered on c_i, the corresponding query voxels V_c_i, s_0 can be obtained by gathering all non-empty voxels within the window. To optimize efficiency, a novel chessboard sampling strategy is presented in Section 3.1.2.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "jyac3IgQ44.f4au9jfat5.03", "instruction": "Improve the readability of this paragraph.", "revised_paragraph": "Revised paragraph: \n\nTo facilitate the analysis, we define a series of window sizes, denoted as {s_k | s_k \u2208 Z_3} Mk = 0, where s_0 represents the size of the query window, and s_1,..., M are the sizes of M successively larger key windows. The input voxel set, V = {v_i | v_i = (x_i, f_i)}, comprising |V| = 1 voxels with xyz coordinates x_i \u2208 Z_3 and feature vectors f_i \u2208 R^C, is partitioned into non-overlapping 3D windows of size s_0. The non-empty windows are identified as query windows, with their centers denoted by {c_i | c_i \u2208 Z_3} Li = 0, where L is the total number of query windows. For each query window centered on c_i, the corresponding query voxels V_c_i, s_0 can be obtained by collecting all non-empty voxels within the window. To achieve efficiency, we propose a novel chessboard sampling strategy, which is detailed in Section 3.1.2.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles, which outperforms existing works on the anytime prediction task. Our automatic sharing improves single member performance by 2% compared to baselines, and matches efficient ensemble performance in the low-parameter regime while offering flexibility. With just 50% of the parameters, SuperWeight Ensembles outperform standard ensembles on ImageNet. We believe this represents a promising step forward in parameter-efficiency, and future work will focus on exploring architecture diversity.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In this study, we propose SuperWeight Ensembles, a novel method for parameter sharing in heterogeneous ensembles. By leveraging gradient information, SuperWeight Ensembles outperform existing approaches on the anytime prediction task, achieving a 2% improvement in single member performance compared to baselines. Notably, our automatic sharing mechanism matches the performance of efficient ensembles in the low-parameter regime, while offering the added flexibility to adjust parameters, a capability not previously available. Furthermore, when we increase the number of parameters, we surpass the performance of standard ensembles on ImageNet, utilizing only 50% of the parameters. We believe that SuperWeight Ensembles represent a significant advancement in parameter efficiency. Future research will focus on exploring architecture diversity in greater depth, as Gontijo-Lopes et al. (2021) have demonstrated that model architecture heterogeneity can be a crucial factor in ensemble diversity on challenging tasks.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In this study, we propose SuperWeight Ensembles, a novel method for parameter sharing in heterogeneous ensembles. By leveraging gradient information, SuperWeight Ensembles outperform existing approaches on the anytime prediction task, achieving a 2% improvement in single member performance compared to baselines. Notably, our automatic sharing mechanism matches the performance of efficient ensembles in the low-parameter regime, while offering the added flexibility to adjust parameters, a capability not previously available. Furthermore, when we increase the number of parameters, we surpass the performance of standard ensembles on ImageNet, utilizing only 50% of the parameters. We believe that SuperWeight Ensembles represent a significant advancement in parameter efficiency. Future research will focus on exploring architecture diversity in greater depth, as Gontijo-Lopes et al. (2021) have demonstrated that model architecture heterogeneity can be a crucial factor in ensemble diversity on challenging tasks.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In this study, we propose SuperWeight Ensembles, a novel method for parameter sharing in heterogeneous ensembles. By leveraging gradient information, SuperWeight Ensembles outperform existing approaches on the anytime prediction task, achieving a 2% improvement in single member performance compared to baselines. Notably, our automatic sharing mechanism matches the performance of efficient ensembles in the low-parameter regime, while offering the added flexibility to adjust parameters, a capability not previously available. Furthermore, when we increase the number of parameters, we surpass the performance of standard ensembles on ImageNet, utilizing only 50% of the parameters. We believe that SuperWeight Ensembles represent a significant advancement in parameter efficiency. Future research will focus on exploring architecture diversity in greater depth, as Gontijo-Lopes et al. (2021) have demonstrated that model architecture heterogeneity can be a crucial factor in ensemble diversity on challenging tasks.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles, which outperforms existing works on the anytime prediction task. Our automatic sharing improves single member performance by 2% compared to baselines, and matches efficient ensemble performance in the low-parameter regime while offering flexibility. With just 50% of the parameters, SuperWeight Ensembles outperform standard ensembles on ImageNet. We believe this represents a promising step forward in parameter-efficiency, and future work will focus on exploring architecture diversity.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In this study, we propose SuperWeight Ensembles, a novel method for parameter sharing in heterogeneous ensembles. By leveraging gradient information, SuperWeight Ensembles outperform existing approaches on the anytime prediction task, achieving a 2% improvement in single member performance compared to baselines. Notably, our automatic sharing mechanism matches the performance of efficient ensembles in the low-parameter regime, while offering the added flexibility to adjust parameters, a capability not previously available. Furthermore, when we increase the number of parameters, we surpass the performance of standard ensembles on ImageNet, utilizing only 50% of the parameters. We believe that SuperWeight Ensembles represent a significant advancement in parameter efficiency. Future research will focus on exploring architecture diversity in greater depth, as Gontijo-Lopes et al. (2021) have demonstrated that model architecture heterogeneity can be a crucial factor in ensemble diversity on challenging tasks.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles, which outperforms existing works on the anytime prediction task. Our automatic sharing improves single member performance by 2% compared to baselines, and matches efficient ensemble performance in the low-parameter regime while offering flexibility. With just 50% of the parameters, SuperWeight Ensembles outperform standard ensembles on ImageNet. We believe this represents a promising step forward in parameter-efficiency, and future work will focus on exploring architecture diversity.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We present SuperWeight Ensembles, a novel method for parameter sharing in heterogeneous ensembles, which surpasses existing approaches in the anytime prediction task. Our automatic sharing mechanism enhances the performance of individual ensemble members by 2% compared to baselines, while matching the efficiency of traditional ensembles in the low-parameter regime and offering greater flexibility. Notably, SuperWeight Ensembles outperform standard ensembles on ImageNet with only 50% of the parameters. We believe this represents a significant step forward in parameter-efficient ensemble methods, and future research will focus on exploring the benefits of architecture diversity in this context.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In this study, we propose SuperWeight Ensembles, a novel method for parameter sharing in heterogeneous ensembles. By leveraging gradient information, SuperWeight Ensembles outperform existing approaches on the anytime prediction task, achieving a 2% improvement in single member performance compared to baselines. Notably, our automatic sharing mechanism matches the performance of efficient ensembles in the low-parameter regime, while offering the added flexibility to adjust parameters, a capability not previously available. Furthermore, when we increase the number of parameters, we surpass the performance of standard ensembles on ImageNet, utilizing only 50% of the parameters. We believe that SuperWeight Ensembles represent a significant advancement in parameter efficiency. Future research will focus on exploring architecture diversity in greater depth, as Gontijo-Lopes et al. (2021) have demonstrated that model architecture heterogeneity can be a crucial factor in ensemble diversity on challenging tasks.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In this study, we propose SuperWeight Ensembles, a novel method for parameter sharing in heterogeneous ensembles. By leveraging gradient information, SuperWeight Ensembles outperform existing approaches on the anytime prediction task, achieving a 2% improvement in single member performance compared to baselines. Notably, our automatic sharing mechanism matches the performance of efficient ensembles in the low-parameter regime, while offering the added flexibility to adjust parameters, a capability not previously available. Furthermore, when we increase the number of parameters, we surpass the performance of standard ensembles on ImageNet, utilizing only 50% of the parameters. We believe that SuperWeight Ensembles represent a significant advancement in parameter efficiency. Future research will focus on exploring architecture diversity in greater depth, as Gontijo-Lopes et al. (2021) have demonstrated that model architecture heterogeneity can be a crucial factor in ensemble diversity on challenging tasks.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles, which outperforms existing works on the anytime prediction task. Our automatic sharing improves single member performance by 2% compared to baselines, and matches efficient ensemble performance in the low-parameter regime while offering flexibility. With just 50% of the parameters, SuperWeight Ensembles outperform standard ensembles on ImageNet. We believe this represents a promising step forward in parameter-efficiency, and future work will focus on exploring architecture diversity.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We present SuperWeight Ensembles, a novel method for parameter sharing in heterogeneous ensembles, which surpasses existing approaches in the anytime prediction task. Our automatic sharing mechanism enhances the performance of individual ensemble members by 2% compared to baselines, while matching the efficiency of traditional ensembles in the low-parameter regime and offering greater flexibility. Notably, SuperWeight Ensembles outperform standard ensembles on ImageNet with only 50% of the parameters. We believe this represents a significant step forward in parameter-efficient ensemble methods, and future research will focus on exploring the benefits of architecture diversity in this context.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "Revised paragraph: \n\nIn this study, we propose SuperWeight Ensembles, a novel method for parameter sharing in heterogeneous ensembles that leverages gradient information to facilitate effective sharing. Our approach outperforms existing works on the anytime prediction task, achieving a 2% improvement in single-member performance compared to baselines. Notably, SuperWeight Ensembles match the performance of efficient ensembles in the low-parameter regime while offering the flexibility to adjust parameters, a capability lacking in prior work. Moreover, when we add parameters, our approach outperforms standard ensembles on ImageNet with just 50% of the parameters. We believe that SuperWeight Ensembles represent a promising step forward in parameter-efficiency, and future work will focus on further exploring architecture diversity, as demonstrated by Gontijo-Lopes et al. (2021), who showed that model architecture heterogeneity can be a key contributor to ensemble diversity on challenging tasks.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "instruction": "Make this paragraph a bit more concise.", "revised_paragraph": "Revised paragraph: \"We introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles, which outperforms existing works on the anytime prediction task by leveraging gradient information. Our automatic sharing improves single member performance by 2% compared to baselines, matching efficient ensemble performance in the low-parameter regime while offering flexibility to adjust parameters. With added parameters, SuperWeight Ensembles outperform standard ensembles on ImageNet with just 50% of the parameters. Future work will explore architecture diversity, building on Gontijo-Lopes et al. (2021), which highlights the importance of model architecture heterogeneity for ensemble diversity on challenging tasks.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: The core of this proof is centered on substituting a neural network for the inner product between the branch net and trunk net, leveraging its ability to approximate infinitely differentiable functions with low complexity and better performance. While DeepONet has been shown to have defects, it can be replaced with a neural network that takes E(u) and y as input. The number of basis p in DeepONet increases the number of parameters in the trunk net, which can be considered a target network in HyperDeepONet. In contrast, models such as Shift-DeepONet and flexDeepONet achieve the desired accuracy with a small number of basis, but require a trade-off, where the first hidden layer of the target network needs numerous units. Notably, NOMAD uses a fully nonlinear reconstruction, with no restriction on the dimension of the last hidden layer in the target network, but the first hidden layer must be wide enough, increasing the number of parameters. For further details, refer to Appendix C."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: The core of this proof substitutes a neural network for the inner product between the branch net and trunk net, leveraging its ability to approximate infinitely differentiable functions with low complexity. This approach has been explored in models like Shift-DeepONet and flexDeepONet, which achieve desired accuracy with a small number of basis. However, there is a trade-off, as the first hidden layer of the target network requires numerous units. Details can be found in Appendix C."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nThe crux of this proof lies in substituting a neural network for the inner product between the branch net and trunk net. This approach is feasible because the inner product is an infinitely differentiable function, which can be approximated with better performance by a neural network with low complexity. Notably, the DeepONet can be replaced with a neural network that takes E(u) and y as input. Increasing the number of basis p in DeepONet, however, results in a larger number of parameters for the trunk net, which can be viewed as a target network in HyperDeepONet. While models like Shift-DeepONet and flexDeepONet can achieve the desired accuracy with a small number of basis, there is a trade-off in which the first hidden layer of the target network requires a large number of units. In contrast, NOMAD, which employs a fully nonlinear reconstruction, does not impose a restriction on the dimension of the last hidden layer of the target network. Nevertheless, the first hidden layer of the target network must be wide enough, leading to an increase in the number of parameters. Further details can be found in Appendix C."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The core of this proof substitutes a neural network for the inner product between the branch net and trunk net, leveraging its ability to approximate infinitely differentiable functions with low complexity. This approach has been explored in models like Shift-DeepONet and flexDeepONet, which achieve desired accuracy with a small number of basis. However, there is a trade-off, as the first hidden layer of the target network requires numerous units. Details can be found in Appendix C."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nThe crux of this proof lies in substituting a neural network for the inner product between the branch net and trunk net. This approach is feasible because the inner product is an infinitely differentiable function, which can be approximated with better performance by a neural network with low complexity. Notably, the DeepONet can be replaced with a neural network that takes E(u) and y as input. Increasing the number of basis p in DeepONet, however, results in a larger number of parameters for the trunk net, which can be viewed as a target network in HyperDeepONet. While models like Shift-DeepONet and flexDeepONet can achieve the desired accuracy with a small number of basis, there is a trade-off in which the first hidden layer of the target network requires a large number of units. In contrast, NOMAD, which employs a fully nonlinear reconstruction, does not impose a restriction on the dimension of the last hidden layer of the target network. Nevertheless, the first hidden layer of the target network must be wide enough, leading to an increase in the number of parameters. Further details can be found in Appendix C."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: The core of this proof is centered on substituting a neural network for the inner product between the branch net and trunk net, leveraging its ability to approximate infinitely differentiable functions with low complexity and better performance. While DeepONet has been shown to have defects, it can be replaced with a neural network that takes E(u) and y as input. The number of basis p in DeepONet increases the number of parameters in the trunk net, which can be considered a target network in HyperDeepONet. In contrast, models such as Shift-DeepONet and flexDeepONet achieve the desired accuracy with a small number of basis, but require a trade-off, where the first hidden layer of the target network needs numerous units. Notably, NOMAD uses a fully nonlinear reconstruction, with no restriction on the dimension of the last hidden layer in the target network, but the first hidden layer must be wide enough, increasing the number of parameters. For further details, refer to Appendix C."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: The core of this proof is centered on substituting a neural network for the inner product between the branch net and trunk net, leveraging its ability to approximate infinitely differentiable functions with low complexity and better performance. While DeepONet has been shown to have defects, it can be replaced with a neural network that takes E(u) and y as input. The number of basis p in DeepONet increases the number of parameters in the trunk net, which can be considered a target network in HyperDeepONet. In contrast, models such as Shift-DeepONet and flexDeepONet achieve the desired accuracy with a small number of basis, but require a trade-off, where the first hidden layer of the target network needs numerous units. Notably, NOMAD uses a fully nonlinear reconstruction, with no restriction on the dimension of the last hidden layer in the target network, but the first hidden layer must be wide enough, increasing the number of parameters. For further details, refer to Appendix C."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: The core of this proof involves substituting a neural network for the inner product between the branch and trunk nets, leveraging its ability to approximate infinitely differentiable functions with low complexity. While DeepONet has limitations, it can be replaced with a neural network taking E(u) and y as input. This approach offers better performance and fewer parameters compared to models like Shift-DeepONet and flexDeepONet, which require a trade-off between accuracy and the number of hidden units."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The crux of this proof lies in substituting a neural network for the inner product between the branch and trunk nets, capitalizing on its capacity to approximate infinitely differentiable functions with minimal complexity. Notwithstanding the limitations of DeepONet, it can be supplanted by a neural network that takes E(u) and y as input. This approach yields superior performance and a reduced parameter count compared to models like Shift-DeepONet and flexDeepONet, which necessitate a trade-off between accuracy and the number of hidden units."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The core of this proof substitutes a neural network for the inner product between the branch net and trunk net, leveraging its ability to approximate infinitely differentiable functions with low complexity. This approach has been explored in models like Shift-DeepONet and flexDeepONet, which achieve desired accuracy with a small number of basis. However, there is a trade-off, as the first hidden layer of the target network requires numerous units. Details can be found in Appendix C."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The crux of this proof involves substituting a neural network for the inner product between the branch net and trunk net, capitalizing on its capacity to approximate infinitely differentiable functions with minimal complexity. This approach has been explored in models such as Shift-DeepONet and flexDeepONet, which have demonstrated desired accuracy with a relatively small number of basis functions. Notably, this approach comes with a trade-off, as the first hidden layer of the target network requires a significant number of units. Further details can be found in Appendix C."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: The core of this proof is centered on substituting a neural network for the inner product between the branch net and trunk net, leveraging its ability to approximate infinitely differentiable functions with low complexity and better performance. While DeepONet has been shown to have defects, it can be replaced with a neural network that takes E(u) and y as input. The number of basis p in DeepONet increases the number of parameters in the trunk net, which can be considered a target network in HyperDeepONet. In contrast, models such as Shift-DeepONet and flexDeepONet achieve the desired accuracy with a small number of basis, but require a trade-off, where the first hidden layer of the target network needs numerous units. Notably, NOMAD uses a fully nonlinear reconstruction, with no restriction on the dimension of the last hidden layer in the target network, but the first hidden layer must be wide enough, increasing the number of parameters. For further details, refer to Appendix C."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "instruction": "Remove unnecessary details. Include citation.", "revised_paragraph": "Revised paragraph: The core of this proof is based on substituting a neural network for the inner product between the branch net and trunk net, as it can approximate the infinitely differentiable function with better performance (Rahman et al., 2020). The DeepONet's defects can be addressed by replacing it with a neural network with E(u) and y as input. Models such as Shift-DeepONet and flexDeepONet achieved desired accuracy with a small number of basis, but with a trade-off of requiring numerous units in the first hidden layer of the target network.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "5t8NvKONr.tls-ZX2iE.02", "instruction": "Rewrite the beginning of the paragraph to improve the argumentation.", "revised_paragraph": "Revised paragraph: The current proof relies on substituting a neural network for the inner product between the branch net and trunk net, which is a crucial innovation. By doing so, we can leverage the neural network's ability to approximate infinitely differentiable functions, such as the inner product, with better performance. Interestingly, the DeepONet's limitations become apparent when we realize that it can be replaced with a neural network that takes E(u) and y as input. Furthermore, the number of basis p in DeepONet increases the number of parameters in the trunk net, which can be considered a target network in HyperDeepONet. While models like Shift-DeepONet and flexDeepONet have achieved desired accuracy with a small number of basis, they are not without their trade-offs, such as requiring numerous units in the first hidden layer of the target network. In contrast, NOMAD's fully nonlinear reconstruction has no such restriction on the dimension of the last hidden layer, but still requires a wide first hidden layer, thereby increasing the number of parameters. For further details, please refer to Appendix C.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Nevertheless, existing pre-training strategies for protein-protein interactions have limitations. Recently, protein language models have drawn attention by adopting the mask-predict paradigm to protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). These methods partially mask amino acid types and use neural networks to recover the masked information, which can predict the mutational effects on binding by correlating the probability of amino acid types with changes in binding free energy (Yang et al., 2022)."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: Despite limitations of pre-training strategies in capturing protein-protein interactions, recent success of protein language models has drawn attention to adopting the mask-predict paradigm for protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). These methods mask amino acid types and use neural networks to recover the information, showing correlation between probability changes and binding free energy changes (Yang et al., 2022), making them unsupervised predictors of mutational effects on binding."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWhile pre-training strategies have shown promise, they often fail to capture the fundamental nature of protein-protein interactions. Recently, the success of protein language models has led to the adoption of the mask-predict paradigm, inspired by BERT, to predict protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). This approach involves partially masking amino acid types on a protein backbone and using neural networks to recover the masked information. Notably, studies have shown that the difference in amino acid type probabilities before and after mutation correlates with changes in binding free energy (Yang et al., 2022). As such, these methods can serve as unsupervised predictors of mutational effects on binding."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWhile pre-training strategies have shown promise, they often fail to capture the fundamental nature of protein-protein interactions. Recently, the success of protein language models has led to the adoption of the mask-predict paradigm, inspired by BERT, to predict protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). This approach involves partially masking amino acid types on a protein backbone and using neural networks to recover the masked information. Notably, studies have shown that the difference in amino acid type probabilities before and after mutation correlates with changes in binding free energy (Yang et al., 2022). As such, these methods can serve as unsupervised predictors of mutational effects on binding."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWhile pre-training strategies have shown promise, they often fail to capture the fundamental nature of protein-protein interactions. Recently, the success of protein language models has led to the adoption of the mask-predict paradigm, inspired by BERT, to predict protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). This approach involves partially masking amino acid types on a protein backbone and using neural networks to recover the masked information. Notably, studies have shown that the difference in amino acid type probabilities before and after mutation correlates with changes in binding free energy (Yang et al., 2022). As such, these methods can serve as unsupervised predictors of mutational effects on binding."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Nevertheless, existing pre-training strategies for protein-protein interactions have limitations. Recently, protein language models have drawn attention by adopting the mask-predict paradigm to protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). These methods partially mask amino acid types and use neural networks to recover the masked information, which can predict the mutational effects on binding by correlating the probability of amino acid types with changes in binding free energy (Yang et al., 2022)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Despite limitations of pre-training strategies in capturing protein-protein interactions, recent success of protein language models has drawn attention to adopting the mask-predict paradigm for protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). These methods mask amino acid types and use neural networks to recover the information, showing correlation between probability changes and binding free energy changes (Yang et al., 2022), making them unsupervised predictors of mutational effects on binding."}, {"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWhile pre-training strategies have shown promise, they often fail to capture the fundamental nature of protein-protein interactions. Recently, the success of protein language models has led to the adoption of the mask-predict paradigm, inspired by BERT, to predict protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). This approach involves partially masking amino acid types on a protein backbone and using neural networks to recover the masked information. Notably, studies have shown that the difference in amino acid type probabilities before and after mutation correlates with changes in binding free energy (Yang et al., 2022). As such, these methods can serve as unsupervised predictors of mutational effects on binding."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Nevertheless, existing pre-training strategies for protein-protein interactions have limitations. Recently, protein language models have drawn attention by adopting the mask-predict paradigm to protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). These methods partially mask amino acid types and use neural networks to recover the masked information, which can predict the mutational effects on binding by correlating the probability of amino acid types with changes in binding free energy (Yang et al., 2022)."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: Existing pre-training strategies for protein-protein interactions have limitations. Recent protein language models adopt the mask-predict paradigm, partially masking amino acid types and using neural networks to recover masked information. This approach can predict mutational effects on binding by correlating amino acid types with changes in binding free energy."}, {"depth": 3, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Recent protein language models have adopted the mask-predict paradigm to address the limitations of existing pre-training strategies for protein-protein interactions. This approach involves partially masking amino acid types and using neural networks to recover the masked information. By correlating amino acid types with changes in binding free energy, this method can predict the mutational effects on binding, providing valuable insights into protein-protein interactions."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWhile pre-training strategies have shown promise, they often fail to capture the fundamental nature of protein-protein interactions. Recently, the success of protein language models has led to the adoption of the mask-predict paradigm, inspired by BERT, to predict protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). This approach involves partially masking amino acid types on a protein backbone and using neural networks to recover the masked information. Notably, studies have shown that the difference in amino acid type probabilities before and after mutation correlates with changes in binding free energy (Yang et al., 2022). As such, these methods can serve as unsupervised predictors of mutational effects on binding."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \n\nWhile pre-training strategies have shown promise, they often fail to capture the fundamental nature of protein-protein interactions. Recently, the success of protein language models has led to the adoption of the mask-predict paradigm, inspired by BERT, to predict protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). This approach involves partially masking amino acid types on a protein backbone and using neural networks to recover the masked information. Notably, studies have shown that the difference in amino acid type probabilities before and after mutation correlates with changes in binding free energy (Yang et al., 2022). As such, these methods can serve as unsupervised predictors of mutational effects on binding."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \n\nRecent studies have adopted the mask-predict paradigm, inspired by BERT, to predict protein 3D structures using protein language models (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). This approach involves partially masking amino acid types and using neural networks to recover the masked information. Notably, the difference in amino acid type probabilities before and after mutation correlates with changes in binding free energy (Yang et al., 2022), making these methods unsupervised predictors of mutational effects on binding."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Despite limitations of pre-training strategies in capturing protein-protein interactions, recent success of protein language models has drawn attention to adopting the mask-predict paradigm for protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). These methods mask amino acid types and use neural networks to recover the information, showing correlation between probability changes and binding free energy changes (Yang et al., 2022), making them unsupervised predictors of mutational effects on binding."}, {"depth": 2, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: Despite the limitations of pre-training strategies in capturing protein-protein interactions, recent advancements in protein language models have sparked interest in applying the mask-predict paradigm to protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). This approach involves masking amino acid types and using neural networks to recover the information, which has been shown to correlate with binding free energy changes (Yang et al., 2022). As a result, these methods have emerged as unsupervised predictors of mutational effects on binding, providing a promising avenue for exploring protein-protein interactions."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "instruction": "Please, rewrite this paragraph.", "revised_paragraph": "Revised paragraph: \n\nDespite the success of pre-training strategies in capturing protein-protein interactions, they do not fully account for the underlying mechanisms of these interactions. Recently, the promising results of protein language models have led to the adoption of the mask-predict paradigm, inspired by BERT, to predict protein 3D structures (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). These methods involve partially masking amino acid types on a protein backbone and utilizing neural networks to recover the masked information. Notably, studies have shown that the difference in amino acid type probabilities before and after mutation is correlated with changes in binding free energy (Yang et al., 2022), suggesting that these methods can serve as unsupervised predictors of mutational effects on binding.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.08", "instruction": "Rewrite this paragraph to make it shorter while keeping all the informations.", "revised_paragraph": "Revised paragraph: Despite the success of pre-training strategies, they do not effectively capture the foundation of protein-protein interactions. Recently, protein language models have been applied to 3D protein structures using the mask-predict paradigm (Wang et al., 2018; Shroff et al., 2020; Jing et al., 2020; Yang et al., 2022; Zhang et al., 2022; Hsu et al., 2022). These methods mask amino acid types and use neural networks to recover the information. Notably, the difference in probability of amino acid types before and after mutation correlates with the change in binding free energy (Yang et al., 2022), making them unsupervised predictors of mutational effects on binding.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes gives rise to diverse approaches for defining convolutions. Notably, our method is closely related to graph-based methods, which often build upon variations of graph convolutional networks (Kipf & Welling, 2017). These methods have been successfully applied to spherical meshes (Perraudin et al.) and cortical surfaces (Cucurull et al.; Zhao et al.). Verma et al. (2018) have further enhanced graph convolutional networks by incorporating anisotropic kernels, which are dynamically computed through an attention mechanism over graph neighbours.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes gives rise to diverse approaches for defining convolutions. Notably, our method is closely related to graph-based methods, which often build upon variations of graph convolutional networks (Kipf & Welling, 2017). These methods have been successfully applied to spherical meshes (Perraudin et al.) and cortical surfaces (Cucurull et al.; Zhao et al.). Verma et al. (2018) have further enhanced graph convolutional networks by incorporating anisotropic kernels, which are dynamically computed through an attention mechanism over graph neighbours.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes gives rise to diverse approaches for defining convolutions. Notably, our method is closely related to graph-based methods, which often build upon variations of graph convolutional networks (Kipf & Welling, 2017). These methods have been successfully applied to spherical meshes (Perraudin et al.) and cortical surfaces (Cucurull et al.; Zhao et al.). Verma et al. (2018) have further enhanced graph convolutional networks by incorporating anisotropic kernels, which are dynamically computed through an attention mechanism over graph neighbours.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes gives rise to diverse approaches for defining convolutions. Notably, our method is closely related to graph-based methods, which often build upon variations of graph convolutional networks (Kipf & Welling, 2017). These methods have been successfully applied to spherical meshes (Perraudin et al.) and cortical surfaces (Cucurull et al.; Zhao et al.). Verma et al. (2018) have further enhanced graph convolutional networks by incorporating anisotropic kernels, which are dynamically computed through an attention mechanism over graph neighbours.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes gives rise to diverse approaches for defining convolutions. Notably, our method is closely related to graph-based methods, which often build upon variations of graph convolutional networks (Kipf & Welling, 2017). These methods have been successfully applied to spherical meshes (Perraudin et al.) and cortical surfaces (Cucurull et al.; Zhao et al.). Verma et al. (2018) have further enhanced graph convolutional networks by incorporating anisotropic kernels, which are dynamically computed through an attention mechanism over graph neighbours.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes gives rise to diverse approaches for defining convolutions. Notably, our method is closely related to graph-based methods, which often build upon variations of graph convolutional networks (Kipf & Welling, 2017). These methods have been successfully applied to spherical meshes (Perraudin et al.) and cortical surfaces (Cucurull et al.; Zhao et al.). Verma et al. (2018) have further enhanced graph convolutional networks by incorporating anisotropic kernels, which are dynamically computed through an attention mechanism over graph neighbours.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes gives rise to diverse approaches for defining convolutions. Notably, our method is closely related to graph-based methods, which often build upon variations of graph convolutional networks (Kipf & Welling, 2017). These methods have been successfully applied to spherical meshes (Perraudin et al.) and cortical surfaces (Cucurull et al.; Zhao et al.). Verma et al. (2018) have further enhanced graph convolutional networks by incorporating anisotropic kernels, which are dynamically computed through an attention mechanism over graph neighbours.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes gives rise to diverse approaches for defining convolutions. Notably, our method is closely related to graph-based methods, which often build upon variations of graph convolutional networks (Kipf & Welling, 2017). These methods have been successfully applied to spherical meshes (Perraudin et al.) and cortical surfaces (Cucurull et al.; Zhao et al.). Verma et al. (2018) have further enhanced graph convolutional networks by incorporating anisotropic kernels, which are dynamically computed through an attention mechanism over graph neighbours.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "instruction": "Add brackets to the citations", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph-based methods which are often based on variations of graph convolutional networks [1]; [2]. GCNs have been applied on spherical meshes [3] and cortical surfaces [4]; [5]. [6] augment GCNs with anisotropic kernels which are dynamically computed via an attention mechanism over graph neighbours.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "F3z0hchpGy.xeuzrNJiNW.02", "instruction": "Put the references between parenthesis.", "revised_paragraph": "Revised paragraph: \"The irregular structure of meshes leads to a variety of approaches to define convolutions. Closely related to our method are graph-based methods which are often based on variations of graph convolutional networks (Kipf & Welling, 2017; Defferrard et al.). GCNs have been applied on spherical meshes (Perraudin et al.) and cortical surfaces (Cucurull et al.; Zhao et al.). Verma et al. (2018) augment GCNs with anisotropic kernels, which are dynamically computed via an attention mechanism over graph neighbours.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We found a significant main effect of W (F(2, 22) = 25.3, p < 0.001, \u03b72p = 0.967), as illustrated in Figure 4(i). Post-hoc comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit significant main effects. Furthermore, no significant interactions were observed."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We found a significant main effect of W (F(2, 22) = 25.3, p < 0.001, \u03b72p = 0.967), as illustrated in Figure 4(i). Post-hoc comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit significant main effects. Furthermore, no significant interactions were observed."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We found a significant main effect of W (F(2, 22) = 25.3, p < 0.001, \u03b72p = 0.967), as illustrated in Figure 4(i). Post-hoc comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit significant main effects. Furthermore, no significant interactions were observed."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We found a significant main effect of W (F(2, 22) = 25.3, p < 0.001, \u03b72p = 0.967), as illustrated in Figure 4(i). Post-hoc comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit significant main effects. Furthermore, no significant interactions were observed."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We found a significant main effect of W (F(2, 22) = 25.3, p < 0.001, \u03b72p = 0.967), as illustrated in Figure 4(i). Post-hoc comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit significant main effects. Furthermore, no significant interactions were observed."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We found a significant main effect of W (F(2, 22) = 25.3, p < 0.001, \u03b72p = 0.967), as illustrated in Figure 4(i). Post-hoc comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit significant main effects. Furthermore, no significant interactions were observed."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We found a significant main effect of W (F(2, 22) = 25.3, p < 0.001, \u03b72p = 0.967), as illustrated in Figure 4(i). Post-hoc comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit significant main effects. Furthermore, no significant interactions were observed."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We found a significant main effect of W (F(2, 22) = 25.3, p < 0.001, \u03b72p = 0.967), as illustrated in Figure 4(i). Post-hoc comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit significant main effects. Furthermore, no significant interactions were observed."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "instruction": "Replace some words in the paragraph", "revised_paragraph": "Revised paragraph: Our results revealed a significant main effect of W, as indicated by a large F-statistic (F(2, 22) = 25.3, p < 0.001, \u03b7\u00b2p = 0.967) (Figure 4(i)). Post-hoc analyses revealed that error rates significantly increased as W decreased. In contrast, the other parameters did not exhibit significant main effects. Furthermore, no significant interactions were observed between the variables.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "instruction": "Slightly revise for readability.", "revised_paragraph": "Revised paragraph: We found a significant main effect of W (F(2, 22) = 25.3, p < 0.001, \u03b72p = 0.967), as depicted in Figure 4(i). Post-hoc analyses revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit significant main effects, and no significant interactions were observed.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image semantic segmentation is the task of assigning pixel-level semantic labels to recognize objects within an image. The advent of Deep Neural Networks (DNNs) has significantly accelerated the development of semantic segmentation in recent years [6, 58, 19]. Nevertheless, training a fully-supervised semantic segmentation model necessitates a large quantity of pixel-wise annotations.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image semantic segmentation is the task of assigning pixel-level semantic labels to recognize objects within an image. The advent of Deep Neural Networks (DNNs) has significantly accelerated the development of semantic segmentation in recent years [6, 58, 19]. Nevertheless, training a fully-supervised semantic segmentation model necessitates a large quantity of pixel-wise annotations.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image semantic segmentation is the task of assigning pixel-level semantic labels to recognize objects within an image. The advent of Deep Neural Networks (DNNs) has significantly accelerated the development of semantic segmentation in recent years [6, 58, 19]. Nevertheless, training a fully-supervised semantic segmentation model necessitates a large quantity of pixel-wise annotations.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image semantic segmentation is the task of assigning pixel-level semantic labels to recognize objects within an image. The advent of Deep Neural Networks (DNNs) has significantly accelerated the development of semantic segmentation in recent years [6, 58, 19]. Nevertheless, training a fully-supervised semantic segmentation model necessitates a large quantity of pixel-wise annotations.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image semantic segmentation is the task of assigning pixel-level semantic labels to recognize objects within an image. The advent of Deep Neural Networks (DNNs) has significantly accelerated the development of semantic segmentation in recent years [6, 58, 19]. Nevertheless, training a fully-supervised semantic segmentation model necessitates a large quantity of pixel-wise annotations.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image semantic segmentation is the task of assigning pixel-level semantic labels to recognize objects within an image. The advent of Deep Neural Networks (DNNs) has significantly accelerated the development of semantic segmentation in recent years [6, 58, 19]. Nevertheless, training a fully-supervised semantic segmentation model necessitates a large quantity of pixel-wise annotations.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image semantic segmentation is the task of assigning pixel-level semantic labels to recognize objects within an image. The advent of Deep Neural Networks (DNNs) has significantly accelerated the development of semantic segmentation in recent years [6, 58, 19]. Nevertheless, training a fully-supervised semantic segmentation model necessitates a large quantity of pixel-wise annotations.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Image semantic segmentation is the task of assigning pixel-level semantic labels to recognize objects within an image. The advent of Deep Neural Networks (DNNs) has significantly accelerated the development of semantic segmentation in recent years [6, 58, 19]. Nevertheless, training a fully-supervised semantic segmentation model necessitates a large quantity of pixel-wise annotations.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "instruction": "Use uppercases properly.", "revised_paragraph": "Revised paragraph: \"Image semantic segmentation is the task of allocating pixel-level semantic labels for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has significantly accelerated the progress of the semantic segmentation task [6, 58, 19] in recent years. However, training a fully-supervised semantic segmentation model requires large numbers of pixel-wise annotations.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "TFoRhVCpnb.yqo5NaW74.00", "instruction": "Use capital letters at the beginning of every words in the names of segmentation methods.", "revised_paragraph": "Revised paragraph: \"Image Semantic Segmentation is the task of pixel-level Semantic Label Allocation for recognizing objects in an image. The development of Deep Neural Networks (DNNs) has promoted the rapid development of the Semantic Segmentation task [6, 58, 19] in recent years. However, training such a Fully-Supervised Semantic Segmentation model requires large numbers of pixel-wise annotations.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe formulate the active 3D human pose estimation problem in a human crowd scenario as a Dec-POMDP, and introduce a novel collaboration framework that leverages the strengths of multiple cameras (n \u2265 3). To improve credit assignment in multi-camera collaboration, we propose a novel approach called CTCR, which yields notable improvements in reconstruction accuracy compared to both passive and active baselines. To further enhance the model's ability to handle highly dynamic scenes, we introduce five auxiliary tasks that help the model learn environment dynamics. Additionally, we provide high-fidelity simulation environments that mimic realistic human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe formulate the active 3D human pose estimation problem in a human crowd scenario as a Dec-POMDP, and introduce a novel collaboration framework that leverages the strengths of multiple cameras (n \u2265 3). To improve credit assignment in multi-camera collaboration, we propose a novel approach called CTCR, which yields notable improvements in reconstruction accuracy compared to both passive and active baselines. To further enhance the model's ability to handle highly dynamic scenes, we introduce five auxiliary tasks that help the model learn environment dynamics. Additionally, we provide high-fidelity simulation environments that mimic realistic human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe formulate the active 3D human pose estimation problem in a human crowd scenario as a Dec-POMDP, and introduce a novel collaboration framework that leverages the strengths of multiple cameras (n \u2265 3). To improve credit assignment in multi-camera collaboration, we propose a novel approach called CTCR, which yields notable improvements in reconstruction accuracy compared to both passive and active baselines. To further enhance the model's ability to handle highly dynamic scenes, we introduce five auxiliary tasks that help the model learn environment dynamics. Additionally, we provide high-fidelity simulation environments that mimic realistic human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe formulate the active 3D human pose estimation problem in a human crowd scenario as a Dec-POMDP, and introduce a novel collaboration framework that leverages the strengths of multiple cameras (n \u2265 3). To improve credit assignment in multi-camera collaboration, we propose a novel approach called CTCR, which yields notable improvements in reconstruction accuracy compared to both passive and active baselines. To further enhance the model's ability to handle highly dynamic scenes, we introduce five auxiliary tasks that help the model learn environment dynamics. Additionally, we provide high-fidelity simulation environments that mimic realistic human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe formulate the active 3D human pose estimation problem in a human crowd scenario as a Dec-POMDP, and introduce a novel collaboration framework that leverages the strengths of multiple cameras (n \u2265 3). To improve credit assignment in multi-camera collaboration, we propose a novel approach called CTCR, which yields notable improvements in reconstruction accuracy compared to both passive and active baselines. To further enhance the model's ability to handle highly dynamic scenes, we introduce five auxiliary tasks that help the model learn environment dynamics. Additionally, we provide high-fidelity simulation environments that mimic realistic human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe formulate the active 3D human pose estimation problem in a human crowd scenario as a Dec-POMDP, and introduce a novel collaboration framework that leverages the strengths of multiple cameras (n \u2265 3). To improve credit assignment in multi-camera collaboration, we propose a novel approach called CTCR, which yields notable improvements in reconstruction accuracy compared to both passive and active baselines. To further enhance the model's ability to handle highly dynamic scenes, we introduce five auxiliary tasks that help the model learn environment dynamics. Additionally, we provide high-fidelity simulation environments that mimic realistic human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe formulate the active 3D human pose estimation problem in a human crowd scenario as a Dec-POMDP, and introduce a novel collaboration framework that leverages the strengths of multiple cameras (n \u2265 3). To improve credit assignment in multi-camera collaboration, we propose a novel approach called CTCR, which yields notable improvements in reconstruction accuracy compared to both passive and active baselines. To further enhance the model's ability to handle highly dynamic scenes, we introduce five auxiliary tasks that help the model learn environment dynamics. Additionally, we provide high-fidelity simulation environments that mimic realistic human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe formulate the active 3D human pose estimation problem in a human crowd scenario as a Dec-POMDP, and introduce a novel collaboration framework that leverages the strengths of multiple cameras (n \u2265 3). To improve credit assignment in multi-camera collaboration, we propose a novel approach called CTCR, which yields notable improvements in reconstruction accuracy compared to both passive and active baselines. To further enhance the model's ability to handle highly dynamic scenes, we introduce five auxiliary tasks that help the model learn environment dynamics. Additionally, we provide high-fidelity simulation environments that mimic realistic human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "instruction": "Switch the second and the third setence and then rephrase the first three sentences", "revised_paragraph": "Revised paragraph: We introduce a novel multi-camera collaboration framework for active 3D human pose estimation in a human crowd problem, formulated as a Dec-POMDP. This framework leverages credit assignment improvements through CTCR, demonstrating notable enhancements in reconstruction accuracy compared to passive and active baselines. Additionally, we propose five auxiliary tasks to help the model learn environment dynamics, further enhancing its ability to handle highly dynamic scenes, and provide high-fidelity environments with authentic behaviors and visualization software for frame-by-frame video analysis.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.01", "instruction": "Change the position of two points.", "revised_paragraph": "Revised paragraph: \"\u2022 We introduce five auxiliary tasks called to help the model learn environment dynamics, further enhancing the model\u2019s ability to handle highly dynamic scenes. \u2022 We formulate active 3D human pose estimation in a human crowd problem as a Dec-POMDP, and proposed a novel multi-camera (n \u2265 3) collaboration framework. \u2022 We propose CTCR to improve credit assignment in multi-camera collaboration and demonstrate notable improvements in reconstruction accuracy compared to both passive and active baselines. \u2022 We contribute high-fidelity environments built for simulating realistic-looking human crowds with authentic behaviors, along with visualization software for frame-by-frame video analysis.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To improve the efficiency of deep convolutional neural networks (CNNs) for image super-resolution (SR), we begin by highlighting the problem setting and the existence of redundant structures within these networks. This redundancy can lead to inefficient processing and suboptimal performance. To address this issue, we propose a novel structure-regularized pruning (SRP) method that aims to compress these networks and achieve more efficient image SR."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To improve the efficiency of deep convolutional neural networks (CNNs) for image super-resolution (SR), we begin by highlighting the problem setting and the existence of redundant structures within these networks. This redundancy can lead to inefficient processing and suboptimal performance. To address this issue, we propose a novel structure-regularized pruning (SRP) method that aims to compress these networks and achieve more efficient image SR."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To improve the efficiency of deep convolutional neural networks (CNNs) for image super-resolution (SR), we begin by highlighting the problem setting and the existence of redundant structures within these networks. This redundancy can lead to inefficient processing and suboptimal performance. To address this issue, we propose a novel structure-regularized pruning (SRP) method that aims to compress these networks and achieve more efficient image SR."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To improve the efficiency of deep convolutional neural networks (CNNs) for image super-resolution (SR), we begin by highlighting the problem setting and the existence of redundant structures within these networks. This redundancy can lead to inefficient processing and suboptimal performance. To address this issue, we propose a novel structure-regularized pruning (SRP) method that aims to compress these networks and achieve more efficient image SR."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To improve the efficiency of deep convolutional neural networks (CNNs) for image super-resolution (SR), we begin by highlighting the problem setting and the existence of redundant structures within these networks. This redundancy can lead to inefficient processing and suboptimal performance. To address this issue, we propose a novel structure-regularized pruning (SRP) method that aims to compress these networks and achieve more efficient image SR."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To improve the efficiency of deep convolutional neural networks (CNNs) for image super-resolution (SR), we begin by highlighting the problem setting and the existence of redundant structures within these networks. This redundancy can lead to inefficient processing and suboptimal performance. To address this issue, we propose a novel structure-regularized pruning (SRP) method that aims to compress these networks and achieve more efficient image SR."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To improve the efficiency of deep convolutional neural networks (CNNs) for image super-resolution (SR), we begin by highlighting the problem setting and the existence of redundant structures within these networks. This redundancy can lead to inefficient processing and suboptimal performance. To address this issue, we propose a novel structure-regularized pruning (SRP) method that aims to compress these networks and achieve more efficient image SR."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: To improve the efficiency of deep convolutional neural networks (CNNs) for image super-resolution (SR), we begin by highlighting the problem setting and the existence of redundant structures within these networks. This redundancy can lead to inefficient processing and suboptimal performance. To address this issue, we propose a novel structure-regularized pruning (SRP) method that aims to compress these networks and achieve more efficient image SR."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "instruction": "Can you paraphrase the last sentence?", "revised_paragraph": "Revised paragraph: We begin by providing an overview of the challenge of using deep convolutional neural networks (CNNs) for image super-resolution (SR). Notably, these networks often exhibit significant redundancy, which hinders their efficiency. To address this issue, we introduce a novel approach, structure-regularized pruning (SRP), which aims to compress and optimize these networks for improved image SR performance.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "aomiOZE_m2.rxb2TiQ6bq.07", "instruction": "Rewrite the last sentence preferring passive voice over active.", "revised_paragraph": "Revised paragraph: \"We first give a brief view of the problem setting about deep CNN for image SR. We also observe that there exists heavy redundancy in the networks. The networks are then compressed by a proposed structure-regularized pruning (SRP) method to pursue more efficient image SR.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, pre-training-based models have been proposed, using learned features to predict mutation effects via regression models (Liu et al., 2021; Yang et al., 2022).\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have been categorized into three groups: end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, another approach involves pre-training a feature extraction network and using regression models to predict mutation effects based on learned features (Liu et al., 2021; Yang et al., 2022).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, pre-training-based models have been proposed, using learned features to predict mutation effects via regression models (Liu et al., 2021; Yang et al., 2022).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, pre-training-based models have been proposed, using learned features to predict mutation effects via regression models (Liu et al., 2021; Yang et al., 2022).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, pre-training-based models have been proposed, using learned features to predict mutation effects via regression models (Liu et al., 2021; Yang et al., 2022).\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have been categorized into three groups: end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, another approach involves pre-training a feature extraction network and using regression models to predict mutation effects based on learned features (Liu et al., 2021; Yang et al., 2022).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, pre-training-based models have been proposed, using learned features to predict mutation effects via regression models (Liu et al., 2021; Yang et al., 2022).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark. However, per-structure correlation remains low.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, pre-training-based models have been proposed, using learned features to predict mutation effects via regression models (Liu et al., 2021; Yang et al., 2022).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, pre-training-based models have been proposed, using learned features to predict mutation effects via regression models (Liu et al., 2021; Yang et al., 2022).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, pre-training-based models have been proposed, using learned features to predict mutation effects via regression models (Liu et al., 2021; Yang et al., 2022).\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Recent deep learning-based approaches to predicting mutational effects on protein binding have emerged. We categorize them into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark. However, per-structure correlation remains low.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "instruction": "Give me a shorter version of this:", "revised_paragraph": "Revised paragraph: Recent advances in predicting mutational effects on protein binding using deep learning have led to the emergence of three categories: end-to-end models, pre-training-based models, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlations on the SKEMPI benchmark. However, per-structure correlations remain low. To address data scarcity, pre-training-based models learn features from protein structures and then apply regression models to predict mutation effects, as demonstrated by Liu et al. (2021) and Yang et al. (2022).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.07", "instruction": "Make this paragraph twice as short by making the content more concise and deleting unnecessary details.", "revised_paragraph": "Revised paragraph: \"Deep learning-based approaches to predicting mutational effects on protein binding have emerged, categorized into end-to-end, pre-training-based, and unsupervised models. End-to-end models directly predict binding free energy differences from mutant and wild-type protein structures, achieving satisfactory correlation on the SKEMPI benchmark (Shan et al., 2022). However, per-structure correlation remains low. To address data scarcity, pre-training feature extraction networks and using regression models to predict mutation effects have been proposed (Liu et al., 2021; Yang et al., 2022).\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To reduce computational cost and avoid extra model parameters, we employ a two-stage optimization strategy. In the first stage, we fix visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. In the second stage, we fix optimal transport parameters and back-propagate the gradient to learn prompts with different characteristics. Optimal transport outperforms conventional distances, such as Euclidean distance of mean features, by aligning visual features for each local prompt and tolerating feature shift [44]. We evaluate our method on 11 datasets, including generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, showing that PLOT can effectively learn representative and comprehensive prompts."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nTo address this problem, we leverage the principles of optimal transport theory [51] and cast the feature sets as discrete probability distributions, where each feature has an equal probability value. To reduce computational costs and avoid additional model parameters, we employ a two-stage optimization strategy to learn the prompts. In the inner loop, we fix both visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. Subsequently, in the outer loop, we fix all optimal transport parameters and back-propagate the gradient to learn prompts with diverse characteristics. In contrast to conventional distances, such as Euclidean distance between mean features, optimal transport can align different visual features for each local prompt, rendering it more robust to visual misalignment and tolerant of feature shifts [44]. This is because optimal transport learns an adaptive transport plan to align features, achieving fine-grained matching across modalities. We conduct experiments on 11 datasets, following the standard settings of CLIP [39] and CoOp [63], to evaluate our method. These experiments span visual classification tasks, including generic objects, scenes, actions, fine-grained categories, and more. The significant result improvements demonstrate that PLOT can effectively learn representative and comprehensive prompts."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To reduce computational cost and avoid extra model parameters, we employ a two-stage optimization strategy. In the first stage, we fix visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. In the second stage, we fix optimal transport parameters and back-propagate the gradient to learn prompts with different characteristics. Optimal transport outperforms conventional distances, such as Euclidean distance of mean features, by aligning visual features for each local prompt and tolerating feature shift [44]. We evaluate our method on 11 datasets, including generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, showing that PLOT can effectively learn representative and comprehensive prompts."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To reduce computational cost and avoid extra model parameters, we employ a two-stage optimization strategy. In the first stage, we fix visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. In the second stage, we fix optimal transport parameters and back-propagate the gradient to learn prompts with different characteristics. Optimal transport outperforms conventional distances, such as Euclidean distance of mean features, by aligning visual features for each local prompt and tolerating feature shift [44]. We evaluate our method on 11 datasets, including generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, showing that PLOT can effectively learn representative and comprehensive prompts."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To reduce computational cost and avoid extra model parameters, we employ a two-stage optimization strategy. In the first stage, we fix visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. In the second stage, we fix optimal transport parameters and back-propagate the gradient to learn prompts with different characteristics. Optimal transport outperforms conventional distances, such as Euclidean distance of mean features, by aligning visual features for each local prompt and tolerating feature shift [44]. We evaluate our method on 11 datasets, including generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, showing that PLOT can effectively learn representative and comprehensive prompts."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nTo address this problem, we leverage the principles of optimal transport theory [51] and cast the feature sets as discrete probability distributions, where each feature has an equal probability value. To reduce computational costs and avoid additional model parameters, we employ a two-stage optimization strategy to learn the prompts. In the inner loop, we fix both visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. Subsequently, in the outer loop, we fix all optimal transport parameters and back-propagate the gradient to learn prompts with diverse characteristics. In contrast to conventional distances, such as Euclidean distance between mean features, optimal transport can align different visual features for each local prompt, rendering it more robust to visual misalignment and tolerant of feature shifts [44]. This is because optimal transport learns an adaptive transport plan to align features, achieving fine-grained matching across modalities. We conduct experiments on 11 datasets, following the standard settings of CLIP [39] and CoOp [63], to evaluate our method. These experiments span visual classification tasks, including generic objects, scenes, actions, fine-grained categories, and more. The significant result improvements demonstrate that PLOT can effectively learn representative and comprehensive prompts."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To reduce computational cost and avoid extra model parameters, we employ a two-stage optimization strategy. In the first stage, we fix visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. In the second stage, we fix optimal transport parameters and back-propagate the gradient to learn prompts with different characteristics. Optimal transport outperforms conventional distances, such as Euclidean distance of mean features, by aligning visual features for each local prompt and tolerating feature shift [44]. We evaluate our method on 11 datasets, including generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, showing that PLOT can effectively learn representative and comprehensive prompts."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To mitigate computational costs and avoid the introduction of additional model parameters, we employ a two-stage optimization strategy. In the first stage, we freeze visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. Subsequently, we fix the optimal transport parameters and back-propagate the gradient to learn prompts with distinct characteristics. Our approach outperforms conventional distances, such as the Euclidean distance between mean features, by effectively aligning visual features for each local prompt and accommodating feature shifts [44]. We evaluate our method on 11 datasets, encompassing generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, thereby demonstrating the effectiveness of PLOT in learning representative and comprehensive prompts."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To reduce computational cost and avoid extra model parameters, we employ a two-stage optimization strategy. In the first stage, we fix visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. In the second stage, we fix optimal transport parameters and back-propagate the gradient to learn prompts with different characteristics. Optimal transport outperforms conventional distances, such as Euclidean distance of mean features, by aligning visual features for each local prompt and tolerating feature shift [44]. We evaluate our method on 11 datasets, including generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, showing that PLOT can effectively learn representative and comprehensive prompts."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To reduce computational cost and avoid extra model parameters, we employ a two-stage optimization strategy. In the first stage, we fix visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. In the second stage, we fix optimal transport parameters and back-propagate the gradient to learn prompts with different characteristics. Optimal transport outperforms conventional distances, such as Euclidean distance of mean features, by aligning visual features for each local prompt and tolerating feature shift [44]. We evaluate our method on 11 datasets, including generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, showing that PLOT can effectively learn representative and comprehensive prompts."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To reduce computational cost and avoid extra model parameters, we employ a two-stage optimization strategy. In the first stage, we fix visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. In the second stage, we fix optimal transport parameters and back-propagate the gradient to learn prompts with different characteristics. Optimal transport outperforms conventional distances, such as Euclidean distance of mean features, by aligning visual features for each local prompt and tolerating feature shift [44]. We evaluate our method on 11 datasets, including generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, showing that PLOT can effectively learn representative and comprehensive prompts."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We address the problem by formulating feature sets as discrete probability distributions using optimal transport theory [51]. To mitigate computational costs and avoid the introduction of additional model parameters, we employ a two-stage optimization strategy. In the first stage, we freeze visual and text features and optimize the optimal transport problem using a fast Sinkhorn distances algorithm. Subsequently, we fix the optimal transport parameters and back-propagate the gradient to learn prompts with distinct characteristics. Our approach outperforms conventional distances, such as the Euclidean distance between mean features, by effectively aligning visual features for each local prompt and accommodating feature shifts [44]. We evaluate our method on 11 datasets, encompassing generic object classification, scene understanding, and fine-grained categories, and demonstrate significant result improvements, thereby demonstrating the effectiveness of PLOT in learning representative and comprehensive prompts."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "instruction": "Remove any unessential information in this paragraph.", "revised_paragraph": "Revised paragraph: We address this problem by introducing optimal transport theory and formulating feature sets as discrete probability distributions. To reduce computational cost and avoid extra model parameters, we employ a two-stage optimization strategy. In the inner loop, we optimize the optimal transport problem using a fast Sinkhorn distances algorithm, while in the outer loop, we learn prompts with different characteristics by back-propagating the gradient. Optimal transport aligns visual features for each local prompt, making it more robust to visual misalignment and feature shift. We evaluate our method on 11 datasets, achieving significant result improvements that demonstrate PLOT's effectiveness in learning representative and comprehensive prompts.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.00", "instruction": "Please exclude the content related to optimal transport.", "revised_paragraph": "Revised paragraph: We learn the prompts with a two-stage optimization strategy to reduce computational cost and avoid extra model parameters. In the first stage, we fix both visual and text features and optimize the prompts using a fast algorithm. In the second stage, we fix all parameters and back-propagate the gradient to learn prompts with different characteristics. We conduct experiments on 11 datasets following the standard setting of CLIP [39] and CoOp [63] to evaluate our method, which spans the visual classification of generic objects, scenes, actions, fine-grained categories, and so on. The significant result improvement demonstrates that our method can effectively learn representative and comprehensive prompts.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The influence of a user on the GitHub platform can be quantified by various metrics, including the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics, such as centrality, can also provide insight into the breadth of influence, for example, by indicating geographic interest (Weber and Luo, 2014). Other features that can be examined include project volume, documentation volume, presence of supporting files, code volume, and standard library usage. Furthermore, the popularity velocity can be measured by calculating the total number of stars divided by the project's lifespan. While few studies have investigated the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs, this area warrants further exploration."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The influence of a user on the GitHub platform can be quantified by various metrics, including the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics, such as centrality, can also provide insight into the breadth of influence, for example, by indicating geographic interest (Weber and Luo, 2014). Other features that can be examined include project volume, documentation volume, presence of supporting files, code volume, and standard library usage. Furthermore, the popularity velocity can be measured by calculating the total number of stars divided by the project's lifespan. While few studies have investigated the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs, this area warrants further exploration."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The influence of a user on the GitHub platform can be quantified by various metrics, including the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics, such as centrality, can also provide insight into the breadth of influence, for example, by indicating geographic interest (Weber and Luo, 2014). Other features that can be examined include project volume, documentation volume, presence of supporting files, code volume, and standard library usage. Furthermore, the popularity velocity can be measured by calculating the total number of stars divided by the project's lifespan. While few studies have investigated the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs, this area warrants further exploration."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The influence of a user on the GitHub platform can be quantified by various metrics, including the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics, such as centrality, can also provide insight into the breadth of influence, for example, by indicating geographic interest (Weber and Luo, 2014). Other features that can be examined include project volume, documentation volume, presence of supporting files, code volume, and standard library usage. Furthermore, the popularity velocity can be measured by calculating the total number of stars divided by the project's lifespan. While few studies have investigated the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs, this area warrants further exploration."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The influence of a user on the GitHub platform can be quantified by various metrics, including the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics, such as centrality, can also provide insight into the breadth of influence, for example, by indicating geographic interest (Weber and Luo, 2014). Other features that can be examined include project volume, documentation volume, presence of supporting files, code volume, and standard library usage. Furthermore, the popularity velocity can be measured by calculating the total number of stars divided by the project's lifespan. While few studies have investigated the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs, this area warrants further exploration."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The influence of a user on the GitHub platform can be quantified by various metrics, including the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics, such as centrality, can also provide insight into the breadth of influence, for example, by indicating geographic interest (Weber and Luo, 2014). Other features that can be examined include project volume, documentation volume, presence of supporting files, code volume, and standard library usage. Furthermore, the popularity velocity can be measured by calculating the total number of stars divided by the project's lifespan. While few studies have investigated the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs, this area warrants further exploration."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The influence of a user on the GitHub platform can be quantified by various metrics, including the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics, such as centrality, can also provide insight into the breadth of influence, for example, by indicating geographic interest (Weber and Luo, 2014). Other features that can be examined include project volume, documentation volume, presence of supporting files, code volume, and standard library usage. Furthermore, the popularity velocity can be measured by calculating the total number of stars divided by the project's lifespan. While few studies have investigated the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs, this area warrants further exploration."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The influence of a user on the GitHub platform can be quantified by various metrics, including the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics, such as centrality, can also provide insight into the breadth of influence, for example, by indicating geographic interest (Weber and Luo, 2014). Other features that can be examined include project volume, documentation volume, presence of supporting files, code volume, and standard library usage. Furthermore, the popularity velocity can be measured by calculating the total number of stars divided by the project's lifespan. While few studies have investigated the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs, this area warrants further exploration."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "instruction": "Make the use of a citation in the second sentence correct. Update the third sentence.", "revised_paragraph": "Revised paragraph: \"Influence on the Github platform can be quantified by the number of followers, stars, mentions, quotes, and up-votes received from other users. According to Weber and Luo (2014), social network metrics such as centrality indicate how broadly influence extends, for example, in terms of geographic interest. Other features that contribute to a project's influence include project volume, documentation volume, presence of supporting files, code volume, and standard library usage. Furthermore, the popularity velocity can be measured by calculating the total number of stars divided by the project's lifespan, and few studies have examined the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "NwOG107NKJ.0PPYM22rdB.02", "instruction": "Improve the readability of this paragraph.", "revised_paragraph": "Revised paragraph: The influence of a user on the GitHub platform can be quantified through various metrics, including the number of followers, stars, mentions, quotes, and up-votes received from other users. Social network metrics, such as centrality, can also provide insight into the breadth of influence, for instance, in terms of geographic interest (Weber and Luo, 2014). Additionally, project volume, documentation volume, presence of supporting files, code volume, and standard library usage can serve as indicators of influence. Furthermore, the popularity velocity of a project can be measured by calculating the total number of stars divided by the project's lifetime. While few studies have explored the influence of user-popularity, repo-popularity, and triadic relationships in dynamic graphs, this research aims to contribute to this area by examining these factors.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Electronic calendars have become essential for managing daily activities, allowing individuals to coordinate schedules and convey priorities. They have also been used to visualize temporal trends, such as energy use and work routines. In healthcare, unit-of-use packaging with date features has improved prescription management and adherence. However, integrating prescription management into the patient's main calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Electronic calendars have become indispensable tools for managing daily activities [16\u201318]. They enable individuals to coordinate schedules with family or team members, conveying the underlying priorities and values behind their scheduling decisions [19]. Calendars have also been employed to visualize temporal trends, including everyday activities such as energy consumption in workplaces, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging with simple date or day features has been used to facilitate prescription management and improve adherence by prompting patients to adhere to prescribed dosing schedules [23]. While stand-alone prescription managers are available, we explore the possibility of integrating prescription management into the patient's primary calendar. However, this integration poses challenges. The first challenge is rendering prescription entries in a way that distinguishes them from regular calendar entries. The second challenge is ensuring that patients reschedule prescription entries within the safety boundaries of the prescription."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Electronic calendars have become essential for managing daily activities, allowing individuals to coordinate schedules and convey priorities. They have also been used to visualize temporal trends, such as energy use and work routines. In healthcare, unit-of-use packaging with date features has improved prescription management and adherence. However, integrating prescription management into the patient's main calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Electronic calendars have become essential for managing daily activities, allowing individuals to coordinate schedules and convey priorities. They have also been used to visualize temporal trends, such as energy use and work routines. In healthcare, unit-of-use packaging with date features has improved prescription management and adherence. However, integrating prescription management into the patient's main calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Electronic calendars have become essential for managing daily activities, allowing individuals to coordinate schedules and convey priorities. They have also been used to visualize temporal trends, such as energy use and work routines. In healthcare, unit-of-use packaging with date features has improved prescription management and adherence. However, integrating prescription management into the patient's main calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Electronic calendars have become indispensable tools for managing daily activities [16\u201318]. They enable individuals to coordinate schedules with family or team members, conveying the underlying priorities and values behind their scheduling decisions [19]. Calendars have also been employed to visualize temporal trends, including everyday activities such as energy consumption in workplaces, fitness tracking, and work routines [20\u201322]. In healthcare, unit-of-use packaging with simple date or day features has been used to facilitate prescription management and improve adherence by prompting patients to adhere to prescribed dosing schedules [23]. While stand-alone prescription managers are available, we explore the possibility of integrating prescription management into the patient's primary calendar. However, this integration poses challenges. The first challenge is rendering prescription entries in a way that distinguishes them from regular calendar entries. The second challenge is ensuring that patients reschedule prescription entries within the safety boundaries of the prescription."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Electronic calendars have become essential for managing daily activities, allowing individuals to coordinate schedules and convey priorities. They have also been used to visualize temporal trends, such as energy use and work routines. In healthcare, unit-of-use packaging with date features has improved prescription management and adherence. However, integrating prescription management into the patient's main calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Electronic calendars have become indispensable tools for managing daily activities, enabling individuals to coordinate schedules and convey priorities. They have also been employed to visualize temporal trends, such as energy consumption and work routines. In the healthcare sector, unit-of-use packaging with date features has enhanced prescription management and adherence. However, integrating prescription management into the patient's primary calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling, which necessitates careful consideration."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Electronic calendars have become essential for managing daily activities, allowing individuals to coordinate schedules and convey priorities. They have also been used to visualize temporal trends, such as energy use and work routines. In healthcare, unit-of-use packaging with date features has improved prescription management and adherence. However, integrating prescription management into the patient's main calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Electronic calendars have become essential for managing daily activities, allowing individuals to coordinate schedules and convey priorities. They have also been used to visualize temporal trends, such as energy use and work routines. In healthcare, unit-of-use packaging with date features has improved prescription management and adherence. However, integrating prescription management into the patient's main calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Electronic calendars have become essential for managing daily activities, allowing individuals to coordinate schedules and convey priorities. They have also been used to visualize temporal trends, such as energy use and work routines. In healthcare, unit-of-use packaging with date features has improved prescription management and adherence. However, integrating prescription management into the patient's main calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Electronic calendars have become indispensable tools for managing daily activities, enabling individuals to coordinate schedules and convey priorities. They have also been employed to visualize temporal trends, such as energy consumption and work routines. In the healthcare sector, unit-of-use packaging with date features has enhanced prescription management and adherence. However, integrating prescription management into the patient's primary calendar poses challenges, including rendering prescription entries and ensuring safe rescheduling, which necessitates careful consideration."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "instruction": "Rewrite the latter half of this paragraph to make it more concise.", "revised_paragraph": "Revised paragraph: Electronic calendars have become essential for managing daily activities [16\u201318]. They facilitate coordination among family or team members, convey scheduling priorities, and visualize temporal trends in activities like energy use, fitness tracking, and work routines [19\u201322]. In healthcare, unit-of-use packaging with date features has improved prescription management and adherence [23]. We propose integrating prescription management into patients' main calendars, but this requires addressing challenges such as differentiating prescription entries from normal ones and ensuring rescheduling within the prescription's safety limits.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.01", "instruction": "Merge the two sentences in the middle  about integrating prescription magagement in a new shorter sentence. Improve the english in the last sentence.", "revised_paragraph": "Revised paragraph: Electronic calendars have become instrumental in managing daily activities, coordinating interactions among individual schedules, and conveying meaning and values behind prioritizing scheduling. They have also been used to visualize temporal trends, such as energy use, fitness tracking, and work routines. Furthermore, unit-of-use packaging with simple date features has been employed in healthcare to manage prescriptions and improve adherence by prompting patients to maintain the prescribed dosing schedule. In this context, integrating prescription management into the main patient calendar poses challenges, including rendering prescription entries distinguishable from normal calendar entries and ensuring that patients reschedule prescriptions within the safety envelope.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: To validate our claims, we conduct an ablation study on the ACIC benchmark, evaluating the effectiveness of ESCFR's components. Table 2 shows that ESCFR reduces the out-of-sample PEHE from 3.254 to 2.316 by augmenting TARNet with stochastic optimal transport, mitigating MSE and UCE issues with RMPR and PFOR, and combining both in a unified framework."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To ensure the accuracy of our results, we conduct an ablation study on the ACIC benchmark, rather than the IHDP benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims. Specifically, we examine the impact of each component on the model's performance, starting with the addition of stochastic optimal transport to TARNet, which reduces the out-of-sample PEHE from 3.254 to 3.207. This is followed by the mitigation of the MSE issue with RMPR and the UCE issue with PFOR, resulting in further reductions of the out-of-sample PEHE to 2.768 and 2.633, respectively. Finally, we demonstrate the benefits of combining RMPR and PFOR in a unified framework, achieving an out-of-sample PEHE of 2.316."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To mitigate the significant variability in the IHDP benchmark, we conduct an ablation study on the ACIC benchmark to assess the effectiveness of ESCFR's components and substantiate our claims in Section 3. By examining Table 2, we observe that ESCFR initially enhances TARNet by incorporating stochastic optimal transport in Section 3.1, which leads to a notable reduction in out-of-sample PEHE from 3.254 to 3.207. Subsequently, it addresses the MSE issue using RMPR in Section 3.2 and the UCE issue using PFOR in Section 3.3, resulting in further reductions in out-of-sample PEHE to 2.768 and 2.633, respectively. Finally, ESCFR integrates RMPR and PFOR within a unified framework in Section 3.4, achieving a PEHE of 2.316."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: To validate our claims, we conduct an ablation study on the ACIC benchmark, evaluating the effectiveness of ESCFR's components. Table 2 shows that ESCFR reduces the out-of-sample PEHE from 3.254 to 2.316 by augmenting TARNet with stochastic optimal transport, mitigating MSE and UCE issues with RMPR and PFOR, and combining both in a unified framework."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To ensure the accuracy of our results, we conduct an ablation study on the ACIC benchmark, rather than the IHDP benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims. Specifically, we examine the impact of each component on the model's performance, starting with the addition of stochastic optimal transport to TARNet, which reduces the out-of-sample PEHE from 3.254 to 3.207. This is followed by the mitigation of the MSE issue with RMPR and the UCE issue with PFOR, resulting in further reductions of the out-of-sample PEHE to 2.768 and 2.633, respectively. Finally, we demonstrate the benefits of combining RMPR and PFOR in a unified framework, achieving an out-of-sample PEHE of 2.316."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: To validate our claims, we conduct an ablation study on the ACIC benchmark, evaluating the effectiveness of ESCFR's components. Table 2 shows that ESCFR reduces the out-of-sample PEHE from 3.254 to 2.316 by augmenting TARNet with stochastic optimal transport, mitigating MSE and UCE issues with RMPR and PFOR, and combining both in a unified framework."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: To validate our claims, we conduct an ablation study on the ACIC benchmark, evaluating the effectiveness of ESCFR's components. Table 2 shows that ESCFR reduces the out-of-sample PEHE from 3.254 to 2.316 by augmenting TARNet with stochastic optimal transport, mitigating MSE and UCE issues with RMPR and PFOR, and combining both in a unified framework."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To mitigate the significant variability in the IHDP benchmark, we conduct an ablation study on the ACIC benchmark to assess the effectiveness of ESCFR's components and substantiate our claims in Section 3. By examining Table 2, we observe that ESCFR initially enhances TARNet by incorporating stochastic optimal transport in Section 3.1, which leads to a notable reduction in out-of-sample PEHE from 3.254 to 3.207. Subsequently, it addresses the MSE issue using RMPR in Section 3.2 and the UCE issue using PFOR in Section 3.3, resulting in further reductions in out-of-sample PEHE to 2.768 and 2.633, respectively. Finally, ESCFR integrates RMPR and PFOR within a unified framework in Section 3.4, achieving a PEHE of 2.316."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: To validate our claims, we conduct an ablation study on the ACIC benchmark, evaluating the effectiveness of ESCFR's components. Table 2 shows that ESCFR reduces the out-of-sample PEHE from 3.254 to 2.316 by augmenting TARNet with stochastic optimal transport, mitigating MSE and UCE issues with RMPR and PFOR, and combining both in a unified framework."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To support our findings, we conducted an ablation study on the ACIC benchmark to assess the impact of each component of ESCFR. The results, presented in Table 2, demonstrate that ESCFR significantly reduces the out-of-sample PEHE from 3.254 to 2.316 by incorporating stochastic optimal transport from TARNet, addressing MSE and UCE issues with RMPR and PFOR, and integrating these components into a unified framework."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To substantiate our findings, we conducted an ablation study on the ACIC benchmark to evaluate the individual contributions of each component of ESCFR. As shown in Table 2, the results indicate that ESCFR exhibits a significant reduction in out-of-sample PEHE, decreasing from 3.254 to 2.316 by incorporating stochastic optimal transport from TARNet, addressing MSE and UCE issues through RMPR and PFOR, and integrating these components into a unified framework."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: To validate our claims, we conduct an ablation study on the ACIC benchmark, evaluating the effectiveness of ESCFR's components. Table 2 shows that ESCFR reduces the out-of-sample PEHE from 3.254 to 2.316 by augmenting TARNet with stochastic optimal transport, mitigating MSE and UCE issues with RMPR and PFOR, and combining both in a unified framework."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: To ensure the accuracy of our results, we conduct an ablation study on the ACIC benchmark, rather than the IHDP benchmark, to evaluate the effectiveness of ESCFR's components and validate our claims. Specifically, we examine the impact of each component on the model's performance, starting with the addition of stochastic optimal transport to TARNet, which reduces the out-of-sample PEHE from 3.254 to 3.207. This is followed by the mitigation of the MSE issue with RMPR and the UCE issue with PFOR, resulting in further reductions of the out-of-sample PEHE to 2.768 and 2.633, respectively. Finally, we demonstrate the benefits of combining RMPR and PFOR in a unified framework, achieving an out-of-sample PEHE of 2.316."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: To validate our claims, we conduct an ablation study on the ACIC benchmark, examining the impact of each component on the model's performance. We start by adding stochastic optimal transport to TARNet, reducing the out-of-sample PEHE from 3.254 to 3.207. We then mitigate the MSE and UCE issues with RMPR and PFOR, respectively, resulting in further reductions of the out-of-sample PEHE to 2.316."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: To validate our claims, we conduct an ablation study on the ACIC benchmark, evaluating the effectiveness of ESCFR's components. Table 2 shows that ESCFR reduces the out-of-sample PEHE from 3.254 to 2.316 by augmenting TARNet with stochastic optimal transport, mitigating MSE and UCE issues with RMPR and PFOR, and combining both in a unified framework."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: To validate our claims, we conduct an ablation study on the ACIC benchmark, assessing the individual contributions of ESCFR's components to its effectiveness. As shown in Table 2, ESCFR significantly reduces the out-of-sample PEHE from 3.254 to 2.316, demonstrating the benefits of augmenting TARNet with stochastic optimal transport, mitigating MSE and UCE issues through the incorporation of RMPR and PFOR, and combining these components in a unified framework."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "instruction": "Make the first sentence more concise.", "revised_paragraph": "Revised paragraph: To evaluate ESCFR's components, we conduct an ablation study on the ACIC benchmark, avoiding IHDP's significant variance. ESCFR first augments TARNet with stochastic optimal transport, reducing out-of-sample PEHE from 3.254 to 3.207. It then mitigates MSE and UCE issues with RMPR and PFOR, respectively, further reducing PEHE to 2.768 and 2.633. Finally, the unified framework combining RMPR and PFOR achieves a PEHE of 2.316.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.17", "instruction": "Simplify the first sentence. Improve the connections between sentences.", "revised_paragraph": "Revised paragraph: To evaluate the effectiveness of ESCFR's components, we conduct an ablation study on the ACIC benchmark, avoiding the variance issues with the IHDP benchmark. Our approach, ESCFR, augments TARNet with stochastic optimal transport, significantly reducing the out-of-sample PEHE from 3.254 to 3.207. By subsequently incorporating RMPR and PFOR, ESCFR mitigates the MSE and UCE issues, respectively, further decreasing the out-of-sample PEHE to 2.768 and 2.633. Finally, the unified framework combining RMPR and PFOR achieves the lowest PEHE of 2.316, demonstrating the effectiveness of ESCFR's components.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Design A calendar supports two types of medication entries: drug and physical activity. Each drug entry is labelled with the name of the drug and includes the dosage in brackets, with a suffix (-WF) indicating that the drug should be taken with food. Physical activity entries are visually distinguished by a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented by rectangles filled with varying shades of grey."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Design A calendar supports two types of medication entries: drug and physical activity. Each drug entry is labelled with the name of the drug and includes the dosage in brackets, with a suffix (-WF) indicating that the drug should be taken with food. Physical activity entries are visually distinguished by a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented by rectangles filled with varying shades of grey."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Design A calendar supports two types of medication entries: drug and physical activity. Each drug entry is labelled with the name of the drug and includes the dosage in brackets, with a suffix (-WF) indicating that the drug should be taken with food. Physical activity entries are visually distinguished by a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented by rectangles filled with varying shades of grey."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Design A calendar supports two types of medication entries: drug and physical activity. Each drug entry is labelled with the name of the drug and includes the dosage in brackets, with a suffix (-WF) indicating that the drug should be taken with food. Physical activity entries are visually distinguished by a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented by rectangles filled with varying shades of grey."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Design A calendar supports two types of medication entries: drug and physical activity. Each drug entry is labelled with the name of the drug and includes the dosage in brackets, with a suffix (-WF) indicating that the drug should be taken with food. Physical activity entries are visually distinguished by a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented by rectangles filled with varying shades of grey."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Design A calendar supports two types of medication entries: drug and physical activity. Each drug entry is labelled with the name of the drug and includes the dosage in brackets, with a suffix (-WF) indicating that the drug should be taken with food. Physical activity entries are visually distinguished by a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented by rectangles filled with varying shades of grey."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Design A calendar supports two types of medication entries: drug and physical activity. Each drug entry is labelled with the name of the drug and includes the dosage in brackets, with a suffix (-WF) indicating that the drug should be taken with food. Physical activity entries are visually distinguished by a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented by rectangles filled with varying shades of grey."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The Design A calendar supports two types of medication entries: drug and physical activity. Each drug entry is labelled with the name of the drug and includes the dosage in brackets, with a suffix (-WF) indicating that the drug should be taken with food. Physical activity entries are visually distinguished by a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented by rectangles filled with varying shades of grey."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "instruction": "Make this paragraph a bit more fluid.", "revised_paragraph": "Revised paragraph: The design of the calendar supports two types of medication entries: drug or physical activity. Each drug entry is labeled with the name of the drug, accompanied by the dosage in brackets, and is further distinguished by the suffix \"-WF\" to indicate that it should be taken with food. In contrast, physical activity entries are visually highlighted with a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented by rectangles with varying shades of grey, providing a clear and organized format for users to manage their daily schedules.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "instruction": "I want to rewrite the first sentence.", "revised_paragraph": "Revised paragraph: Design A is a medication calendar that categorizes entries into two types: drug or physical activity. Each drug entry is labeled with the drug name and includes a bracketed dosage, with a suffix (-WF) indicating that the drug should be taken with food. Physical activity entries are visually distinguished by a full-color fill, a dashed border, and a label indicating the activity name. Other calendar entries are represented by rectangles filled with varying shades of grey.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We present the training curves of Algorithm 1 on the AKI dataset in Figures 3 and 4. Figure 3 shows the performance of RL policies evaluated on train, validation, and test sets, with the three curves closely matching, confirming the generalizability of the learned dynamic classification policy. Figure 4 demonstrates the classifier's improvement in making accurate predictions during RL training, with training only on data selected by the RL algorithm."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We present the training curves of Algorithm 1 on the AKI dataset in Figures 3 and 4. Figure 3 shows the performance of RL policies evaluated on train, validation, and test sets, with the three curves closely matching, confirming the generalizability of the learned dynamic classification policy. Figure 4 demonstrates the classifier's improvement in making accurate predictions during RL training, with training only on data selected by the RL algorithm."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We present the training curves of Algorithm 1 on the AKI dataset in Figures 3 and 4. Figure 3 shows the performance of RL policies evaluated on train, validation, and test sets, with the three curves closely matching, confirming the generalizability of the learned dynamic classification policy. Figure 4 demonstrates the classifier's improvement in making accurate predictions during RL training, with training only on data selected by the RL algorithm."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We present the training curves of Algorithm 1 on the AKI dataset in Figures 3 and 4. Figure 3 shows the performance of RL policies evaluated on train, validation, and test sets, with the three curves closely matching, confirming the generalizability of the learned dynamic classification policy. Figure 4 demonstrates the classifier's improvement in making accurate predictions during RL training, with training only on data selected by the RL algorithm."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We present the training curves of Algorithm 1 on the AKI dataset in Figures 3 and 4. Figure 3 shows the performance of RL policies evaluated on train, validation, and test sets, with the three curves closely matching, confirming the generalizability of the learned dynamic classification policy. Figure 4 demonstrates the classifier's improvement in making accurate predictions during RL training, with training only on data selected by the RL algorithm."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We present the training curves of Algorithm 1 on the AKI dataset in Figures 3 and 4. Figure 3 shows the performance of RL policies evaluated on train, validation, and test sets, with the three curves closely matching, confirming the generalizability of the learned dynamic classification policy. Figure 4 demonstrates the classifier's improvement in making accurate predictions during RL training, with training only on data selected by the RL algorithm."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We present the training curves of Algorithm 1 on the AKI dataset in Figures 3 and 4. Figure 3 shows the performance of RL policies evaluated on train, validation, and test sets, with the three curves closely matching, confirming the generalizability of the learned dynamic classification policy. Figure 4 demonstrates the classifier's improvement in making accurate predictions during RL training, with training only on data selected by the RL algorithm."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We present the training curves of Algorithm 1 on the AKI dataset in Figures 3 and 4. Figure 3 shows the performance of RL policies evaluated on train, validation, and test sets, with the three curves closely matching, confirming the generalizability of the learned dynamic classification policy. Figure 4 demonstrates the classifier's improvement in making accurate predictions during RL training, with training only on data selected by the RL algorithm."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "instruction": "Move the less important results to an appendix.", "revised_paragraph": "Revised paragraph: \"We present the training curves of Algorithm 1 on AKI dataset in Figure 3, which demonstrates the generalizability of the learned dynamic classification policy through the close match between the performance curves on train, validation, and test sets. Figure 4 shows the learning process of the diagnostic classifier, which is trained from scratch in end-to-end training and maps partially-observed patient states to diagnoses/predictions. We evaluate this classifier on static data distributions to eliminate the effect of dynamic test selection and focus on classification quality, and observe improved prediction quality during RL training.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "jd7eZJSVj.YFwsqqBl_J.00", "instruction": "Replace less important results by a reference to Appendix B. Revise this paragraph.", "revised_paragraph": "Revised paragraph: \"We present the training curves of Algorithm 1 on AKI dataset in Figure 3 and 4. The performance of the RL policies is evaluated on train, validation, and test sets, as shown in Figure 3, demonstrating the generalizability of the learned dynamic classification policy. Additionally, as described in Appendix B, the SM-DDPO learns the disease model through end-to-end training, mapping partially-observed patient states to diagnoses/predictions. The quality of these predictions is evaluated on static data distributions, eliminating the effect of dynamic test selection and focusing on classification quality, as shown in Figure 4, where the classifier improves its prediction quality during RL training.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as CFR-WASS and the proposed ESCFR, outperform statistical methods in terms of out-of-sample PEHE and AUUC. While they mitigate treatment selection bias, they are hindered by MSE and UCE issues. Our ESCFR achieves significant improvements over baselines, which we attribute to its robust design incorporating RMPR and PFOR regularizers.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods effectively mitigate treatment selection bias and improve overall performance. Specifically, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, outperforming most statistical methods in this regard. Additionally, it obtains an AUUC of 0.715 on IHDP, surpassing all other baselines. Although representation-based methods can be effective, they are limited by issues with mean squared error (MSE) and unbiased coverage error (UCE), which hinder the mitigation of treatment selection bias. In contrast, our proposed ESCFR method demonstrates significant improvements across various metrics when compared to state-of-the-art baselines, which we attribute to the design of our robust regularizers, RMPR and PFOR, that are resistant to MSE and UCE issues.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as CFR-WASS and the proposed ESCFR, outperform statistical methods in terms of out-of-sample PEHE and AUUC. While they mitigate treatment selection bias, they are hindered by MSE and UCE issues. Our ESCFR achieves significant improvements over baselines, which we attribute to its robust design incorporating RMPR and PFOR regularizers.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods effectively mitigate treatment selection bias and improve overall performance. Specifically, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, outperforming most statistical methods in this regard. Additionally, it obtains an AUUC of 0.715 on IHDP, surpassing all other baselines. Although representation-based methods can be effective, they are limited by issues with mean squared error (MSE) and unbiased coverage error (UCE), which hinder the mitigation of treatment selection bias. In contrast, our proposed ESCFR method demonstrates significant improvements across various metrics when compared to state-of-the-art baselines, which we attribute to the design of our robust regularizers, RMPR and PFOR, that are resistant to MSE and UCE issues.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as CFR-WASS and the proposed ESCFR, outperform statistical methods in terms of out-of-sample PEHE and AUUC. While they mitigate treatment selection bias, they are hindered by MSE and UCE issues. Our ESCFR achieves significant improvements over baselines, which we attribute to its robust design incorporating RMPR and PFOR regularizers.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods effectively mitigate treatment selection bias and improve overall performance. Specifically, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, outperforming most statistical methods in this regard. Additionally, it obtains an AUUC of 0.715 on IHDP, surpassing all other baselines. Although representation-based methods can be effective, they are limited by issues with mean squared error (MSE) and unbiased coverage error (UCE), which hinder the mitigation of treatment selection bias. In contrast, our proposed ESCFR method demonstrates significant improvements across various metrics when compared to state-of-the-art baselines, which we attribute to the design of our robust regularizers, RMPR and PFOR, that are resistant to MSE and UCE issues.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as CFR-WASS and the proposed ESCFR, outperform statistical methods in terms of out-of-sample PEHE and AUUC. While they mitigate treatment selection bias, they are hindered by MSE and UCE issues. Our ESCFR achieves significant improvements over baselines, which we attribute to its robust design incorporating RMPR and PFOR regularizers.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods effectively mitigate treatment selection bias and improve overall performance. Specifically, CFR-WASS achieves an out-of-sample PEHE of 3.207 on ACIC, outperforming most statistical methods in this regard. Additionally, it obtains an AUUC of 0.715 on IHDP, surpassing all other baselines. Although representation-based methods can be effective, they are limited by issues with mean squared error (MSE) and unbiased coverage error (UCE), which hinder the mitigation of treatment selection bias. In contrast, our proposed ESCFR method demonstrates significant improvements across various metrics when compared to state-of-the-art baselines, which we attribute to the design of our robust regularizers, RMPR and PFOR, that are resistant to MSE and UCE issues.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as CFR-WASS and the proposed ESCFR, outperform statistical methods in terms of out-of-sample PEHE and AUUC. While they mitigate treatment selection bias, they are hindered by MSE and UCE issues. Our ESCFR achieves significant improvements over baselines, which we attribute to its robust design incorporating RMPR and PFOR regularizers.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods, including CFR-WASS and the proposed ESCFR, consistently outperform statistical methods in terms of out-of-sample predictive error (PEHE) and area under the receiver operating characteristic curve (AUUC). Although they effectively mitigate treatment selection bias, they are limited by mean squared error (MSE) and unbiased cumulative error (UCE) issues. Our ESCFR algorithm demonstrates significant improvements over baseline models, which we attribute to its robust design, incorporating recursive mean prediction and partial forward regression regularizers.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as CFR-WASS and the proposed ESCFR, outperform statistical methods in terms of out-of-sample PEHE and AUUC. While they mitigate treatment selection bias, they are hindered by MSE and UCE issues. Our ESCFR achieves significant improvements over baselines, which we attribute to its robust design incorporating RMPR and PFOR regularizers.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods, including CFR-WASS and the proposed ESCFR, consistently outperform statistical methods in terms of out-of-sample predictive error (PEHE) and area under the receiver operating characteristic curve (AUUC). Although they effectively mitigate treatment selection bias, they are limited by mean squared error (MSE) and unbiased cumulative error (UCE) issues. Our ESCFR algorithm demonstrates significant improvements over baseline models, which we attribute to its robust design, incorporating recursive mean prediction and partial forward regression regularizers.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as CFR-WASS and the proposed ESCFR, outperform statistical methods in terms of out-of-sample PEHE and AUUC. While they mitigate treatment selection bias, they are hindered by MSE and UCE issues. Our ESCFR achieves significant improvements over baselines, which we attribute to its robust design incorporating RMPR and PFOR regularizers.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods, including CFR-WASS and the proposed ESCFR, consistently outperform statistical methods in terms of out-of-sample predictive error (PEHE) and area under the receiver operating characteristic curve (AUUC). Although they effectively mitigate treatment selection bias, they are limited by mean squared error (MSE) and unbiased cumulative error (UCE) issues. Our ESCFR algorithm demonstrates significant improvements over baseline models, which we attribute to its robust design, incorporating recursive mean prediction and partial forward regression regularizers.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as CFR-WASS and the proposed ESCFR, outperform statistical methods in terms of out-of-sample PEHE and AUUC. While they mitigate treatment selection bias, they are hindered by MSE and UCE issues. Our ESCFR achieves significant improvements over baselines, which we attribute to its robust design incorporating RMPR and PFOR regularizers.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods, including CFR-WASS and the proposed ESCFR, consistently outperform statistical methods in terms of out-of-sample predictive error (PEHE) and area under the receiver operating characteristic curve (AUUC). Although they effectively mitigate treatment selection bias, they are limited by mean squared error (MSE) and unbiased cumulative error (UCE) issues. Our ESCFR algorithm demonstrates significant improvements over baseline models, which we attribute to its robust design, incorporating recursive mean prediction and partial forward regression regularizers.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "instruction": "Remove redundant information and use more scientific words.", "revised_paragraph": "Revised paragraph: \"Representation-based methods effectively alleviate treatment selection bias and improve overall performance. Specifically, CFR-WASS achieves an out-of-sample predictive error (PEHE) of 3.207 on the Artificial Control Intervention Challenge (ACIC), surpassing most statistical methods. Moreover, it obtains an area under the receiver operating characteristic curve (AUUC) of 0.715 on the Infant Health and Development Program (IHDP), outperforming all other baselines. However, mean squared error (MSE) and unbiased cumulative error (UCE) issues remain a challenge for these methods. In contrast, our proposed ESCFR method exhibits significant improvements across various metrics compared to state-of-the-art baselines, which we attribute to the design of our robustness-promoting regularizers, namely the recursive mean prediction regularizer (RMPR) and penalty function for outlier reduction (PFOR), enabling ESCFR to be resilient to MSE and UCE.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.16", "instruction": "Make this text simpler and more readable. Remove unnecessary details about AUUC.", "revised_paragraph": "Revised paragraph: Representation-based methods can help reduce treatment selection bias and improve overall performance. For instance, CFR-WASS achieves a PEHE of 3.207 on ACIC, outperforming most statistical methods. Similarly, it obtains an AUUC of 0.715 on IHDP, exceeding other baselines. However, issues with MSE and UCE still hinder the mitigation of treatment selection bias. Our proposed ESCFR method shows significant improvements over various state-of-the-art baselines, which we attribute to the design of our RMPR and PFOR regularizers, making it more robust to MSE and UCE.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Ablations: Figure 5 presents the ablation results for test actions. In the Grid World, all ablations utilize the summary of the action set as input, aggregated through various mechanisms, enabling them to identify available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relations, summary-ablations perform similarly to AGILE. This trend is also observed in RecSim and Real RecSys, where the information about the most common category is sufficient to select items from the same category to maximize CPR (as shown in Figure 6(c)). As a result, we observe only 5-20% gains for AGILE over the ablations. To verify the consistency of these results, we further evaluate the performance on two additional RecSim tasks: (i) Direct CPR, where the goal is to maximize CPR while receiving an additional CPR metric reward on top of the click/no-click reward (Section B.3), and (ii) Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Our results consistently show that AGILE outperforms the ablations."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 5 illustrates the ablation results on test actions in Grid World, where all ablations utilize the summary of the action set as input, aggregated through various mechanisms. This enables them to identify the available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relationships, the summary-ablations perform similarly to AGILE. This trend is also observed in RecSim and Real RecSys, where the information about the most common category is sufficient to select items from the same category to maximize CPR (as shown in Figure 6(c)). Consequently, we observe only 5-20% gains of AGILE over the ablations. To further validate the consistency of our results, we evaluate the performance on two additional RecSim tasks: (i) Direct CPR, where the agent receives an additional CPR metric reward on top of the click/no-click reward (see Section B.3); and (ii) Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Our results consistently show that AGILE outperforms the ablations.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 5 illustrates the ablation results on test actions in Grid World, where all ablations utilize the summary of the action set as input, aggregated through various mechanisms. This enables them to identify the available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relationships, the summary-ablations perform similarly to AGILE. This trend is also observed in RecSim and Real RecSys, where the information about the most common category is sufficient to select items from the same category to maximize CPR (as shown in Figure 6(c)). Consequently, we observe only 5-20% gains of AGILE over the ablations. To further validate the consistency of our results, we evaluate the performance on two additional RecSim tasks: (i) Direct CPR, where the agent receives an additional CPR metric reward on top of the click/no-click reward (see Section B.3); and (ii) Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Our results consistently show that AGILE outperforms the ablations.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Ablations: Figure 5 presents the ablation results for test actions. In the Grid World, all ablations utilize the summary of the action set as input, aggregated through various mechanisms, enabling them to identify available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relations, summary-ablations perform similarly to AGILE. This trend is also observed in RecSim and Real RecSys, where the information about the most common category is sufficient to select items from the same category to maximize CPR (as shown in Figure 6(c)). As a result, we observe only 5-20% gains for AGILE over the ablations. To verify the consistency of these results, we further evaluate the performance on two additional RecSim tasks: (i) Direct CPR, where the goal is to maximize CPR while receiving an additional CPR metric reward on top of the click/no-click reward (Section B.3), and (ii) Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Our results consistently show that AGILE outperforms the ablations."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Ablations: Figure 5 presents the ablation results for test actions. In the Grid World, all ablations utilize the summary of the action set as input, aggregated through various mechanisms, enabling them to identify available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relations, summary-ablations perform similarly to AGILE. This trend is also observed in RecSim and Real RecSys, where the information about the most common category is sufficient to select items from the same category to maximize CPR (as shown in Figure 6(c)). As a result, we observe only 5-20% gains for AGILE over the ablations. To verify the consistency of these results, we further evaluate the performance on two additional RecSim tasks: (i) Direct CPR, where the goal is to maximize CPR while receiving an additional CPR metric reward on top of the click/no-click reward (Section B.3), and (ii) Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Our results consistently show that AGILE outperforms the ablations."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The ablation results for test actions are presented in Figure 5. In the Grid World, all ablations utilize the summary of the action set as input, aggregated through various mechanisms, allowing them to identify available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relations, summary-ablations perform similarly to AGILE. This trend is also observed in RecSim and Real RecSys, where the information about the most common category is sufficient to select items from the same category to maximize CPR (as shown in Figure 6(c)). Notably, we observe only 5-20% gains for AGILE over the ablations. To verify the consistency of these results, we further evaluate the performance on two additional RecSim tasks: Direct CPR, where the goal is to maximize CPR while receiving an additional CPR metric reward on top of the click/no-click reward (Section B.3), and Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Our results consistently demonstrate that AGILE outperforms the ablations, indicating its robustness in different scenarios."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 5 illustrates the ablation results on test actions in Grid World, where all ablations utilize the summary of the action set as input, aggregated through various mechanisms. This enables them to identify the available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relationships, the summary-ablations perform similarly to AGILE. This trend is also observed in RecSim and Real RecSys, where the information about the most common category is sufficient to select items from the same category to maximize CPR (as shown in Figure 6(c)). Consequently, we observe only 5-20% gains of AGILE over the ablations. To further validate the consistency of our results, we evaluate the performance on two additional RecSim tasks: (i) Direct CPR, where the agent receives an additional CPR metric reward on top of the click/no-click reward (see Section B.3); and (ii) Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Our results consistently show that AGILE outperforms the ablations.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Ablations: Figure 5 presents the ablation results for test actions. In the Grid World, all ablations utilize the summary of the action set as input, aggregated through various mechanisms, enabling them to identify available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relations, summary-ablations perform similarly to AGILE. This trend is also observed in RecSim and Real RecSys, where the information about the most common category is sufficient to select items from the same category to maximize CPR (as shown in Figure 6(c)). As a result, we observe only 5-20% gains for AGILE over the ablations. To verify the consistency of these results, we further evaluate the performance on two additional RecSim tasks: (i) Direct CPR, where the goal is to maximize CPR while receiving an additional CPR metric reward on top of the click/no-click reward (Section B.3), and (ii) Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Our results consistently show that AGILE outperforms the ablations."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "instruction": "Correct some issues in the paragraph and replace certain words to improve it", "revised_paragraph": "Revised paragraph: \"Figure 5 presents the ablation results on test actions in Grid World. The ablations utilize the summary of the action set as input, aggregated through various mechanisms, allowing them to identify available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relationships, summary-ablations perform on par with AGILE. This trend is also observed in RecSim and Real RecSys, where knowledge of the most common category is sufficient to select items from the same category to maximize CPR (e.g., Figure 6(c)). Consequently, we observe only 5-20% gains of AGILE over the ablations. To validate the consistency of these results, we further evaluate the performance on two additional RecSim tasks: (i) Direct CPR, where the goal is to maximize CPR, with an additional CPR metric reward on top of the click/no-click reward (Section B.3); and (ii) Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Notably, we reproduce the trend that AGILE outperforms the ablations.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "instruction": "Improve the overall clarity of the paragraph.", "revised_paragraph": "Revised paragraph: Figure 5 presents the ablation results on test actions in the Grid World environment, where all ablations utilize the summary of the action set as input, aggregated via different mechanisms. This allows them to identify available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relations, the summary-ablations perform similarly to AGILE, as seen in Figure 6(c) for RecSim and Real RecSys, where the most common category's information is sufficient to select items to maximize CPR. Our results show only 5-20% gains of AGILE over the ablations. To ensure the consistency of these results, we further evaluate AGILE and the ablations on two additional RecSim tasks: direct CPR, where the agent receives an additional CPR metric reward, and the pairing environment, where the goal is to recommend pairs of associated items based on pre-defined pairings.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We set a small constant M and a number of particle functions r to estimate the log marginal likelihood log p (D) with mini-batches. We aim to estimate \u2207FLD, X(Q[T]) = 0 using unbiased estimates of \u2113(D, fiXD) and a theoretical framework that guarantees maximizing a lower bound of log p (D) with full-batch training. We present two algorithms, Stein functional variational NNs and Stein functional variational gradient boosting, which rely on the estimated Stein functional variational gradient. If an analytical score gradient is unavailable, we can use a score gradient estimator, which requires function samples of the prior process evaluated at X."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We set a small constant M and a number of particle functions r to estimate the log marginal likelihood log p (D) with mini-batches. We aim to estimate \u2207FLD, X(Q[T]) = 0 using unbiased estimates of \u2113(D, fiXD) and a theoretical framework that guarantees maximizing a lower bound of log p (D) with full-batch training. We present two algorithms, Stein functional variational NNs and Stein functional variational gradient boosting, which rely on the estimated Stein functional variational gradient. If an analytical score gradient is unavailable, we can use a score gradient estimator, which requires function samples of the prior process evaluated at X."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We set a small constant M and a number of particle functions r to estimate the log marginal likelihood log p (D) with mini-batches. We aim to estimate \u2207FLD, X(Q[T]) = 0 using unbiased estimates of \u2113(D, fiXD) and a theoretical framework that guarantees maximizing a lower bound of log p (D) with full-batch training. We present two algorithms, Stein functional variational NNs and Stein functional variational gradient boosting, which rely on the estimated Stein functional variational gradient. If an analytical score gradient is unavailable, we can use a score gradient estimator, which requires function samples of the prior process evaluated at X."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We set a small constant M and a number of particle functions r to estimate the log marginal likelihood log p (D) with mini-batches. We aim to estimate \u2207FLD, X(Q[T]) = 0 using unbiased estimates of \u2113(D, fiXD) and a theoretical framework that guarantees maximizing a lower bound of log p (D) with full-batch training. We present two algorithms, Stein functional variational NNs and Stein functional variational gradient boosting, which rely on the estimated Stein functional variational gradient. If an analytical score gradient is unavailable, we can use a score gradient estimator, which requires function samples of the prior process evaluated at X."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We set a small constant M and a number of particle functions r to estimate the log marginal likelihood log p (D) with mini-batches. We aim to estimate \u2207FLD, X(Q[T]) = 0 using unbiased estimates of \u2113(D, fiXD) and a theoretical framework that guarantees maximizing a lower bound of log p (D) with full-batch training. We present two algorithms, Stein functional variational NNs and Stein functional variational gradient boosting, which rely on the estimated Stein functional variational gradient. If an analytical score gradient is unavailable, we can use a score gradient estimator, which requires function samples of the prior process evaluated at X."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We set a small constant M and a number of particle functions r to estimate the log marginal likelihood log p (D) with mini-batches. We aim to estimate \u2207FLD, X(Q[T]) = 0 using unbiased estimates of \u2113(D, fiXD) and a theoretical framework that guarantees maximizing a lower bound of log p (D) with full-batch training. We present two algorithms, Stein functional variational NNs and Stein functional variational gradient boosting, which rely on the estimated Stein functional variational gradient. If an analytical score gradient is unavailable, we can use a score gradient estimator, which requires function samples of the prior process evaluated at X."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We set a small constant M and a number of particle functions r to estimate the log marginal likelihood log p (D) with mini-batches. We aim to estimate \u2207FLD, X(Q[T]) = 0 using unbiased estimates of \u2113(D, fiXD) and a theoretical framework that guarantees maximizing a lower bound of log p (D) with full-batch training. We present two algorithms, Stein functional variational NNs and Stein functional variational gradient boosting, which rely on the estimated Stein functional variational gradient. If an analytical score gradient is unavailable, we can use a score gradient estimator, which requires function samples of the prior process evaluated at X."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: We set a small constant M and a number of particle functions r to estimate the log marginal likelihood log p (D) with mini-batches. We aim to estimate \u2207FLD, X(Q[T]) = 0 using unbiased estimates of \u2113(D, fiXD) and a theoretical framework that guarantees maximizing a lower bound of log p (D) with full-batch training. We present two algorithms, Stein functional variational NNs and Stein functional variational gradient boosting, which rely on the estimated Stein functional variational gradient. If an analytical score gradient is unavailable, we can use a score gradient estimator, which requires function samples of the prior process evaluated at X."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "instruction": "Remove details about the theoretical framework and make this paragraph more concise.", "revised_paragraph": "Revised paragraph: We set a small constant number for M, as L D, [ X D, X M ] is a lower bound for the log marginal likelihood log p ( D ) for M > 1. We also set r to a number of particle functions that can represent the posterior SP reasonably well. We aim to estimate the gradient of the functional log likelihood F L D, X ( Q [ T ] ) =0 with mini-batches. We use mini-batch training with \u03bb = s/n, which provides reasonable performance in practice, although L D s, X is not a lower bound of log p ( D ). Our approach builds upon SVGD and offers an additional gradient-free method that only requires evaluating the marginal densities of the prior process.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "Z3g7qGrao.v3MXAzVXjk.00", "instruction": "Remove unnecessary content to make this paragraph shorter.", "revised_paragraph": "Revised paragraph: We set a small constant number M and a number of particle functions r to estimate the log marginal likelihood log p(D) with mini-batches. We are interested in estimating the gradient of the functional FLD, X(Q[T]) with mini-batches. Although LDs, X is not a lower bound of log p(D), we found that \u03bb = s/n results in reasonable performance in practice. Our theoretical framework guarantees that full-batch training maximizes a lower bound of log p(D). We present two algorithms, Stein functional variational NNs and Stein functional variational gradient boosting, which depend on the score gradient of the functional prior evaluated at X. If no analytical score gradient exists, we use a score gradient estimator, which requires function samples of the prior process evaluated at X.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We evaluate DVRL on 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. The datasets include Blog, Adult, and Rossmann (tabular); HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 (image); and Email Spam and SMS Spam (language). Details can be found in the provided hyper-links (in blue).\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We evaluate DVRL on 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. The datasets include Blog, Adult, and Rossmann (tabular); HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 (image); and Email Spam and SMS Spam (language). Details can be found in the provided hyper-links (in blue).\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We evaluate DVRL on 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. The datasets include Blog, Adult, and Rossmann (tabular); HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 (image); and Email Spam and SMS Spam (language). Details can be found in the provided hyper-links (in blue).\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"We evaluate DVRL on 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. The datasets include Blog, Adult, and Rossmann (tabular); HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 (image); and Email Spam and SMS Spam (language). Details can be found in the provided hyper-links (in blue).\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We evaluate DVRL on 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. The datasets include Blog, Adult, and Rossmann (tabular); HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 (image); and Email Spam and SMS Spam (language). Details can be found in the provided hyper-links (in blue).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We evaluate DVRL on 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. The datasets include Blog, Adult, and Rossmann (tabular); HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 (image); and Email Spam and SMS Spam (language). Details can be found in the provided hyper-links (in blue).\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We evaluate DVRL on 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. The datasets include Blog, Adult, and Rossmann (tabular); HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 (image); and Email Spam and SMS Spam (language). Details can be found in the provided hyper-links (in blue).\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We evaluate DVRL on 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. The datasets include Blog, Adult, and Rossmann (tabular); HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 (image); and Email Spam and SMS Spam (language). Details can be found in the provided hyper-links (in blue).\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "instruction": "Make the last sentence more concise.", "revised_paragraph": "Revised paragraph: Datasets: We evaluate DVRL using 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. Specifically, these include Blog, Adult, Rossmann, HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, CIFAR-100, Email Spam, and SMS Spam. Detailed information on these datasets can be found in the provided hyperlinks.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "instruction": "Make the last sentence shorter.", "revised_paragraph": "Revised paragraph: Datasets: We evaluate DVRL using 12 public datasets, comprising 3 tabular, 7 image, and 2 language datasets. The datasets include Blog, Adult, and Rossmann (tabular), HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 (image), and Email Spam and SMS Spam (language). More information can be found in the provided hyperlinks.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"In our design, calendar entries are represented as rectangular bars, with height indicating duration and color hue representing the user-defined category. Medication entries are displayed as bars with vertical position and height indicating the allowed administration period. A horizontal marker indicates the preferred administration time, with higher opacity for preferred and lower opacity for allowed times. The color hue encodes the type of medication.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Calendar entries are presented in a standard calendar format, where the height of rectangular entries corresponds to their duration, and their color hue represents their type or category, as set by the user. The entry's name is also displayed as a label. For medication entries, we use bars or rectangles to represent the allowed administration period, with the vertical position and height indicating the start and end times. A horizontal marker is embossed on the bar to indicate the preferred administration time, which triggers a reminder if programmed. The preferred administration time is displayed with higher opacity, while the allowed administrative time is shown with lower opacity. The color hue of the medication entry encodes the type of medication."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Calendar entries are presented in a standard calendar format, where the height of rectangular entries corresponds to their duration, and their color hue represents their type or category, as set by the user. The entry's name is also displayed as a label. For medication entries, we use bars or rectangles to represent the allowed administration period, with the vertical position and height indicating the start and end times. A horizontal marker is embossed on the bar to indicate the preferred administration time, which triggers a reminder if programmed. The preferred administration time is displayed with higher opacity, while the allowed administrative time is shown with lower opacity. The color hue of the medication entry encodes the type of medication."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Calendar entries are presented in a standard calendar format, where the height of rectangular entries corresponds to their duration, and their color hue represents their type or category, as set by the user. The entry's name is also displayed as a label. For medication entries, we use bars or rectangles to represent the allowed administration period, with the vertical position and height indicating the start and end times. A horizontal marker is embossed on the bar to indicate the preferred administration time, which triggers a reminder if programmed. The preferred administration time is displayed with higher opacity, while the allowed administrative time is shown with lower opacity. The color hue of the medication entry encodes the type of medication."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"In our design, calendar entries are represented as rectangular bars, with height indicating duration and color hue representing the user-defined category. Medication entries are displayed as bars with vertical position and height indicating the allowed administration period. A horizontal marker indicates the preferred administration time, with higher opacity for preferred and lower opacity for allowed times. The color hue encodes the type of medication.\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Calendar entries are presented in a standard calendar format, where the height of rectangular entries corresponds to their duration, and their color hue represents their type or category, as set by the user. The entry's name is also displayed as a label. For medication entries, we use bars or rectangles to represent the allowed administration period, with the vertical position and height indicating the start and end times. A horizontal marker is embossed on the bar to indicate the preferred administration time, which triggers a reminder if programmed. The preferred administration time is displayed with higher opacity, while the allowed administrative time is shown with lower opacity. The color hue of the medication entry encodes the type of medication."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"In our design, calendar entries are represented as rectangular bars, with height indicating duration and color hue representing the user-defined category. Medication entries are displayed as bars with vertical position and height indicating the allowed administration period. A horizontal marker indicates the preferred administration time, with higher opacity for preferred and lower opacity for allowed times. The color hue encodes the type of medication.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"In our design, calendar entries are visualized as rectangular bars, where the height of each bar corresponds to the duration and the color hue represents the user-defined category. Medication entries are displayed as bars with vertical position and height indicating the allowed administration period. A horizontal marker is used to indicate the preferred administration time, with higher opacity indicating preferred times and lower opacity indicating allowed times. The color hue of each bar further encodes the type of medication being represented.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Calendar entries are presented in a standard calendar format, where the height of rectangular entries corresponds to their duration, and their color hue represents their type or category, as set by the user. The entry's name is also displayed as a label. For medication entries, we use bars or rectangles to represent the allowed administration period, with the vertical position and height indicating the start and end times. A horizontal marker is embossed on the bar to indicate the preferred administration time, which triggers a reminder if programmed. The preferred administration time is displayed with higher opacity, while the allowed administrative time is shown with lower opacity. The color hue of the medication entry encodes the type of medication."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Calendar entries are presented in a standard calendar format, where the height of rectangular entries corresponds to their duration, and their color hue represents their type or category, as set by the user. The entry's name is also displayed as a label. For medication entries, we use bars or rectangles to represent the allowed administration period, with the vertical position and height indicating the start and end times. A horizontal marker is embossed on the bar to indicate the preferred administration time, which triggers a reminder if programmed. The preferred administration time is displayed with higher opacity, while the allowed administrative time is shown with lower opacity. The color hue of the medication entry encodes the type of medication."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"In our design, calendar entries are represented as rectangular bars, with height indicating duration and color hue representing the user-defined category. Medication entries are displayed as bars with vertical position and height indicating the allowed administration period. A horizontal marker indicates the preferred administration time, with higher opacity for preferred and lower opacity for allowed times. The color hue encodes the type of medication.\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"In our design, calendar entries are visualized as rectangular bars, where the height of each bar corresponds to the duration and the color hue represents the user-defined category. Medication entries are displayed as bars with vertical position and height indicating the allowed administration period. A horizontal marker is used to indicate the preferred administration time, with higher opacity indicating preferred times and lower opacity indicating allowed times. The color hue of each bar further encodes the type of medication being represented.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "instruction": "Improve the English of this paragraph.", "revised_paragraph": "Revised paragraph: \"Calendar entries are visualized in a standard calendar format, where the height of rectangular entries corresponds to their duration, and their color hue indicates the user-defined category or type. In addition, medication entries are represented by rectangles (or bars) that convey the start and end dates of the permitted administration period. A horizontal embossed marker is placed on the bar to indicate the preferred administration time, which is the point at which a reminder would be triggered if programmed. The preferred administration time is depicted with higher opacity, while the allowed administration time is shown with lower opacity. The color hue of each medication entry encodes its type.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.10", "instruction": "Make the first sentence more concise and direct.", "revised_paragraph": "Revised paragraph: Calendar entries are represented as rectangular blocks, with height indicating duration, color hue denoting category, and label displaying the entry name. Medication entries are also represented as bars, with vertical position and height indicating the allowed administration period. An embossed horizontal marker on the bar indicates the preferred administration time, with higher opacity indicating the preferred time and lower opacity indicating the allowed time. Color hue encodes the type of medication.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our method offers a solution to the challenges mentioned earlier. By training the rotamer density estimator solely on protein structures, it becomes an unsupervised learner that can accurately predict the effect of mutations on binding, even in the absence of annotated mutation data. Notably, our method does not require the structure of the mutated protein as input, instead treating mutated structures as latent variables and using the rotamer density estimator to approximate the underlying distribution. Our approach outperforms both empirical energy functions and machine learning models in predicting \u2206\u2206G values. Furthermore, as a generative model for rotamers, the RDE accurately predicts sidechain conformations."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our method offers a solution to the challenges mentioned earlier. By training the rotamer density estimator solely on protein structures, it becomes an unsupervised learner that can accurately predict the effect of mutations on binding, even in the absence of annotated mutation data. Notably, our method does not require the structure of the mutated protein as input, instead treating mutated structures as latent variables and using the rotamer density estimator to approximate the underlying distribution. Our approach outperforms both empirical energy functions and machine learning models in predicting \u2206\u2206G values. Furthermore, as a generative model for rotamers, the RDE accurately predicts sidechain conformations."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our method offers a solution to the challenges mentioned earlier. By training the rotamer density estimator solely on protein structures, it becomes an unsupervised learner that can accurately predict the effect of mutations on binding, even in the absence of annotated mutation data. Notably, our method does not require the structure of the mutated protein as input, instead treating mutated structures as latent variables and using the rotamer density estimator to approximate the underlying distribution. Our approach outperforms both empirical energy functions and machine learning models in predicting \u2206\u2206G values. Furthermore, as a generative model for rotamers, the RDE accurately predicts sidechain conformations."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our method offers a solution to the challenges mentioned earlier. By training the rotamer density estimator solely on protein structures, it becomes an unsupervised learner that can accurately predict the effect of mutations on binding, even in the absence of annotated mutation data. Notably, our method does not require the structure of the mutated protein as input, instead treating mutated structures as latent variables and using the rotamer density estimator to approximate the underlying distribution. Our approach outperforms both empirical energy functions and machine learning models in predicting \u2206\u2206G values. Furthermore, as a generative model for rotamers, the RDE accurately predicts sidechain conformations."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our method offers a solution to the challenges mentioned earlier. By training the rotamer density estimator solely on protein structures, it becomes an unsupervised learner that can accurately predict the effect of mutations on binding, even in the absence of annotated mutation data. Notably, our method does not require the structure of the mutated protein as input, instead treating mutated structures as latent variables and using the rotamer density estimator to approximate the underlying distribution. Our approach outperforms both empirical energy functions and machine learning models in predicting \u2206\u2206G values. Furthermore, as a generative model for rotamers, the RDE accurately predicts sidechain conformations."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our method offers a solution to the challenges mentioned earlier. By training the rotamer density estimator solely on protein structures, it becomes an unsupervised learner that can accurately predict the effect of mutations on binding, even in the absence of annotated mutation data. Notably, our method does not require the structure of the mutated protein as input, instead treating mutated structures as latent variables and using the rotamer density estimator to approximate the underlying distribution. Our approach outperforms both empirical energy functions and machine learning models in predicting \u2206\u2206G values. Furthermore, as a generative model for rotamers, the RDE accurately predicts sidechain conformations."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our method offers a solution to the challenges mentioned earlier. By training the rotamer density estimator solely on protein structures, it becomes an unsupervised learner that can accurately predict the effect of mutations on binding, even in the absence of annotated mutation data. Notably, our method does not require the structure of the mutated protein as input, instead treating mutated structures as latent variables and using the rotamer density estimator to approximate the underlying distribution. Our approach outperforms both empirical energy functions and machine learning models in predicting \u2206\u2206G values. Furthermore, as a generative model for rotamers, the RDE accurately predicts sidechain conformations."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our method offers a solution to the challenges mentioned earlier. By training the rotamer density estimator solely on protein structures, it becomes an unsupervised learner that can accurately predict the effect of mutations on binding, even in the absence of annotated mutation data. Notably, our method does not require the structure of the mutated protein as input, instead treating mutated structures as latent variables and using the rotamer density estimator to approximate the underlying distribution. Our approach outperforms both empirical energy functions and machine learning models in predicting \u2206\u2206G values. Furthermore, as a generative model for rotamers, the RDE accurately predicts sidechain conformations."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "instruction": "Give me a more formal version of the following paragraph.", "revised_paragraph": "Revised paragraph: Our proposed method offers a solution to the aforementioned challenges. By training the rotamer density estimator solely on protein structures, it operates as an unsupervised learner, enabling the estimation of the effect of mutations on binding in the absence of annotated mutation data. Furthermore, our approach does not necessitate the input of the mutated protein structure, instead treating these structures as latent variables and utilizing the rotamer density estimator as an approximator of the latent distribution. Notably, our method outperforms empirical energy functions and machine learning models in predicting \u0394\u0394G values. Additionally, as a generative model for rotamers, the RDE accurately predicts sidechain conformations.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.05", "instruction": "Rewrite this paragraph in a more formal and academic way.", "revised_paragraph": "Revised paragraph: Our proposed method offers a novel solution to the challenges discussed earlier. By training the rotamer density estimator solely on protein structures, it functions as an unsupervised learner that elucidates the impact of mutations on binding affinity, thereby circumventing the limitations imposed by the scarcity of annotated mutation data. Notably, our approach does not necessitate the structural information of the mutated protein as input, instead treating mutated structures as latent variables and employing the rotamer density estimator as an approximator of the underlying latent distribution. Comparative evaluations reveal that our method outperforms empirical energy functions and machine learning models in predicting \u0394\u0394G values. Moreover, as a generative model for rotamers, the RDE demonstrates exceptional accuracy in predicting sidechain conformations.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator are derived from PDB-REDO, a refined X-ray structure database. The structures are filtered to exclude those with a resolution worse than 3.5 \u02daA and clustered by 50% sequence identity, resulting in 38,413 chain clusters. The clusters are randomly divided into training, validation, and test sets (95%/0.5%/4.5%). During training, a cluster is randomly selected, and a chain is randomly chosen from it. The structure is then cropped into a 128-amino acid patch, constructed by selecting a seed amino acid and its 127 nearest neighbors based on C-beta distances. To simulate mutations, 10% of the patch's amino acids have their rotamers masked, and noise is added to the rotamers of amino acids within 8 \u02daA of the closest masked amino acid."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator were derived from PDB-REDO (Joosten et al., 2014), a database of refined X-ray structures. To ensure high-quality structures, all entries with a resolution worse than 3.5 \u00c5 were removed. The protein chains were then clustered based on 50% sequence identity, resulting in 38,413 distinct clusters. These clusters were randomly divided into training, validation, and test sets in a ratio of 95:0.5:4.5. During training, the data loader selected a cluster at random and then randomly chose a chain from that cluster. Each structure was cropped into a 128-amino acid patch, constructed by first selecting a seed amino acid and then identifying its 127 nearest neighbors based on C-beta distances. To simulate mutations, the rotamers of 10% of the patch's amino acids were masked. Additionally, noise was added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid was less than 8 \u00c5."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator are derived from PDB-REDO, a refined X-ray structure database. The structures are filtered to exclude those with a resolution worse than 3.5 \u02daA and clustered by 50% sequence identity, resulting in 38,413 chain clusters. The clusters are randomly divided into training, validation, and test sets (95%/0.5%/4.5%). During training, a cluster is randomly selected, and a chain is randomly chosen from it. The structure is then cropped into a 128-amino acid patch, constructed by selecting a seed amino acid and its 127 nearest neighbors based on C-beta distances. To simulate mutations, 10% of the patch's amino acids have their rotamers masked, and noise is added to the rotamers of amino acids within 8 \u02daA of the closest masked amino acid."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator are derived from PDB-REDO, a refined X-ray structure database. The structures are filtered to exclude those with a resolution worse than 3.5 \u02daA and clustered by 50% sequence identity, resulting in 38,413 chain clusters. The clusters are randomly divided into training, validation, and test sets (95%/0.5%/4.5%). During training, a cluster is randomly selected, and a chain is randomly chosen from it. The structure is then cropped into a 128-amino acid patch, constructed by selecting a seed amino acid and its 127 nearest neighbors based on C-beta distances. To simulate mutations, 10% of the patch's amino acids have their rotamers masked, and noise is added to the rotamers of amino acids within 8 \u02daA of the closest masked amino acid."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator were derived from PDB-REDO (Joosten et al., 2014), a database of refined X-ray structures. To ensure high-quality structures, all entries with a resolution worse than 3.5 \u00c5 were removed. The protein chains were then clustered based on 50% sequence identity, resulting in 38,413 distinct clusters. These clusters were randomly divided into training, validation, and test sets in a ratio of 95:0.5:4.5. During training, the data loader selected a cluster at random and then randomly chose a chain from that cluster. Each structure was cropped into a 128-amino acid patch, constructed by first selecting a seed amino acid and then identifying its 127 nearest neighbors based on C-beta distances. To simulate mutations, the rotamers of 10% of the patch's amino acids were masked. Additionally, noise was added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid was less than 8 \u00c5."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator are derived from PDB-REDO, a refined X-ray structure database. The structures are filtered to exclude those with a resolution worse than 3.5 \u02daA and clustered by 50% sequence identity, resulting in 38,413 chain clusters. The clusters are randomly divided into training, validation, and test sets (95%/0.5%/4.5%). During training, a cluster is randomly selected, and a chain is randomly chosen from it. The structure is then cropped into a 128-amino acid patch, constructed by selecting a seed amino acid and its 127 nearest neighbors based on C-beta distances. To simulate mutations, 10% of the patch's amino acids have their rotamers masked, and noise is added to the rotamers of amino acids within 8 \u02daA of the closest masked amino acid."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator are derived from PDB-REDO, a refined X-ray structure database. The structures are filtered to exclude those with a resolution worse than 3.5 \u02daA and clustered by 50% sequence identity, resulting in 38,413 chain clusters. The clusters are randomly divided into training, validation, and test sets (95%/0.5%/4.5%). During training, a cluster is randomly selected, and a chain is randomly chosen from it. The structure is then cropped into a 128-amino acid patch, constructed by selecting a seed amino acid and its 127 nearest neighbors based on C-beta distances. To simulate mutations, 10% of the patch's amino acids have their rotamers masked, and noise is added to the rotamers of amino acids within 8 \u02daA of the closest masked amino acid."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator were derived from PDB-REDO, a refined X-ray structure database. To ensure data quality, structures with a resolution worse than 3.5 \u00c5 were excluded, and the remaining structures were clustered based on 50% sequence identity, resulting in 38,413 chain clusters. The clusters were then randomly divided into training, validation, and test sets (95%/0.5%/4.5%). During training, a cluster was randomly selected, and a chain was randomly chosen from it. The structure was then cropped into a 128-amino acid patch by selecting a seed amino acid and its 127 nearest neighbors based on C-beta distances. To simulate mutations, 10% of the patch's amino acids had their rotamers masked, and noise was added to the rotamers of amino acids within 8 \u00c5 of the closest masked amino acid."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator are derived from PDB-REDO, a refined X-ray structure database. The structures are filtered to exclude those with a resolution worse than 3.5 \u02daA and clustered by 50% sequence identity, resulting in 38,413 chain clusters. The clusters are randomly divided into training, validation, and test sets (95%/0.5%/4.5%). During training, a cluster is randomly selected, and a chain is randomly chosen from it. The structure is then cropped into a 128-amino acid patch, constructed by selecting a seed amino acid and its 127 nearest neighbors based on C-beta distances. To simulate mutations, 10% of the patch's amino acids have their rotamers masked, and noise is added to the rotamers of amino acids within 8 \u02daA of the closest masked amino acid."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator are derived from PDB-REDO, a refined X-ray structure database. The structures are filtered to exclude those with a resolution worse than 3.5 \u02daA and clustered by 50% sequence identity, resulting in 38,413 chain clusters. The clusters are randomly divided into training, validation, and test sets (95%/0.5%/4.5%). During training, a cluster is randomly selected, and a chain is randomly chosen from it. The structure is then cropped into a 128-amino acid patch, constructed by selecting a seed amino acid and its 127 nearest neighbors based on C-beta distances. To simulate mutations, 10% of the patch's amino acids have their rotamers masked, and noise is added to the rotamers of amino acids within 8 \u02daA of the closest masked amino acid."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator were derived from PDB-REDO (Joosten et al., 2014), a database of refined X-ray structures. To ensure high-quality structures, all entries with a resolution worse than 3.5 \u00c5 were removed. The protein chains were then clustered based on 50% sequence identity, resulting in 38,413 distinct clusters. These clusters were randomly divided into training, validation, and test sets in a ratio of 95:0.5:4.5. During training, the data loader selected a cluster at random and then randomly chose a chain from that cluster. Each structure was cropped into a 128-amino acid patch, constructed by first selecting a seed amino acid and then identifying its 127 nearest neighbors based on C-beta distances. To simulate mutations, the rotamers of 10% of the patch's amino acids were masked. Additionally, noise was added to the rotamers of amino acids whose C-beta distance to the closest masked amino acid was less than 8 \u00c5."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator were derived from PDB-REDO (Joosten et al., 2014). To ensure high-quality structures, entries with a resolution worse than 3.5 \u00c5 were removed. The protein chains were then clustered based on 50% sequence identity, resulting in 38,413 distinct clusters. These clusters were randomly divided into training, validation, and test sets. During training, a cluster was randomly selected and a chain was randomly chosen from that cluster. Each structure was cropped into a 128-amino acid patch, with 10% of amino acids' rotamers masked and noise added to those within 8 \u00c5 of the closest masked amino acid."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "instruction": "Please, remove unnecessary details of this paragraph", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a database of refined X-ray structures. The dataset is preprocessed by removing structures with resolution worse than 3.5 \u02daA, clustering protein chains by 50% sequence identity, and randomly dividing the clusters into training, validation, and test sets (95%/0.5%/4.5%). During training, a cluster is randomly selected, and a chain is randomly chosen from the cluster. The structure is then cropped into a 128-amino acid patch, and 10% of the patch's amino acids have their rotamers masked to emulate mutations.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.18", "instruction": "Delete unnecessary details. Improve the linking between ideas.", "revised_paragraph": "Revised paragraph: The datasets for training the rotamer density estimator are derived from PDB-REDO (Joosten et al., 2014), a refined X-ray structure database. We filtered out structures with resolution worse than 3.5 \u02daA and clustered protein chains by 50% sequence identity, resulting in 38,413 clusters. These clusters were randomly divided into a training set (95%), validation set (0.5%), and test set (4.5%). During training, we randomly selected a cluster, chose a chain from it, and cropped the structure into a 128-amino-acid patch centered on a seed amino acid. To emulate mutations, we masked the rotamers of 10% of amino acids, and added noise to those with C-beta distances less than 8 \u02daA to the closest masked amino acid.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In all experiments, we employ an image size of 128 \u00d7 128 pixels and a batch size ranging from 12 to 16, contingent upon available memory. For optimization, we utilize RMSProp (Tieleman & Hinton, 2012) with a learning rate of 1 \u00d7 10^(-5) for the foreground module and Adam (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 10^(-3) for the background module, except for Figure 5, where we employ a learning rate of 1 \u00d7 10^(-4) to ensure a fair comparison with SPAIR. Additionally, we implement gradient clipping with a maximum norm of 1.0. In Atari game experiments, we find it beneficial to fix \u03b1 for the initial several thousand steps, and then vary the actual value and number of steps for different games. This approach enables both the foreground and background modules to learn effectively during the early stages of training."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In all experiments, we employ an image size of 128 \u00d7 128 pixels and a batch size ranging from 12 to 16, contingent upon available memory. For optimization, we utilize RMSProp (Tieleman & Hinton, 2012) with a learning rate of 1 \u00d7 10^(-5) for the foreground module and Adam (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 10^(-3) for the background module, except for Figure 5, where we employ a learning rate of 1 \u00d7 10^(-4) to ensure a fair comparison with SPAIR. Additionally, we implement gradient clipping with a maximum norm of 1.0. In Atari game experiments, we find it beneficial to fix \u03b1 for the initial several thousand steps, and then vary the actual value and number of steps for different games. This approach enables both the foreground and background modules to learn effectively during the early stages of training."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In all experiments, we employ an image size of 128 \u00d7 128 pixels and a batch size ranging from 12 to 16, contingent upon available memory. For optimization, we utilize RMSProp (Tieleman & Hinton, 2012) with a learning rate of 1 \u00d7 10^(-5) for the foreground module and Adam (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 10^(-3) for the background module, except for Figure 5, where we employ a learning rate of 1 \u00d7 10^(-4) to ensure a fair comparison with SPAIR. Additionally, we implement gradient clipping with a maximum norm of 1.0. In Atari game experiments, we find it beneficial to fix \u03b1 for the initial several thousand steps, and then vary the actual value and number of steps for different games. This approach enables both the foreground and background modules to learn effectively during the early stages of training."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In all experiments, we employ an image size of 128 \u00d7 128 pixels and a batch size ranging from 12 to 16, contingent upon available memory. For optimization, we utilize RMSProp (Tieleman & Hinton, 2012) with a learning rate of 1 \u00d7 10^(-5) for the foreground module and Adam (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 10^(-3) for the background module, except for Figure 5, where we employ a learning rate of 1 \u00d7 10^(-4) to ensure a fair comparison with SPAIR. Additionally, we implement gradient clipping with a maximum norm of 1.0. In Atari game experiments, we find it beneficial to fix \u03b1 for the initial several thousand steps, and then vary the actual value and number of steps for different games. This approach enables both the foreground and background modules to learn effectively during the early stages of training."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In all experiments, we employ an image size of 128 \u00d7 128 pixels and a batch size ranging from 12 to 16, contingent upon available memory. For optimization, we utilize RMSProp (Tieleman & Hinton, 2012) with a learning rate of 1 \u00d7 10^(-5) for the foreground module and Adam (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 10^(-3) for the background module, except for Figure 5, where we employ a learning rate of 1 \u00d7 10^(-4) to ensure a fair comparison with SPAIR. Additionally, we implement gradient clipping with a maximum norm of 1.0. In Atari game experiments, we find it beneficial to fix \u03b1 for the initial several thousand steps, and then vary the actual value and number of steps for different games. This approach enables both the foreground and background modules to learn effectively during the early stages of training."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In all experiments, we employ an image size of 128 \u00d7 128 pixels and a batch size ranging from 12 to 16, contingent upon available memory. For optimization, we utilize RMSProp (Tieleman & Hinton, 2012) with a learning rate of 1 \u00d7 10^(-5) for the foreground module and Adam (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 10^(-3) for the background module, except for Figure 5, where we employ a learning rate of 1 \u00d7 10^(-4) to ensure a fair comparison with SPAIR. Additionally, we implement gradient clipping with a maximum norm of 1.0. In Atari game experiments, we find it beneficial to fix \u03b1 for the initial several thousand steps, and then vary the actual value and number of steps for different games. This approach enables both the foreground and background modules to learn effectively during the early stages of training."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In all experiments, we employ an image size of 128 \u00d7 128 pixels and a batch size ranging from 12 to 16, contingent upon available memory. For optimization, we utilize RMSProp (Tieleman & Hinton, 2012) with a learning rate of 1 \u00d7 10^(-5) for the foreground module and Adam (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 10^(-3) for the background module, except for Figure 5, where we employ a learning rate of 1 \u00d7 10^(-4) to ensure a fair comparison with SPAIR. Additionally, we implement gradient clipping with a maximum norm of 1.0. In Atari game experiments, we find it beneficial to fix \u03b1 for the initial several thousand steps, and then vary the actual value and number of steps for different games. This approach enables both the foreground and background modules to learn effectively during the early stages of training."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In all experiments, we employ an image size of 128 \u00d7 128 pixels and a batch size ranging from 12 to 16, contingent upon available memory. For optimization, we utilize RMSProp (Tieleman & Hinton, 2012) with a learning rate of 1 \u00d7 10^(-5) for the foreground module and Adam (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 10^(-3) for the background module, except for Figure 5, where we employ a learning rate of 1 \u00d7 10^(-4) to ensure a fair comparison with SPAIR. Additionally, we implement gradient clipping with a maximum norm of 1.0. In Atari game experiments, we find it beneficial to fix \u03b1 for the initial several thousand steps, and then vary the actual value and number of steps for different games. This approach enables both the foreground and background modules to learn effectively during the early stages of training."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "instruction": "Split the long sentences into more concise sentences.", "revised_paragraph": "Revised paragraph: We use an image size of 128 \u00d7 128 and a batch size of 12 to 16, depending on memory usage, for all experiments. The RMSProp optimizer with a learning rate of 1 \u00d7 10 \u2212 5 is used for the foreground module, while Adam with a learning rate of 1 \u00d7 10 \u2212 3 is used for the background module, except for Figure 5, where a learning rate of 1 \u00d7 10 \u2212 4 is employed to ensure fair comparison. Additionally, gradient clipping with a maximum norm of 1.0 is applied. In Atari games, we find it beneficial to set \u03b1 to a fixed value for the first several thousand steps, allowing both modules to learn in the early stage of training, and varying the actual value and number of steps for different games.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "instruction": "The second sentence is too long, split it and make it more readable.", "revised_paragraph": "Revised paragraph: For all experiments, we use an image size of 128 \u00d7 128 and a batch size of 12 to 16, depending on memory usage. We employ the RMSProp optimizer (Tieleman & Hinton, 2012) with a learning rate of 1 \u00d7 10^-5 for the foreground module. In contrast, the background module uses the Adam optimizer (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 10^-3, except for Figure 5, where a learning rate of 1 \u00d7 10^-4 is used to ensure fair comparison with SPAIR. Additionally, we apply gradient clipping with a maximum norm of 1.0. For Atari games, we found it beneficial to set \u03b1 to a fixed value for the first several thousand steps, allowing the foreground and background modules to learn in the early stages of training.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIn the Hierarchical Deep Neural Network Optimizer (HDNO), a dialogue act is viewed as an option, whereas each generated word from the Natural Language Generator (NLG) is considered a primitive action. This distinction leads to a policy hierarchy, where dialogue policy serves as the high-level policy and NLG policy acts as the low-level policy. Unlike traditional modular systems, HDNO provides NLG with contextual information to satisfy the option framework. Furthermore, the primitive action space, which includes a termination symbol, enables NLG to take responsibility for termination, thereby absorbing the termination policy into the intra-option policy. This is formally defined in Definition 1."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In HDNO, a dialogue act is viewed as an option, whereas each generated word from NLG is treated as a primitive action. Consequently, dialogue policy and NLG assume the roles of high-level and low-level policies, respectively. Unlike traditional modular systems, we introduce contextual information to NLG to align with the option framework. Furthermore, since the primitive action space, comprising a vocabulary, includes a termination symbol, NLG can handle termination, thereby eliminating the need for a separate termination policy. As a result, the termination policy is subsumed by the intra-option policy. HDNO is formally defined in Definition 1.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In HDNO, a dialogue act is viewed as an option, whereas each generated word from NLG is treated as a primitive action. Consequently, dialogue policy and NLG assume the roles of high-level and low-level policies, respectively. Unlike traditional modular systems, we introduce contextual information to NLG to align with the option framework. Furthermore, since the primitive action space, comprising a vocabulary, includes a termination symbol, NLG can handle termination, thereby eliminating the need for a separate termination policy. As a result, the termination policy is subsumed by the intra-option policy. HDNO is formally defined in Definition 1.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIn the Hierarchical Deep Neural Network Optimizer (HDNO), a dialogue act is viewed as an option, whereas each generated word from the Natural Language Generator (NLG) is considered a primitive action. This distinction leads to a policy hierarchy, where dialogue policy serves as the high-level policy and NLG policy acts as the low-level policy. Unlike traditional modular systems, HDNO provides NLG with contextual information to satisfy the option framework. Furthermore, the primitive action space, which includes a termination symbol, enables NLG to take responsibility for termination, thereby absorbing the termination policy into the intra-option policy. This is formally defined in Definition 1."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIn the Hierarchical Deep Neural Network Optimizer (HDNO), a dialogue act is viewed as an option, whereas each generated word from the Natural Language Generator (NLG) is considered a primitive action. This distinction leads to a policy hierarchy, where dialogue policy serves as the high-level policy and NLG policy acts as the low-level policy. Unlike traditional modular systems, HDNO provides NLG with contextual information to satisfy the option framework. Furthermore, the primitive action space, which includes a termination symbol, enables NLG to take responsibility for termination, thereby absorbing the termination policy into the intra-option policy. This is formally defined in Definition 1."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nIn the Hierarchical Deep Neural Network Optimizer (HDNO), a dialogue act is treated as an option, while each generated word from the Natural Language Generator (NLG) is regarded as a primitive action. This distinction gives rise to a policy hierarchy, where the dialogue policy serves as the high-level policy and the NLG policy functions as the low-level policy. Unlike traditional modular systems, HDNO provides NLG with contextual information to satisfy the option framework, thereby deviating from the conventional approach. Moreover, the primitive action space, which includes a termination symbol, enables NLG to assume responsibility for termination, effectively integrating the termination policy into the intra-option policy. This concept is formally defined in Definition 1."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"In HDNO, a dialogue act is viewed as an option, whereas each generated word from NLG is treated as a primitive action. Consequently, dialogue policy and NLG assume the roles of high-level and low-level policies, respectively. Unlike traditional modular systems, we introduce contextual information to NLG to align with the option framework. Furthermore, since the primitive action space, comprising a vocabulary, includes a termination symbol, NLG can handle termination, thereby eliminating the need for a separate termination policy. As a result, the termination policy is subsumed by the intra-option policy. HDNO is formally defined in Definition 1.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIn the Hierarchical Deep Neural Network Optimizer (HDNO), a dialogue act is viewed as an option, whereas each generated word from the Natural Language Generator (NLG) is considered a primitive action. This distinction leads to a policy hierarchy, where dialogue policy serves as the high-level policy and NLG policy acts as the low-level policy. Unlike traditional modular systems, HDNO provides NLG with contextual information to satisfy the option framework. Furthermore, the primitive action space, which includes a termination symbol, enables NLG to take responsibility for termination, thereby absorbing the termination policy into the intra-option policy. This is formally defined in Definition 1."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "instruction": "Rewrite some formulations to describe HDNO more as a state than a progress.", "revised_paragraph": "Revised paragraph: HDNO is a state where dialogue acts are options and generated words from NLG are primitive actions. Within this state, dialogue policy serves as a high-level policy, guiding the overall direction, while NLG operates as a low-level policy, executing the primitive actions. Unlike traditional modular systems, HDNO incorporates contextual information to satisfy the option framework. Additionally, the primitive action space, comprising a termination symbol, enables NLG to assume responsibility for termination, rendering the termination policy unnecessary. HDNO is formally defined in De\ufb01nition 1.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "82kcycVoyM.V4CEs3gijY.00", "instruction": "Make the last sentence more direct. Give slightly more context for better readability.", "revised_paragraph": "Revised paragraph: \"In HDNO, a dialogue act is considered an option, whereas each generated word from NLG is viewed as a primitive action. This distinction allows dialogue policy to serve as the high-level policy, guiding the overall conversation direction, while NLG functions as the low-level policy, responsible for generating specific words. Unlike traditional modular systems, we incorporate contextual information into NLG to align with the option framework. Additionally, the primitive action space, which includes a termination symbol, enables NLG to manage termination, rendering the termination policy unnecessary. As a result, HDNO is formally defined in De\ufb01nition 1.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nWe propagate labels within visually coherent regions, leveraging the relationship between visual and semantic similarity. To generate an over-segmentation, we employ the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010). This bottom-up approach considers local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments for pixel i as its own segment and all others, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we consider only segments within the same image as positive and negative samples. We align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Low-level image similarity is propagated within visually coherent regions, where visual similarity often correlates with semantic similarity. We use the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010) to generate an over-segmentation. This bottom-up segmentation technique considers both local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments with respect to a pixel as its own segment and all other segments, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we only consider segments within the same image as positive and negative samples, and align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Low-level image similarity is propagated within visually coherent regions, where visual similarity often correlates with semantic similarity. We use the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010) to generate an over-segmentation. This bottom-up segmentation technique considers both local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments with respect to a pixel as its own segment and all other segments, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we only consider segments within the same image as positive and negative samples, and align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nWe propagate labels within visually coherent regions, leveraging the relationship between visual and semantic similarity. To generate an over-segmentation, we employ the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010). This bottom-up approach considers local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments for pixel i as its own segment and all others, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we consider only segments within the same image as positive and negative samples. We align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nWe propagate labels within visually coherent regions, leveraging the relationship between visual and semantic similarity. To generate an over-segmentation, we employ the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010). This bottom-up approach considers local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments for pixel i as its own segment and all others, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we consider only segments within the same image as positive and negative samples. We align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}, {"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Low-level image similarity is propagated within visually coherent regions, where visual similarity often correlates with semantic similarity. We use the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010) to generate an over-segmentation. This bottom-up segmentation technique considers both local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments with respect to a pixel as its own segment and all other segments, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we only consider segments within the same image as positive and negative samples, and align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Low-level image similarity is propagated within visually coherent regions, where visual similarity often correlates with semantic similarity. We use the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010) to generate an over-segmentation. This bottom-up segmentation technique considers both local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments with respect to a pixel as its own segment and all other segments, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we only consider segments within the same image as positive and negative samples, and align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nWe propagate labels within visually coherent regions, leveraging the relationship between visual and semantic similarity. To generate an over-segmentation, we employ the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010). This bottom-up approach considers local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments for pixel i as its own segment and all others, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we consider only segments within the same image as positive and negative samples. We align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nWe propagate labels within visually coherent regions, leveraging the relationship between visual and semantic similarity. To generate an over-segmentation, we employ the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010). This bottom-up approach considers local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments for pixel i as its own segment and all others, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we consider only segments within the same image as positive and negative samples. We align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \n\nWe generate an over-segmentation by combining the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010). This bottom-up approach considers local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We use K-Means clustering segmentations with SegSort (Hwang et al., 2019) to align the contour-based over-segmentations."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Low-level image similarity is propagated within visually coherent regions, where visual similarity often correlates with semantic similarity. We use the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010) to generate an over-segmentation. This bottom-up segmentation technique considers both local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments with respect to a pixel as its own segment and all other segments, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we only consider segments within the same image as positive and negative samples, and align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: We employ the HED contour detector (Xie & Tu, 2015) and gPb-owt-ucm procedure (Arbelaez et al., 2010) to generate an over-segmentation, considering local and global appearance affinity without semantic information. This bottom-up approach results in segments that may contain pixels from different categories. We define positive and negative segments relative to a pixel, and learn embeddings that respect low-level visual cues using K-Means clustering segmentations aligned with contour-based over-segmentations (Hwang et al., 2019)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \n\nWe propagate labels within visually coherent regions, leveraging the relationship between visual and semantic similarity. To generate an over-segmentation, we employ the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010). This bottom-up approach considers local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments for pixel i as its own segment and all others, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we consider only segments within the same image as positive and negative samples. We align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}, {"depth": 2, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \n\nWe generate an over-segmentation by combining the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010). This bottom-up approach considers local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We use K-Means clustering segmentations with SegSort (Hwang et al., 2019) to align the contour-based over-segmentations."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: Low-level image similarity is propagated within visually coherent regions, where visual similarity often correlates with semantic similarity. We use the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010) to generate an over-segmentation. This bottom-up segmentation technique considers both local and global appearance affinity without semantic information, resulting in segments that may contain pixels from different categories. We define positive and negative segments with respect to a pixel as its own segment and all other segments, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we only consider segments within the same image as positive and negative samples, and align the contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019)."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: We employ the HED contour detector (Xie & Tu, 2015) and gPb-owt-ucm procedure (Arbelaez et al., 2010) to generate an over-segmentation, considering local and global appearance affinity without semantic information. This bottom-up approach results in segments that may contain pixels from different categories. We define positive and negative segments relative to a pixel, and learn embeddings that respect low-level visual cues using K-Means clustering segmentations aligned with contour-based over-segmentations (Hwang et al., 2019)."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "instruction": "Make this paragraph considerably more concise. Remove any unnecessary details that are not essential for the main point of the paragraph.", "revised_paragraph": "Revised paragraph: Low-level image similarity is propagated by labeling visually coherent regions, as visual similarity often corresponds to semantic similarity. We employ a bottom-up segmentation technique, using the HED contour detector (Xie & Tu, 2015) and gPb-owt-ucm (Arbelaez et al., 2010), to generate an over-segmentation. For learning pixel embeddings, we define positive and negative segments relative to a pixel, considering only segments within the same image. This formulation helps learn embeddings that respect low-level visual cues.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.08", "instruction": "This paragraph is too long, make it almost 50% shorter but keep the important informations.", "revised_paragraph": "Revised paragraph: \n\nLow-level image similarity is propagated by labeling visually coherent regions, as visual similarity often corresponds to semantic similarity. We employ the HED contour detector (Xie & Tu, 2015) and the gPb-owt-ucm procedure (Arbelaez et al., 2010) to generate an over-segmentation. This bottom-up approach considers both local and global appearance affinity without semantic information, potentially including pixels from different categories. We define positive and negative segments for pixel i as its own segment and all others, respectively, to learn embeddings that respect low-level visual cues. In our implementation, we consider only segments within the same image as positive and negative samples, aligning contour-based over-segmentations with K-Means clustering segmentations using SegSort (Hwang et al., 2019).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We utilize the OpenAI Gym MuJoCo locomotion tasks with the Hopper-v2 environment, using the medium-v2, medium-replay-v2, and medium-expert-v2 datasets to construct expert demonstrations and an unlabeled dataset. We select the best episodes from the D4RL dataset based on episodic return and discard original reward information to obtain the unlabeled dataset. We then use OTR to label the dataset based on optimal coupling with expert demonstrations and proceed with offline RL algorithm execution."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We utilize the OpenAI Gym MuJoCo locomotion tasks with the Hopper-v2 environment, using the medium-v2, medium-replay-v2, and medium-expert-v2 datasets to construct expert demonstrations and an unlabeled dataset. We select the best episodes from the D4RL dataset based on episodic return and discard original reward information to obtain the unlabeled dataset. We then use OTR to label the dataset based on optimal coupling with expert demonstrations and proceed with offline RL algorithm execution."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We utilize the OpenAI Gym MuJoCo locomotion tasks with the Hopper-v2 environment, using the medium-v2, medium-replay-v2, and medium-expert-v2 datasets to construct expert demonstrations and an unlabeled dataset. We select the best episodes from the D4RL dataset based on episodic return and discard original reward information to obtain the unlabeled dataset. We then use OTR to label the dataset based on optimal coupling with expert demonstrations and proceed with offline RL algorithm execution."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We utilize the OpenAI Gym MuJoCo locomotion tasks with the Hopper-v2 environment, using the medium-v2, medium-replay-v2, and medium-expert-v2 datasets to construct expert demonstrations and an unlabeled dataset. We select the best episodes from the D4RL dataset based on episodic return and discard original reward information to obtain the unlabeled dataset. We then use OTR to label the dataset based on optimal coupling with expert demonstrations and proceed with offline RL algorithm execution."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We utilize the OpenAI Gym MuJoCo locomotion tasks with the Hopper-v2 environment, using the medium-v2, medium-replay-v2, and medium-expert-v2 datasets to construct expert demonstrations and an unlabeled dataset. We select the best episodes from the D4RL dataset based on episodic return and discard original reward information to obtain the unlabeled dataset. We then use OTR to label the dataset based on optimal coupling with expert demonstrations and proceed with offline RL algorithm execution."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We utilize the OpenAI Gym MuJoCo locomotion tasks with the Hopper-v2 environment, using the medium-v2, medium-replay-v2, and medium-expert-v2 datasets to construct expert demonstrations and an unlabeled dataset. We select the best episodes from the D4RL dataset based on episodic return and discard original reward information to obtain the unlabeled dataset. We then use OTR to label the dataset based on optimal coupling with expert demonstrations and proceed with offline RL algorithm execution."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We utilize the OpenAI Gym MuJoCo locomotion tasks with the Hopper-v2 environment, using the medium-v2, medium-replay-v2, and medium-expert-v2 datasets to construct expert demonstrations and an unlabeled dataset. We select the best episodes from the D4RL dataset based on episodic return and discard original reward information to obtain the unlabeled dataset. We then use OTR to label the dataset based on optimal coupling with expert demonstrations and proceed with offline RL algorithm execution."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We utilize the OpenAI Gym MuJoCo locomotion tasks with the Hopper-v2 environment, using the medium-v2, medium-replay-v2, and medium-expert-v2 datasets to construct expert demonstrations and an unlabeled dataset. We select the best episodes from the D4RL dataset based on episodic return and discard original reward information to obtain the unlabeled dataset. We then use OTR to label the dataset based on optimal coupling with expert demonstrations and proceed with offline RL algorithm execution."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "instruction": "Remove the fourth sentence", "revised_paragraph": "Revised paragraph: Hopper-v2) from the OpenAI Gym MuJoCo locomotion tasks. For each environment, we use the medium-v2, medium-replay-v2, and medium-expert-v2 datasets to construct the expert demonstrations and the unlabeled dataset. For the expert demonstrations, we choose the best episodes from the D4RL dataset based on the episodic return. We then run OTR to label the dataset based on the optimal coupling between the unlabeled episodes and the chosen expert demonstrations. Afterward, we proceed with running the offline RL algorithm.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "RPX7thbt2Mv.PdsbQ4ckYr.01", "instruction": "Exclude unnecessary information.", "revised_paragraph": "Revised paragraph: \"We use the Hopper-v2 environment from the OpenAI Gym MuJoCo locomotion tasks, with expert demonstrations and an unlabeled dataset constructed from the medium-v2, medium-replay-v2, and medium-expert-v2 datasets. We select the best episodes from the D4RL dataset based on episodic return to obtain the expert demonstrations. The unlabeled dataset is obtained by discarding the original reward information and running OTR to label it based on the optimal coupling with the expert demonstrations. We then apply an offline RL algorithm to the labeled dataset.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Pointing targets, such as buttons or icons, should be performed quickly and accurately. The movement time is influenced by two primary factors: target size and the distance between the cursor's initial position and the target [11, 19]. As the distance increases and the target size decreases, movement time grows. Additionally, placing non-obstructive distractors along the path to the target prolongs movement time [6, 23]. In Experiment 1, we observed longer movement times when pointing to a target at the top edge, as the cursor was temporarily hidden by a notch, causing users to either avoid the notch or move the cursor cautiously around it."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Pointing targets, such as buttons or icons, should be performed quickly and accurately. The movement time is influenced by two primary factors: target size and the distance between the cursor's initial position and the target [11, 19]. As the distance increases and the target size decreases, movement time grows. Additionally, placing non-obstructive distractors along the path to the target prolongs movement time [6, 23]. In Experiment 1, we observed longer movement times when pointing to a target at the top edge, as the cursor was temporarily hidden by a notch, causing users to either avoid the notch or move the cursor cautiously around it."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Pointing targets, such as buttons or icons, should be performed quickly and accurately. The movement time is influenced by two primary factors: target size and the distance between the cursor's initial position and the target [11, 19]. As the distance increases and the target size decreases, movement time grows. Additionally, placing non-obstructive distractors along the path to the target prolongs movement time [6, 23]. In Experiment 1, we observed longer movement times when pointing to a target at the top edge, as the cursor was temporarily hidden by a notch, causing users to either avoid the notch or move the cursor cautiously around it."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Pointing targets, such as buttons or icons, should be performed quickly and accurately. The movement time is influenced by two primary factors: target size and the distance between the cursor's initial position and the target [11, 19]. As the distance increases and the target size decreases, movement time grows. Additionally, placing non-obstructive distractors along the path to the target prolongs movement time [6, 23]. In Experiment 1, we observed longer movement times when pointing to a target at the top edge, as the cursor was temporarily hidden by a notch, causing users to either avoid the notch or move the cursor cautiously around it."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Pointing targets, such as buttons or icons, should be performed quickly and accurately. The movement time is influenced by two primary factors: target size and the distance between the cursor's initial position and the target [11, 19]. As the distance increases and the target size decreases, movement time grows. Additionally, placing non-obstructive distractors along the path to the target prolongs movement time [6, 23]. In Experiment 1, we observed longer movement times when pointing to a target at the top edge, as the cursor was temporarily hidden by a notch, causing users to either avoid the notch or move the cursor cautiously around it."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Pointing targets, such as buttons or icons, should be performed quickly and accurately. The movement time is influenced by two primary factors: target size and the distance between the cursor's initial position and the target [11, 19]. As the distance increases and the target size decreases, movement time grows. Additionally, placing non-obstructive distractors along the path to the target prolongs movement time [6, 23]. In Experiment 1, we observed longer movement times when pointing to a target at the top edge, as the cursor was temporarily hidden by a notch, causing users to either avoid the notch or move the cursor cautiously around it."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Pointing targets, such as buttons or icons, should be performed quickly and accurately. The movement time is influenced by two primary factors: target size and the distance between the cursor's initial position and the target [11, 19]. As the distance increases and the target size decreases, movement time grows. Additionally, placing non-obstructive distractors along the path to the target prolongs movement time [6, 23]. In Experiment 1, we observed longer movement times when pointing to a target at the top edge, as the cursor was temporarily hidden by a notch, causing users to either avoid the notch or move the cursor cautiously around it."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Pointing targets, such as buttons or icons, should be performed quickly and accurately. The movement time is influenced by two primary factors: target size and the distance between the cursor's initial position and the target [11, 19]. As the distance increases and the target size decreases, movement time grows. Additionally, placing non-obstructive distractors along the path to the target prolongs movement time [6, 23]. In Experiment 1, we observed longer movement times when pointing to a target at the top edge, as the cursor was temporarily hidden by a notch, causing users to either avoid the notch or move the cursor cautiously around it."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "instruction": "Improve English in this paragraph. Explain more about the experiments", "revised_paragraph": "Revised paragraph: Pointing accuracy and speed are critical factors in human-computer interaction. Two primary variables influencing movement time are target size and distance from the initial cursor position to the target [11, 19]. As the distance increases and target size decreases, movement time also increases. Additionally, the presence of distractors along the path to the target, which do not obscure the cursor, can further prolong movement time [6, 23]. In Experiment 1, we observed longer movement times when the cursor was hidden by a notch while pointing at a target located at the top edge from another target at the same edge. This occurred because users may intentionally avoid the notch or move the mouse cursor cautiously near it, which can lead to increased movement times.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.02", "instruction": "Add a sentence to introduce the experiment. Improve the paragraph for better readability.", "revised_paragraph": "Revised paragraph: \"To investigate the impact of a notch on pointing performance, an experiment was designed to test the movement time and accuracy of participants when pointing to targets with and without a notch. Pointing should be fast and accurate, and the two main factors that affect movement time are the target size and the distance from the initial position of the cursor to the target [11,19]. The movement time increases as the distance increases and the target size decreases. Furthermore, placing distractors (which do not hide the cursor) on the path to the target increases the movement time [6,23]. In Experiment 1, we found that the presence of a notch significantly increased movement time, as participants took longer to point to targets at the top edge when the cursor was hidden by the notch, compared to pointing to targets without a notch.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we adapt the grid world environment introduced by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a goal. The agent has constant access to four basic actions: moving in four directions and turning left. However, in each task instance, two of the four available special skills - turning right, stepping forward, digging orange lava, and digging pink lava - are randomly selected. The agent can temporarily walk on lava without harm, but can remove it by using the corresponding dig-lava skill. This allows agents to create shortcuts to the goal and receive a higher reward when these skills are available. We employ Proximal Policy Optimization (PPO) to train all methods."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we adapt the grid world environment introduced by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a goal. The agent has constant access to four basic actions: moving in four directions and turning left. However, in each task instance, two of the four available special skills - turning right, stepping forward, digging orange lava, and digging pink lava - are randomly selected. The agent can temporarily walk on lava without harm, but can remove it by using the corresponding dig-lava skill. This allows agents to create shortcuts to the goal and receive a higher reward when these skills are available. We employ Proximal Policy Optimization (PPO) to train all methods."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we adapt the grid world environment introduced by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a goal. The agent has constant access to four basic actions: moving in four directions and turning left. However, in each task instance, two of the four available special skills - turning right, stepping forward, digging orange lava, and digging pink lava - are randomly selected. The agent can temporarily walk on lava without harm, but can remove it by using the corresponding dig-lava skill. This allows agents to create shortcuts to the goal and receive a higher reward when these skills are available. We employ Proximal Policy Optimization (PPO) to train all methods."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we adapt the grid world environment introduced by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a goal. The agent has constant access to four basic actions: moving in four directions and turning left. However, in each task instance, two of the four available special skills - turning right, stepping forward, digging orange lava, and digging pink lava - are randomly selected. The agent can temporarily walk on lava without harm, but can remove it by using the corresponding dig-lava skill. This allows agents to create shortcuts to the goal and receive a higher reward when these skills are available. We employ Proximal Policy Optimization (PPO) to train all methods."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we adapt the grid world environment introduced by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a goal. The agent has constant access to four basic actions: moving in four directions and turning left. However, in each task instance, two of the four available special skills - turning right, stepping forward, digging orange lava, and digging pink lava - are randomly selected. The agent can temporarily walk on lava without harm, but can remove it by using the corresponding dig-lava skill. This allows agents to create shortcuts to the goal and receive a higher reward when these skills are available. We employ Proximal Policy Optimization (PPO) to train all methods."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we adapt the grid world environment introduced by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a goal. The agent has constant access to four basic actions: moving in four directions and turning left. However, in each task instance, two of the four available special skills - turning right, stepping forward, digging orange lava, and digging pink lava - are randomly selected. The agent can temporarily walk on lava without harm, but can remove it by using the corresponding dig-lava skill. This allows agents to create shortcuts to the goal and receive a higher reward when these skills are available. We employ Proximal Policy Optimization (PPO) to train all methods."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we adapt the grid world environment introduced by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a goal. The agent has constant access to four basic actions: moving in four directions and turning left. However, in each task instance, two of the four available special skills - turning right, stepping forward, digging orange lava, and digging pink lava - are randomly selected. The agent can temporarily walk on lava without harm, but can remove it by using the corresponding dig-lava skill. This allows agents to create shortcuts to the goal and receive a higher reward when these skills are available. We employ Proximal Policy Optimization (PPO) to train all methods."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we adapt the grid world environment introduced by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a goal. The agent has constant access to four basic actions: moving in four directions and turning left. However, in each task instance, two of the four available special skills - turning right, stepping forward, digging orange lava, and digging pink lava - are randomly selected. The agent can temporarily walk on lava without harm, but can remove it by using the corresponding dig-lava skill. This allows agents to create shortcuts to the goal and receive a higher reward when these skills are available. We employ Proximal Policy Optimization (PPO) to train all methods."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "instruction": "Rewrite some sentences, making them more connected and using more formal language.", "revised_paragraph": "Revised paragraph: In this study, we adapt the grid world environment proposed by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a goal. The agent has constant access to four basic movements (up, down, left, and right) and a turn-left skill, as depicted in Figure 5. However, two of the four special skills - turn-right, step-forward, dig-orange-lava, and dig-pink-lava - are randomly sampled for the agent in each task instance. Notably, the agent can temporarily traverse lava for one time step without perishing, but can remove it by utilizing the corresponding dig-lava skill. This allows the agent to exploit available dig-lava skills to construct shortcut paths to the goal, thereby earning a higher reward. We employ Proximal Policy Optimization (PPO) to train all methods.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.07", "instruction": "Use a slightly more academic logical language.", "revised_paragraph": "Revised paragraph: We introduce a modified grid world environment, inspired by Chevalier-Boisvert et al. (2018), where an agent must navigate a 2D maze with two lava rivers to reach a predetermined goal. The agent possesses a standard set of actions, including four directional movements and a turn-left skill (Figure 5). Additionally, the agent is endowed with a set of four special skills, comprising turn-right, step-forward, dig-orange-lava, and dig-pink-lava, which are randomly sampled for each task instance. The agent is capable of traversing lava for a single time step without incurring harm, but can eliminate lava by utilizing the corresponding dig-lava skill. This enables the agent to create shortcut paths to the goal, thereby receiving a higher reward when the dig-lava skills are available. We employ Proximal Policy Optimization (PPO) to train all methods.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Methods for predicting mutational effects on single proteins can be categorized as structure-based or sequence-based. Structure-based approaches, which include biophysical, statistical, and deep learning-based methods, predict thermal stability or fitness rather than binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based methods, such as protein language models (PLMs) trained on large sequence databases, can also predict mutational effects without requiring multiple sequence alignments (Meier et al., 2021).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nMethods for predicting mutational effects for single proteins can be broadly classified into two categories: structure-based and sequence-based approaches. Structure-based methods can further be divided into biophysical, statistical, and deep learning-based approaches. These methods aim to predict the thermal stability or fitness of the protein, rather than the binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). In contrast, sequence-based methods, which are often referred to as evolution-based approaches, rely solely on the protein's evolutionary history to predict mutational effects. This is typically achieved by analyzing multiple sequence alignments (MSAs) constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recently, protein language models (PLMs) trained on large sequence databases have shown the ability to evaluate mutations without the need for MSAs (Meier et al., 2021)."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nMethods for predicting mutational effects for single proteins can be broadly classified into two categories: structure-based and sequence-based approaches. Structure-based methods can further be divided into biophysical, statistical, and deep learning-based approaches. These methods aim to predict the thermal stability or fitness of the protein, rather than the binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). In contrast, sequence-based methods, which are often referred to as evolution-based approaches, rely solely on the protein's evolutionary history to predict mutational effects. This is typically achieved by analyzing multiple sequence alignments (MSAs) constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recently, protein language models (PLMs) trained on large sequence databases have shown the ability to evaluate mutations without the need for MSAs (Meier et al., 2021)."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nMethods for predicting mutational effects for single proteins can be broadly classified into two categories: structure-based and sequence-based approaches. Structure-based methods can further be divided into biophysical, statistical, and deep learning-based approaches. These methods aim to predict the thermal stability or fitness of the protein, rather than the binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). In contrast, sequence-based methods, which are often referred to as evolution-based approaches, rely solely on the protein's evolutionary history to predict mutational effects. This is typically achieved by analyzing multiple sequence alignments (MSAs) constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recently, protein language models (PLMs) trained on large sequence databases have shown the ability to evaluate mutations without the need for MSAs (Meier et al., 2021)."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Methods for predicting mutational effects on single proteins can be categorized as structure-based or sequence-based. Structure-based approaches, which include biophysical, statistical, and deep learning-based methods, predict thermal stability or fitness rather than binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based methods, such as protein language models (PLMs) trained on large sequence databases, can also predict mutational effects without requiring multiple sequence alignments (Meier et al., 2021).\""}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nMethods for predicting mutational effects for single proteins can be broadly classified into two categories: structure-based and sequence-based approaches. Structure-based methods can further be divided into biophysical, statistical, and deep learning-based approaches. These methods aim to predict the thermal stability or fitness of the protein, rather than the binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). In contrast, sequence-based methods, which are often referred to as evolution-based approaches, rely solely on the protein's evolutionary history to predict mutational effects. This is typically achieved by analyzing multiple sequence alignments (MSAs) constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recently, protein language models (PLMs) trained on large sequence databases have shown the ability to evaluate mutations without the need for MSAs (Meier et al., 2021)."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Methods for predicting mutational effects on single proteins can be categorized as structure-based or sequence-based. Structure-based approaches, which include biophysical, statistical, and deep learning-based methods, predict thermal stability or fitness rather than binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based methods, such as protein language models (PLMs) trained on large sequence databases, can also predict mutational effects without requiring multiple sequence alignments (Meier et al., 2021).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Methods for predicting the effects of mutations on individual proteins can be broadly classified into two categories: structure-based and sequence-based approaches. Structure-based methods, which encompass biophysical, statistical, and deep learning-based techniques, typically predict thermal stability or fitness rather than binding free energy, as demonstrated by Schymkowitz et al. (2005), Park et al. (2016), and Alford et al. (2017). In contrast, sequence-based methods, such as protein language models (PLMs) trained on large sequence databases, can accurately predict mutational effects without relying on multiple sequence alignments, as shown by Meier et al. (2021).\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nMethods for predicting mutational effects for single proteins can be broadly classified into two categories: structure-based and sequence-based approaches. Structure-based methods can further be divided into biophysical, statistical, and deep learning-based approaches. These methods aim to predict the thermal stability or fitness of the protein, rather than the binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). In contrast, sequence-based methods, which are often referred to as evolution-based approaches, rely solely on the protein's evolutionary history to predict mutational effects. This is typically achieved by analyzing multiple sequence alignments (MSAs) constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recently, protein language models (PLMs) trained on large sequence databases have shown the ability to evaluate mutations without the need for MSAs (Meier et al., 2021)."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nMethods for predicting mutational effects for single proteins can be broadly classified into two categories: structure-based and sequence-based approaches. Structure-based methods can further be divided into biophysical, statistical, and deep learning-based approaches. These methods aim to predict the thermal stability or fitness of the protein, rather than the binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). In contrast, sequence-based methods, which are often referred to as evolution-based approaches, rely solely on the protein's evolutionary history to predict mutational effects. This is typically achieved by analyzing multiple sequence alignments (MSAs) constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recently, protein language models (PLMs) trained on large sequence databases have shown the ability to evaluate mutations without the need for MSAs (Meier et al., 2021)."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Methods for predicting mutational effects on single proteins can be categorized as structure-based or sequence-based. Structure-based approaches, which include biophysical, statistical, and deep learning-based methods, predict thermal stability or fitness rather than binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based methods, such as protein language models (PLMs) trained on large sequence databases, can also predict mutational effects without requiring multiple sequence alignments (Meier et al., 2021).\""}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \"Methods for predicting the effects of mutations on individual proteins can be broadly classified into two categories: structure-based and sequence-based approaches. Structure-based methods, which encompass biophysical, statistical, and deep learning-based techniques, typically predict thermal stability or fitness rather than binding free energy, as demonstrated by Schymkowitz et al. (2005), Park et al. (2016), and Alford et al. (2017). In contrast, sequence-based methods, such as protein language models (PLMs) trained on large sequence databases, can accurately predict mutational effects without relying on multiple sequence alignments, as shown by Meier et al. (2021).\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "instruction": "Review the following paragraph", "revised_paragraph": "Revised paragraph: \n\nMethods for predicting mutational effects for single proteins can be categorized into two primary approaches: structure-based and sequence-based. Structure-based methods can be further divided into biophysical, statistical, and deep learning-based approaches, which primarily focus on predicting thermal stability or fitness of the protein rather than binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Alternatively, sequence-based methods involve mining a protein's evolutionary history to predict mutational effects. This can be achieved through statistical analysis of multiple sequence alignments (MSAs), which are constructed by searching large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). More recently, protein language models (PLMs) trained on large sequence databases have demonstrated the capability to evaluate mutations without the need for MSAs (Meier et al., 2021).", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "instruction": "Make this paragraph shorter and more fitted to academic style.", "revised_paragraph": "Revised paragraph: \n\nMethods for predicting mutational effects for single proteins can be categorized into structure-based and sequence-based approaches. Structure-based methods, including biophysical, statistical, and deep learning-based approaches, primarily focus on predicting thermal stability or fitness rather than binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based methods, which mine a protein's evolutionary history, can also be used to predict mutational effects. This is typically done by analyzing multiple sequence alignments constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recently, protein language models trained on large sequence databases have been shown to evaluate mutations without the need for multiple sequence alignments (Meier et al., 2021).", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is notoriously difficult due to the presence of treatment selection bias. Most existing representation-based methods address this issue by aligning the distributions of different treatment groups in the representation space. However, they still grapple with two critical limitations: (1) Mini-batch Sampling Effects (MSE), which can lead to alignment failure due to outcome imbalance or outliers in the batch; and (2) Unobserved Confounder Effects (UCE), where unobserved confounders can compromise the correct alignment.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is notoriously difficult due to the presence of treatment selection bias. Most existing representation-based methods address this issue by aligning the distributions of different treatment groups in the representation space. However, they still grapple with two critical limitations: (1) Mini-batch Sampling Effects (MSE), which can lead to alignment failure due to outcome imbalance or outliers in the batch; and (2) Unobserved Confounder Effects (UCE), where unobserved confounders can compromise the correct alignment.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is notoriously difficult due to the presence of treatment selection bias. Most existing representation-based methods address this issue by aligning the distributions of different treatment groups in the representation space. However, they still grapple with two critical limitations: (1) Mini-batch Sampling Effects (MSE), which can lead to alignment failure due to outcome imbalance or outliers in the batch; and (2) Unobserved Confounder Effects (UCE), where unobserved confounders can compromise the correct alignment.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is notoriously difficult due to the presence of treatment selection bias. Most existing representation-based methods address this issue by aligning the distributions of different treatment groups in the representation space. However, they still grapple with two critical limitations: (1) Mini-batch Sampling Effects (MSE), which can lead to alignment failure due to outcome imbalance or outliers in the batch; and (2) Unobserved Confounder Effects (UCE), where unobserved confounders can compromise the correct alignment.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is notoriously difficult due to the presence of treatment selection bias. Most existing representation-based methods address this issue by aligning the distributions of different treatment groups in the representation space. However, they still grapple with two critical limitations: (1) Mini-batch Sampling Effects (MSE), which can lead to alignment failure due to outcome imbalance or outliers in the batch; and (2) Unobserved Confounder Effects (UCE), where unobserved confounders can compromise the correct alignment.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is notoriously difficult due to the presence of treatment selection bias. Most existing representation-based methods address this issue by aligning the distributions of different treatment groups in the representation space. However, they still grapple with two critical limitations: (1) Mini-batch Sampling Effects (MSE), which can lead to alignment failure due to outcome imbalance or outliers in the batch; and (2) Unobserved Confounder Effects (UCE), where unobserved confounders can compromise the correct alignment.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is notoriously difficult due to the presence of treatment selection bias. Most existing representation-based methods address this issue by aligning the distributions of different treatment groups in the representation space. However, they still grapple with two critical limitations: (1) Mini-batch Sampling Effects (MSE), which can lead to alignment failure due to outcome imbalance or outliers in the batch; and (2) Unobserved Confounder Effects (UCE), where unobserved confounders can compromise the correct alignment.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is notoriously difficult due to the presence of treatment selection bias. Most existing representation-based methods address this issue by aligning the distributions of different treatment groups in the representation space. However, they still grapple with two critical limitations: (1) Mini-batch Sampling Effects (MSE), which can lead to alignment failure due to outcome imbalance or outliers in the batch; and (2) Unobserved Confounder Effects (UCE), where unobserved confounders can compromise the correct alignment.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "instruction": "Improve the english of this paragraph.", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is notoriously difficult due to the pervasive influence of treatment selection bias. Existing representation-based methods attempt to mitigate this issue by aligning the distributions of different treatment groups in the representation space. However, they still grapple with two critical challenges: (1) Mini-batch Sampling Effects (MSE), which can lead to alignment failure due to outcome imbalance or outliers in the batch; (2) Unobserved Confounder Effects (UCE), where unobserved confounders can compromise the accuracy of the alignment.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.00", "instruction": "Edit this paragraph by making more formal choices of wording.", "revised_paragraph": "Revised paragraph: \"Estimating individual treatment effects from observational data is a complex task owing to the presence of treatment selection bias. Existing representation-based methods endeavour to address this challenge by aligning the distributions of treatment groups within the representation space. Nevertheless, these approaches are susceptible to two significant limitations: (1) Mini-batch Sampling Effects (MSE), which can arise from outcome imbalance or outliers in the batch, compromising alignment; (2) Unobserved Confounder Effects (UCE), where unobserved confounders can impede accurate alignment.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"PSM methods, such as matching methods, have demonstrated promising performance on ranking metrics, which is why they are widely favored by counterfactual ranking applications (Betlei et al., 2021) in practice. Nevertheless, their poor performance on precision in estimated heterogeneous effects (PEHE) limits their application in counterfactual estimation applications, such as advertising systems, where accuracy metrics are paramount.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"PSM methods, such as matching methods, have demonstrated promising performance on ranking metrics, which is why they are widely favored by counterfactual ranking applications (Betlei et al., 2021) in practice. Nevertheless, their poor performance on precision in estimated heterogeneous effects (PEHE) limits their application in counterfactual estimation applications, such as advertising systems, where accuracy metrics are paramount.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"PSM methods, such as matching methods, have demonstrated promising performance on ranking metrics, which is why they are widely favored by counterfactual ranking applications (Betlei et al., 2021) in practice. Nevertheless, their poor performance on precision in estimated heterogeneous effects (PEHE) limits their application in counterfactual estimation applications, such as advertising systems, where accuracy metrics are paramount.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"PSM methods, such as matching methods, have demonstrated promising performance on ranking metrics, which is why they are widely favored by counterfactual ranking applications (Betlei et al., 2021) in practice. Nevertheless, their poor performance on precision in estimated heterogeneous effects (PEHE) limits their application in counterfactual estimation applications, such as advertising systems, where accuracy metrics are paramount.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"PSM methods, such as matching methods, have demonstrated promising performance on ranking metrics, which is why they are widely favored by counterfactual ranking applications (Betlei et al., 2021) in practice. Nevertheless, their poor performance on precision in estimated heterogeneous effects (PEHE) limits their application in counterfactual estimation applications, such as advertising systems, where accuracy metrics are paramount.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"PSM methods, such as matching methods, have demonstrated promising performance on ranking metrics, which is why they are widely favored by counterfactual ranking applications (Betlei et al., 2021) in practice. Nevertheless, their poor performance on precision in estimated heterogeneous effects (PEHE) limits their application in counterfactual estimation applications, such as advertising systems, where accuracy metrics are paramount.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"PSM methods, such as matching methods, have demonstrated promising performance on ranking metrics, which is why they are widely favored by counterfactual ranking applications (Betlei et al., 2021) in practice. Nevertheless, their poor performance on precision in estimated heterogeneous effects (PEHE) limits their application in counterfactual estimation applications, such as advertising systems, where accuracy metrics are paramount.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"PSM methods, such as matching methods, have demonstrated promising performance on ranking metrics, which is why they are widely favored by counterfactual ranking applications (Betlei et al., 2021) in practice. Nevertheless, their poor performance on precision in estimated heterogeneous effects (PEHE) limits their application in counterfactual estimation applications, such as advertising systems, where accuracy metrics are paramount.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "instruction": "Make first half concise and second half precise.", "revised_paragraph": "Revised paragraph: \"PSM methods, like PSM, excel in ranking metrics, making them a popular choice for counterfactual ranking applications (Betlei et al., 2021). However, their limited performance on PEHE restricts their use in critical accuracy-oriented applications, such as advertising systems, where precise estimation is essential.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.15", "instruction": "Improve the writing in this paragraph.", "revised_paragraph": "Revised paragraph: Matching methods, such as Propensity Score Matching (PSM), have demonstrated promising performance on ranking metrics, which is why they are widely favored by counterfactual ranking applications (Betlei et al., 2021) in practice. Nevertheless, their poor performance on the Precision in Estimation of Heterogeneous Effects (PEHE) metric hinders their application in counterfactual estimation applications, such as advertising systems, where accuracy metrics are paramount.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Branch Decider. In the absence of network context during deployment, a branch decider module is essential to address this challenge. The branch decider leverages the cluster labels obtained during the training stage to classify inference-time observations using a K-Nearest Neighbors [45] algorithm. This light-weight distance-based metric enables the classification of observations into one of the training groupings, thereby triggering the execution of the corresponding branch's symbolic policy. Figure 3 illustrates our comprehensive training and deployment techniques.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Branch Decider. In the absence of network context during deployment, a branch decider module is essential to address this challenge. The branch decider leverages the cluster labels obtained during the training stage to classify inference-time observations using a K-Nearest Neighbors [45] algorithm. This light-weight distance-based metric enables the classification of observations into one of the training groupings, thereby triggering the execution of the corresponding branch's symbolic policy. Figure 3 illustrates our comprehensive training and deployment techniques.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Branch Decider. In the absence of network context during deployment, a branch decider module is essential to address this challenge. The branch decider leverages the cluster labels obtained during the training stage to classify inference-time observations using a K-Nearest Neighbors [45] algorithm. This light-weight distance-based metric enables the classification of observations into one of the training groupings, thereby triggering the execution of the corresponding branch's symbolic policy. Figure 3 illustrates our comprehensive training and deployment techniques.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Branch Decider. In the absence of network context during deployment, a branch decider module is essential to address this challenge. The branch decider leverages the cluster labels obtained during the training stage to classify inference-time observations using a K-Nearest Neighbors [45] algorithm. This light-weight distance-based metric enables the classification of observations into one of the training groupings, thereby triggering the execution of the corresponding branch's symbolic policy. Figure 3 illustrates our comprehensive training and deployment techniques.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Branch Decider. In the absence of network context during deployment, a branch decider module is essential to address this challenge. The branch decider leverages the cluster labels obtained during the training stage to classify inference-time observations using a K-Nearest Neighbors [45] algorithm. This light-weight distance-based metric enables the classification of observations into one of the training groupings, thereby triggering the execution of the corresponding branch's symbolic policy. Figure 3 illustrates our comprehensive training and deployment techniques.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Branch Decider. In the absence of network context during deployment, a branch decider module is essential to address this challenge. The branch decider leverages the cluster labels obtained during the training stage to classify inference-time observations using a K-Nearest Neighbors [45] algorithm. This light-weight distance-based metric enables the classification of observations into one of the training groupings, thereby triggering the execution of the corresponding branch's symbolic policy. Figure 3 illustrates our comprehensive training and deployment techniques.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Branch Decider. In the absence of network context during deployment, a branch decider module is essential to address this challenge. The branch decider leverages the cluster labels obtained during the training stage to classify inference-time observations using a K-Nearest Neighbors [45] algorithm. This light-weight distance-based metric enables the classification of observations into one of the training groupings, thereby triggering the execution of the corresponding branch's symbolic policy. Figure 3 illustrates our comprehensive training and deployment techniques.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Branch Decider. In the absence of network context during deployment, a branch decider module is essential to address this challenge. The branch decider leverages the cluster labels obtained during the training stage to classify inference-time observations using a K-Nearest Neighbors [45] algorithm. This light-weight distance-based metric enables the classification of observations into one of the training groupings, thereby triggering the execution of the corresponding branch's symbolic policy. Figure 3 illustrates our comprehensive training and deployment techniques.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "instruction": "Rewrite some formulations, preferring shorter ones and fix typos.", "revised_paragraph": "Revised paragraph: \"Branch Decider. To address the unknown network context during deployment, we introduce a branch decider module. The module reuses training-stage cluster labels for K-NN classification [45], using a lightweight distance metric to classify inference-time observations into training groupings and execute the corresponding branch's symbolic policy. Figure 3 illustrates our complete training and deployment techniques.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hAi0PMz9T7.Ut8ESfYp1.02", "instruction": "Improve the english of this text.", "revised_paragraph": "Revised paragraph: \"Branch Decider. To address the uncertainty surrounding the network context during deployment, a branch decider module is necessary. This module leverages the cluster labels obtained during the training stage for a K-Nearest Neighbors classification [45], utilizing a lightweight distance-based metric to classify inference-time observations into one of the training groupings. This enables the execution of the corresponding branch's symbolic policy. Figure 3 illustrates our comprehensive training and deployment techniques.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: SuperWeights are linear combinations of templates reused by multiple layers. They capture a single operation on input features, such as edge or texture detection, and are generated via a weighted combination of trainable parameters held by Weight Templates. To generate weights for a single layer, we construct SuperWeights from Weight Template parameters and concatenate them to create the final weights, as illustrated in Figure 2."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: SuperWeights are linear combinations of templates reused by multiple layers. They capture a single operation on input features, such as edge or texture detection, and are generated via a weighted combination of trainable parameters held by Weight Templates. To generate weights for a single layer, we construct SuperWeights from Weight Template parameters and concatenate them to create the final weights, as illustrated in Figure 2."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: SuperWeights are linear combinations of templates reused by multiple layers. They capture a single operation on input features, such as edge or texture detection, and are generated via a weighted combination of trainable parameters held by Weight Templates. To generate weights for a single layer, we construct SuperWeights from Weight Template parameters and concatenate them to create the final weights, as illustrated in Figure 2."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: SuperWeights are linear combinations of templates reused by multiple layers. They capture a single operation on input features, such as edge or texture detection, and are generated via a weighted combination of trainable parameters held by Weight Templates. To generate weights for a single layer, we construct SuperWeights from Weight Template parameters and concatenate them to create the final weights, as illustrated in Figure 2."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: SuperWeights are linear combinations of templates reused by multiple layers. They capture a single operation on input features, such as edge or texture detection, and are generated via a weighted combination of trainable parameters held by Weight Templates. To generate weights for a single layer, we construct SuperWeights from Weight Template parameters and concatenate them to create the final weights, as illustrated in Figure 2."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: SuperWeights are linear combinations of templates reused by multiple layers. They capture a single operation on input features, such as edge or texture detection, and are generated via a weighted combination of trainable parameters held by Weight Templates. To generate weights for a single layer, we construct SuperWeights from Weight Template parameters and concatenate them to create the final weights, as illustrated in Figure 2."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: SuperWeights are linear combinations of templates reused by multiple layers. They capture a single operation on input features, such as edge or texture detection, and are generated via a weighted combination of trainable parameters held by Weight Templates. To generate weights for a single layer, we construct SuperWeights from Weight Template parameters and concatenate them to create the final weights, as illustrated in Figure 2."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: SuperWeights are linear combinations of templates reused by multiple layers. They capture a single operation on input features, such as edge or texture detection, and are generated via a weighted combination of trainable parameters held by Weight Templates. To generate weights for a single layer, we construct SuperWeights from Weight Template parameters and concatenate them to create the final weights, as illustrated in Figure 2."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "instruction": "Edit the first part of this paragraph for conciseness.", "revised_paragraph": "Revised paragraph: \"SuperWeights are linear combinations of templates reused by multiple layers, capturing a single operation on input features. These SuperWeights are generated via a weighted combination of one or more templates of trainable parameters held by Weight Templates. To generate weights for a single layer, we construct SuperWeights from Weight Template parameters (Section 3.1) and concatenate all used SuperWeights to create the final weights (illustrated in Figure 2).\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.00", "instruction": "Make the first half of the paragraphe shorter by merging the two sentences and removing the details about how superweights are generated.", "revised_paragraph": "Revised paragraph: SuperWeights, which are linear combinations of templates reused by multiple layers, capture a single operation on input features. To generate the weights for a single layer, we construct SuperWeights from trainable parameters held by Weight Templates and then concatenate all used SuperWeights to create the final weights, as illustrated in the center-right column of Figure 2.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' feedback on Design B was critical, as most were unsuccessful in completing the task. Five participants found the design unsuitable, citing a lack of visual cues to indicate allowed medication intake times. Three participants suggested rescheduling medication in any available slot, while others were unsure how to proceed. Some participants misinterpreted the bar indicating allowed schedule times as extended release time, and others found the design's use of a full hour to represent a single medication intake time confusing."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' feedback on Design B was critical, as most were unsuccessful in completing the task. Five participants found the design unsuitable, citing a lack of visual cues to indicate allowed medication intake times. Three participants suggested rescheduling medication in any available slot, while others were unsure how to proceed. Some participants misinterpreted the bar indicating allowed schedule times as extended release time, and others found the design's use of a full hour to represent a single medication intake time confusing."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' feedback on Design B was critical, as most were unsuccessful in completing the task. Five participants found the design unsuitable, citing a lack of visual cues to indicate allowed medication intake times. Three participants suggested rescheduling medication in any available slot, while others were unsure how to proceed. Some participants misinterpreted the bar indicating allowed schedule times as extended release time, and others found the design's use of a full hour to represent a single medication intake time confusing."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' feedback on Design B was critical, as most were unsuccessful in completing the task. Five participants found the design unsuitable, citing a lack of visual cues to indicate allowed medication intake times. Three participants suggested rescheduling medication in any available slot, while others were unsure how to proceed. Some participants misinterpreted the bar indicating allowed schedule times as extended release time, and others found the design's use of a full hour to represent a single medication intake time confusing."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' feedback on Design B was critical, as most were unsuccessful in completing the task. Five participants found the design unsuitable, citing a lack of visual cues to indicate allowed medication intake times. Three participants suggested rescheduling medication in any available slot, while others were unsure how to proceed. Some participants misinterpreted the bar indicating allowed schedule times as extended release time, and others found the design's use of a full hour to represent a single medication intake time confusing."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' feedback on Design B was critical, as most were unsuccessful in completing the task. Five participants found the design unsuitable, citing a lack of visual cues to indicate allowed medication intake times. Three participants suggested rescheduling medication in any available slot, while others were unsure how to proceed. Some participants misinterpreted the bar indicating allowed schedule times as extended release time, and others found the design's use of a full hour to represent a single medication intake time confusing."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' feedback on Design B was critical, as most were unsuccessful in completing the task. Five participants found the design unsuitable, citing a lack of visual cues to indicate allowed medication intake times. Three participants suggested rescheduling medication in any available slot, while others were unsure how to proceed. Some participants misinterpreted the bar indicating allowed schedule times as extended release time, and others found the design's use of a full hour to represent a single medication intake time confusing."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Participants' feedback on Design B was critical, as most were unsuccessful in completing the task. Five participants found the design unsuitable, citing a lack of visual cues to indicate allowed medication intake times. Three participants suggested rescheduling medication in any available slot, while others were unsure how to proceed. Some participants misinterpreted the bar indicating allowed schedule times as extended release time, and others found the design's use of a full hour to represent a single medication intake time confusing."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "instruction": "Make this paragraph much more concise.", "revised_paragraph": "Revised paragraph: Participants' feedback on Design B was crucial in identifying its limitations. While the design did not support task completion, participants provided insightful comments. Five participants deemed the design unsuitable, citing a lack of visual cues for alternative medication intake times. Three participants suggested rescheduling medication in any available slot, while others proposed observing for potential conflicts. Additionally, some participants misinterpreted the bar as indicating extended release times, and others felt that the design's use of a full hour on the calendar was misleading.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.14", "instruction": "Please write more concisely about design B.", "revised_paragraph": "Revised paragraph: Design B struggled to support participants in completing the task, with only 3 successful attempts out of 20. Participants provided valuable feedback, citing the lack of clear indication of allowed medication intake times and the potential for misinterpretation. For instance, some participants believed the marker on the medication entry indicated extended release times, while others thought it allowed rescheduling in any free slot. P10 and P6 specifically criticized the design for occupying a full hour on the calendar, which they felt was inconsistent with the concept of taking medication at a specific time point.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We drew inspiration from the approach proposed by Chen et al., who developed a model for the supervised SNLI task (Bowman et al., 2015). Their model combines the outputs from a global mean-pooling function and a global max-pooling function to generate a sentence representation, resulting in a performance improvement on the SNLI dataset. Furthermore, Conneau et al. (2017) discovered that the model incorporating the global max-pooling function exhibits stronger transferability than its mean-pooling counterpart after supervised training on SNLI.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We drew inspiration from the approach proposed by Chen et al., who developed a model for the supervised SNLI task (Bowman et al., 2015). Their model combines the outputs from a global mean-pooling function and a global max-pooling function to generate a sentence representation, resulting in a performance improvement on the SNLI dataset. Furthermore, Conneau et al. (2017) discovered that the model incorporating the global max-pooling function exhibits stronger transferability than its mean-pooling counterpart after supervised training on SNLI.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We drew inspiration from the approach proposed by Chen et al., who developed a model for the supervised SNLI task (Bowman et al., 2015). Their model combines the outputs from a global mean-pooling function and a global max-pooling function to generate a sentence representation, resulting in a performance improvement on the SNLI dataset. Furthermore, Conneau et al. (2017) discovered that the model incorporating the global max-pooling function exhibits stronger transferability than its mean-pooling counterpart after supervised training on SNLI.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We drew inspiration from the approach proposed by Chen et al., who developed a model for the supervised SNLI task (Bowman et al., 2015). Their model combines the outputs from a global mean-pooling function and a global max-pooling function to generate a sentence representation, resulting in a performance improvement on the SNLI dataset. Furthermore, Conneau et al. (2017) discovered that the model incorporating the global max-pooling function exhibits stronger transferability than its mean-pooling counterpart after supervised training on SNLI.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We drew inspiration from the approach proposed by Chen et al., who developed a model for the supervised SNLI task (Bowman et al., 2015). Their model combines the outputs from a global mean-pooling function and a global max-pooling function to generate a sentence representation, resulting in a performance improvement on the SNLI dataset. Furthermore, Conneau et al. (2017) discovered that the model incorporating the global max-pooling function exhibits stronger transferability than its mean-pooling counterpart after supervised training on SNLI.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We drew inspiration from the approach proposed by Chen et al., who developed a model for the supervised SNLI task (Bowman et al., 2015). Their model combines the outputs from a global mean-pooling function and a global max-pooling function to generate a sentence representation, resulting in a performance improvement on the SNLI dataset. Furthermore, Conneau et al. (2017) discovered that the model incorporating the global max-pooling function exhibits stronger transferability than its mean-pooling counterpart after supervised training on SNLI.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We drew inspiration from the approach proposed by Chen et al., who developed a model for the supervised SNLI task (Bowman et al., 2015). Their model combines the outputs from a global mean-pooling function and a global max-pooling function to generate a sentence representation, resulting in a performance improvement on the SNLI dataset. Furthermore, Conneau et al. (2017) discovered that the model incorporating the global max-pooling function exhibits stronger transferability than its mean-pooling counterpart after supervised training on SNLI.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"We drew inspiration from the approach proposed by Chen et al., who developed a model for the supervised SNLI task (Bowman et al., 2015). Their model combines the outputs from a global mean-pooling function and a global max-pooling function to generate a sentence representation, resulting in a performance improvement on the SNLI dataset. Furthermore, Conneau et al. (2017) discovered that the model incorporating the global max-pooling function exhibits stronger transferability than its mean-pooling counterpart after supervised training on SNLI.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "instruction": "Rewrite this paragraph using more formal language", "revised_paragraph": "Revised paragraph: We drew inspiration from the approach proposed by Chen et al., which endeavours to develop a model for the supervised SNLI task, as described by Bowman et al. (2015). The model in question combines the outputs of a global mean-pooling function and a global max-pooling function to generate a sentence representation, thereby achieving a performance enhancement on the SNLI dataset. Furthermore, Conneau et al. (2017) discovered that the model incorporating a global max-pooling function exhibits superior transferability compared to the model utilizing a global mean-pooling function following supervised training on SNLI.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "SyF8k7bCW.HytIRPamf.04", "instruction": "Rephrase the text", "revised_paragraph": "Revised paragraph: Building upon the concept proposed by Chen et al., we aimed to develop a model for the supervised SNLI task, as previously explored by Bowman et al. (2015). Our model combines the outputs of global mean-pooling and global max-pooling functions to generate a sentence representation, which has been shown to yield a performance boost on the SNLI dataset. Notably, Conneau et al. (2017) discovered that the model incorporating the global max-pooling function exhibits stronger transferability after supervised training on SNLI compared to the model with global mean-pooling function.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: In this work, we compared two approaches to alleviate the issue of frequently moving targets in updating the Q-network. Firstly, we examined the impact of periodic syncing between networks with different frequency periods, specifically 10 (Fig. 13 (a)) and 500. Secondly, we explored the effect of varying the dimensionality of the action graph representation, encoding node-features in 32 or 64 dimensions."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIn this work, we explored two approaches to alleviate the issue of frequently moving targets in updating Q-networks. Firstly, we compared the impact of periodic syncing between the target and main networks, as proposed by Mnih et al. (2015), using two extreme frequency periods: 10 (as shown in Fig. 13 (a)) and 500 (AGILE-Tuned). Secondly, we investigated the effect of varying the dimensionality of node features in the action graph, encoding them in either 32 (Graph-dim=32) or 64 (AGILE-Tuned) dimensions to understand the difficulty in expressing action relations through compact representations."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: In this work, we compared two approaches to alleviate the issue of frequently moving targets in updating the Q-network. Firstly, we examined the impact of periodic syncing between networks with different frequency periods, specifically 10 (Fig. 13 (a)) and 500. Secondly, we explored the effect of varying the dimensionality of the action graph representation, encoding node-features in 32 or 64 dimensions."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIn this work, we explored two approaches to alleviate the issue of frequently moving targets in updating Q-networks. Firstly, we compared the impact of periodic syncing between the target and main networks, as proposed by Mnih et al. (2015), using two extreme frequency periods: 10 (as shown in Fig. 13 (a)) and 500 (AGILE-Tuned). Secondly, we investigated the effect of varying the dimensionality of node features in the action graph, encoding them in either 32 (Graph-dim=32) or 64 (AGILE-Tuned) dimensions to understand the difficulty in expressing action relations through compact representations."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: In this work, we compared two approaches to alleviate the issue of frequently moving targets in updating the Q-network. Firstly, we examined the impact of periodic syncing between networks with different frequency periods, specifically 10 (Fig. 13 (a)) and 500. Secondly, we explored the effect of varying the dimensionality of the action graph representation, encoding node-features in 32 or 64 dimensions."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIn this work, we explored two approaches to alleviate the issue of frequently moving targets in updating Q-networks. Firstly, we compared the impact of periodic syncing between the target and main networks, as proposed by Mnih et al. (2015), using two extreme frequency periods: 10 (as shown in Fig. 13 (a)) and 500 (AGILE-Tuned). Secondly, we investigated the effect of varying the dimensionality of node features in the action graph, encoding them in either 32 (Graph-dim=32) or 64 (AGILE-Tuned) dimensions to understand the difficulty in expressing action relations through compact representations."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: In this work, we compared two approaches to alleviate the issue of frequently moving targets in updating the Q-network. Firstly, we examined the impact of periodic syncing between networks with different frequency periods, specifically 10 (Fig. 13 (a)) and 500. Secondly, we explored the effect of varying the dimensionality of the action graph representation, encoding node-features in 32 or 64 dimensions."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: \n\nIn this work, we explored two approaches to alleviate the issue of frequently moving targets in updating Q-networks. Firstly, we compared the impact of periodic syncing between the target and main networks, as proposed by Mnih et al. (2015), using two extreme frequency periods: 10 (as shown in Fig. 13 (a)) and 500 (AGILE-Tuned). Secondly, we investigated the effect of varying the dimensionality of node features in the action graph, encoding them in either 32 (Graph-dim=32) or 64 (AGILE-Tuned) dimensions to understand the difficulty in expressing action relations through compact representations."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: In this work, we compared two approaches to alleviate the issue of frequently moving targets in updating the Q-network. Firstly, we examined the impact of periodic syncing between networks with different frequency periods, specifically 10 (Fig. 13 (a)) and 500. Secondly, we explored the effect of varying the dimensionality of the action graph representation, encoding node-features in 32 or 64 dimensions."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we investigated two methods to mitigate the problem of frequently moving targets in updating our Q-network. Specifically, we analyzed the effect of periodic synchronization between networks with different frequency periods, including a 10-minute interval (as shown in Fig. 13 (a)) and a 500-minute interval. Additionally, we examined the impact of varying the dimensionality of our action graph representation, where node features were encoded in either 32 or 64 dimensions."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: In this work, we compared two approaches to alleviate the issue of frequently moving targets in updating the Q-network. Firstly, we examined the impact of periodic syncing between networks with different frequency periods, specifically 10 (Fig. 13 (a)) and 500. Secondly, we explored the effect of varying the dimensionality of the action graph representation, encoding node-features in 32 or 64 dimensions."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we investigated two methods to mitigate the problem of frequently moving targets in updating our Q-network. Specifically, we analyzed the effect of periodic synchronization between networks with different frequency periods, including a 10-minute interval (as shown in Fig. 13 (a)) and a 500-minute interval. Additionally, we examined the impact of varying the dimensionality of our action graph representation, where node features were encoded in either 32 or 64 dimensions."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: In this work, we compared two approaches to alleviate the issue of frequently moving targets in updating the Q-network. Firstly, we examined the impact of periodic syncing between networks with different frequency periods, specifically 10 (Fig. 13 (a)) and 500. Secondly, we explored the effect of varying the dimensionality of the action graph representation, encoding node-features in 32 or 64 dimensions."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we investigated two methods to mitigate the problem of frequently moving targets in updating our Q-network. Specifically, we analyzed the effect of periodic synchronization between networks with different frequency periods, including a 10-minute interval (as shown in Fig. 13 (a)) and a 500-minute interval. Additionally, we examined the impact of varying the dimensionality of our action graph representation, where node features were encoded in either 32 or 64 dimensions."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: In this work, we compared two approaches to alleviate the issue of frequently moving targets in updating the Q-network. Firstly, we examined the impact of periodic syncing between networks with different frequency periods, specifically 10 (Fig. 13 (a)) and 500. Secondly, we explored the effect of varying the dimensionality of the action graph representation, encoding node-features in 32 or 64 dimensions."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: In this study, we investigated two methods to mitigate the problem of frequently moving targets in updating our Q-network. Specifically, we analyzed the effect of periodic synchronization between networks with different frequency periods, including a 10-minute interval (as shown in Fig. 13 (a)) and a 500-minute interval. Additionally, we examined the impact of varying the dimensionality of our action graph representation, where node features were encoded in either 32 or 64 dimensions."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "instruction": "Improve the English of this paragraph and make it shorter.", "revised_paragraph": "Revised paragraph: In this work, we addressed the challenges of updating Q-networks in the presence of a moving target by comparing two syncing frequency periods: 10 (Fig. 13(a)) and 500 (AGILE-Tuned). We also explored the impact of compact representation on action relation expression by encoding node features in 32 or 64 dimensions, as demonstrated in AGILE-Tuned and Graph-dim=32, respectively.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.19", "instruction": "Make the wording of this paragraph much more straight forward, to be more consice.", "revised_paragraph": "Revised paragraph: We compared two methods to update the Q-network: AGILE-Tuned without changing the sync frequency, and AGILE-Tuned without changing the graph dimension. In the first method, we used the same syncing frequency as in Mnih et al. (2015), but with different frequency periods (10 and 500). In the second method, we compared the performance of the action graph with node-features encoded in 32 and 64 dimensions.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We use the Something-Something V2 dataset, which is larger and more diverse than Action Genome, with 200K videos including basic human activities created by a large number of crowd workers. We propose the Action Graph representation, a temporal extension of spatial graphs, which we argue is more natural for representing videos of actions.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Building on Ji et al.'s (2019) Action Genome dataset, we use the larger and more diverse Something-Something V2 dataset (Goyal et al., 2017) for our study. This dataset includes 200K videos, featuring basic human activities annotated by a large number of crowd workers. We propose the Action Graph representation, a temporal extension of spatial graphs, which we argue is a more natural way to represent videos of actions.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We use the Something-Something V2 dataset, which is larger and more diverse than Action Genome, with 200K videos including basic human activities created by a large number of crowd workers. We propose the Action Graph representation, a temporal extension of spatial graphs, which we argue is more natural for representing videos of actions.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Building on Ji et al.'s (2019) Action Genome dataset, we use the larger and more diverse Something-Something V2 dataset (Goyal et al., 2017) for our study. This dataset includes 200K videos, featuring basic human activities annotated by a large number of crowd workers. We propose the Action Graph representation, a temporal extension of spatial graphs, which we argue is a more natural way to represent videos of actions.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We use the Something-Something V2 dataset, which is larger and more diverse than Action Genome, with 200K videos including basic human activities created by a large number of crowd workers. We propose the Action Graph representation, a temporal extension of spatial graphs, which we argue is more natural for representing videos of actions.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"We utilize the Something-Something V2 dataset, a larger and more diverse collection of 200K videos featuring basic human activities, created by a large number of crowd workers. Our approach, Action Graph, extends spatial graphs to represent videos of actions in a more natural and temporal manner.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"We use the Something-Something V2 dataset, which is larger and more diverse than Action Genome, with 200K videos including basic human activities created by a large number of crowd workers. We propose the Action Graph representation, a temporal extension of spatial graphs, which we argue is more natural for representing videos of actions.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Building on Ji et al.'s (2019) Action Genome dataset, we use the larger and more diverse Something-Something V2 dataset (Goyal et al., 2017) for our study. This dataset includes 200K videos, featuring basic human activities annotated by a large number of crowd workers. We propose the Action Graph representation, a temporal extension of spatial graphs, which we argue is a more natural way to represent videos of actions.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "instruction": "Remove the argument that Action Graph is a more natural representation.", "revised_paragraph": "Revised paragraph: \"Recently, Ji et al. (2019) presented Action Genome, a new video dataset annotated by SGs. This dataset includes spatio-temporal SG annotations, where for each video, few individual frames were chosen and spatially annotated by SGs. Here, we use the Something-Something V2 (Goyal et al., 2017) dataset that is larger (200K vs. 10K videos) and more diverse since it includes basic human activities created by a large number of crowd workers. We propose the Action Graph representation, and use it to represent videos of actions.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "4cxEpKddZp.QPmWFhqQU6.00", "instruction": "Remove the less important details in the last sentence.", "revised_paragraph": "Revised paragraph: Recently, Ji et al. (2019) presented Action Genome, a new video dataset annotated by SGs. This dataset includes spatio-temporal SG annotations, where for each video, few individual frames were chosen and spatially annotated by SGs. We use the Something-Something V2 (Goyal et al., 2017) dataset, which is larger and more diverse than Action Genome. We propose the Action Graph representation, which we view as a temporal extension of SGs, and argue it is more natural for representing videos of actions.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 as the backbone network for VOC experiments, and PSPNet for DensePose dataset experiments. We use pre-trained models on the ImageNet dataset. The models are trained with hyperparameters set according to the type of annotations and dataset, as shown in Table 1. For inference, we employ k-nearest neighbor retrievals using SegSort. Further details on hyperparameters and training settings can be found in the Appendix.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as the backbone network for VOC experiments, and PSPNet (Zhao et al., 2017) for DensePose dataset. We use pre-trained models on ImageNet (Deng et al., 2009) and adjust hyper-parameters (listed in Table 1) according to annotation types and datasets. For inference, we employ k-nearest neighbor retrievals as described in SegSort (Hwang et al., 2019). See the Appendix for further details.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Our experiments employ various architectures and training settings. For the VOC dataset, we utilize the DeepLab framework (Chen et al., 2017) with ResNet101 (He et al., 2016) as the backbone network. In contrast, we adopt PSPNet (Zhao et al., 2017) as the backbone network for the DensePose dataset. All models are pre-trained on the ImageNet (Deng et al., 2009) dataset. The hyperparameters \u03bb I, \u03bb C, \u03bb O, and \u03bb A are tailored to the specific type of annotation and dataset, as shown in Table 1. During inference, we employ the SegSort method (Hwang et al., 2019) to perform k-nearest neighbor retrievals. Additional details on hyperparameters and training settings can be found in the Appendix.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 as the backbone network for VOC experiments, and PSPNet for DensePose dataset experiments. We use pre-trained models on the ImageNet dataset. The models are trained with hyperparameters set according to the type of annotations and dataset, as shown in Table 1. For inference, we employ k-nearest neighbor retrievals using SegSort. Further details on hyperparameters and training settings can be found in the Appendix.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 as the backbone network for VOC experiments, and PSPNet for DensePose dataset experiments. We use pre-trained models on the ImageNet dataset. The models are trained with hyperparameters set according to the type of annotations and dataset, as shown in Table 1. For inference, we employ k-nearest neighbor retrievals using SegSort. Further details on hyperparameters and training settings can be found in the Appendix.\""}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as the backbone network for VOC experiments, and PSPNet (Zhao et al., 2017) for DensePose dataset. We use pre-trained models on ImageNet (Deng et al., 2009) and adjust hyper-parameters (listed in Table 1) according to annotation types and datasets. For inference, we employ k-nearest neighbor retrievals as described in SegSort (Hwang et al., 2019). See the Appendix for further details.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 as the backbone network for VOC experiments, and PSPNet for DensePose dataset experiments. We use pre-trained models on the ImageNet dataset. The models are trained with hyperparameters set according to the type of annotations and dataset, as shown in Table 1. For inference, we employ k-nearest neighbor retrievals using SegSort. Further details on hyperparameters and training settings can be found in the Appendix.\""}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Our experiments employ various architectures and training settings. For the VOC dataset, we utilize the DeepLab framework (Chen et al., 2017) with ResNet101 (He et al., 2016) as the backbone network. In contrast, we adopt PSPNet (Zhao et al., 2017) as the backbone network for the DensePose dataset. All models are pre-trained on the ImageNet (Deng et al., 2009) dataset. The hyperparameters \u03bb I, \u03bb C, \u03bb O, and \u03bb A are tailored to the specific type of annotation and dataset, as shown in Table 1. During inference, we employ the SegSort method (Hwang et al., 2019) to perform k-nearest neighbor retrievals. Additional details on hyperparameters and training settings can be found in the Appendix.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 as the backbone network for VOC experiments, and PSPNet for DensePose dataset experiments. We use pre-trained models on the ImageNet dataset. The models are trained with hyperparameters set according to the type of annotations and dataset, as shown in Table 1. For inference, we employ k-nearest neighbor retrievals using SegSort. Further details on hyperparameters and training settings can be found in the Appendix.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 and PSPNet as backbone networks. We use pre-trained models on ImageNet and fine-tune them with hyperparameters tailored to each dataset, as shown in Table 1. Inference is performed using SegSort with k-nearest neighbor retrievals. Additional details can be found in the Appendix.\""}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Our architecture is built upon the DeepLab framework, employing ResNet101 and PSPNet as our backbone networks. We leverage pre-trained models on ImageNet and fine-tune them with dataset-specific hyperparameters, as outlined in Table 1. During inference, we utilize SegSort with k-nearest neighbor retrievals. Further details are provided in the Appendix.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 as the backbone network for VOC experiments, and PSPNet for DensePose dataset experiments. We use pre-trained models on the ImageNet dataset. The models are trained with hyperparameters set according to the type of annotations and dataset, as shown in Table 1. For inference, we employ k-nearest neighbor retrievals using SegSort. Further details on hyperparameters and training settings can be found in the Appendix.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 as the backbone network for VOC experiments, and PSPNet for DensePose dataset experiments. We use pre-trained models on the ImageNet dataset. The models are trained with hyperparameters set according to the type of annotations and dataset, as shown in Table 1. For inference, we employ k-nearest neighbor retrievals using SegSort. Further details on hyperparameters and training settings can be found in the Appendix.\""}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 and PSPNet as backbone networks. We use pre-trained models on ImageNet and fine-tune them with hyperparameters tailored to each dataset, as shown in Table 1. Inference is performed using SegSort with k-nearest neighbor retrievals. Additional details can be found in the Appendix.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "revisions": [{"depth": 1, "intention": "Content_deletion", "revised_paragraph": "Revised paragraph: \"Our architecture is based on DeepLab with ResNet101 as the backbone network for VOC experiments, and PSPNet for DensePose dataset experiments. We use pre-trained models on the ImageNet dataset. The models are trained with hyperparameters set according to the type of annotations and dataset, as shown in Table 1. For inference, we employ k-nearest neighbor retrievals using SegSort. Further details on hyperparameters and training settings can be found in the Appendix.\""}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Our architecture is built upon DeepLab, utilizing ResNet101 as the backbone network for experiments on the VOC dataset, and PSPNet for those on the DensePose dataset. We leverage pre-trained models on the ImageNet dataset and fine-tune them using hyperparameters tailored to the specific type of annotations and dataset, as outlined in Table 1. For inference, we employ k-nearest neighbor retrievals via SegSort. Additional details on hyperparameters and training settings can be found in the Appendix.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "instruction": "Move the less important details of the training into an appendix. ", "revised_paragraph": "Revised paragraph: \"Architecture, training and testing. For all the experiments on VOC, we base our architecture on DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as backbone network. For the experiments on DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as backbone network. We only use models pre-trained on ImageNet (Deng et al., 2009) dataset. The hyper-parameters and settings for training and testing are shown in Table 1. For inference, we perform k-nearest neighbor retrievals as described in SegSort (Hwang et al., 2019).\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "atxti8SVk.3K9AmPwALM.14", "instruction": "VOC is now named PASCAL VOC. Replace the last two sentence by a reference to an appendix. Correct the english in this paragraph.", "revised_paragraph": "Revised paragraph: Architecture, training, and testing. For all experiments on PASCAL VOC, we base our architecture on DeepLab (Chen et al., 2017) with ResNet101 (He et al., 2016) as the backbone network. For experiments on the DensePose dataset, we adopt PSPNet (Zhao et al., 2017) as the backbone network. Our models are pre-trained on the ImageNet (Deng et al., 2009) dataset. The hyper-parameters and settings for training and testing are presented in Table 1 and detailed in Appendix A.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The design of a calendar should be familiar to users, with a layout, medication entries, and icons similar to existing calendars. Over 80% of participants preferred Design B due to its resemblance to existing calendars, despite Design A being intended to resemble existing calendars. The height of medication entries in Design A was a major factor, as participants found it introduced too much clutter. The preferred layout should be vertically oriented, with days of the week at the top and times on the left. Medication entries should use a consistent unit and show the actual quantity (e.g., milligrams) rather than relative classifications. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned with the entry, not as part of medication summaries."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The design of a calendar should adhere to familiar calendar interfaces (DG2) to ensure user comfort. Our analysis reveals that this principle was consistently applied in various design aspects, including layout, medication entries, and annotation icons. Notably, over 80% of participants preferred Design B due to its probable similarity to existing calendars, which was surprising given that Design A was intended to resemble familiar calendars. However, Design A was overshadowed by the excessive clutter introduced by the medication entries, which spanned the entire administration period. Our findings suggest that the preferred layout should be vertically oriented, with days of the week at the top and times of the day on the left. Moreover, the dosage and unit used in medication entries should be consistent with those used in prescriptions, displaying actual quantities (e.g., milligrams) rather than relative classifications. This principle also applies to the icon used to denote medication that should be taken with food. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned alongside the entry rather than as part of medication summaries."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The design of a calendar should be familiar to users, with a layout, medication entries, and icons similar to existing calendars. Over 80% of participants preferred Design B due to its resemblance to existing calendars, despite Design A being intended to resemble existing calendars. The height of medication entries in Design A was a major factor, as participants found it introduced too much clutter. The preferred layout should be vertically oriented, with days of the week at the top and times on the left. Medication entries should use a consistent unit and show the actual quantity (e.g., milligrams) rather than relative classifications. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned with the entry, not as part of medication summaries."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The design of a calendar should be familiar to users, with a layout, medication entries, and icons similar to existing calendars. Over 80% of participants preferred Design B due to its resemblance to existing calendars, despite Design A being intended to resemble existing calendars. The height of medication entries in Design A was a major factor, as participants found it introduced too much clutter. The preferred layout should be vertically oriented, with days of the week at the top and times on the left. Medication entries should use a consistent unit and show the actual quantity (e.g., milligrams) rather than relative classifications. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned with the entry, not as part of medication summaries."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The design of a calendar should be familiar to users, with a layout, medication entries, and icons similar to existing calendars. Over 80% of participants preferred Design B due to its resemblance to existing calendars, despite Design A being intended to resemble existing calendars. The height of medication entries in Design A was a major factor, as participants found it introduced too much clutter. The preferred layout should be vertically oriented, with days of the week at the top and times on the left. Medication entries should use a consistent unit and show the actual quantity (e.g., milligrams) rather than relative classifications. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned with the entry, not as part of medication summaries."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The design of a calendar should adhere to familiar calendar interfaces (DG2) to ensure user comfort. Our analysis reveals that this principle was consistently applied in various design aspects, including layout, medication entries, and annotation icons. Notably, over 80% of participants preferred Design B due to its probable similarity to existing calendars, which was surprising given that Design A was intended to resemble familiar calendars. However, Design A was overshadowed by the excessive clutter introduced by the medication entries, which spanned the entire administration period. Our findings suggest that the preferred layout should be vertically oriented, with days of the week at the top and times of the day on the left. Moreover, the dosage and unit used in medication entries should be consistent with those used in prescriptions, displaying actual quantities (e.g., milligrams) rather than relative classifications. This principle also applies to the icon used to denote medication that should be taken with food. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned alongside the entry rather than as part of medication summaries."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The design of a calendar should be familiar to users, with a layout, medication entries, and icons similar to existing calendars. Over 80% of participants preferred Design B due to its resemblance to existing calendars, despite Design A being intended to resemble existing calendars. The height of medication entries in Design A was a major factor, as participants found it introduced too much clutter. The preferred layout should be vertically oriented, with days of the week at the top and times on the left. Medication entries should use a consistent unit and show the actual quantity (e.g., milligrams) rather than relative classifications. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned with the entry, not as part of medication summaries."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The design of a calendar should be user-friendly and familiar, with a layout, medication entries, and icons that closely resemble existing calendars. Notably, over 80% of participants preferred Design B due to its similarity to existing calendars, despite Design A's intended resemblance. The excessive height of medication entries in Design A was a major drawback, as participants found it introduced unnecessary clutter. Our findings suggest that a vertically oriented layout is preferred, with days of the week at the top and times on the left. Moreover, medication entries should utilize a consistent unit and display the actual quantity (e.g., milligrams) rather than relative classifications. Furthermore, the use of realistic food-related icons, such as bananas, is more effective than custom-designed icons, and should be positioned alongside the entry rather than as part of medication summaries."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The design of a calendar should be familiar to users, with a layout, medication entries, and icons similar to existing calendars. Over 80% of participants preferred Design B due to its resemblance to existing calendars, despite Design A being intended to resemble existing calendars. The height of medication entries in Design A was a major factor, as participants found it introduced too much clutter. The preferred layout should be vertically oriented, with days of the week at the top and times on the left. Medication entries should use a consistent unit and show the actual quantity (e.g., milligrams) rather than relative classifications. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned with the entry, not as part of medication summaries."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The design of a calendar should be familiar to users, with a layout, medication entries, and icons similar to existing calendars. Over 80% of participants preferred Design B due to its resemblance to existing calendars, despite Design A being intended to resemble existing calendars. The height of medication entries in Design A was a major factor, as participants found it introduced too much clutter. The preferred layout should be vertically oriented, with days of the week at the top and times on the left. Medication entries should use a consistent unit and show the actual quantity (e.g., milligrams) rather than relative classifications. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned with the entry, not as part of medication summaries."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The design of a calendar should be familiar to users, with a layout, medication entries, and icons similar to existing calendars. Over 80% of participants preferred Design B due to its resemblance to existing calendars, despite Design A being intended to resemble existing calendars. The height of medication entries in Design A was a major factor, as participants found it introduced too much clutter. The preferred layout should be vertically oriented, with days of the week at the top and times on the left. Medication entries should use a consistent unit and show the actual quantity (e.g., milligrams) rather than relative classifications. Realistic food-related icons, such as bananas, are more effective than custom-designed icons, and should be positioned with the entry, not as part of medication summaries."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The design of a calendar should be user-friendly and familiar, with a layout, medication entries, and icons that closely resemble existing calendars. Notably, over 80% of participants preferred Design B due to its similarity to existing calendars, despite Design A's intended resemblance. The excessive height of medication entries in Design A was a major drawback, as participants found it introduced unnecessary clutter. Our findings suggest that a vertically oriented layout is preferred, with days of the week at the top and times on the left. Moreover, medication entries should utilize a consistent unit and display the actual quantity (e.g., milligrams) rather than relative classifications. Furthermore, the use of realistic food-related icons, such as bananas, is more effective than custom-designed icons, and should be positioned alongside the entry rather than as part of medication summaries."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "instruction": "Make this paragraph more concise.", "revised_paragraph": "Revised paragraph: The design of a calendar should adhere to familiar interfaces, observed in aspects such as layout, medication entries, and icons. Over 80% of participants preferred Design B due to its similarity to existing calendars, despite Design A being intended to resemble them. The main reason for Design A's rejection was the clutter introduced by medication entries spanning the entire administration period. Results suggest a vertically oriented layout with days of the week at the top and times on the left, using familiar dosage units and consistent with prescriptions. Realistic food-related icons, such as bananas, should be used to denote medication taken with food, positioned together with entries rather than in summaries.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.15", "instruction": "Shorten my sentence related to realistic food-related icons.", "revised_paragraph": "Revised paragraph: The design of a calendar should not deviate from calendar interfaces that users are familiar with (DG2). This was observed in various aspects of the design, including layout, medication entries, and icons used to annotate entries. For instance, realistic food-related icons, such as bananas, were more effective in indicating the \"take-with-food\" action than custom-designed icons, such as a spoon. This preference was surprising, as Design A, intended to resemble existing calendars, was overshadowed by Design B due to the latter's vertical layout and consistent medication entry units.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work's central novelty lies in learning a discrete representation, enabling structured search on two levels. To demonstrate the necessity of this discrete latent space, we introduce two ablative baselines that replace the VQ-VAE with a generic autoencoder and a VAE.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work's central novelty lies in learning a discrete representation, enabling structured search on two levels. To demonstrate the necessity of this discrete latent space, we introduce two ablative baselines that replace the VQ-VAE with a generic autoencoder and a VAE.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work's central novelty lies in learning a discrete representation, enabling structured search on two levels. To demonstrate the necessity of this discrete latent space, we introduce two ablative baselines that replace the VQ-VAE with a generic autoencoder and a VAE.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work's central novelty lies in learning a discrete representation, enabling structured search on two levels. To demonstrate the necessity of this discrete latent space, we introduce two ablative baselines that replace the VQ-VAE with a generic autoencoder and a VAE.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work's central novelty lies in learning a discrete representation, enabling structured search on two levels. To demonstrate the necessity of this discrete latent space, we introduce two ablative baselines that replace the VQ-VAE with a generic autoencoder and a VAE.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work's central novelty lies in learning a discrete representation, enabling structured search on two levels. To demonstrate the necessity of this discrete latent space, we introduce two ablative baselines that replace the VQ-VAE with a generic autoencoder and a VAE.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work's central novelty lies in learning a discrete representation, enabling structured search on two levels. To demonstrate the necessity of this discrete latent space, we introduce two ablative baselines that replace the VQ-VAE with a generic autoencoder and a VAE.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our work's central novelty lies in learning a discrete representation, enabling structured search on two levels. To demonstrate the necessity of this discrete latent space, we introduce two ablative baselines that replace the VQ-VAE with a generic autoencoder and a VAE.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "instruction": "Make this paragraph more concise.", "revised_paragraph": "Revised paragraph: \"Our work's central innovation lies in demonstrating that learning a discrete representation enables structured search on two levels. To validate this, we introduce two ablative baselines: a generic autoencoder and a VAE, replacing the VQ-VAE to show its necessity.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "instruction": "Make this paragraph shorter.", "revised_paragraph": "Revised paragraph: Our work's central novelty lies in learning a discrete representation that enables structured search on two levels. To demonstrate the necessity of this discrete latent space, we introduce two ablative baselines, replacing the VQ-VAE with a generic autoencoder and a VAE.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"To illustrate the concept of selection collider bias, consider two scenarios. In the first, we ask you to randomly assign a gender to a person born in 1801 and one in 1999, given that birth date and gender are independent in reality. In contrast, in the second scenario, we ask you to guess the gender of a person born in 1801 and one in 1999, but only if you have seen their Wikipedia articles. In this case, you may base your guess on a combination of factors, including birth date, gender, and what is recorded in Wikipedia.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"To illustrate the concept of selection collider bias, consider two scenarios. In the first, we ask you to randomly assign a gender to a person born in 1801 and one in 1999, given that birth date and gender are independent in reality. In contrast, in the second scenario, we ask you to guess the gender of a person born in 1801 and one in 1999, but only if you have seen their Wikipedia articles. In this case, you may base your guess on a combination of factors, including birth date, gender, and what is recorded in Wikipedia.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"To illustrate the concept of selection collider bias, consider two scenarios. In the first, we ask you to randomly assign a gender to a person born in 1801 and one in 1999, given that birth date and gender are independent in reality. In contrast, in the second scenario, we ask you to guess the gender of a person born in 1801 and one in 1999, but only if you have seen their Wikipedia articles. In this case, you may base your guess on a combination of factors, including birth date, gender, and what is recorded in Wikipedia.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"To illustrate the concept of selection collider bias, consider two scenarios. In the first, we ask you to randomly assign a gender to a person born in 1801 and one in 1999, given that birth date and gender are independent in reality. In contrast, in the second scenario, we ask you to guess the gender of a person born in 1801 and one in 1999, but only if you have seen their Wikipedia articles. In this case, you may base your guess on a combination of factors, including birth date, gender, and what is recorded in Wikipedia.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"To illustrate the concept of selection collider bias, consider two scenarios. In the first, we ask you to randomly assign a gender to a person born in 1801 and one in 1999, given that birth date and gender are independent in reality. In contrast, in the second scenario, we ask you to guess the gender of a person born in 1801 and one in 1999, but only if you have seen their Wikipedia articles. In this case, you may base your guess on a combination of factors, including birth date, gender, and what is recorded in Wikipedia.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"To illustrate the concept of selection collider bias, consider two scenarios. In the first, we ask you to randomly assign a gender to a person born in 1801 and one in 1999, given that birth date and gender are independent in reality. In contrast, in the second scenario, we ask you to guess the gender of a person born in 1801 and one in 1999, but only if you have seen their Wikipedia articles. In this case, you may base your guess on a combination of factors, including birth date, gender, and what is recorded in Wikipedia.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"To illustrate the concept of selection collider bias, consider two scenarios. In the first, we ask you to randomly assign a gender to a person born in 1801 and one in 1999, given that birth date and gender are independent in reality. In contrast, in the second scenario, we ask you to guess the gender of a person born in 1801 and one in 1999, but only if you have seen their Wikipedia articles. In this case, you may base your guess on a combination of factors, including birth date, gender, and what is recorded in Wikipedia.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "revisions": [{"depth": 1, "intention": "Rewritting_heavy", "revised_paragraph": "Revised paragraph: \"To illustrate the concept of selection collider bias, consider two scenarios. In the first, we ask you to randomly assign a gender to a person born in 1801 and one in 1999, given that birth date and gender are independent in reality. In contrast, in the second scenario, we ask you to guess the gender of a person born in 1801 and one in 1999, but only if you have seen their Wikipedia articles. In this case, you may base your guess on a combination of factors, including birth date, gender, and what is recorded in Wikipedia.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "instruction": "Rewrite this paragraph to improve its clarity.", "revised_paragraph": "Revised paragraph: \"To illustrate the concept of selection collider bias, consider the following example. If we were to ask you to guess the gender of a randomly selected individual born in 1801 and another born in 1999, you might respond randomly, as birth date and gender are independent in the real world. However, if we asked you to guess the gender of individuals born in 1801 and 1999, whom you had just read about in two random Wikipedia articles, your response would likely be influenced by a combination of factors, including birth date, gender, and the types of information typically recorded on Wikipedia.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "Mu-tqfqX-.6NSudk3nD.03", "instruction": "This paragraph is confusing, rewrite to make it clearer and more readable.", "revised_paragraph": "Revised paragraph: \"To illustrate selection collider bias, consider a thought experiment. If we asked you to guess the gender of a person born in 1801 and one in 1999, you might use a random process, such as flipping a coin, since birth date and gender are generally unrelated in the real world. In contrast, if we asked you to guess the gender of individuals born in 1801 and 1999, whom you had just read about in two random Wikipedia articles, you would likely rely on information from the articles, including birth date, gender, and what is recorded on Wikipedia. This highlights the potential for selection collider bias to occur when conditioning on a third variable, such as article content.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model for predicting sidechain structures by sampling from the estimated distribution. We use RDE to sample sidechain torsional angles for structures with removed sidechains in our PDB-REDO test split, selecting the highest-probability rotamer as the final prediction. Compared to Rosetta (fixbb) and SCWRL4, RDE outperforms these baselines on all four torsional angles in terms of angular errors, as shown in Table 4."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model that predicts sidechain conformations by sampling from an estimated distribution. In our study, we employ the RDE to sample sidechain torsional angles (rotamers) for structures with removed sidechains in our test split of PDB-REDO. Specifically, for each amino acid, we independently sample 10 rotamers and select the one with the highest probability as the final prediction. We compare the performance of RDE with two baseline methods, Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009), and the results, presented in Table 4, demonstrate that RDE outperforms the baselines in terms of angular errors for all four torsional angles. For a more detailed analysis of per-amino-acid accuracy, please refer to Table 11 in the appendix."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model designed to predict sidechain conformations by sampling from an estimated distribution. In our study, we utilize the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, we independently sample 10 rotamers and select the one with the highest probability as the final prediction. We compare the performance of RDE with two baseline methods, Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). The results, presented in Table 4, demonstrate that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Additionally, detailed per-amino-acid accuracy is provided in Table 11 of the appendix."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model that predicts sidechain conformations by sampling from an estimated distribution. In our study, we employ the RDE to sample sidechain torsional angles (rotamers) for structures with removed sidechains in our test split of PDB-REDO. Specifically, for each amino acid, we independently sample 10 rotamers and select the one with the highest probability as the final prediction. We compare the performance of RDE with two baseline methods, Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009), and the results, presented in Table 4, demonstrate that RDE outperforms the baselines in terms of angular errors for all four torsional angles. For a more detailed analysis of per-amino-acid accuracy, please refer to Table 11 in the appendix."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model designed to predict sidechain conformations by sampling from an estimated distribution. In our study, we utilize the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, we independently sample 10 rotamers and select the one with the highest probability as the final prediction. We compare the performance of RDE with two baseline methods, Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). The results, presented in Table 4, demonstrate that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Additionally, detailed per-amino-acid accuracy is provided in Table 11 of the appendix."}, {"intention": "Concision", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model for predicting sidechain structures by sampling from the estimated distribution. We use RDE to sample sidechain torsional angles for structures with removed sidechains in our PDB-REDO test split, selecting the highest-probability rotamer as the final prediction. Compared to Rosetta (fixbb) and SCWRL4, RDE outperforms these baselines on all four torsional angles in terms of angular errors, as shown in Table 4."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model for predicting sidechain structures by sampling from the estimated distribution. We use RDE to sample sidechain torsional angles for structures with removed sidechains in our PDB-REDO test split, selecting the highest-probability rotamer as the final prediction. Compared to Rosetta (fixbb) and SCWRL4, RDE outperforms these baselines on all four torsional angles in terms of angular errors, as shown in Table 4."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model that predicts sidechain structures by randomly sampling from its estimated distribution. To predict sidechain torsional angles for structures with missing sidechains in our PDB-REDO test split, we use RDE to generate a range of possible sidechain conformations and select the one with the highest probability as our final prediction. Notably, RDE outperforms the Rosetta (fixbb) and SCWRL4 baselines in terms of angular errors for all four torsional angles, as demonstrated in Table 4."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model that predicts sidechain structures by randomly sampling from its estimated probability distribution. To predict sidechain torsional angles for structures with missing sidechains in our PDB-REDO test split, we employ RDE to generate a range of possible sidechain conformations and select the conformation with the highest probability as our final prediction. Notably, RDE outperforms the Rosetta (fixbb) and SCWRL4 baselines in terms of angular errors for all four torsional angles, as illustrated in Table 4."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model that predicts sidechain conformations by sampling from an estimated distribution. In our study, we employ the RDE to sample sidechain torsional angles (rotamers) for structures with removed sidechains in our test split of PDB-REDO. Specifically, for each amino acid, we independently sample 10 rotamers and select the one with the highest probability as the final prediction. We compare the performance of RDE with two baseline methods, Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009), and the results, presented in Table 4, demonstrate that RDE outperforms the baselines in terms of angular errors for all four torsional angles. For a more detailed analysis of per-amino-acid accuracy, please refer to Table 11 in the appendix."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model designed to predict sidechain conformations by sampling from an estimated distribution. In our study, we utilize the RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, we independently sample 10 rotamers and select the one with the highest probability as the final prediction. We compare the performance of RDE with two baseline methods, Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009). The results, presented in Table 4, demonstrate that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Additionally, detailed per-amino-acid accuracy is provided in Table 11 of the appendix."}, {"depth": 2, "intention": "Concision", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model used to predict sidechain conformations by sampling from an estimated distribution. We applied RDE to sample sidechain torsional angles for structures with sidechains removed in our PDB-REDO test split. For each amino acid, we sampled 10 rotamers and selected the one with the highest probability as the final prediction. Our results, presented in Table 4, show that RDE outperforms Rosetta (fixbb) and SCWRL4 on all four torsional angles in terms of angular errors."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "instruction": "Make this paragraph more fluid.", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model that predicts sidechain conformations by sampling from the estimated distribution. To evaluate its performance, we applied RDE to sample sidechain torsional angles (rotamers) for structures with sidechains removed in our test split of PDB-REDO. For each amino acid, we independently sampled 10 rotamers and selected the one with the highest probability as the final prediction. We compared RDE with two baseline methods, Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009), and the results, presented in Table 4, demonstrate that RDE outperforms the baselines on all four torsional angles in terms of angular errors. Further details on per-amino-acid accuracy are provided in Table 11 of the appendix.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.25", "instruction": "Make the beginning of the paragraph more concise. Make the end of the paragraph more fitting to the academic style.", "revised_paragraph": "Revised paragraph: The rotamer density estimator (RDE) is a generative model for predicting sidechain conformations by sampling from the estimated distribution. We employed RDE to sample sidechain torsional angles (rotamers) for structures with removed sidechains in our PDB-REDO test split. For each amino acid, 10 rotamers were sampled independently, and the one with the highest probability was selected as the final prediction. Our results, presented in Table 4, demonstrate that RDE outperforms baseline methods Rosetta (fixbb) (Leman et al., 2020) and SCWRL4 (Krivov et al., 2009) in terms of angular errors. A detailed analysis of per-amino-acid accuracy is provided in Table 11 of the appendix.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our approach, D RAGON, combines a cross-modal encoder (GreaseLM) with a pretraining objective that performs bidirectional self-supervision on text-KG pairs. This objective unifies masked language modeling and KG link prediction to enable joint reasoning between text and KG. We finetune the pretrained model for downstream tasks. While individual components are not novel, our contribution lies in integrating them effectively and demonstrating a significantly performant pretrained model.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our approach, D RAGON, combines a cross-modal encoder (GreaseLM) with a pretraining objective that performs bidirectional self-supervision on text-KG pairs. This objective unifies masked language modeling and KG link prediction to enable joint reasoning between text and KG. We finetune the pretrained model for downstream tasks. While individual components are not novel, our contribution lies in integrating them effectively and demonstrating a significantly performant pretrained model.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our approach, D RAGON, combines a cross-modal encoder (GreaseLM) with a pretraining objective that performs bidirectional self-supervision on text-KG pairs. This objective unifies masked language modeling and KG link prediction to enable joint reasoning between text and KG. We finetune the pretrained model for downstream tasks. While individual components are not novel, our contribution lies in integrating them effectively and demonstrating a significantly performant pretrained model.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our approach, D RAGON, combines a cross-modal encoder (GreaseLM) with a pretraining objective that performs bidirectional self-supervision on text-KG pairs. This objective unifies masked language modeling and KG link prediction to enable joint reasoning between text and KG. We finetune the pretrained model for downstream tasks. While individual components are not novel, our contribution lies in integrating them effectively and demonstrating a significantly performant pretrained model.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our approach, D RAGON, combines a cross-modal encoder (GreaseLM) with a pretraining objective that performs bidirectional self-supervision on text-KG pairs. This objective unifies masked language modeling and KG link prediction to enable joint reasoning between text and KG. We finetune the pretrained model for downstream tasks. While individual components are not novel, our contribution lies in integrating them effectively and demonstrating a significantly performant pretrained model.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our approach, D RAGON, combines a cross-modal encoder (GreaseLM) with a pretraining objective that performs bidirectional self-supervision on text-KG pairs. This objective unifies masked language modeling and KG link prediction to enable joint reasoning between text and KG. We finetune the pretrained model for downstream tasks. While individual components are not novel, our contribution lies in integrating them effectively and demonstrating a significantly performant pretrained model.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our approach, D RAGON, combines a cross-modal encoder (GreaseLM) with a pretraining objective that performs bidirectional self-supervision on text-KG pairs. This objective unifies masked language modeling and KG link prediction to enable joint reasoning between text and KG. We finetune the pretrained model for downstream tasks. While individual components are not novel, our contribution lies in integrating them effectively and demonstrating a significantly performant pretrained model.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Our approach, D RAGON, combines a cross-modal encoder (GreaseLM) with a pretraining objective that performs bidirectional self-supervision on text-KG pairs. This objective unifies masked language modeling and KG link prediction to enable joint reasoning between text and KG. We finetune the pretrained model for downstream tasks. While individual components are not novel, our contribution lies in integrating them effectively and demonstrating a significantly performant pretrained model.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "instruction": "Make this paragraph more concise.", "revised_paragraph": "Revised paragraph: Our approach, D RAGON, consists of a cross-modal encoder (GreaseLM) that fuses text and knowledge graph (KG) pairs bidirectionally, and a pretraining objective that combines masked language modeling (MLM) and KG link prediction (LinkPred) to enable joint reasoning. We describe how we fine-tune the pre-trained model for downstream tasks. While individual components are not novel, our contribution lies in effectively unifying them and demonstrating the resulting model's performance.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "yxeD_Ju-SM.p9Au1Sb-uj.00", "instruction": "Make the last sentence more concise.", "revised_paragraph": "Revised paragraph: \"KG, D RAGON consists of a cross-modal encoder (GreaseLM) that fuses the input text-KG pair bidirectionally (\u00a72.2), and a pretraining objective that performs bidirectional self-supervision on the text-KG input (\u00a72.3). Our pretraining objective unifies masked language modeling (MLM) and KG link prediction (LinkPred) to make text and KG mutually inform each other and learn joint reasoning over them. We then finetune the pretrained D RAGON model for downstream tasks (\u00a72.4). Our contribution lies in effectively integrating these components and demonstrating their performance in a single, unified model.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The NS-RNN model of DuSell & Chiang (2020) differs from the superposition stack by maintaining a probability distribution over whole stacks, using a weighted PDA. With cubic time and quadratic space complexity, it exhibits higher run times than other stack RNNs, but often achieves better task performance.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The NS-RNN model of DuSell & Chiang (2020) differs from the superposition stack by maintaining a probability distribution over whole stacks, using a weighted PDA. With cubic time and quadratic space complexity, it exhibits higher run times than other stack RNNs, but often achieves better task performance.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The NS-RNN model of DuSell & Chiang (2020) differs from the superposition stack by maintaining a probability distribution over whole stacks, using a weighted PDA. With cubic time and quadratic space complexity, it exhibits higher run times than other stack RNNs, but often achieves better task performance.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"The NS-RNN model of DuSell & Chiang (2020) differs from the superposition stack by maintaining a probability distribution over whole stacks, using a weighted PDA. With cubic time and quadratic space complexity, it exhibits higher run times than other stack RNNs, but often achieves better task performance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The NS-RNN model of DuSell & Chiang (2020) differs from the superposition stack by maintaining a probability distribution over whole stacks, using a weighted PDA. With cubic time and quadratic space complexity, it exhibits higher run times than other stack RNNs, but often achieves better task performance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The NS-RNN model of DuSell & Chiang (2020) differs from the superposition stack by maintaining a probability distribution over whole stacks, using a weighted PDA. With cubic time and quadratic space complexity, it exhibits higher run times than other stack RNNs, but often achieves better task performance.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The NS-RNN model of DuSell & Chiang (2020) differs from the superposition stack by maintaining a probability distribution over whole stacks, using a weighted PDA. With cubic time and quadratic space complexity, it exhibits higher run times than other stack RNNs, but often achieves better task performance.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"The NS-RNN model of DuSell & Chiang (2020) differs from the superposition stack by maintaining a probability distribution over whole stacks, using a weighted PDA. With cubic time and quadratic space complexity, it exhibits higher run times than other stack RNNs, but often achieves better task performance.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "instruction": "Make this paragraph shorter", "revised_paragraph": "Revised paragraph: \"The NS-RNN model of DuSell & Chiang (2020) differs from the superposition stack in that it maintains a probability distribution over whole stacks using a weighted PDA. Although it has higher time and space complexity, resulting in longer run times, it often achieves better task performance.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OzYyHKPyj7.O9Mk1uqXra.02", "instruction": "Remove the unnessential details from the paragraph.", "revised_paragraph": "Revised paragraph: \"The Nondeterministic Stack RNN (NS-RNN) model of DuSell & Chiang (2020) maintains a probability distribution over whole stacks, using a weighted PDA. It has cubic time complexity and quadratic space complexity, leading to higher wall-clock run time but often better task performance.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provided both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher adjusted R\u00b2 and lower AIC was considered superior. We considered differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provide both the adjusted R-squared values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher R-squared value and lower AIC value is considered better. Notably, differences in AIC values exceeding 2 are worth considering, while differences exceeding 10 are deemed significant. In Experiment 1, we controlled the starting position of trials. We excluded Eqs. 5 and 6 from the comparison as the values of B in these models could not be accurately obtained.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provided both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher adjusted R\u00b2 and lower AIC was considered superior. We considered differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provided both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher adjusted R\u00b2 and lower AIC was considered superior. We considered differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provided both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher adjusted R\u00b2 and lower AIC was considered superior. We considered differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provide both the adjusted R-squared values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher R-squared value and lower AIC value is considered better. Notably, differences in AIC values exceeding 2 are worth considering, while differences exceeding 10 are deemed significant. In Experiment 1, we controlled the starting position of trials. We excluded Eqs. 5 and 6 from the comparison as the values of B in these models could not be accurately obtained.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provided both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher adjusted R\u00b2 and lower AIC was considered superior. We considered differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provide both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model (2). A model with a higher adjusted R\u00b2 and lower AIC is considered superior. We consider differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated, thereby ensuring the integrity of our analysis."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provided both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher adjusted R\u00b2 and lower AIC was considered superior. We considered differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provided both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher adjusted R\u00b2 and lower AIC was considered superior. We considered differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provided both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A model with a higher adjusted R\u00b2 and lower AIC was considered superior. We considered differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To facilitate comparison, we provide both adjusted R\u00b2 values and Akaike information criterion (AIC) values, which account for the varying number of constants included in each model (2). A model with a higher adjusted R\u00b2 and lower AIC is considered superior. We consider differences in AIC values greater than 2 to be worth noting, and those exceeding 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials. Notably, we excluded Eqs. 5 and 6 from the comparison, as the values of B in these models could not be accurately estimated, thereby ensuring the integrity of our analysis."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "instruction": "Restructured some sentences in this paragraph and merge the last two sentences ", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points, with both adjusted R\u00b2 values and Akaike information criterion (AIC) values provided to account for the varying number of constants included in each model [2]. A model with a higher R\u00b2 and lower AIC was considered better. Notably, differences in AIC greater than 2 were deemed worth considering, and those exceeding 10 were considered significant.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "instruction": "Improve the liking between phrases.", "revised_paragraph": "Revised paragraph: Table 1 presents the results of model fitting using all 120 data points. To evaluate the models, we compared the adjusted R\u00b2 values alongside Akaike information criterion (AIC) values, which account for the varying number of constants included in each model [2]. A better model was defined as one with a higher R\u00b2 and lower AIC. We considered differences in AIC values greater than 2 to be noteworthy and those greater than 10 to be statistically significant. In Experiment 1, we controlled the starting position of trials, excluding Eqs. 5 and 6 from comparison due to the inability to accurately obtain the B values in these models.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"By applying the implicit function theorem to Equation 8, we derive the Jacobians \u2202Y\u2217(z,\u03b8)/\u2202z and \u2202Y\u2217(z,\u03b8)/\u2202\u03b8, which are sufficient for integrating iDSPN into an autodiff framework. The detailed derivation is presented in Appendix B.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"By applying the implicit function theorem to Equation 8, we derive the Jacobians \u2202Y\u2217(z,\u03b8)/\u2202z and \u2202Y\u2217(z,\u03b8)/\u2202\u03b8, which are sufficient for integrating iDSPN into an autodiff framework. The detailed derivation is presented in Appendix B.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"By applying the implicit function theorem to Equation 8, we derive the Jacobians \u2202Y\u2217(z,\u03b8)/\u2202z and \u2202Y\u2217(z,\u03b8)/\u2202\u03b8, which are sufficient for integrating iDSPN into an autodiff framework. The detailed derivation is presented in Appendix B.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"By applying the implicit function theorem to Equation 8, we derive the Jacobians \u2202Y\u2217(z,\u03b8)/\u2202z and \u2202Y\u2217(z,\u03b8)/\u2202\u03b8, which are sufficient for integrating iDSPN into an autodiff framework. The detailed derivation is presented in Appendix B.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"By applying the implicit function theorem to Equation 8, we derive the Jacobians \u2202Y\u2217(z,\u03b8)/\u2202z and \u2202Y\u2217(z,\u03b8)/\u2202\u03b8, which are sufficient for integrating iDSPN into an autodiff framework. The detailed derivation is presented in Appendix B.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"By applying the implicit function theorem to Equation 8, we derive the Jacobians \u2202Y\u2217(z,\u03b8)/\u2202z and \u2202Y\u2217(z,\u03b8)/\u2202\u03b8, which are sufficient for integrating iDSPN into an autodiff framework. The detailed derivation is presented in Appendix B.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"By applying the implicit function theorem to Equation 8, we derive the Jacobians \u2202Y\u2217(z,\u03b8)/\u2202z and \u2202Y\u2217(z,\u03b8)/\u2202\u03b8, which are sufficient for integrating iDSPN into an autodiff framework. The detailed derivation is presented in Appendix B.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"By applying the implicit function theorem to Equation 8, we derive the Jacobians \u2202Y\u2217(z,\u03b8)/\u2202z and \u2202Y\u2217(z,\u03b8)/\u2202\u03b8, which are sufficient for integrating iDSPN into an autodiff framework. The detailed derivation is presented in Appendix B.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "instruction": "Simplify the first sentence.", "revised_paragraph": "Revised paragraph: By applying the implicit function theorem to Equation 8, we obtain the Jacobians \u2202 Y \u2217 ( z, \u03b8 ) /\u2202 z and \u2202 Y \u2217 ( z, \u03b8 ) /\u2202 \u03b8, which are necessary for iDSPN to fit into an autodiff framework.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "CVRUl83zah.I75TtW0V7.09", "instruction": "Improve the readability of those sentences.", "revised_paragraph": "Revised paragraph: By applying the implicit function theorem to Equation 8, we derive the Jacobians of Y\u2217(z,\u03b8) with respect to z and \u03b8, which are essential for integrating iDSPN into an automatic differentiation framework. The detailed calculation is presented in Appendix B.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We investigate the suitability of state space topological properties as completeness thresholds for cost-optimal planning with 0-cost actions, identifying the sublist diameter and a new property, the subset diameter, as effective thresholds. We demonstrate that no tighter threshold can be computed without exploiting cost information, the initial state, or the goal. A SAT compilation is devised for cost-optimal planning, and an any-time planning algorithm is developed, which iteratively improves an upper bound on the total cost. Experimental results show that the algorithm computes plans with costs better than the initial costs and, in many cases, matches the optimal cost, also proving optimality for several instances."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We investigate the suitability of state space topological properties as completeness thresholds for cost-optimal planning with 0-cost actions, identifying the sublist diameter and a new property, the subset diameter, as effective thresholds. We demonstrate that no tighter threshold can be computed without exploiting cost information, the initial state, or the goal. A SAT compilation is devised for cost-optimal planning, and an any-time planning algorithm is developed, which iteratively improves an upper bound on the total cost. Experimental results show that the algorithm computes plans with costs better than the initial costs and, in many cases, matches the optimal cost, also proving optimality for several instances."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We investigate the suitability of state space topological properties as completeness thresholds for cost-optimal planning with 0-cost actions, identifying the sublist diameter and a new property, the subset diameter, as effective thresholds. We demonstrate that no tighter threshold can be computed without exploiting cost information, the initial state, or the goal. A SAT compilation is devised for cost-optimal planning, and an any-time planning algorithm is developed, which iteratively improves an upper bound on the total cost. Experimental results show that the algorithm computes plans with costs better than the initial costs and, in many cases, matches the optimal cost, also proving optimality for several instances."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We investigate the suitability of state space topological properties as completeness thresholds for cost-optimal planning with 0-cost actions, identifying the sublist diameter and a new property, the subset diameter, as effective thresholds. We demonstrate that no tighter threshold can be computed without exploiting cost information, the initial state, or the goal. A SAT compilation is devised for cost-optimal planning, and an any-time planning algorithm is developed, which iteratively improves an upper bound on the total cost. Experimental results show that the algorithm computes plans with costs better than the initial costs and, in many cases, matches the optimal cost, also proving optimality for several instances."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We investigate the suitability of state space topological properties as completeness thresholds for cost-optimal planning with 0-cost actions, identifying the sublist diameter and a new property, the subset diameter, as effective thresholds. We demonstrate that no tighter threshold can be computed without exploiting cost information, the initial state, or the goal. A SAT compilation is devised for cost-optimal planning, and an any-time planning algorithm is developed, which iteratively improves an upper bound on the total cost. Experimental results show that the algorithm computes plans with costs better than the initial costs and, in many cases, matches the optimal cost, also proving optimality for several instances."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We investigate the suitability of state space topological properties as completeness thresholds for cost-optimal planning with 0-cost actions, identifying the sublist diameter and a new property, the subset diameter, as effective thresholds. We demonstrate that no tighter threshold can be computed without exploiting cost information, the initial state, or the goal. A SAT compilation is devised for cost-optimal planning, and an any-time planning algorithm is developed, which iteratively improves an upper bound on the total cost. Experimental results show that the algorithm computes plans with costs better than the initial costs and, in many cases, matches the optimal cost, also proving optimality for several instances."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We investigate the suitability of state space topological properties as completeness thresholds for cost-optimal planning with 0-cost actions, identifying the sublist diameter and a new property, the subset diameter, as effective thresholds. We demonstrate that no tighter threshold can be computed without exploiting cost information, the initial state, or the goal. A SAT compilation is devised for cost-optimal planning, and an any-time planning algorithm is developed, which iteratively improves an upper bound on the total cost. Experimental results show that the algorithm computes plans with costs better than the initial costs and, in many cases, matches the optimal cost, also proving optimality for several instances."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We investigate the suitability of state space topological properties as completeness thresholds for cost-optimal planning with 0-cost actions, identifying the sublist diameter and a new property, the subset diameter, as effective thresholds. We demonstrate that no tighter threshold can be computed without exploiting cost information, the initial state, or the goal. A SAT compilation is devised for cost-optimal planning, and an any-time planning algorithm is developed, which iteratively improves an upper bound on the total cost. Experimental results show that the algorithm computes plans with costs better than the initial costs and, in many cases, matches the optimal cost, also proving optimality for several instances."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "instruction": "Make the beginning of this paragraph shorter.", "revised_paragraph": "Revised paragraph: We study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions of 0-cost. We identify the sublist diameter and a new property, the subset diameter, as completeness thresholds, showing that no tighter threshold can be computed without exploiting cost information, the initial state, or the goal. We devise a SAT compilation for cost optimal planning and use it in an any-time planning as satisfiability algorithm, where the horizon is fixed from the beginning to the completeness threshold. Experiments demonstrate that the algorithm computes plans with costs better than the initial costs, and in many cases, it can compute optimal-cost plans. Additionally, the algorithm proves the optimality of certain costs for several instances, some of which could not be proven optimal by the LM-cut planning heuristic.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "BkxG1CvhWf.wcpE7maMLZ4.01", "instruction": "Make the beginning of this paragraph shorter.", "revised_paragraph": "Revised paragraph: We study the suitability of different state space topological properties as completeness thresholds for cost optimal planning with actions of 0-cost. We identify the sublist diameter and a new topological property, the subset diameter, as completeness thresholds. The sublist diameter has the advantage of being practically bounded, while the subset diameter is shown to be the tightest completeness threshold computable without exploiting cost information, the initial state, or the goal. To evaluate the practical utility of these thresholds, we devise a SAT compilation for cost optimal planning and integrate it into an any-time planning as satisfiability algorithm.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Although the dog images in Figure 2 appear distinct at the pixel level, they convey similar semantic meanings. Notably, these images have a small augmented distance, which allows us to partially characterize the semantic distance using the proposed metric. Building on this idea, we introduce the (\u03c3, \u03b4) -augmentation to quantify the concentration of augmented data based on the augmented distance."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 2 depicts dog images that, despite their pixel-level differences, convey similar semantic meanings. Notably, they exhibit a small augmented distance. This suggests that the proposed augmented distance can partially capture the semantic distance. Building on this notion, we introduce the (\u03c3, \u03b4)-augmentation metric to quantify the concentration of augmented data.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Although the dog images in Figure 2 appear distinct at the pixel level, they convey similar semantic meanings. Notably, these images have a small augmented distance, which allows us to partially characterize the semantic distance using the proposed metric. Building on this idea, we introduce the (\u03c3, \u03b4) -augmentation to quantify the concentration of augmented data based on the augmented distance."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 2 depicts dog images that, despite their pixel-level differences, convey similar semantic meanings. Notably, they exhibit a small augmented distance. This suggests that the proposed augmented distance can partially capture the semantic distance. Building on this notion, we introduce the (\u03c3, \u03b4)-augmentation metric to quantify the concentration of augmented data.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Although the dog images in Figure 2 appear distinct at the pixel level, they convey similar semantic meanings. Notably, these images have a small augmented distance, which allows us to partially characterize the semantic distance using the proposed metric. Building on this idea, we introduce the (\u03c3, \u03b4) -augmentation to quantify the concentration of augmented data based on the augmented distance."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Although the dog images in Figure 2 appear distinct at the pixel level, they share similar semantic meanings. Notably, these images have a small augmented distance, which enables us to partially characterize the semantic distance using the proposed metric. Building on this idea, we introduce the (\u03c3, \u03b4) -augmentation, a novel approach to quantify the concentration of augmented data based on the augmented distance."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Although the dog images in Figure 2 appear distinct at the pixel level, they convey similar semantic meanings. Notably, these images have a small augmented distance, which allows us to partially characterize the semantic distance using the proposed metric. Building on this idea, we introduce the (\u03c3, \u03b4) -augmentation to quantify the concentration of augmented data based on the augmented distance."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Figure 2 depicts dog images that, despite their pixel-level differences, convey similar semantic meanings. Notably, they exhibit a small augmented distance. This suggests that the proposed augmented distance can partially capture the semantic distance. Building on this notion, we introduce the (\u03c3, \u03b4)-augmentation metric to quantify the concentration of augmented data.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "instruction": "Use formal words.", "revised_paragraph": "Revised paragraph: The canine images depicted in Figure 2 exhibit disparate pixel-level characteristics, yet they convey analogous semantic meanings. Furthermore, they exhibit a relatively small augmented distance. Consequently, the proposed augmented distance can be employed to partially quantify the semantic distance. Building upon this notion, we introduce the (\u03c3, \u03b4) -augmentation paradigm to assess the concentration of augmented data.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.03", "instruction": "Improve this paragraph (mostly the first sentence) to make it less confusing.", "revised_paragraph": "Revised paragraph: \"The dog images in Figure 2, although visually distinct at the pixel level, convey similar semantic meanings. This similarity is reflected in their small augmented distance, which can be used to partially characterize the semantic distance. Building on this idea, we introduce the (\u03c3, \u03b4)-augmentation, a metric that measures the concentration of augmented data based on the proposed augmented distance.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has inspired our research, particularly in specifying high-level behavior and generating rewards. While TL-guided policy learning has made progress, the exploration problem remains. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be tedious, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we use signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Temporal logic (TL)-guided policy learning has been an area of inspiration for us. In this field, TL is often used to specify the ego agent's desired high-level behavior and generate rewards. Recent surveys by the authors of [17, 18, 19] provide an overview of the use of TL in reinforcement learning (RL). However, the exploration problem still persists in these methods. To address this, the authors of [20, 21] learn finite state automata from demonstrations and use them to guide planning with the value iteration network, thereby avoiding exploration. Designing a TL formula that yields satisfying behaviors can be tedious and time-consuming. To alleviate this issue, researchers have worked on making components of the formula learnable from data. For instance, [22] learns linear temporal logic (LTL) formulas from demonstrations, while [24] proposes a method that learns reward machines from demonstrations. A common limitation of these methods is that they operate on propositions (binary variables with values true or false), which requires either high-level demonstrations (proposition traces) or a mapping from low-level states to propositions. This limitation restricts these methods to operate on discrete and finite state and action spaces. In contrast, our proposed LogicRiskNet operates on continuous signals, enabling us to learn from continuous demonstration trajectories, which are more readily available in robotic systems."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nWe have drawn inspiration from the field of temporal logic (TL)-guided policy learning. In this area, TL is often employed to specify the ego agent's desired high-level behavior and generate rewards. Recent surveys by the authors of [17, 18, 19] provide a comprehensive overview of the use of TL in reinforcement learning (RL). However, the exploration problem persists in these methods. To address this issue, the authors of [20, 21] learn finite state automata from demonstrations and utilize them to guide planning with the value iteration network, thereby avoiding exploration. While designing a TL formula that yields satisfying behaviors can be a tedious task, researchers have made progress in enabling components of the formula to learn from data. For instance, [22] learns linear temporal logic (LTL) formulas from demonstrations, while [24] proposes a method that learns reward machines from demonstrations, leveraging the close relationship between TL and automata. A commonality among these methods is that they operate on LTL formulas that rely on propositions (binary variables with true or false values). Consequently, either high-level demonstrations (proposition traces) or a mapping from low-level states to propositions is required, which limits their applicability to discrete and finite state and action spaces. In contrast, our method utilizes stochastic temporal logic (STL), which operates on continuous signals, enabling us to learn from continuous demonstration trajectories that are more readily available in robotic systems. The LogicRiskNet that we propose is also learnable from demonstrations, offering a more practical solution for real-world applications."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has inspired our research, particularly in specifying high-level behavior and generating rewards. While TL-guided policy learning has made progress, the exploration problem remains. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be tedious, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we use signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has inspired our research, particularly in specifying high-level behavior and generating rewards. While TL-guided policy learning has made progress, the exploration problem remains. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be tedious, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we use signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations."}, {"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Temporal logic (TL)-guided policy learning has been an area of inspiration for us. In this field, TL is often used to specify the ego agent's desired high-level behavior and generate rewards. Recent surveys by the authors of [17, 18, 19] provide an overview of the use of TL in reinforcement learning (RL). However, the exploration problem still persists in these methods. To address this, the authors of [20, 21] learn finite state automata from demonstrations and use them to guide planning with the value iteration network, thereby avoiding exploration. Designing a TL formula that yields satisfying behaviors can be tedious and time-consuming. To alleviate this issue, researchers have worked on making components of the formula learnable from data. For instance, [22] learns linear temporal logic (LTL) formulas from demonstrations, while [24] proposes a method that learns reward machines from demonstrations. A common limitation of these methods is that they operate on propositions (binary variables with values true or false), which requires either high-level demonstrations (proposition traces) or a mapping from low-level states to propositions. This limitation restricts these methods to operate on discrete and finite state and action spaces. In contrast, our proposed LogicRiskNet operates on continuous signals, enabling us to learn from continuous demonstration trajectories, which are more readily available in robotic systems."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has inspired our research, particularly in specifying high-level behavior and generating rewards. While TL-guided policy learning has made progress, the exploration problem remains. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be tedious, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we use signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph:\n\nWe have drawn inspiration from the field of temporal logic (TL)-guided policy learning. In this area, TL is often employed to specify the ego agent's desired high-level behavior and generate rewards. Recent surveys by the authors of [17, 18, 19] provide a comprehensive overview of the use of TL in reinforcement learning (RL). However, the exploration problem persists in these methods. To address this issue, the authors of [20, 21] learn finite state automata from demonstrations and utilize them to guide planning with the value iteration network, thereby avoiding exploration. While designing a TL formula that yields satisfying behaviors can be a tedious task, researchers have made progress in enabling components of the formula to learn from data. For instance, [22] learns linear temporal logic (LTL) formulas from demonstrations, while [24] proposes a method that learns reward machines from demonstrations, leveraging the close relationship between TL and automata. A commonality among these methods is that they operate on LTL formulas that rely on propositions (binary variables with true or false values). Consequently, either high-level demonstrations (proposition traces) or a mapping from low-level states to propositions is required, which limits their applicability to discrete and finite state and action spaces. In contrast, our method utilizes stochastic temporal logic (STL), which operates on continuous signals, enabling us to learn from continuous demonstration trajectories that are more readily available in robotic systems. The LogicRiskNet that we propose is also learnable from demonstrations, offering a more practical solution for real-world applications."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has inspired our research, particularly in specifying high-level behavior and generating rewards. While TL-guided policy learning has made progress, the exploration problem remains. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be tedious, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we use signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our research has been inspired by temporal logic (TL), which has been particularly effective in specifying high-level behavior and generating rewards. While TL-guided policy learning has made significant progress, the exploration problem remains a major challenge. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be time-consuming, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we employ signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations, offering a novel solution to this problem."}, {"depth": 3, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Our research has been motivated by temporal logic (TL), which has proven effective in specifying high-level behavior and generating rewards. Despite significant progress in TL-guided policy learning, the exploration problem remains a major challenge. To address this, some methods learn finite state automata from demonstrations and utilize them to guide planning. However, designing TL formulas can be time-consuming, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we employ signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations, offering a novel solution to this problem."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has inspired our research, particularly in specifying high-level behavior and generating rewards. While TL-guided policy learning has made progress, the exploration problem remains. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be tedious, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we use signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has inspired our research, particularly in specifying high-level behavior and generating rewards. While TL-guided policy learning has made progress, the exploration problem remains. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be tedious, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we use signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations."}, {"depth": 2, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Our research has been inspired by temporal logic (TL), which has been particularly effective in specifying high-level behavior and generating rewards. While TL-guided policy learning has made significant progress, the exploration problem remains a major challenge. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be time-consuming, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we employ signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations, offering a novel solution to this problem."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has inspired our research, particularly in specifying high-level behavior and generating rewards. While TL-guided policy learning has made progress, the exploration problem remains. To address this, some methods learn finite state automata from demonstrations and use them to guide planning. However, designing TL formulas can be tedious, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we use signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Our proposed LogicRiskNet is also learnable from demonstrations."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has been a significant inspiration for our research, particularly in defining high-level behavior and generating rewards. Although TL-guided policy learning has made significant progress, the exploration problem remains a pressing challenge. To address this, some methods learn finite state automata from demonstrations and employ them to guide planning. However, designing TL formulas can be a time-consuming and laborious process, and learning components from data is a promising direction. Our approach differs from existing methods, which operate on discrete and finite state spaces using linear temporal logic (LTL) formulas. In contrast, we utilize signal temporal logic (STL), which enables learning from continuous demonstration trajectories, a common scenario in robotic systems. Notably, our proposed LogicRiskNet is also learnable from demonstrations, offering a more flexible and adaptive solution."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "instruction": "Make this paragraph easier to read, remove unnecessary details if needed", "revised_paragraph": "Revised paragraph: \n\nTemporal logic (TL) has inspired our work, particularly in policy learning. TL is often used to specify the ego agent's desired high-level behavior and generate rewards. Recent surveys by [17, 18, 19] highlight the use of TL in reinforcement learning. However, the exploration problem persists in these methods. Authors [20, 21] have proposed learning finite state automata from demonstrations and using them to guide planning with the value iteration network, thereby avoiding exploration. To address the tedious process of manually designing TL formulas, researchers have developed methods to learn components of the formula from data. For instance, [22] learns linear temporal logic (LTL) formulas from demonstrations, while [24] proposes a method that learns reward machines from demonstrations. Our proposed LogicRiskNet method differs from these approaches as it operates on continuous signals using signal temporal logic (STL), enabling learning from continuous demonstration trajectories, which are more readily available in robotic systems.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "fJhx73ErBg.NeKLbmOxG8.03", "instruction": "Summarize the last third of this paragraph in one sentence. Smooth out the writing.", "revised_paragraph": "Revised paragraph: Temporal logic (TL) has been used to guide policy learning, often specifying the ego agent's desired high-level behavior and generating rewards, but existing methods still face the exploration problem, and designing a TL formula can be tedious, whereas recent work has focused on learning TL formulas or automata from demonstrations, which are limited to discrete and finite state and action spaces, but our proposed LogicRiskNet method can learn from continuous demonstration trajectories, operating on continuous signals.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Representation-based methods, such as BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), aim to balance the distributions in the latent space. Building upon CFR, Liuyi et al. and Hassanpour & Greiner (2020) introduced additional factors, including local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) proposed alternative approaches, using adversarial training to balance the distributions of representations. The primary approach to mitigating treatment selection bias has been representation learning, which offers advantages in avoiding high variance issues and scalability in large-scale scenarios."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), achieve balance in the latent space by manipulating distributions. Liuyi et al. and Hassanpour & Greiner (2020) have further enhanced CFR by incorporating local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) have proposed using adversarial training to balance representation distributions. Notably, representation learning has emerged as the primary approach to mitigate treatment selection bias, owing to its ability to avoid high variance issues and its suitability for large-scale scenarios.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Representation-based methods, such as BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), aim to balance the distributions in the latent space. Building upon CFR, Liuyi et al. and Hassanpour & Greiner (2020) introduced additional factors, including local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) proposed alternative approaches, using adversarial training to balance the distributions of representations. The primary approach to mitigating treatment selection bias has been representation learning, which offers advantages in avoiding high variance issues and scalability in large-scale scenarios."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), achieve balance in the latent space by manipulating distributions. Liuyi et al. and Hassanpour & Greiner (2020) have further enhanced CFR by incorporating local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) have proposed using adversarial training to balance representation distributions. Notably, representation learning has emerged as the primary approach to mitigate treatment selection bias, owing to its ability to avoid high variance issues and its suitability for large-scale scenarios.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Representation-based methods, such as BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), aim to balance the distributions in the latent space. Building upon CFR, Liuyi et al. and Hassanpour & Greiner (2020) introduced additional factors, including local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) proposed alternative approaches, using adversarial training to balance the distributions of representations. The primary approach to mitigating treatment selection bias has been representation learning, which offers advantages in avoiding high variance issues and scalability in large-scale scenarios."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: Representation-based methods, such as Bayesian neural networks (Johansson et al., 2016) and contrastive fairness regularizers (Uri et al., 2017), aim to balance the distributions in the latent space. Building on the contrastive fairness regularizer, Liuyi et al. and Hassanpour & Greiner (2020) introduced additional factors, including local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) proposed alternative approaches, utilizing adversarial training to balance the distributions of representations. The primary approach to mitigating treatment selection bias has been representation learning, which offers advantages in avoiding high-variance issues and scalability in large-scale scenarios."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"depth": 1, "intention": "Rewritting_medium", "revised_paragraph": "Revised paragraph: Representation-based methods, such as BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), aim to balance the distributions in the latent space. Building upon CFR, Liuyi et al. and Hassanpour & Greiner (2020) introduced additional factors, including local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) proposed alternative approaches, using adversarial training to balance the distributions of representations. The primary approach to mitigating treatment selection bias has been representation learning, which offers advantages in avoiding high variance issues and scalability in large-scale scenarios."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "revisions": [{"depth": 1, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), achieve balance in the latent space by manipulating distributions. Liuyi et al. and Hassanpour & Greiner (2020) have further enhanced CFR by incorporating local similarity and non-confounding factors, respectively. Kallus (2020) and Yoon et al. (2018) have proposed using adversarial training to balance representation distributions. Notably, representation learning has emerged as the primary approach to mitigate treatment selection bias, owing to its ability to avoid high variance issues and its suitability for large-scale scenarios.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "instruction": "Make the benefit clearer.", "revised_paragraph": "Revised paragraph: \"Representation-based methods, such as BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), have been widely adopted to mitigate treatment selection bias by balancing the distributions in the latent space. Building upon these approaches, Liuyi et al. and Hassanpour & Greiner (2020) have further enhanced CFR by incorporating local similarity and non-confounding factors, respectively. Additionally, Kallus (2020) and Yoon et al. (2018) have proposed adversarial training to balance the distributions of representations. The primary advantage of representation learning lies in its ability to avoid the high variance issue and its scalability to large-scale scenarios, making it a popular approach to address treatment selection bias.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.19", "instruction": "Reorder the elements in sentences to improve the readability.", "revised_paragraph": "Revised paragraph: Representation learning has been the primary approach to mitigate the treatment selection bias, owing to its avoidance of the high variance issue and suitability for large-scale scenarios. This approach is achieved through various representation-based methods, such as BNN (Johansson et al., 2016) and CFR (Uri et al., 2017), which balance the distributions in the latent space. To further augment these methods, Liuyi et al. and Hassanpour & Greiner (2020) incorporate local similarity and non-confounding factors, respectively. Additionally, Kallus (2020) and Yoon et al. (2018) propose adversarial training to balance the distributions of representations.", "type_approach": "instruction-annot_2"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Both DeiT and ViT employ an extra learnable class token for classification, which is not inherently translation-invariant. To address this, we propose replacing the class token with a global average pooling (GAP), resulting in CVPT-GAP. Combining this with translation-equivariant positional encodings, CVPT-GAP achieves superior image classification performance due to its utmost translation-invariance.\""}], "type_approach": "separate-labels-union"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Both DeiT and ViT employ an extra learnable class token for classification, which is not inherently translation-invariant. To address this, we propose replacing the class token with a global average pooling (GAP), resulting in CVPT-GAP. Combining this with translation-equivariant positional encodings, CVPT-GAP achieves superior image classification performance due to its utmost translation-invariance.\""}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Both DeiT and ViT employ an extra learnable class token for classification, which is not inherently translation-invariant. To address this, we propose replacing the class token with a global average pooling (GAP), resulting in CVPT-GAP. Combining this with translation-equivariant positional encodings, CVPT-GAP achieves superior image classification performance due to its utmost translation-invariance.\""}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: \"Both DeiT and ViT employ an extra learnable class token for classification, which is not inherently translation-invariant. To address this, we propose replacing the class token with a global average pooling (GAP), resulting in CVPT-GAP. Combining this with translation-equivariant positional encodings, CVPT-GAP achieves superior image classification performance due to its utmost translation-invariance.\""}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Both DeiT and ViT employ an extra learnable class token for classification, which is not inherently translation-invariant. To address this, we propose replacing the class token with a global average pooling (GAP), resulting in CVPT-GAP. Combining this with translation-equivariant positional encodings, CVPT-GAP achieves superior image classification performance due to its utmost translation-invariance.\""}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Both DeiT and ViT employ an extra learnable class token for classification, which is not inherently translation-invariant. To address this, we propose replacing the class token with a global average pooling (GAP), resulting in CVPT-GAP. Combining this with translation-equivariant positional encodings, CVPT-GAP achieves superior image classification performance due to its utmost translation-invariance.\""}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Both DeiT and ViT employ an extra learnable class token for classification, which is not inherently translation-invariant. To address this, we propose replacing the class token with a global average pooling (GAP), resulting in CVPT-GAP. Combining this with translation-equivariant positional encodings, CVPT-GAP achieves superior image classification performance due to its utmost translation-invariance.\""}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: \"Both DeiT and ViT employ an extra learnable class token for classification, which is not inherently translation-invariant. To address this, we propose replacing the class token with a global average pooling (GAP), resulting in CVPT-GAP. Combining this with translation-equivariant positional encodings, CVPT-GAP achieves superior image classification performance due to its utmost translation-invariance.\""}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "instruction": "Simplify the conclusions of this paragraph wo make it clearer and more concise.", "revised_paragraph": "Revised paragraph: \"DeiT and ViT both use an extra learnable class token for classification. While not inherently translation-invariant, this token can learn to be so. A simpler alternative is to replace it with a global average pooling (GAP) layer, which is inherently translation-invariant. By combining this with translation-equivariant positional encodings, our CVPT-GAP model achieves better image classification performance.\"", "type_approach": "instruction-annot_1"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "instruction": "Simplify the last sentence  by removing the notion of translation-equivariant  and just calling it conditional positional encodings.", "revised_paragraph": "Revised paragraph: \"In addition, both DeiT and ViT utilize an extra learnable class token to perform classi\ufb01cation (i.e., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with conditional positional encodings, CVPT-GAP is thus much better suited for image classification tasks.\"", "type_approach": "instruction-annot_2"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We study the setting where all instances come with instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. We extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals, and provide guarantees for page migration in both the auto-regressive setting and the general case, with details in Appendix C."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe investigate a setting where each instance is accompanied by instance-specific features, a natural and practical assumption [27, 30] that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, as well as other information like weather or day of the week. These features are fed into functions, including linear predictors, neural networks, or trees, whose parameters can be learned from data. We focus on linear predictors, which, due to their convex and affine composition, are amenable to similar analyses as above. For instance, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. In contrast, page migration is more challenging, as the outputs must lie in the simplex. We address this by restricting to rectangular stochastic matrices with columns in the simplex. The results are presented in Appendix C. Notably, our guarantees for page migration extend to the auto-regressive setting, where server probabilities are determined by a fixed linear transform of past states."}], "type_approach": "separate-labels-union"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We study the setting where all instances come with instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. We extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals, and provide guarantees for page migration in both the auto-regressive setting and the general case, with details in Appendix C."}], "type_approach": "separate-labels-intersection"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We study the setting where all instances come with instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. We extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals, and provide guarantees for page migration in both the auto-regressive setting and the general case, with details in Appendix C."}, {"intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: \n\nWe investigate a setting where each instance is accompanied by instance-specific features, a natural and practical assumption [27, 30] that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, as well as other information like weather or day of the week. These features are fed into functions, including linear predictors, neural networks, or trees, whose parameters can be learned from data. We focus on linear predictors, which, due to their convex and affine composition, are amenable to similar analyses as above. For instance, it is straightforward to extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals. In contrast, page migration is more challenging, as the outputs must lie in the simplex. We address this by restricting to rectangular stochastic matrices with columns in the simplex. The results are presented in Appendix C. Notably, our guarantees for page migration extend to the auto-regressive setting, where server probabilities are determined by a fixed linear transform of past states."}], "type_approach": "separate-labels-annot_1"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"intention": "Concision", "revised_paragraph": "Revised paragraph: We study the setting where all instances come with instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. We extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals, and provide guarantees for page migration in both the auto-regressive setting and the general case, with details in Appendix C."}], "type_approach": "separate-labels-annot_2"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We study the setting where all instances come with instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. We extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals, and provide guarantees for page migration in both the auto-regressive setting and the general case, with details in Appendix C."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We investigate a setting where instances are characterized by instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other relevant information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. Building upon these results, we extend the matching results to provide bounds on the regret and sample complexity of learning a linear predictor of duals, and offer guarantees for page migration in both the auto-regressive setting and the general case, with additional details provided in Appendix C."}], "type_approach": "iterative-labels-union"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We study the setting where all instances come with instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. We extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals, and provide guarantees for page migration in both the auto-regressive setting and the general case, with details in Appendix C."}], "type_approach": "iterative-labels-intersection"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We study the setting where all instances come with instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. We extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals, and provide guarantees for page migration in both the auto-regressive setting and the general case, with details in Appendix C."}, {"depth": 2, "intention": "Rewritting_light", "revised_paragraph": "Revised paragraph: We investigate a setting where instances are characterized by instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other relevant information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. Building upon these results, we extend the matching results to provide bounds on the regret and sample complexity of learning a linear predictor of duals, and offer guarantees for page migration in both the auto-regressive setting and the general case, with additional details provided in Appendix C."}], "type_approach": "iterative-labels-annot_1"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "revisions": [{"depth": 1, "intention": "Concision", "revised_paragraph": "Revised paragraph: We study the setting where all instances come with instance-specific features, a natural and practical assumption that encompasses numerical representations of the instance itself, such as bits representing a query or a graph, or other information like weather or day of the week. We focus on linear predictors, which can be analyzed similarly to previous results since the composition of a convex and affine function is convex. We extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals, and provide guarantees for page migration in both the auto-regressive setting and the general case, with details in Appendix C."}], "type_approach": "iterative-labels-annot_2"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "instruction": "Remove unecessary details, use abbrieviation. ", "revised_paragraph": "Revised paragraph: We focus on instances with instance-specific features, a natural and practical assumption that includes numerical representations of the instance itself or other information such as weather or day of the week. These features are passed to functions like linear predictors, neural nets, or trees, whose parameters can be learned from data. We analyze linear predictors, which are amenable to similar analyses since the composition of a convex and affine function is convex. Our results extend to bound the regret and sample complexity of learning a linear predictor of duals. For page migration, we restrict to rectangular stochastic matrices to ensure outputs lie in the simplex. Our guarantees cover the auto-regressive setting where server probabilities are determined by a fixed linear transform of past states.", "type_approach": "instruction-annot_1"}
{"id_paragraph": "CzTbgFKuy.hfDu8DsDq6.01", "instruction": "Make this paragraph a bit more concise.", "revised_paragraph": "Revised paragraph: We focus on a setting where instances are accompanied by instance-specific features, a natural and practical assumption [27, 30] that includes numerical representations of the instance itself or other information such as weather or day of the week. These features are passed to functions like linear predictors, neural nets, or trees, whose parameters can be learned from data. We study linear predictors, which are amenable to similar analyses as above. We extend the matching results to bound the regret and sample complexity of learning a linear predictor of duals and provide guarantees for page migration, including the auto-regressive setting where server probabilities are determined by a fixed linear transform of past states.", "type_approach": "instruction-annot_2"}
